{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a1003\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\a1003\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\a1003\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_path\n",
    "#save_path\n",
    "#new_folder\n",
    "filemane = []\n",
    "curr_path = os.getcwd() \n",
    "def resize_image(curr_path, data_path, new_folder, save_path, filemane):\n",
    "    curr_path = curr_path\n",
    "    os.chdir(curr_path + '\\\\food_recog')\n",
    "    newpath = new_folder \n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "        \n",
    "    os.chdir(data_path)    \n",
    "    for i in range(len(os.listdir())):\n",
    "        filemane.append(os.listdir()[i]) # os.listdir()[i] is the file we want\n",
    "        image = Image.open(os.listdir()[i])\n",
    "        resize_image = image.resize((190,200))\n",
    "        resize_image.save(save_path + os.listdir()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = curr_path + '\\\\food_recog\\\\orange'\n",
    "save_path = curr_path + '\\\\food_recog\\\\resize_orange\\\\'\n",
    "new_folder = curr_path + '\\\\food_recog\\\\resize_orange'\n",
    "resize_image(curr_path, data_path, new_folder, save_path, filemane)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### label_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize_path\n",
    "#target_name\n",
    "inputs = []\n",
    "targets = []\n",
    "def label_image(resize_path, target_name):\n",
    "    \n",
    "    os.chdir(resize_path)\n",
    "    for i in range(len(os.listdir())):    \n",
    "        image = Image.open(os.listdir()[i])\n",
    "        np_image = np.array(image)\n",
    "        inputs.append(np_image)\n",
    "        targets.append(target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_path = curr_path + '\\\\food_recog\\\\resize_chili'\n",
    "target_name = 'chili'\n",
    "label_image(resize_path, target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_path =  curr_path + '\\\\food_recog\\\\resize_tomato'\n",
    "target_name = 'tomato'\n",
    "label_image(resize_path, target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_path =  curr_path + '\\\\food_recog\\\\resize_mushroom'\n",
    "target_name = 'mushroom'\n",
    "label_image(resize_path, target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_path =  curr_path + '\\\\food_recog\\\\resize_banana'\n",
    "target_name = 'banana'\n",
    "label_image(resize_path, target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_path =  curr_path + '\\\\food_recog\\\\resize_cucumber'\n",
    "target_name = 'cucumber'\n",
    "label_image(resize_path, target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_path =  curr_path + '\\\\food_recog\\\\resize_ginger'\n",
    "target_name = 'ginger'\n",
    "label_image(resize_path, target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_path =  curr_path + '\\\\food_recog\\\\resize_green_onion'\n",
    "target_name = 'green_onion'\n",
    "label_image(resize_path, target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_path =  curr_path + '\\\\food_recog\\\\resize_garlic'\n",
    "target_name = 'garlic'\n",
    "label_image(resize_path, target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_path =  curr_path + '\\\\food_recog\\\\resize_shallots'\n",
    "target_name = 'shallots'\n",
    "label_image(resize_path, target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_path =  curr_path + '\\\\food_recog\\\\resize_apple'\n",
    "target_name = 'apple'\n",
    "label_image(resize_path, target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_path =  curr_path + '\\\\food_recog\\\\resize_orange'\n",
    "target_name = 'orange'\n",
    "label_image(resize_path, target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_data = np.array(inputs)\n",
    "targets_data = np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1057, 200, 190, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x202b1650160>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(inputs_data[1,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chili'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image processing class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class image_process(object):\n",
    "    \n",
    "\n",
    "    def __init__(self, inputs_data, targets_data):\n",
    "        self.whole_inputs = np.array(inputs_data)\n",
    "        self.whole_targets = np.array(targets_data)\n",
    "        self.red_inputs = np.array(inputs_data)[:,:,:,:1]\n",
    "        self.green_inputs = np.array(inputs_data)[:,:,:,1:2]\n",
    "        self.blue_inputs = np.array(inputs_data)[:,:,:,2:3]\n",
    "    \n",
    "    def red_pic(self):\n",
    "        \n",
    "        red = self.whole_inputs\n",
    "        red[:,:,:,1:2] = 0\n",
    "        red[:,:,:,2:3] = 0\n",
    "        \n",
    "        return red\n",
    "    \n",
    "    def green_pic(self):    \n",
    "        \n",
    "        green = self.whole_inputs\n",
    "        green[:,:,:,:1] = 0\n",
    "        green[:,:,:,2:3] = 0\n",
    "        \n",
    "        return green\n",
    "    \n",
    "    def blue_pic(self):\n",
    "        \n",
    "        blue = self.whole_inputs\n",
    "        blue[:,:,:,:1] = 0\n",
    "        blue[:,:,:,1:2] = 0\n",
    "        \n",
    "        return blue\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_data, targets_data = shuffle(inputs_data, targets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs_data[2,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20db5ca45b0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(inputs_data[2,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ginger'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensional reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "reshape_inputs_data = inputs_data.reshape((inputs_data.shape[0], inputs_data.shape[1]*inputs_data.shape[2]*inputs_data.shape[3]))\n",
    "\n",
    "pca = PCA(0.95)\n",
    "reduction_inputs = pca.fit_transform(reshape_inputs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs_data[1,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduction_inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion = 0.8\n",
    "number_training = int(0.8*(reduction_inputs.shape[0]))\n",
    "\n",
    "x_train, x_test, y_train, y_test = reduction_inputs[:number_training], reduction_inputs[number_training:], targets_data[:number_training], targets_data[number_training:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(773, 192)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To prevent vanishing/exploding gradients problems and neuron die: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Utilize different initialization stategy (Xavier initialization or Glorot initialization or LeCun initialization)\n",
    "#### 2. Try different activation function: ( SELU > ELU > LeakyReLU > ReLU > tanh > logistic)\n",
    "#### 3. Batch Normalization: zero-centers and normalizes each each layer's inputs\n",
    "#### 4. Gradient Clipping: Clip every component of the gradient vector to the value between -1 and 1 (prevent exploding gradients)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " SELU (with LeCun initialization strategy) (only work in sequential architecture): self-normalized and preserve the mean of the output and SD are 0.\n",
    " ELU: Prevent neuron die but slower than SELU.\n",
    " Leaky ReLU: prevent neuron die when the input is zero or negative, (hyperparameter: alpha)\n",
    " Randomized Leaky ReLU: similar to Leaky ReLU, but alpha is randomly assign.\n",
    " Parametric Leaky ReLU: similzr to Leaky ReLU, but alpha is updated by backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other techniques to improve learning model: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Pretrain the data (reusing pretrain layers, unsupervised pretraining and pretrain on an auxiliary task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speed up the training: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Good initialization strategy\n",
    "#### 2. Good activation function\n",
    "#### 3. Batch Normalization\n",
    "#### 4. Pretrain the model\n",
    "#### 5. Faster optimizer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Momentum Optimizer: Accelerate the gradient and take previous gradient into account\n",
    "2. Nesterov Accelerated Gradient: reduce the oscillations caused by large momentum. (just slightly ahead in the direction of the momentum)\n",
    "3. AdaGrad: Correct the direction of the graident to the global optimum but often stop early when training NN. So it is proper to simple quadratic problem but not suitable for complex issue.\n",
    "4. RMSProp: Similar to AdaGrad but it accumulate only the gradients from the most recent iterations (and with one more hyperparameter beta(decay rate, defualt by 0.9)\n",
    "5. Adam: combine momentum and RMSProp (speed up and toward the right direction)\n",
    "6. Nadam: Adam + Nesterove trick\n",
    "7. AdaMax: Adam use l2 to scales down the parameters and Adamax use l(unlimit) norm to get the max of time-decayed gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_tr = x_train\n",
    "inputs_te = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(y_train, columns = [\"targets\"])\n",
    "targets_tr = np.array(pd.get_dummies(train_df)).astype(\"float32\")\n",
    "\n",
    "test_df = pd.DataFrame(y_test, columns = [\"targets\"])\n",
    "targets_te = np.array(pd.get_dummies(test_df)).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_ann_selu_relu(inputs_size, outputs_size, n_layers, n_neurons, lr, kernel_init, active_function):\n",
    "    model_ann = tf.keras.Sequential()\n",
    "    \n",
    "    model_ann.add(tf.keras.layers.Flatten(input_shape = inputs_size)) ### inputs layers\n",
    "    for i in range(n_layers):\n",
    "        model_ann.add(tf.keras.layers.Dense(n_neurons, activation = active_function, kernel_initializer = kernel_init))\n",
    "    \n",
    "    model_ann.add(tf.keras.layers.Dense(outputs_size, activation = \"softmax\")) ### outputs layers\n",
    "    \n",
    "    \n",
    "    opt = tf.keras.optimizers.SGD(lr = lr)\n",
    "    model_ann.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics = [\"accuracy\"])\n",
    "    \n",
    "    return model_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_ann_leakyrelu(inputs_size, outputs_size, n_layers, n_neurons, lr, kernel_init):\n",
    "    model_ann = tf.keras.Sequential()\n",
    "    \n",
    "    model_ann.add(tf.keras.layers.Flatten(input_shape = inputs_size)) ### inputs layers\n",
    "    for i in range(n_layers):\n",
    "        model_ann.add(tf.keras.layers.Dense(n_neurons, kernel_initializer = kernel_init))\n",
    "        model_ann.add(tf.keras.layers.LeakyReLU())\n",
    "    \n",
    "    model_ann.add(tf.keras.layers.Dense(outputs_size, activation = \"softmax\")) ### outputs layers\n",
    "    \n",
    "    \n",
    "    opt = tf.keras.optimizers.SGD(lr = lr)\n",
    "    model_ann.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics = [\"accuracy\"])\n",
    "\n",
    "    return model_ann\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a1003\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_1 = model_ann_leakyrelu(inputs_size = [inputs_tr.shape[1]], outputs_size = targets_tr.shape[1], n_layers = 15, n_neurons = 100, lr = 0.0001, kernel_init = \"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 100)               19300     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_42 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_43 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 11)                1111      \n",
      "=================================================================\n",
      "Total params: 161,811\n",
      "Trainable params: 161,811\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "std_inputs_tr = inputs_tr / 255\n",
    "\n",
    "std = StandardScaler()\n",
    "std_inputs_te = inputs_te / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "25/25 [==============================] - 1s 14ms/step - loss: 10.1920 - accuracy: 0.1255 - val_loss: 5.9357 - val_accuracy: 0.1443\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 4.8101 - accuracy: 0.1630 - val_loss: 4.0670 - val_accuracy: 0.1546\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.5286 - accuracy: 0.2135 - val_loss: 3.3177 - val_accuracy: 0.2113\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 2.8999 - accuracy: 0.2717 - val_loss: 2.9623 - val_accuracy: 0.2268\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 2.5512 - accuracy: 0.3273 - val_loss: 2.6517 - val_accuracy: 0.2680\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.3106 - accuracy: 0.3661 - val_loss: 2.4913 - val_accuracy: 0.2732\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 2.1330 - accuracy: 0.4010 - val_loss: 2.3277 - val_accuracy: 0.3196\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.9788 - accuracy: 0.4230 - val_loss: 2.1702 - val_accuracy: 0.3402\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.8476 - accuracy: 0.4528 - val_loss: 2.0886 - val_accuracy: 0.3557\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.7423 - accuracy: 0.4838 - val_loss: 2.0069 - val_accuracy: 0.3969\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.6478 - accuracy: 0.4929 - val_loss: 1.9123 - val_accuracy: 0.4175\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.5649 - accuracy: 0.5201 - val_loss: 1.8335 - val_accuracy: 0.4433\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.4874 - accuracy: 0.5395 - val_loss: 1.7858 - val_accuracy: 0.4794\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.4221 - accuracy: 0.5511 - val_loss: 1.7035 - val_accuracy: 0.5000\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.3589 - accuracy: 0.5718 - val_loss: 1.6820 - val_accuracy: 0.5103\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.3077 - accuracy: 0.5938 - val_loss: 1.6505 - val_accuracy: 0.5052\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.2543 - accuracy: 0.6028 - val_loss: 1.5741 - val_accuracy: 0.5361\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.2071 - accuracy: 0.6119 - val_loss: 1.5189 - val_accuracy: 0.5670\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.1578 - accuracy: 0.6300 - val_loss: 1.4896 - val_accuracy: 0.5670\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.1159 - accuracy: 0.6442 - val_loss: 1.4476 - val_accuracy: 0.5876\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0740 - accuracy: 0.6559 - val_loss: 1.4247 - val_accuracy: 0.5876\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0405 - accuracy: 0.6662 - val_loss: 1.3794 - val_accuracy: 0.6082\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0022 - accuracy: 0.6818 - val_loss: 1.3609 - val_accuracy: 0.6082\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.9677 - accuracy: 0.6882 - val_loss: 1.3412 - val_accuracy: 0.6082\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.9397 - accuracy: 0.6960 - val_loss: 1.3024 - val_accuracy: 0.6340\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.9089 - accuracy: 0.7128 - val_loss: 1.2887 - val_accuracy: 0.6340\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.8786 - accuracy: 0.7219 - val_loss: 1.2703 - val_accuracy: 0.6392\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.8528 - accuracy: 0.7335 - val_loss: 1.2428 - val_accuracy: 0.6289\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.8269 - accuracy: 0.7322 - val_loss: 1.2082 - val_accuracy: 0.6598\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.8016 - accuracy: 0.7490 - val_loss: 1.1886 - val_accuracy: 0.6598\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7790 - accuracy: 0.7555 - val_loss: 1.1867 - val_accuracy: 0.6649\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7550 - accuracy: 0.7658 - val_loss: 1.1724 - val_accuracy: 0.6753\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7336 - accuracy: 0.7723 - val_loss: 1.1401 - val_accuracy: 0.6701\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7135 - accuracy: 0.7762 - val_loss: 1.1222 - val_accuracy: 0.6753\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6951 - accuracy: 0.7878 - val_loss: 1.1131 - val_accuracy: 0.6804\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6755 - accuracy: 0.7904 - val_loss: 1.1092 - val_accuracy: 0.6856\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6574 - accuracy: 0.8085 - val_loss: 1.0815 - val_accuracy: 0.6959\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6405 - accuracy: 0.8060 - val_loss: 1.0743 - val_accuracy: 0.6907\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6223 - accuracy: 0.8137 - val_loss: 1.0635 - val_accuracy: 0.6959\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6057 - accuracy: 0.8202 - val_loss: 1.0489 - val_accuracy: 0.6959\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5887 - accuracy: 0.8292 - val_loss: 1.0310 - val_accuracy: 0.7010\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.8396 - val_loss: 1.0160 - val_accuracy: 0.7062\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5637 - accuracy: 0.8409 - val_loss: 1.0084 - val_accuracy: 0.7113\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.8435 - val_loss: 1.0043 - val_accuracy: 0.7113\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.8551 - val_loss: 0.9963 - val_accuracy: 0.7165\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.8564 - val_loss: 0.9811 - val_accuracy: 0.7216\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.8564 - val_loss: 0.9838 - val_accuracy: 0.7062\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.8668 - val_loss: 0.9642 - val_accuracy: 0.7268\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.8668 - val_loss: 0.9614 - val_accuracy: 0.7268\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.8706 - val_loss: 0.9405 - val_accuracy: 0.7371\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.8719 - val_loss: 0.9420 - val_accuracy: 0.7320\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.8745 - val_loss: 0.9270 - val_accuracy: 0.7320\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.8745 - val_loss: 0.9144 - val_accuracy: 0.7423\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.8797 - val_loss: 0.9180 - val_accuracy: 0.7526\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.8887 - val_loss: 0.9062 - val_accuracy: 0.7423\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8887 - val_loss: 0.8921 - val_accuracy: 0.7577\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3974 - accuracy: 0.8965 - val_loss: 0.8936 - val_accuracy: 0.7474\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3880 - accuracy: 0.9004 - val_loss: 0.8760 - val_accuracy: 0.7526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3785 - accuracy: 0.9069 - val_loss: 0.8627 - val_accuracy: 0.7474\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3702 - accuracy: 0.9043 - val_loss: 0.8526 - val_accuracy: 0.7526\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3620 - accuracy: 0.9120 - val_loss: 0.8667 - val_accuracy: 0.7629\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3540 - accuracy: 0.9082 - val_loss: 0.8502 - val_accuracy: 0.7577\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3456 - accuracy: 0.9107 - val_loss: 0.8457 - val_accuracy: 0.7629\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3384 - accuracy: 0.9120 - val_loss: 0.8415 - val_accuracy: 0.7577\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3322 - accuracy: 0.9094 - val_loss: 0.8378 - val_accuracy: 0.7629\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3245 - accuracy: 0.9146 - val_loss: 0.8223 - val_accuracy: 0.7732\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3167 - accuracy: 0.9159 - val_loss: 0.8198 - val_accuracy: 0.7680\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3091 - accuracy: 0.9198 - val_loss: 0.8247 - val_accuracy: 0.7577\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3048 - accuracy: 0.9237 - val_loss: 0.8171 - val_accuracy: 0.7680\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2974 - accuracy: 0.9224 - val_loss: 0.8182 - val_accuracy: 0.7680\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2911 - accuracy: 0.9276 - val_loss: 0.7911 - val_accuracy: 0.7732\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2859 - accuracy: 0.9301 - val_loss: 0.7883 - val_accuracy: 0.7680\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2796 - accuracy: 0.9301 - val_loss: 0.7905 - val_accuracy: 0.7732\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2744 - accuracy: 0.9340 - val_loss: 0.7755 - val_accuracy: 0.7732\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2690 - accuracy: 0.9379 - val_loss: 0.7782 - val_accuracy: 0.7629\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2654 - accuracy: 0.9340 - val_loss: 0.7678 - val_accuracy: 0.7784\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2589 - accuracy: 0.9366 - val_loss: 0.7682 - val_accuracy: 0.7784\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2535 - accuracy: 0.9418 - val_loss: 0.7652 - val_accuracy: 0.7835\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.9444 - val_loss: 0.7668 - val_accuracy: 0.7835\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2449 - accuracy: 0.9418 - val_loss: 0.7592 - val_accuracy: 0.7835\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2403 - accuracy: 0.9431 - val_loss: 0.7523 - val_accuracy: 0.7835\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2360 - accuracy: 0.9457 - val_loss: 0.7497 - val_accuracy: 0.7835\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2321 - accuracy: 0.9495 - val_loss: 0.7466 - val_accuracy: 0.7835\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2281 - accuracy: 0.9495 - val_loss: 0.7460 - val_accuracy: 0.7887\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2237 - accuracy: 0.9483 - val_loss: 0.7305 - val_accuracy: 0.7990\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2203 - accuracy: 0.9508 - val_loss: 0.7381 - val_accuracy: 0.7938\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2165 - accuracy: 0.9495 - val_loss: 0.7378 - val_accuracy: 0.7887\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2127 - accuracy: 0.9547 - val_loss: 0.7313 - val_accuracy: 0.7938\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.9508 - val_loss: 0.7346 - val_accuracy: 0.7938\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2046 - accuracy: 0.9560 - val_loss: 0.7367 - val_accuracy: 0.7835\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2026 - accuracy: 0.9573 - val_loss: 0.7226 - val_accuracy: 0.7887\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1983 - accuracy: 0.9586 - val_loss: 0.7252 - val_accuracy: 0.7938\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1952 - accuracy: 0.9547 - val_loss: 0.7055 - val_accuracy: 0.8041\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1918 - accuracy: 0.9560 - val_loss: 0.7086 - val_accuracy: 0.8093\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1886 - accuracy: 0.9586 - val_loss: 0.6945 - val_accuracy: 0.8093\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1862 - accuracy: 0.9638 - val_loss: 0.7005 - val_accuracy: 0.8093\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1826 - accuracy: 0.9638 - val_loss: 0.6994 - val_accuracy: 0.8144\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1793 - accuracy: 0.9664 - val_loss: 0.6966 - val_accuracy: 0.8196\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1763 - accuracy: 0.9651 - val_loss: 0.6948 - val_accuracy: 0.8196\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1733 - accuracy: 0.9664 - val_loss: 0.6850 - val_accuracy: 0.8196\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1708 - accuracy: 0.9664 - val_loss: 0.6865 - val_accuracy: 0.8247\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1678 - accuracy: 0.9677 - val_loss: 0.6863 - val_accuracy: 0.8247\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1655 - accuracy: 0.9715 - val_loss: 0.6870 - val_accuracy: 0.8196\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1623 - accuracy: 0.9702 - val_loss: 0.6829 - val_accuracy: 0.8247\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1598 - accuracy: 0.9715 - val_loss: 0.6820 - val_accuracy: 0.8247\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1573 - accuracy: 0.9741 - val_loss: 0.6849 - val_accuracy: 0.8247\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1550 - accuracy: 0.9741 - val_loss: 0.6720 - val_accuracy: 0.8247\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1528 - accuracy: 0.9741 - val_loss: 0.6742 - val_accuracy: 0.8299\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1500 - accuracy: 0.9741 - val_loss: 0.6823 - val_accuracy: 0.8351\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9741 - val_loss: 0.6702 - val_accuracy: 0.8299\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9754 - val_loss: 0.6657 - val_accuracy: 0.8402\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1435 - accuracy: 0.9754 - val_loss: 0.6626 - val_accuracy: 0.8351\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1417 - accuracy: 0.9754 - val_loss: 0.6613 - val_accuracy: 0.8402\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1391 - accuracy: 0.9754 - val_loss: 0.6622 - val_accuracy: 0.8454\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1371 - accuracy: 0.9754 - val_loss: 0.6582 - val_accuracy: 0.8454\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1351 - accuracy: 0.9754 - val_loss: 0.6607 - val_accuracy: 0.8454\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1333 - accuracy: 0.9767 - val_loss: 0.6553 - val_accuracy: 0.8454\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1310 - accuracy: 0.9767 - val_loss: 0.6531 - val_accuracy: 0.8454\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1293 - accuracy: 0.9767 - val_loss: 0.6516 - val_accuracy: 0.8454\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1276 - accuracy: 0.9793 - val_loss: 0.6483 - val_accuracy: 0.8454\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1255 - accuracy: 0.9806 - val_loss: 0.6634 - val_accuracy: 0.8402\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1245 - accuracy: 0.9793 - val_loss: 0.6503 - val_accuracy: 0.8454\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1218 - accuracy: 0.9806 - val_loss: 0.6454 - val_accuracy: 0.8454\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1199 - accuracy: 0.9806 - val_loss: 0.6441 - val_accuracy: 0.8454\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1183 - accuracy: 0.9806 - val_loss: 0.6425 - val_accuracy: 0.8454\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9806 - val_loss: 0.6382 - val_accuracy: 0.8454\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1150 - accuracy: 0.9806 - val_loss: 0.6387 - val_accuracy: 0.8454\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1132 - accuracy: 0.9832 - val_loss: 0.6379 - val_accuracy: 0.8454\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1118 - accuracy: 0.9819 - val_loss: 0.6399 - val_accuracy: 0.8454\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1104 - accuracy: 0.9819 - val_loss: 0.6368 - val_accuracy: 0.8505\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1089 - accuracy: 0.9832 - val_loss: 0.6370 - val_accuracy: 0.8454\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1072 - accuracy: 0.9832 - val_loss: 0.6337 - val_accuracy: 0.8505\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1057 - accuracy: 0.9845 - val_loss: 0.6364 - val_accuracy: 0.8505\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1044 - accuracy: 0.9832 - val_loss: 0.6371 - val_accuracy: 0.8505\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1029 - accuracy: 0.9858 - val_loss: 0.6302 - val_accuracy: 0.8505\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1015 - accuracy: 0.9845 - val_loss: 0.6301 - val_accuracy: 0.8454\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1003 - accuracy: 0.9858 - val_loss: 0.6220 - val_accuracy: 0.8505\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0989 - accuracy: 0.9845 - val_loss: 0.6238 - val_accuracy: 0.8454\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0975 - accuracy: 0.9858 - val_loss: 0.6229 - val_accuracy: 0.8505\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0964 - accuracy: 0.9858 - val_loss: 0.6155 - val_accuracy: 0.8505\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0953 - accuracy: 0.9884 - val_loss: 0.6155 - val_accuracy: 0.8454\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0938 - accuracy: 0.9884 - val_loss: 0.6166 - val_accuracy: 0.8505\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0928 - accuracy: 0.9884 - val_loss: 0.6117 - val_accuracy: 0.8505\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0916 - accuracy: 0.9897 - val_loss: 0.6124 - val_accuracy: 0.8505\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0905 - accuracy: 0.9909 - val_loss: 0.6237 - val_accuracy: 0.8505\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0897 - accuracy: 0.9922 - val_loss: 0.6142 - val_accuracy: 0.8505\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0881 - accuracy: 0.9935 - val_loss: 0.6097 - val_accuracy: 0.8505\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0869 - accuracy: 0.9935 - val_loss: 0.6052 - val_accuracy: 0.8505\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0858 - accuracy: 0.9935 - val_loss: 0.6039 - val_accuracy: 0.8505\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0850 - accuracy: 0.9948 - val_loss: 0.6028 - val_accuracy: 0.8505\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0838 - accuracy: 0.9935 - val_loss: 0.6016 - val_accuracy: 0.8505\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0828 - accuracy: 0.9948 - val_loss: 0.6019 - val_accuracy: 0.8505\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.0805 - accuracy: 0.99 - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9948 - val_loss: 0.6051 - val_accuracy: 0.8505\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0811 - accuracy: 0.9948 - val_loss: 0.6043 - val_accuracy: 0.8505\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0799 - accuracy: 0.9948 - val_loss: 0.6015 - val_accuracy: 0.8505\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0791 - accuracy: 0.9948 - val_loss: 0.5980 - val_accuracy: 0.8505\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0780 - accuracy: 0.9948 - val_loss: 0.5986 - val_accuracy: 0.8557\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0772 - accuracy: 0.9948 - val_loss: 0.5955 - val_accuracy: 0.8608\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0764 - accuracy: 0.9948 - val_loss: 0.6004 - val_accuracy: 0.8608\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0755 - accuracy: 0.9948 - val_loss: 0.5967 - val_accuracy: 0.8608\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0747 - accuracy: 0.9948 - val_loss: 0.5914 - val_accuracy: 0.8660\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0738 - accuracy: 0.9948 - val_loss: 0.5897 - val_accuracy: 0.8660\n",
      "Epoch 163/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0731 - accuracy: 0.9948 - val_loss: 0.5891 - val_accuracy: 0.8660\n",
      "Epoch 164/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9961 - val_loss: 0.5885 - val_accuracy: 0.8660\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.9948 - val_loss: 0.5886 - val_accuracy: 0.8660\n",
      "Epoch 166/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.9961 - val_loss: 0.5948 - val_accuracy: 0.8557\n",
      "Epoch 167/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.9961 - val_loss: 0.5911 - val_accuracy: 0.8608\n",
      "Epoch 168/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.9961 - val_loss: 0.5867 - val_accuracy: 0.8660\n",
      "Epoch 169/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.9961 - val_loss: 0.5851 - val_accuracy: 0.8660\n",
      "Epoch 170/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.9961 - val_loss: 0.5860 - val_accuracy: 0.8660\n",
      "Epoch 171/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.9961 - val_loss: 0.5860 - val_accuracy: 0.8660\n",
      "Epoch 172/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9961 - val_loss: 0.5846 - val_accuracy: 0.8660\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.9961 - val_loss: 0.5842 - val_accuracy: 0.8660\n",
      "Epoch 174/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9961 - val_loss: 0.5801 - val_accuracy: 0.8660\n",
      "Epoch 175/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.9961 - val_loss: 0.5792 - val_accuracy: 0.8660\n",
      "Epoch 176/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9961 - val_loss: 0.5770 - val_accuracy: 0.8660\n",
      "Epoch 177/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.9961 - val_loss: 0.5773 - val_accuracy: 0.8660\n",
      "Epoch 178/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.9961 - val_loss: 0.5735 - val_accuracy: 0.8660\n",
      "Epoch 179/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.9961 - val_loss: 0.5729 - val_accuracy: 0.8660\n",
      "Epoch 180/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9961 - val_loss: 0.5731 - val_accuracy: 0.8660\n",
      "Epoch 181/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9961 - val_loss: 0.5751 - val_accuracy: 0.8660\n",
      "Epoch 182/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.9961 - val_loss: 0.5716 - val_accuracy: 0.8660\n",
      "Epoch 183/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9961 - val_loss: 0.5728 - val_accuracy: 0.8711\n",
      "Epoch 184/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9961 - val_loss: 0.5741 - val_accuracy: 0.8711\n",
      "Epoch 185/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9961 - val_loss: 0.5739 - val_accuracy: 0.8711\n",
      "Epoch 186/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9961 - val_loss: 0.5733 - val_accuracy: 0.8711\n",
      "Epoch 187/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.9961 - val_loss: 0.5742 - val_accuracy: 0.8711\n",
      "Epoch 188/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9961 - val_loss: 0.5733 - val_accuracy: 0.8711\n",
      "Epoch 189/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9961 - val_loss: 0.5687 - val_accuracy: 0.8711\n",
      "Epoch 190/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9961 - val_loss: 0.5780 - val_accuracy: 0.8711\n",
      "Epoch 191/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9961 - val_loss: 0.5750 - val_accuracy: 0.8711\n",
      "Epoch 192/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9961 - val_loss: 0.5690 - val_accuracy: 0.8711\n",
      "Epoch 193/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9961 - val_loss: 0.5676 - val_accuracy: 0.8711\n",
      "Epoch 194/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9961 - val_loss: 0.5663 - val_accuracy: 0.8711\n",
      "Epoch 195/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9961 - val_loss: 0.5678 - val_accuracy: 0.8711\n",
      "Epoch 196/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9961 - val_loss: 0.5655 - val_accuracy: 0.8711\n",
      "Epoch 197/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9961 - val_loss: 0.5635 - val_accuracy: 0.8711\n",
      "Epoch 198/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9961 - val_loss: 0.5674 - val_accuracy: 0.8711\n",
      "Epoch 199/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9961 - val_loss: 0.5610 - val_accuracy: 0.8711\n",
      "Epoch 200/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9961 - val_loss: 0.5611 - val_accuracy: 0.8711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20dd1151b80>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop_cb = tf.keras.callbacks.EarlyStopping(patience = 10)\n",
    "model_1.fit(std_inputs_tr, targets_tr, validation_data = (std_inputs_te, targets_te), epochs = 200, callbacks = [early_stop_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomizedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = tf.keras.wrappers.scikit_learn.KerasRegressor(model_ann_selu_relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model_ann_selu_relu(inputs_size, outputs_size, n_layers, n_neurons, lr, kernel_init, active_function):\n",
    "### model_ann_leakyrelu(inputs_size, outputs_size, n_layers, n_neurons, lr, kernel_init)\n",
    "\n",
    "\n",
    "search_para = { \"inputs_size\" : [[inputs_tr.shape[1]]], \"outputs_size\" : [targets_tr.shape[1]], \n",
    "              \"n_layers\":[15,20,30,40], \"n_neurons\":[50,100,200,300], \"lr\":[0.1, 0.01, 0.001,0.0001, 0.00001, 0.000001],\n",
    "              \"kernel_init\":['he_normal', 'lecum_normal'], 'active_function':['selu', 'relu']}\n",
    "rnd_search_cv = RandomizedSearchCV(keras_model, search_para, cv = 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 583 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "583/583 [==============================]583/583 [==============================] - 3s 6ms/step - loss: 2.1746 - acc: 0.1321 - val_loss: 2.1497 - val_acc: 0.1543 ETA: 1s - loss: 2.1691 - acc:\n",
      "\n",
      "Epoch 2/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1950 - acc: 0.1286 - val_loss: 2.2042 - val_acc: 0.0988 ETA: 0s - loss: 2.1926 - ac\n",
      "\n",
      "Epoch 3/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1936 - acc: 0.1218 - val_loss: 2.1982 - val_acc: 0.1235\n",
      "\n",
      "Epoch 4/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1687 - acc: 0.1492 - val_loss: 2.0521 - val_acc: 0.2037\n",
      "\n",
      "Epoch 5/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.2053 - acc: 0.1458 - val_loss: 2.2000 - val_acc: 0.1235\n",
      "\n",
      "Epoch 6/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1743 - acc: 0.1732 - val_loss: 2.1749 - val_acc: 0.2099\n",
      "\n",
      "Epoch 7/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 3ms/step - loss: 2.0815 - acc: 0.1955 - val_loss: 1.9813 - val_acc: 0.2346\n",
      "\n",
      "Epoch 8/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1843 - acc: 0.1252 - val_loss: 2.2170 - val_acc: 0.0988\n",
      "\n",
      "Epoch 9/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1951 - acc: 0.1252 - val_loss: 2.1946 - val_acc: 0.1235\n",
      "\n",
      "Epoch 10/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1915 - acc: 0.1372 - val_loss: 2.1891 - val_acc: 0.1543\n",
      "\n",
      "Epoch 11/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1908 - acc: 0.1372 - val_loss: 2.1877 - val_acc: 0.1543\n",
      "\n",
      "Epoch 12/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1875 - acc: 0.1372 - val_loss: 2.1935 - val_acc: 0.1543\n",
      "\n",
      "Epoch 13/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1800 - acc: 0.1458 - val_loss: 2.1729 - val_acc: 0.2037\n",
      "\n",
      "Epoch 14/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1399 - acc: 0.2367 - val_loss: 2.1271 - val_acc: 0.2284\n",
      "\n",
      "Epoch 15/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.9941 - acc: 0.2196 - val_loss: 1.8758 - val_acc: 0.2469\n",
      "\n",
      "Epoch 16/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.8093 - acc: 0.2350 - val_loss: 1.7675 - val_acc: 0.2222\n",
      "\n",
      "Epoch 17/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1397 - acc: 0.1458 - val_loss: 2.2075 - val_acc: 0.0679\n",
      "\n",
      "Epoch 18/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.2003 - acc: 0.1218 - val_loss: 2.1894 - val_acc: 0.1543\n",
      "\n",
      "Epoch 19/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1646 - acc: 0.1698 - val_loss: 2.0725 - val_acc: 0.1728\n",
      "\n",
      "Epoch 20/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1092 - acc: 0.1870 - val_loss: 1.7845 - val_acc: 0.2407\n",
      "\n",
      "Epoch 21/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 3ms/step - loss: 1.8350 - acc: 0.2436 - val_loss: 1.6416 - val_acc: 0.2346\n",
      "\n",
      "Epoch 22/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.7527 - acc: 0.2196 - val_loss: 2.8809 - val_acc: 0.1111\n",
      "\n",
      "Epoch 23/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1111 - acc: 0.1612 - val_loss: 1.7686 - val_acc: 0.2654\n",
      "\n",
      "Epoch 24/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.7287 - acc: 0.2367 - val_loss: 1.6054 - val_acc: 0.2284\n",
      "\n",
      "Epoch 25/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.7019 - acc: 0.2436 - val_loss: 1.5642 - val_acc: 0.1914\n",
      "\n",
      "Epoch 26/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.7833 - acc: 0.2281 - val_loss: 2.7920 - val_acc: 0.1235\n",
      "\n",
      "Epoch 27/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.9077 - acc: 0.2024 - val_loss: 1.6776 - val_acc: 0.1975\n",
      "\n",
      "Epoch 28/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.6841 - acc: 0.2573 - val_loss: 1.5519 - val_acc: 0.2593\n",
      "\n",
      "Epoch 29/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 3ms/step - loss: 1.4850 - acc: 0.3516 - val_loss: 1.4158 - val_acc: 0.3580\n",
      "\n",
      "Epoch 30/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.6807 - acc: 0.3002 - val_loss: 1.4141 - val_acc: 0.3457\n",
      "\n",
      "Epoch 31/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.6522 - acc: 0.3053 - val_loss: 1.5879 - val_acc: 0.4136\n",
      "\n",
      "Epoch 32/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.5960 - acc: 0.3139 - val_loss: 1.4472 - val_acc: 0.3889\n",
      "\n",
      "Epoch 33/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.4996 - acc: 0.3396 - val_loss: 1.6084 - val_acc: 0.2716\n",
      "\n",
      "Epoch 34/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.7330 - acc: 0.3036 - val_loss: 1.6933 - val_acc: 0.2654\n",
      "\n",
      "Epoch 35/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.5395 - acc: 0.3139 - val_loss: 1.4104 - val_acc: 0.3519\n",
      "\n",
      "Epoch 36/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.5867 - acc: 0.3242 - val_loss: 1.6434 - val_acc: 0.2840\n",
      "\n",
      "Epoch 37/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.4968 - acc: 0.3173 - val_loss: 1.3987 - val_acc: 0.3086\n",
      "\n",
      "Epoch 38/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.3916 - acc: 0.3448 - val_loss: 1.3267 - val_acc: 0.4198\n",
      "\n",
      "Epoch 39/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.3968 - acc: 0.2796 - val_loss: 3.0061 - val_acc: 0.1049\n",
      "\n",
      "Epoch 40/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.0976 - acc: 0.1818 - val_loss: 1.7474 - val_acc: 0.2037\n",
      "\n",
      "Epoch 41/200\n",
      "583/583 [==============================]583/583 [==============================] - 2s 3ms/step - loss: 1.7025 - acc: 0.2453 - val_loss: 1.6093 - val_acc: 0.1852\n",
      "\n",
      "Epoch 42/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.6578 - acc: 0.2744 - val_loss: 1.4871 - val_acc: 0.4259\n",
      "\n",
      "Epoch 43/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.5306 - acc: 0.3225 - val_loss: 1.6213 - val_acc: 0.2716\n",
      "\n",
      "Epoch 44/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.4878 - acc: 0.3208 - val_loss: 1.3463 - val_acc: 0.4012\n",
      "\n",
      "Epoch 45/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.6312 - acc: 0.3190 - val_loss: 1.4621 - val_acc: 0.3457\n",
      "\n",
      "Epoch 46/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.3905 - acc: 0.3842 - val_loss: 1.3959 - val_acc: 0.3210\n",
      "\n",
      "Epoch 47/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.6657 - acc: 0.3654 - val_loss: 2.5786 - val_acc: 0.0679\n",
      "\n",
      "Epoch 48/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.0175 - acc: 0.2384 - val_loss: 2.5508 - val_acc: 0.1605\n",
      "\n",
      "65/65 [==============================]65/65 [==============================] - 0s 613us/step\n",
      "\n",
      "Train on 583 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "583/583 [==============================]583/583 [==============================] - 3s 6ms/step - loss: 2.1518 - acc: 0.1407 - val_loss: 2.1835 - val_acc: 0.2160\n",
      "\n",
      "Epoch 2/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1592 - acc: 0.1647 - val_loss: 2.2093 - val_acc: 0.1235\n",
      "\n",
      "Epoch 3/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1832 - acc: 0.1355 - val_loss: 2.1761 - val_acc: 0.0802\n",
      "\n",
      "Epoch 4/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1449 - acc: 0.1561 - val_loss: 2.2184 - val_acc: 0.1235\n",
      "\n",
      "Epoch 5/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1864 - acc: 0.1338 - val_loss: 2.1865 - val_acc: 0.1235\n",
      "\n",
      "Epoch 6/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1188 - acc: 0.1801 - val_loss: 1.8895 - val_acc: 0.3272 ETA: 0s - loss: 2.1668 - acc\n",
      "\n",
      "Epoch 7/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.0296 - acc: 0.2196 - val_loss: 2.8567 - val_acc: 0.2593\n",
      "\n",
      "Epoch 8/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.2953 - acc: 0.1235 - val_loss: 2.2345 - val_acc: 0.1235\n",
      "\n",
      "Epoch 9/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1897 - acc: 0.1647 - val_loss: 2.2011 - val_acc: 0.1543\n",
      "\n",
      "Epoch 10/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1638 - acc: 0.1715 - val_loss: 2.2283 - val_acc: 0.1111\n",
      "\n",
      "Epoch 11/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.0981 - acc: 0.1938 - val_loss: 2.2124 - val_acc: 0.1420\n",
      "\n",
      "Epoch 12/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.0488 - acc: 0.2213 - val_loss: 2.2544 - val_acc: 0.1235\n",
      "\n",
      "Epoch 13/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.2028 - acc: 0.1201 - val_loss: 2.2085 - val_acc: 0.1235\n",
      "\n",
      "Epoch 14/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1913 - acc: 0.1201 - val_loss: 2.2005 - val_acc: 0.0679\n",
      "\n",
      "Epoch 15/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1898 - acc: 0.1201 - val_loss: 2.2099 - val_acc: 0.0679\n",
      "\n",
      "Epoch 16/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1902 - acc: 0.1286 - val_loss: 2.2056 - val_acc: 0.1235\n",
      "\n",
      "65/65 [==============================]65/65 [==============================] - 0s 856us/step\n",
      "\n",
      "Train on 583 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "583/583 [==============================]583/583 [==============================] - 4s 7ms/step - loss: 2.1666 - acc: 0.1561 - val_loss: 3.0137 - val_acc: 0.1543\n",
      "\n",
      "Epoch 2/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.2477 - acc: 0.1149 - val_loss: 2.1851 - val_acc: 0.2222\n",
      "\n",
      "Epoch 3/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.1521 - acc: 0.1921 - val_loss: 2.0582 - val_acc: 0.1111\n",
      "\n",
      "Epoch 4/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.9910 - acc: 0.2127 - val_loss: 3.9539 - val_acc: 0.1605\n",
      "\n",
      "Epoch 5/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.2434 - acc: 0.1732 - val_loss: 2.0970 - val_acc: 0.1790\n",
      "\n",
      "Epoch 6/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.0292 - acc: 0.2213 - val_loss: 1.7346 - val_acc: 0.2346\n",
      "\n",
      "Epoch 7/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1919 - acc: 0.1441 - val_loss: 2.2111 - val_acc: 0.1235\n",
      "\n",
      "Epoch 8/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1928 - acc: 0.1321 - val_loss: 2.1970 - val_acc: 0.1543\n",
      "\n",
      "Epoch 9/200\n",
      "583/583 [==============================]576/583 [============================>.] - ETA: 0s - loss: 2.1912 - acc: 0.147583/583 [==============================] - 1s 2ms/step - loss: 2.1910 - acc: 0.1475 - val_loss: 2.1907 - val_acc: 0.1543\n",
      "\n",
      "Epoch 10/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1731 - acc: 0.1750 - val_loss: 2.2157 - val_acc: 0.1235\n",
      "\n",
      "Epoch 11/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1148 - acc: 0.2264 - val_loss: 2.0163 - val_acc: 0.2346\n",
      "\n",
      "Epoch 12/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.0455 - acc: 0.2075 - val_loss: 1.7811 - val_acc: 0.3086\n",
      "\n",
      "Epoch 13/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.7421 - acc: 0.2521 - val_loss: 1.9745 - val_acc: 0.2037\n",
      "\n",
      "Epoch 14/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.7812 - acc: 0.2230 - val_loss: 1.7822 - val_acc: 0.2346\n",
      "\n",
      "Epoch 15/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.5421 - acc: 0.3431 - val_loss: 2.2050 - val_acc: 0.1667\n",
      "\n",
      "Epoch 16/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.9343 - acc: 0.2144 - val_loss: 1.6625 - val_acc: 0.2778\n",
      "\n",
      "Epoch 17/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.5612 - acc: 0.3499 - val_loss: 1.2720 - val_acc: 0.4383\n",
      "\n",
      "Epoch 18/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.5393 - acc: 0.3533 - val_loss: 1.3640 - val_acc: 0.4259\n",
      "\n",
      "Epoch 19/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.2117 - acc: 0.4168 - val_loss: 1.3900 - val_acc: 0.4753\n",
      "\n",
      "Epoch 20/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.1103 - acc: 0.4751 - val_loss: 0.8489 - val_acc: 0.6790\n",
      "\n",
      "Epoch 21/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.3902 - acc: 0.4202 - val_loss: 1.2219 - val_acc: 0.4136\n",
      "\n",
      "Epoch 22/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.2414 - acc: 0.4391 - val_loss: 1.0794 - val_acc: 0.5309\n",
      "\n",
      "Epoch 23/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.5911 - acc: 0.1732 - val_loss: 2.2358 - val_acc: 0.1543\n",
      "\n",
      "Epoch 24/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.2042 - acc: 0.1355 - val_loss: 2.2164 - val_acc: 0.1235\n",
      "\n",
      "Epoch 25/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 3ms/step - loss: 2.1702 - acc: 0.2041 - val_loss: 2.1468 - val_acc: 0.1296\n",
      "\n",
      "Epoch 26/200\n",
      "583/583 [==============================]583/583 [==============================] - 2s 3ms/step - loss: 2.0089 - acc: 0.2521 - val_loss: 5.2420 - val_acc: 0.2531\n",
      "\n",
      "Epoch 27/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.3870 - acc: 0.1424 - val_loss: 2.2149 - val_acc: 0.1543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1989 - acc: 0.1424 - val_loss: 2.2058 - val_acc: 0.1543\n",
      "\n",
      "Epoch 29/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1901 - acc: 0.1527 - val_loss: 2.1861 - val_acc: 0.1543\n",
      "\n",
      "Epoch 30/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1590 - acc: 0.1904 - val_loss: 2.1753 - val_acc: 0.2222\n",
      "\n",
      "65/65 [==============================]65/65 [==============================] - 0s 590us/step\n",
      "\n",
      "Train on 583 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "583/583 [==============================]583/583 [==============================] - 4s 6ms/step - loss: 2.1694 - acc: 0.1218 - val_loss: 2.1865 - val_acc: 0.1235\n",
      "\n",
      "Epoch 2/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1936 - acc: 0.1304 - val_loss: 2.2062 - val_acc: 0.0988\n",
      "\n",
      "Epoch 3/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1925 - acc: 0.1235 - val_loss: 2.2055 - val_acc: 0.1235\n",
      "\n",
      "Epoch 4/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1874 - acc: 0.1355 - val_loss: 2.2037 - val_acc: 0.1235\n",
      "\n",
      "Epoch 5/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1826 - acc: 0.1561 - val_loss: 2.1898 - val_acc: 0.1420\n",
      "\n",
      "Epoch 6/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1678 - acc: 0.2178 - val_loss: 2.1650 - val_acc: 0.2407\n",
      "\n",
      "Epoch 7/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1025 - acc: 0.2419 - val_loss: 2.2502 - val_acc: 0.1235\n",
      "\n",
      "Epoch 8/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1992 - acc: 0.1355 - val_loss: 2.2164 - val_acc: 0.1235\n",
      "\n",
      "Epoch 9/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1899 - acc: 0.1355 - val_loss: 2.2009 - val_acc: 0.1235\n",
      "\n",
      "Epoch 10/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1823 - acc: 0.1355 - val_loss: 2.2181 - val_acc: 0.1235\n",
      "\n",
      "Epoch 11/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1375 - acc: 0.1904 - val_loss: 2.2212 - val_acc: 0.1420\n",
      "\n",
      "Epoch 12/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.0326 - acc: 0.1938 - val_loss: 1.8315 - val_acc: 0.2284\n",
      "\n",
      "Epoch 13/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.8895 - acc: 0.2247 - val_loss: 7.0349 - val_acc: 0.1605\n",
      "\n",
      "Epoch 14/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.5086 - acc: 0.1201 - val_loss: 2.2270 - val_acc: 0.1543\n",
      "\n",
      "Epoch 15/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1662 - acc: 0.1818 - val_loss: 2.1205 - val_acc: 0.2346\n",
      "\n",
      "Epoch 16/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.0427 - acc: 0.2333 - val_loss: 1.9568 - val_acc: 0.2593\n",
      "\n",
      "Epoch 17/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.8883 - acc: 0.2453 - val_loss: 2.4964 - val_acc: 0.0988\n",
      "\n",
      "Epoch 18/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1619 - acc: 0.1732 - val_loss: 2.2390 - val_acc: 0.1111\n",
      "\n",
      "Epoch 19/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.9175 - acc: 0.1990 - val_loss: 1.6939 - val_acc: 0.2716\n",
      "\n",
      "Epoch 20/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.8256 - acc: 0.2298 - val_loss: 1.9264 - val_acc: 0.2469\n",
      "\n",
      "Epoch 21/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 3ms/step - loss: 1.7470 - acc: 0.2521 - val_loss: 1.5494 - val_acc: 0.3395\n",
      "\n",
      "Epoch 22/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.9137 - acc: 0.2213 - val_loss: 1.5903 - val_acc: 0.2593\n",
      "\n",
      "Epoch 23/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.7921 - acc: 0.2041 - val_loss: 1.7775 - val_acc: 0.3333\n",
      "\n",
      "Epoch 24/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.4303 - acc: 0.1715 - val_loss: 2.2010 - val_acc: 0.1605\n",
      "\n",
      "Epoch 25/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.0972 - acc: 0.1578 - val_loss: 1.9511 - val_acc: 0.1605\n",
      "\n",
      "Epoch 26/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.7133 - acc: 0.2470 - val_loss: 1.8839 - val_acc: 0.2654\n",
      "\n",
      "Epoch 27/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.5516 - acc: 0.2573 - val_loss: 1.8191 - val_acc: 0.2963\n",
      "\n",
      "Epoch 28/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.9839 - acc: 0.2710 - val_loss: 1.5942 - val_acc: 0.2222\n",
      "\n",
      "Epoch 29/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.4292 - acc: 0.3087 - val_loss: 1.4669 - val_acc: 0.3210\n",
      "\n",
      "Epoch 30/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.4602 - acc: 0.3087 - val_loss: 2.8871 - val_acc: 0.1235\n",
      "\n",
      "Epoch 31/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.7554 - acc: 0.2453 - val_loss: 1.3429 - val_acc: 0.4198\n",
      "\n",
      "Epoch 32/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.3840 - acc: 0.3310 - val_loss: 1.2628 - val_acc: 0.4877\n",
      "\n",
      "Epoch 33/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.3739 - acc: 0.3465 - val_loss: 1.2781 - val_acc: 0.3765\n",
      "\n",
      "Epoch 34/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.3544 - acc: 0.3722 - val_loss: 2.6032 - val_acc: 0.2222\n",
      "\n",
      "Epoch 35/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.6453 - acc: 0.2864 - val_loss: 1.9026 - val_acc: 0.2778\n",
      "\n",
      "Epoch 36/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.3385 - acc: 0.2882 - val_loss: 1.3518 - val_acc: 0.3519\n",
      "\n",
      "Epoch 37/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.3368 - acc: 0.3465 - val_loss: 1.3404 - val_acc: 0.3580\n",
      "\n",
      "Epoch 38/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.3005 - acc: 0.3688 - val_loss: 1.3170 - val_acc: 0.3025\n",
      "\n",
      "Epoch 39/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.3102 - acc: 0.3894 - val_loss: 1.2682 - val_acc: 0.3951\n",
      "\n",
      "Epoch 40/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 3ms/step - loss: 1.7084 - acc: 0.3431 - val_loss: 1.6009 - val_acc: 0.3272\n",
      "\n",
      "Epoch 41/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.4649 - acc: 0.3688 - val_loss: 1.2999 - val_acc: 0.3210\n",
      "\n",
      "Epoch 42/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.3006 - acc: 0.3808 - val_loss: 1.2104 - val_acc: 0.5185\n",
      "\n",
      "Epoch 43/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.2404 - acc: 0.4168 - val_loss: 1.1161 - val_acc: 0.5123\n",
      "\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.3587 - acc: 0.4014 - val_loss: 3.3520 - val_acc: 0.2346\n",
      "\n",
      "Epoch 45/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.9199 - acc: 0.2624 - val_loss: 1.2347 - val_acc: 0.5000\n",
      "\n",
      "Epoch 46/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.2546 - acc: 0.4288 - val_loss: 1.1779 - val_acc: 0.4383\n",
      "\n",
      "Epoch 47/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.4493 - acc: 0.3533 - val_loss: 1.1004 - val_acc: 0.4938\n",
      "\n",
      "Epoch 48/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.2845 - acc: 0.3756 - val_loss: 1.3201 - val_acc: 0.3580\n",
      "\n",
      "Epoch 49/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.2684 - acc: 0.3911 - val_loss: 1.2094 - val_acc: 0.4321\n",
      "\n",
      "Epoch 50/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.2993 - acc: 0.4117 - val_loss: 2.2814 - val_acc: 0.2037\n",
      "\n",
      "Epoch 51/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.6832 - acc: 0.2693 - val_loss: 1.5870 - val_acc: 0.4568\n",
      "\n",
      "Epoch 52/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.4502 - acc: 0.3465 - val_loss: 1.2362 - val_acc: 0.4691\n",
      "\n",
      "Epoch 53/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.3432 - acc: 0.4271 - val_loss: 1.7892 - val_acc: 0.3765\n",
      "\n",
      "Epoch 54/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.6910 - acc: 0.2727 - val_loss: 1.1892 - val_acc: 0.4815\n",
      "\n",
      "Epoch 55/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.2449 - acc: 0.4254 - val_loss: 1.3666 - val_acc: 0.3457\n",
      "\n",
      "Epoch 56/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.3078 - acc: 0.3928 - val_loss: 1.5836 - val_acc: 0.2963\n",
      "\n",
      "Epoch 57/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.3358 - acc: 0.1578 - val_loss: 2.2245 - val_acc: 0.1049\n",
      "\n",
      "65/65 [==============================]65/65 [==============================] - 0s 639us/step\n",
      "\n",
      "Train on 583 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "583/583 [==============================]583/583 [==============================] - 4s 7ms/step - loss: 2.1990 - acc: 0.1269 - val_loss: 2.1806 - val_acc: 0.1296\n",
      "\n",
      "Epoch 2/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1490 - acc: 0.1578 - val_loss: 2.2014 - val_acc: 0.1235\n",
      "\n",
      "Epoch 3/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1827 - acc: 0.1441 - val_loss: 2.0768 - val_acc: 0.1667\n",
      "\n",
      "Epoch 4/200\n",
      "583/583 [==============================]583/583 [==============================] - 2s 3ms/step - loss: 2.2392 - acc: 0.1441 - val_loss: 2.2120 - val_acc: 0.1235\n",
      "\n",
      "Epoch 5/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1789 - acc: 0.1681 - val_loss: 2.1909 - val_acc: 0.1481 ETA: 0s - loss: 2.1811 - acc: 0.16\n",
      "\n",
      "Epoch 6/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 3ms/step - loss: 2.1120 - acc: 0.1818 - val_loss: 2.2134 - val_acc: 0.1235\n",
      "\n",
      "Epoch 7/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 3ms/step - loss: 2.1936 - acc: 0.1338 - val_loss: 2.2038 - val_acc: 0.1235\n",
      "\n",
      "Epoch 8/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 3ms/step - loss: 2.1889 - acc: 0.1355 - val_loss: 2.2027 - val_acc: 0.1235\n",
      "\n",
      "Epoch 9/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1893 - acc: 0.1355 - val_loss: 2.1999 - val_acc: 0.1235\n",
      "\n",
      "Epoch 10/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1889 - acc: 0.1355 - val_loss: 2.1960 - val_acc: 0.0988\n",
      "\n",
      "Epoch 11/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1820 - acc: 0.1630 - val_loss: 2.1948 - val_acc: 0.1358\n",
      "\n",
      "Epoch 12/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1514 - acc: 0.2264 - val_loss: 2.0791 - val_acc: 0.2654\n",
      "\n",
      "Epoch 13/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.0221 - acc: 0.2333 - val_loss: 2.1768 - val_acc: 0.1605\n",
      "\n",
      "65/65 [==============================]65/65 [==============================] - 0s 1ms/step\n",
      "\n",
      "Train on 583 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "583/583 [==============================]583/583 [==============================] - 4s 7ms/step - loss: 2.1669 - acc: 0.1269 - val_loss: 2.0685 - val_acc: 0.1543\n",
      "\n",
      "Epoch 2/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1617 - acc: 0.1304 - val_loss: 2.1474 - val_acc: 0.1049\n",
      "\n",
      "Epoch 3/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1273 - acc: 0.1698 - val_loss: 2.1837 - val_acc: 0.1543\n",
      "\n",
      "Epoch 4/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1674 - acc: 0.1424 - val_loss: 2.2006 - val_acc: 0.0988\n",
      "\n",
      "Epoch 5/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1538 - acc: 0.1389 - val_loss: 2.2138 - val_acc: 0.1111\n",
      "\n",
      "Epoch 6/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1810 - acc: 0.1132 - val_loss: 2.1094 - val_acc: 0.1543\n",
      "\n",
      "Epoch 7/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1010 - acc: 0.1407 - val_loss: 2.2151 - val_acc: 0.0988\n",
      "\n",
      "Epoch 8/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1897 - acc: 0.1166 - val_loss: 2.2003 - val_acc: 0.1543\n",
      "\n",
      "Epoch 9/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1840 - acc: 0.1458 - val_loss: 2.1866 - val_acc: 0.1543\n",
      "\n",
      "Epoch 10/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1747 - acc: 0.1475 - val_loss: 2.1691 - val_acc: 0.1543 loss: 2.1808 - acc:\n",
      "\n",
      "Epoch 11/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1282 - acc: 0.1887 - val_loss: 2.1042 - val_acc: 0.2346\n",
      "\n",
      "65/65 [==============================]65/65 [==============================] - 0s 1ms/step\n",
      "\n",
      "Train on 583 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "583/583 [==============================]583/583 [==============================] - 5s 8ms/step - loss: 2.1770 - acc: 0.1698 - val_loss: 2.1915 - val_acc: 0.1358\n",
      "\n",
      "Epoch 2/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.1680 - acc: 0.1492 - val_loss: 2.2108 - val_acc: 0.1235\n",
      "\n",
      "Epoch 3/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1809 - acc: 0.1355 - val_loss: 2.1112 - val_acc: 0.2407\n",
      "\n",
      "Epoch 4/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.0876 - acc: 0.2075 - val_loss: 2.0013 - val_acc: 0.2840\n",
      "\n",
      "Epoch 5/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1107 - acc: 0.1767 - val_loss: 2.0698 - val_acc: 0.2037\n",
      "\n",
      "Epoch 6/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.9652 - acc: 0.2298 - val_loss: 2.0830 - val_acc: 0.1914\n",
      "\n",
      "Epoch 7/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.8700 - acc: 0.2247 - val_loss: 2.4432 - val_acc: 0.1235\n",
      "\n",
      "Epoch 8/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1944 - acc: 0.1578 - val_loss: 2.1286 - val_acc: 0.2284\n",
      "\n",
      "Epoch 9/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1728 - acc: 0.1852 - val_loss: 2.2321 - val_acc: 0.1235 ETA: 0s - loss: 2.1555 - acc: 0.\n",
      "\n",
      "Epoch 10/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1961 - acc: 0.1252 - val_loss: 2.1969 - val_acc: 0.1358\n",
      "\n",
      "Epoch 11/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1383 - acc: 0.1612 - val_loss: 2.0754 - val_acc: 0.1420\n",
      "\n",
      "Epoch 12/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.0893 - acc: 0.1835 - val_loss: 2.4234 - val_acc: 0.0988\n",
      "\n",
      "Epoch 13/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 3ms/step - loss: 1.8863 - acc: 0.2024 - val_loss: 4.8005 - val_acc: 0.0988\n",
      "\n",
      "Epoch 14/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.3255 - acc: 0.1132 - val_loss: 2.1904 - val_acc: 0.1543\n",
      "\n",
      "65/65 [==============================]65/65 [==============================] - 0s 1ms/step\n",
      "\n",
      "Train on 583 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "583/583 [==============================]583/583 [==============================] - 4s 8ms/step - loss: 2.1784 - acc: 0.1389 - val_loss: 2.1867 - val_acc: 0.1235\n",
      "\n",
      "Epoch 2/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1503 - acc: 0.1732 - val_loss: 2.2040 - val_acc: 0.1235 ETA: 0s - loss: 2.1057 - acc: - ETA: 0s - loss: 2.1496 - acc: 0.17\n",
      "\n",
      "Epoch 3/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1906 - acc: 0.1492 - val_loss: 2.2174 - val_acc: 0.1235 ETA: 0s - loss: 2.1805 - acc:\n",
      "\n",
      "Epoch 4/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1923 - acc: 0.1252 - val_loss: 2.2101 - val_acc: 0.1235\n",
      "\n",
      "Epoch 5/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1876 - acc: 0.1081 - val_loss: 2.2023 - val_acc: 0.1235\n",
      "\n",
      "Epoch 6/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 3ms/step - loss: 2.1817 - acc: 0.1389 - val_loss: 2.2031 - val_acc: 0.1235\n",
      "\n",
      "Epoch 7/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.1577 - acc: 0.2024 - val_loss: 2.1487 - val_acc: 0.2037\n",
      "\n",
      "Epoch 8/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.0801 - acc: 0.1904 - val_loss: 2.1581 - val_acc: 0.2469\n",
      "\n",
      "Epoch 9/200\n",
      "583/583 [==============================]583/583 [==============================] - 2s 3ms/step - loss: 2.1472 - acc: 0.1835 - val_loss: 2.2200 - val_acc: 0.0988\n",
      "\n",
      "Epoch 10/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 3ms/step - loss: 2.1669 - acc: 0.1424 - val_loss: 2.2036 - val_acc: 0.0988\n",
      "\n",
      "Epoch 11/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 3ms/step - loss: 2.0800 - acc: 0.1750 - val_loss: 2.0570 - val_acc: 0.1111\n",
      "\n",
      "Epoch 12/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 3ms/step - loss: 1.9568 - acc: 0.2110 - val_loss: 1.9222 - val_acc: 0.2346\n",
      "\n",
      "Epoch 13/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 3ms/step - loss: 1.9201 - acc: 0.2384 - val_loss: 2.3048 - val_acc: 0.1605\n",
      "\n",
      "Epoch 14/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.0447 - acc: 0.2213 - val_loss: 1.9509 - val_acc: 0.2531 ETA: 0s - loss: 2.1186 -\n",
      "\n",
      "Epoch 15/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.9095 - acc: 0.2247 - val_loss: 2.1029 - val_acc: 0.1605\n",
      "\n",
      "Epoch 16/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.8646 - acc: 0.2676 - val_loss: 2.1483 - val_acc: 0.2469\n",
      "\n",
      "Epoch 17/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.7648 - acc: 0.2487 - val_loss: 1.8820 - val_acc: 0.3210\n",
      "\n",
      "Epoch 18/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.5880 - acc: 0.3722 - val_loss: 2.0654 - val_acc: 0.2840\n",
      "\n",
      "Epoch 19/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 2.0086 - acc: 0.2436 - val_loss: 2.0451 - val_acc: 0.2654\n",
      "\n",
      "Epoch 20/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.6187 - acc: 0.3516 - val_loss: 1.7449 - val_acc: 0.2469\n",
      "\n",
      "Epoch 21/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.3476 - acc: 0.3859 - val_loss: 1.2956 - val_acc: 0.3457\n",
      "\n",
      "Epoch 22/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.9244 - acc: 0.2727 - val_loss: 1.6052 - val_acc: 0.3642\n",
      "\n",
      "Epoch 23/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.5353 - acc: 0.3808 - val_loss: 2.0172 - val_acc: 0.2099\n",
      "\n",
      "Epoch 24/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.4741 - acc: 0.3671 - val_loss: 1.7979 - val_acc: 0.3457\n",
      "\n",
      "Epoch 25/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.3438 - acc: 0.3654 - val_loss: 1.3396 - val_acc: 0.3395\n",
      "\n",
      "Epoch 26/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 3ms/step - loss: 1.3427 - acc: 0.4202 - val_loss: 1.2114 - val_acc: 0.3951\n",
      "\n",
      "Epoch 27/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 3ms/step - loss: 1.0826 - acc: 0.5163 - val_loss: 1.0726 - val_acc: 0.4568\n",
      "\n",
      "Epoch 28/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.5660 - acc: 0.3671 - val_loss: 1.5100 - val_acc: 0.2840\n",
      "\n",
      "Epoch 29/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.3032 - acc: 0.3705 - val_loss: 1.4153 - val_acc: 0.3457\n",
      "\n",
      "Epoch 30/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.4603 - acc: 0.3722 - val_loss: 1.6082 - val_acc: 0.3210\n",
      "\n",
      "Epoch 31/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.3633 - acc: 0.3739 - val_loss: 1.5407 - val_acc: 0.3086\n",
      "\n",
      "Epoch 32/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.2275 - acc: 0.4254 - val_loss: 1.9449 - val_acc: 0.2654\n",
      "\n",
      "Epoch 33/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.8306 - acc: 0.2710 - val_loss: 1.7687 - val_acc: 0.3210\n",
      "\n",
      "Epoch 34/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.4643 - acc: 0.3671 - val_loss: 1.9974 - val_acc: 0.3272\n",
      "\n",
      "Epoch 35/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.4087 - acc: 0.3894 - val_loss: 2.3554 - val_acc: 0.1667\n",
      "\n",
      "Epoch 36/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 755us/step - loss: 1.3781 - acc: 0.4271 - val_loss: 1.0715 - val_acc: 0.4938\n",
      "\n",
      "Epoch 37/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 792us/step - loss: 1.1507 - acc: 0.4871 - val_loss: 1.1383 - val_acc: 0.4938\n",
      "\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================]583/583 [==============================] - 0s 688us/step - loss: 2.1343 - acc: 0.2727 - val_loss: 1.5329 - val_acc: 0.4568\n",
      "\n",
      "Epoch 39/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 716us/step - loss: 1.7084 - acc: 0.3465 - val_loss: 2.1400 - val_acc: 0.2037\n",
      "\n",
      "Epoch 40/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 701us/step - loss: 2.0556 - acc: 0.1887 - val_loss: 2.4438 - val_acc: 0.1111\n",
      "\n",
      "Epoch 41/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 654us/step - loss: 1.8459 - acc: 0.2539 - val_loss: 5.2610 - val_acc: 0.0370\n",
      "\n",
      "Epoch 42/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 634us/step - loss: 2.0867 - acc: 0.2196 - val_loss: 1.8839 - val_acc: 0.2099\n",
      "\n",
      "Epoch 43/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 653us/step - loss: 1.7503 - acc: 0.2642 - val_loss: 2.0418 - val_acc: 0.1235\n",
      "\n",
      "Epoch 44/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 631us/step - loss: 2.5894 - acc: 0.2230 - val_loss: 2.0599 - val_acc: 0.2037\n",
      "\n",
      "Epoch 45/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 657us/step - loss: 1.8202 - acc: 0.2487 - val_loss: 1.3390 - val_acc: 0.3765\n",
      "\n",
      "Epoch 46/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 716us/step - loss: 1.9489 - acc: 0.2504 - val_loss: 1.6641 - val_acc: 0.2284\n",
      "\n",
      "65/65 [==============================]65/65 [==============================] - 0s 504us/step\n",
      "\n",
      "Train on 584 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "584/584 [==============================]584/584 [==============================] - 2s 3ms/step - loss: 2.1668 - acc: 0.1318 - val_loss: 2.1905 - val_acc: 0.1049 ETA: 0s - loss: 2.1599 - acc: 0.12\n",
      "\n",
      "Epoch 2/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 806us/step - loss: 2.1824 - acc: 0.1558 - val_loss: 2.2009 - val_acc: 0.1235\n",
      "\n",
      "Epoch 3/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 659us/step - loss: 2.1661 - acc: 0.1507 - val_loss: 3.6829 - val_acc: 0.0988\n",
      "\n",
      "Epoch 4/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 615us/step - loss: 2.2579 - acc: 0.1301 - val_loss: 2.1828 - val_acc: 0.1358\n",
      "\n",
      "Epoch 5/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 849us/step - loss: 2.1145 - acc: 0.2192 - val_loss: 2.1784 - val_acc: 0.1420\n",
      "\n",
      "Epoch 6/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 689us/step - loss: 2.0906 - acc: 0.1832 - val_loss: 2.2136 - val_acc: 0.1235\n",
      "\n",
      "Epoch 7/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 599us/step - loss: 2.1938 - acc: 0.1336 - val_loss: 2.2080 - val_acc: 0.1235\n",
      "\n",
      "Epoch 8/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 620us/step - loss: 2.1907 - acc: 0.1336 - val_loss: 2.2064 - val_acc: 0.0679\n",
      "\n",
      "Epoch 9/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 743us/step - loss: 2.1877 - acc: 0.1182 - val_loss: 2.1979 - val_acc: 0.06790s - loss: 2.1851 - acc: 0.12\n",
      "\n",
      "Epoch 10/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 686us/step - loss: 2.1861 - acc: 0.1541 - val_loss: 2.1941 - val_acc: 0.1173\n",
      "\n",
      "Epoch 11/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 687us/step - loss: 2.1731 - acc: 0.2295 - val_loss: 2.1884 - val_acc: 0.1605\n",
      "\n",
      "Epoch 12/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 658us/step - loss: 2.0980 - acc: 0.2226 - val_loss: 2.0785 - val_acc: 0.1667\n",
      "\n",
      "Epoch 13/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 742us/step - loss: 1.9721 - acc: 0.2072 - val_loss: 2.0405 - val_acc: 0.2593\n",
      "\n",
      "Epoch 14/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 620us/step - loss: 1.8668 - acc: 0.2654 - val_loss: 2.6770 - val_acc: 0.1852\n",
      "\n",
      "Epoch 15/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 752us/step - loss: 1.9584 - acc: 0.2277 - val_loss: 3.1343 - val_acc: 0.2160\n",
      "\n",
      "Epoch 16/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 660us/step - loss: 2.2549 - acc: 0.1301 - val_loss: 2.2276 - val_acc: 0.1235\n",
      "\n",
      "Epoch 17/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 620us/step - loss: 2.1998 - acc: 0.1336 - val_loss: 2.2068 - val_acc: 0.1235\n",
      "\n",
      "Epoch 18/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 712us/step - loss: 2.1932 - acc: 0.1336 - val_loss: 2.2029 - val_acc: 0.1235\n",
      "\n",
      "Epoch 19/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 649us/step - loss: 2.1904 - acc: 0.1301 - val_loss: 2.2043 - val_acc: 0.1235\n",
      "\n",
      "Epoch 20/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 674us/step - loss: 2.1891 - acc: 0.1216 - val_loss: 2.1987 - val_acc: 0.1543\n",
      "\n",
      "Epoch 21/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 616us/step - loss: 2.1892 - acc: 0.0976 - val_loss: 2.1998 - val_acc: 0.1235\n",
      "\n",
      "Epoch 22/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 709us/step - loss: 2.1882 - acc: 0.1336 - val_loss: 2.1987 - val_acc: 0.1543\n",
      "\n",
      "Epoch 23/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 659us/step - loss: 2.1888 - acc: 0.1267 - val_loss: 2.1989 - val_acc: 0.1235\n",
      "\n",
      "64/64 [==============================]64/64 [==============================] - 0s 280us/step\n",
      "\n",
      "Train on 584 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "584/584 [==============================]584/584 [==============================] - 2s 3ms/step - loss: 2.1779 - acc: 0.1592 - val_loss: 2.1992 - val_acc: 0.1914\n",
      "\n",
      "Epoch 2/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 653us/step - loss: 2.1566 - acc: 0.1627 - val_loss: 2.2010 - val_acc: 0.1235\n",
      "\n",
      "Epoch 3/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 629us/step - loss: 2.1635 - acc: 0.1455 - val_loss: 1.9457 - val_acc: 0.1605\n",
      "\n",
      "Epoch 4/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 598us/step - loss: 2.1751 - acc: 0.1318 - val_loss: 2.2078 - val_acc: 0.1235\n",
      "\n",
      "Epoch 5/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 624us/step - loss: 2.1890 - acc: 0.1027 - val_loss: 2.2005 - val_acc: 0.1235\n",
      "\n",
      "Epoch 6/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 777us/step - loss: 2.1763 - acc: 0.1473 - val_loss: 2.1532 - val_acc: 0.1790\n",
      "\n",
      "Epoch 7/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 658us/step - loss: 2.1432 - acc: 0.1575 - val_loss: 2.1532 - val_acc: 0.1481\n",
      "\n",
      "Epoch 8/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 763us/step - loss: 2.1378 - acc: 0.1490 - val_loss: 3.6536 - val_acc: 0.1049\n",
      "\n",
      "Epoch 9/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 655us/step - loss: 2.3006 - acc: 0.1079 - val_loss: 2.2071 - val_acc: 0.1235\n",
      "\n",
      "Epoch 10/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 602us/step - loss: 2.1921 - acc: 0.1199 - val_loss: 2.2055 - val_acc: 0.1235\n",
      "\n",
      "Epoch 11/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 700us/step - loss: 2.1909 - acc: 0.1233 - val_loss: 2.2024 - val_acc: 0.1543\n",
      "\n",
      "Epoch 12/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 622us/step - loss: 2.1886 - acc: 0.1387 - val_loss: 2.2001 - val_acc: 0.1543\n",
      "\n",
      "Epoch 13/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 645us/step - loss: 2.1751 - acc: 0.1336 - val_loss: 2.1579 - val_acc: 0.2778\n",
      "\n",
      "64/64 [==============================]64/64 [==============================] - 0s 246us/step\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a1003\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\a1003\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\a1003\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\wrappers\\scikit_learn.py\", line 157, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"<ipython-input-133-0e22e4ed6ba9>\", line 6, in model_ann_selu_relu\n",
      "    model_ann.add(tf.keras.layers.Dense(n_neurons, activation = active_function, kernel_initializer = kernel_init))\n",
      "  File \"C:\\Users\\a1003\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\layers\\core.py\", line 780, in __init__\n",
      "    kernel_initializer=initializers.get(kernel_initializer),\n",
      "  File \"C:\\Users\\a1003\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\initializers.py\", line 198, in get\n",
      "    return deserialize(config)\n",
      "  File \"C:\\Users\\a1003\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\initializers.py\", line 190, in deserialize\n",
      "    printable_module_name='initializer')\n",
      "  File \"C:\\Users\\a1003\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\utils\\generic_utils.py\", line 154, in deserialize_keras_object\n",
      "    raise ValueError('Unknown ' + printable_module_name + ': ' + class_name)\n",
      "ValueError: Unknown initializer: lecum_normal\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 583 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "583/583 [==============================]583/583 [==============================] - 2s 3ms/step - loss: 2.2626 - acc: 0.1355 - val_loss: 2.1985 - val_acc: 0.1543\n",
      "\n",
      "Epoch 2/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 518us/step - loss: 2.2578 - acc: 0.1355 - val_loss: 2.1957 - val_acc: 0.1543\n",
      "\n",
      "Epoch 3/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 538us/step - loss: 2.2537 - acc: 0.1355 - val_loss: 2.1931 - val_acc: 0.1543\n",
      "\n",
      "Epoch 4/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 533us/step - loss: 2.2499 - acc: 0.1355 - val_loss: 2.1906 - val_acc: 0.1543\n",
      "\n",
      "Epoch 5/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 465us/step - loss: 2.2464 - acc: 0.1355 - val_loss: 2.1886 - val_acc: 0.1543\n",
      "\n",
      "Epoch 6/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 550us/step - loss: 2.2433 - acc: 0.1355 - val_loss: 2.1865 - val_acc: 0.1543\n",
      "\n",
      "Epoch 7/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 554us/step - loss: 2.2400 - acc: 0.1355 - val_loss: 2.1847 - val_acc: 0.1543\n",
      "\n",
      "Epoch 8/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 581us/step - loss: 2.2368 - acc: 0.1355 - val_loss: 2.1830 - val_acc: 0.1543\n",
      "\n",
      "Epoch 9/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 518us/step - loss: 2.2337 - acc: 0.1338 - val_loss: 2.1814 - val_acc: 0.1543\n",
      "\n",
      "Epoch 10/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 553us/step - loss: 2.2309 - acc: 0.1338 - val_loss: 2.1799 - val_acc: 0.1543\n",
      "\n",
      "Epoch 11/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 495us/step - loss: 2.2282 - acc: 0.1338 - val_loss: 2.1786 - val_acc: 0.1543\n",
      "\n",
      "Epoch 12/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 563us/step - loss: 2.2260 - acc: 0.1338 - val_loss: 2.1775 - val_acc: 0.1543\n",
      "\n",
      "Epoch 13/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.2238 - acc: 0.1338 - val_loss: 2.1764 - val_acc: 0.1543\n",
      "\n",
      "Epoch 14/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 502us/step - loss: 2.2217 - acc: 0.1338 - val_loss: 2.1754 - val_acc: 0.1543\n",
      "\n",
      "Epoch 15/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 598us/step - loss: 2.2196 - acc: 0.1338 - val_loss: 2.1745 - val_acc: 0.1543\n",
      "\n",
      "Epoch 16/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 621us/step - loss: 2.2177 - acc: 0.1338 - val_loss: 2.1738 - val_acc: 0.1543\n",
      "\n",
      "Epoch 17/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 579us/step - loss: 2.2160 - acc: 0.1338 - val_loss: 2.1730 - val_acc: 0.1543\n",
      "\n",
      "Epoch 18/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 2.2143 - acc: 0.1338 - val_loss: 2.1723 - val_acc: 0.1543\n",
      "\n",
      "Epoch 19/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 554us/step - loss: 2.2127 - acc: 0.1338 - val_loss: 2.1718 - val_acc: 0.1543\n",
      "\n",
      "Epoch 20/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 498us/step - loss: 2.2112 - acc: 0.1338 - val_loss: 2.1712 - val_acc: 0.1543\n",
      "\n",
      "Epoch 21/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 546us/step - loss: 2.2098 - acc: 0.1338 - val_loss: 2.1706 - val_acc: 0.1543\n",
      "\n",
      "Epoch 22/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 648us/step - loss: 2.2085 - acc: 0.1338 - val_loss: 2.1700 - val_acc: 0.1543\n",
      "\n",
      "Epoch 23/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 582us/step - loss: 2.2072 - acc: 0.1338 - val_loss: 2.1695 - val_acc: 0.1543\n",
      "\n",
      "Epoch 24/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 612us/step - loss: 2.2060 - acc: 0.1338 - val_loss: 2.1690 - val_acc: 0.1543\n",
      "\n",
      "Epoch 25/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 646us/step - loss: 2.2048 - acc: 0.1338 - val_loss: 2.1686 - val_acc: 0.1543\n",
      "\n",
      "Epoch 26/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 540us/step - loss: 2.2037 - acc: 0.1355 - val_loss: 2.1682 - val_acc: 0.1543\n",
      "\n",
      "Epoch 27/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 604us/step - loss: 2.2027 - acc: 0.1355 - val_loss: 2.1678 - val_acc: 0.1543\n",
      "\n",
      "Epoch 28/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 539us/step - loss: 2.2016 - acc: 0.1355 - val_loss: 2.1674 - val_acc: 0.1543\n",
      "\n",
      "Epoch 29/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.2005 - acc: 0.1372 - val_loss: 2.1671 - val_acc: 0.1543\n",
      "\n",
      "Epoch 30/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.1994 - acc: 0.1372 - val_loss: 2.1668 - val_acc: 0.1543\n",
      "\n",
      "Epoch 31/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 2.1983 - acc: 0.1372 - val_loss: 2.1664 - val_acc: 0.1543\n",
      "\n",
      "Epoch 32/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 539us/step - loss: 2.1974 - acc: 0.1372 - val_loss: 2.1660 - val_acc: 0.1543\n",
      "\n",
      "Epoch 33/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 489us/step - loss: 2.1964 - acc: 0.1372 - val_loss: 2.1656 - val_acc: 0.1543\n",
      "\n",
      "Epoch 34/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 515us/step - loss: 2.1955 - acc: 0.1372 - val_loss: 2.1652 - val_acc: 0.1543\n",
      "\n",
      "Epoch 35/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 584us/step - loss: 2.1944 - acc: 0.1372 - val_loss: 2.1649 - val_acc: 0.1543\n",
      "\n",
      "Epoch 36/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 554us/step - loss: 2.1936 - acc: 0.1372 - val_loss: 2.1645 - val_acc: 0.1543\n",
      "\n",
      "Epoch 37/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 548us/step - loss: 2.1927 - acc: 0.1372 - val_loss: 2.1640 - val_acc: 0.1543\n",
      "\n",
      "Epoch 38/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.1919 - acc: 0.1372 - val_loss: 2.1637 - val_acc: 0.1543\n",
      "\n",
      "Epoch 39/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 487us/step - loss: 2.1910 - acc: 0.1372 - val_loss: 2.1633 - val_acc: 0.1543\n",
      "\n",
      "Epoch 40/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 507us/step - loss: 2.1902 - acc: 0.1372 - val_loss: 2.1629 - val_acc: 0.1543\n",
      "\n",
      "Epoch 41/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 2.1894 - acc: 0.1372 - val_loss: 2.1625 - val_acc: 0.1543TA: 0s - loss: 2.2067 - acc: 0.1\n",
      "\n",
      "Epoch 42/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 2.1887 - acc: 0.1372 - val_loss: 2.1622 - val_acc: 0.1543\n",
      "\n",
      "Epoch 43/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 602us/step - loss: 2.1880 - acc: 0.1372 - val_loss: 2.1618 - val_acc: 0.1543\n",
      "\n",
      "Epoch 44/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 572us/step - loss: 2.1873 - acc: 0.1372 - val_loss: 2.1613 - val_acc: 0.1543\n",
      "\n",
      "Epoch 45/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 527us/step - loss: 2.1866 - acc: 0.1372 - val_loss: 2.1609 - val_acc: 0.1543\n",
      "\n",
      "Epoch 46/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 583us/step - loss: 2.1859 - acc: 0.1372 - val_loss: 2.1606 - val_acc: 0.1543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 47/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 517us/step - loss: 2.1853 - acc: 0.1372 - val_loss: 2.1602 - val_acc: 0.1543\n",
      "\n",
      "Epoch 48/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 487us/step - loss: 2.1846 - acc: 0.1372 - val_loss: 2.1599 - val_acc: 0.1543\n",
      "\n",
      "Epoch 49/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 635us/step - loss: 2.1840 - acc: 0.1372 - val_loss: 2.1594 - val_acc: 0.1543\n",
      "\n",
      "Epoch 50/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 588us/step - loss: 2.1834 - acc: 0.1372 - val_loss: 2.1590 - val_acc: 0.1543\n",
      "\n",
      "Epoch 51/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 594us/step - loss: 2.1828 - acc: 0.1372 - val_loss: 2.1587 - val_acc: 0.1543\n",
      "\n",
      "Epoch 52/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 607us/step - loss: 2.1822 - acc: 0.1372 - val_loss: 2.1583 - val_acc: 0.1543\n",
      "\n",
      "Epoch 53/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 568us/step - loss: 2.1816 - acc: 0.1372 - val_loss: 2.1579 - val_acc: 0.1543\n",
      "\n",
      "Epoch 54/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 540us/step - loss: 2.1811 - acc: 0.1372 - val_loss: 2.1576 - val_acc: 0.1543\n",
      "\n",
      "Epoch 55/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 521us/step - loss: 2.1805 - acc: 0.1372 - val_loss: 2.1572 - val_acc: 0.1543\n",
      "\n",
      "Epoch 56/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 600us/step - loss: 2.1799 - acc: 0.1389 - val_loss: 2.1568 - val_acc: 0.1543\n",
      "\n",
      "Epoch 57/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.1794 - acc: 0.1389 - val_loss: 2.1564 - val_acc: 0.1543\n",
      "\n",
      "Epoch 58/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 510us/step - loss: 2.1788 - acc: 0.1389 - val_loss: 2.1560 - val_acc: 0.1543\n",
      "\n",
      "Epoch 59/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 552us/step - loss: 2.1783 - acc: 0.1389 - val_loss: 2.1556 - val_acc: 0.1543\n",
      "\n",
      "Epoch 60/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 628us/step - loss: 2.1777 - acc: 0.1389 - val_loss: 2.1552 - val_acc: 0.1543\n",
      "\n",
      "Epoch 61/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 576us/step - loss: 2.1772 - acc: 0.1389 - val_loss: 2.1548 - val_acc: 0.1543\n",
      "\n",
      "Epoch 62/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 508us/step - loss: 2.1766 - acc: 0.1389 - val_loss: 2.1544 - val_acc: 0.1543\n",
      "\n",
      "Epoch 63/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 515us/step - loss: 2.1761 - acc: 0.1389 - val_loss: 2.1540 - val_acc: 0.1605\n",
      "\n",
      "Epoch 64/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.1756 - acc: 0.1389 - val_loss: 2.1536 - val_acc: 0.1605\n",
      "\n",
      "Epoch 65/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 533us/step - loss: 2.1751 - acc: 0.1389 - val_loss: 2.1532 - val_acc: 0.1605\n",
      "\n",
      "Epoch 66/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 562us/step - loss: 2.1746 - acc: 0.1389 - val_loss: 2.1528 - val_acc: 0.1605\n",
      "\n",
      "Epoch 67/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 560us/step - loss: 2.1740 - acc: 0.1389 - val_loss: 2.1525 - val_acc: 0.1605\n",
      "\n",
      "Epoch 68/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.1736 - acc: 0.1389 - val_loss: 2.1522 - val_acc: 0.1605\n",
      "\n",
      "Epoch 69/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 545us/step - loss: 2.1731 - acc: 0.1389 - val_loss: 2.1517 - val_acc: 0.1605\n",
      "\n",
      "Epoch 70/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 658us/step - loss: 2.1726 - acc: 0.1407 - val_loss: 2.1513 - val_acc: 0.1605\n",
      "\n",
      "Epoch 71/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 524us/step - loss: 2.1721 - acc: 0.1407 - val_loss: 2.1510 - val_acc: 0.1605\n",
      "\n",
      "Epoch 72/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 481us/step - loss: 2.1716 - acc: 0.1407 - val_loss: 2.1506 - val_acc: 0.1605\n",
      "\n",
      "Epoch 73/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 559us/step - loss: 2.1711 - acc: 0.1407 - val_loss: 2.1502 - val_acc: 0.1605TA: 0s - loss: 2.1750 - acc: 0.13\n",
      "\n",
      "Epoch 74/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 518us/step - loss: 2.1706 - acc: 0.1407 - val_loss: 2.1498 - val_acc: 0.1605\n",
      "\n",
      "Epoch 75/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 573us/step - loss: 2.1701 - acc: 0.1407 - val_loss: 2.1494 - val_acc: 0.1605\n",
      "\n",
      "Epoch 76/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 570us/step - loss: 2.1697 - acc: 0.1407 - val_loss: 2.1490 - val_acc: 0.1605\n",
      "\n",
      "Epoch 77/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 2.1692 - acc: 0.1407 - val_loss: 2.1486 - val_acc: 0.1605\n",
      "\n",
      "Epoch 78/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 534us/step - loss: 2.1687 - acc: 0.1407 - val_loss: 2.1483 - val_acc: 0.1605\n",
      "\n",
      "Epoch 79/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 519us/step - loss: 2.1682 - acc: 0.1407 - val_loss: 2.1479 - val_acc: 0.1605\n",
      "\n",
      "Epoch 80/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.1677 - acc: 0.1407 - val_loss: 2.1475 - val_acc: 0.1605\n",
      "\n",
      "Epoch 81/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 495us/step - loss: 2.1672 - acc: 0.1407 - val_loss: 2.1472 - val_acc: 0.1605\n",
      "\n",
      "Epoch 82/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 505us/step - loss: 2.1667 - acc: 0.1407 - val_loss: 2.1468 - val_acc: 0.1605\n",
      "\n",
      "Epoch 83/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 497us/step - loss: 2.1663 - acc: 0.1407 - val_loss: 2.1465 - val_acc: 0.1605\n",
      "\n",
      "Epoch 84/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 593us/step - loss: 2.1658 - acc: 0.1424 - val_loss: 2.1461 - val_acc: 0.1605\n",
      "\n",
      "Epoch 85/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 531us/step - loss: 2.1654 - acc: 0.1424 - val_loss: 2.1458 - val_acc: 0.1605\n",
      "\n",
      "Epoch 86/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 2.1649 - acc: 0.1424 - val_loss: 2.1454 - val_acc: 0.1605\n",
      "\n",
      "Epoch 87/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 574us/step - loss: 2.1644 - acc: 0.1424 - val_loss: 2.1450 - val_acc: 0.1605\n",
      "\n",
      "Epoch 88/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 513us/step - loss: 2.1640 - acc: 0.1424 - val_loss: 2.1446 - val_acc: 0.1667\n",
      "\n",
      "Epoch 89/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 504us/step - loss: 2.1635 - acc: 0.1424 - val_loss: 2.1443 - val_acc: 0.1667\n",
      "\n",
      "Epoch 90/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 527us/step - loss: 2.1631 - acc: 0.1424 - val_loss: 2.1440 - val_acc: 0.1667\n",
      "\n",
      "Epoch 91/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 513us/step - loss: 2.1626 - acc: 0.1424 - val_loss: 2.1436 - val_acc: 0.1728\n",
      "\n",
      "Epoch 92/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 2.1621 - acc: 0.1441 - val_loss: 2.1432 - val_acc: 0.1728\n",
      "\n",
      "Epoch 93/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 545us/step - loss: 2.1617 - acc: 0.1458 - val_loss: 2.1429 - val_acc: 0.1728TA: 0s - loss: 2.1549 - acc: 0.15\n",
      "\n",
      "Epoch 94/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 579us/step - loss: 2.1612 - acc: 0.1458 - val_loss: 2.1425 - val_acc: 0.1728\n",
      "\n",
      "Epoch 95/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 474us/step - loss: 2.1607 - acc: 0.1475 - val_loss: 2.1421 - val_acc: 0.1728\n",
      "\n",
      "Epoch 96/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 496us/step - loss: 2.1602 - acc: 0.1509 - val_loss: 2.1417 - val_acc: 0.1728\n",
      "\n",
      "Epoch 97/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 565us/step - loss: 2.1598 - acc: 0.1509 - val_loss: 2.1413 - val_acc: 0.1728\n",
      "\n",
      "Epoch 98/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 580us/step - loss: 2.1593 - acc: 0.1509 - val_loss: 2.1409 - val_acc: 0.1728\n",
      "\n",
      "Epoch 99/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 515us/step - loss: 2.1588 - acc: 0.1509 - val_loss: 2.1406 - val_acc: 0.1728\n",
      "\n",
      "Epoch 100/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 559us/step - loss: 2.1584 - acc: 0.1509 - val_loss: 2.1402 - val_acc: 0.1728\n",
      "\n",
      "Epoch 101/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 615us/step - loss: 2.1579 - acc: 0.1509 - val_loss: 2.1398 - val_acc: 0.1728\n",
      "\n",
      "Epoch 102/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 555us/step - loss: 2.1574 - acc: 0.1509 - val_loss: 2.1394 - val_acc: 0.1728TA: 0s - loss: 2.1758 - acc: 0.\n",
      "\n",
      "Epoch 103/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 482us/step - loss: 2.1570 - acc: 0.1509 - val_loss: 2.1391 - val_acc: 0.1728\n",
      "\n",
      "Epoch 104/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 574us/step - loss: 2.1565 - acc: 0.1509 - val_loss: 2.1386 - val_acc: 0.1728\n",
      "\n",
      "Epoch 105/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 452us/step - loss: 2.1561 - acc: 0.1509 - val_loss: 2.1383 - val_acc: 0.1728\n",
      "\n",
      "Epoch 106/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 632us/step - loss: 2.1556 - acc: 0.1509 - val_loss: 2.1379 - val_acc: 0.1728\n",
      "\n",
      "Epoch 107/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 469us/step - loss: 2.1551 - acc: 0.1527 - val_loss: 2.1375 - val_acc: 0.1790\n",
      "\n",
      "Epoch 108/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 477us/step - loss: 2.1547 - acc: 0.1527 - val_loss: 2.1372 - val_acc: 0.1728\n",
      "\n",
      "Epoch 109/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 597us/step - loss: 2.1542 - acc: 0.1527 - val_loss: 2.1368 - val_acc: 0.1852\n",
      "\n",
      "Epoch 110/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 570us/step - loss: 2.1538 - acc: 0.1527 - val_loss: 2.1364 - val_acc: 0.1790\n",
      "\n",
      "Epoch 111/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 597us/step - loss: 2.1533 - acc: 0.1527 - val_loss: 2.1360 - val_acc: 0.1790\n",
      "\n",
      "Epoch 112/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 572us/step - loss: 2.1528 - acc: 0.1527 - val_loss: 2.1356 - val_acc: 0.1790\n",
      "\n",
      "Epoch 113/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 578us/step - loss: 2.1524 - acc: 0.1527 - val_loss: 2.1351 - val_acc: 0.1790\n",
      "\n",
      "Epoch 114/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 511us/step - loss: 2.1519 - acc: 0.1527 - val_loss: 2.1348 - val_acc: 0.1790\n",
      "\n",
      "Epoch 115/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 518us/step - loss: 2.1515 - acc: 0.1527 - val_loss: 2.1344 - val_acc: 0.1790\n",
      "\n",
      "Epoch 116/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 538us/step - loss: 2.1510 - acc: 0.1527 - val_loss: 2.1339 - val_acc: 0.1790\n",
      "\n",
      "Epoch 117/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 576us/step - loss: 2.1505 - acc: 0.1527 - val_loss: 2.1335 - val_acc: 0.1790\n",
      "\n",
      "Epoch 118/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 580us/step - loss: 2.1500 - acc: 0.1527 - val_loss: 2.1331 - val_acc: 0.1790\n",
      "\n",
      "Epoch 119/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 600us/step - loss: 2.1496 - acc: 0.1527 - val_loss: 2.1327 - val_acc: 0.1790\n",
      "\n",
      "Epoch 120/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 528us/step - loss: 2.1491 - acc: 0.1527 - val_loss: 2.1324 - val_acc: 0.1790\n",
      "\n",
      "Epoch 121/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 567us/step - loss: 2.1486 - acc: 0.1527 - val_loss: 2.1320 - val_acc: 0.1790\n",
      "\n",
      "Epoch 122/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 743us/step - loss: 2.1481 - acc: 0.1527 - val_loss: 2.1316 - val_acc: 0.1790\n",
      "\n",
      "Epoch 123/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 662us/step - loss: 2.1476 - acc: 0.1527 - val_loss: 2.1311 - val_acc: 0.1790\n",
      "\n",
      "Epoch 124/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 601us/step - loss: 2.1471 - acc: 0.1527 - val_loss: 2.1306 - val_acc: 0.1790\n",
      "\n",
      "Epoch 125/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 575us/step - loss: 2.1466 - acc: 0.1527 - val_loss: 2.1302 - val_acc: 0.1790\n",
      "\n",
      "Epoch 126/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 508us/step - loss: 2.1461 - acc: 0.1527 - val_loss: 2.1297 - val_acc: 0.1790\n",
      "\n",
      "Epoch 127/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 576us/step - loss: 2.1456 - acc: 0.1527 - val_loss: 2.1293 - val_acc: 0.1790\n",
      "\n",
      "Epoch 128/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 569us/step - loss: 2.1450 - acc: 0.1527 - val_loss: 2.1289 - val_acc: 0.1852\n",
      "\n",
      "Epoch 129/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 545us/step - loss: 2.1445 - acc: 0.1527 - val_loss: 2.1284 - val_acc: 0.1852\n",
      "\n",
      "Epoch 130/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 571us/step - loss: 2.1440 - acc: 0.1544 - val_loss: 2.1279 - val_acc: 0.1852\n",
      "\n",
      "Epoch 131/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 495us/step - loss: 2.1435 - acc: 0.1544 - val_loss: 2.1274 - val_acc: 0.1852\n",
      "\n",
      "Epoch 132/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 615us/step - loss: 2.1429 - acc: 0.1544 - val_loss: 2.1270 - val_acc: 0.1852\n",
      "\n",
      "Epoch 133/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 491us/step - loss: 2.1424 - acc: 0.1561 - val_loss: 2.1265 - val_acc: 0.1852\n",
      "\n",
      "Epoch 134/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 568us/step - loss: 2.1419 - acc: 0.1561 - val_loss: 2.1261 - val_acc: 0.1852\n",
      "\n",
      "Epoch 135/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 540us/step - loss: 2.1414 - acc: 0.1561 - val_loss: 2.1256 - val_acc: 0.1852\n",
      "\n",
      "Epoch 136/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 513us/step - loss: 2.1408 - acc: 0.1561 - val_loss: 2.1251 - val_acc: 0.1852\n",
      "\n",
      "Epoch 137/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 539us/step - loss: 2.1402 - acc: 0.1578 - val_loss: 2.1247 - val_acc: 0.1852\n",
      "\n",
      "Epoch 138/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 555us/step - loss: 2.1397 - acc: 0.1578 - val_loss: 2.1240 - val_acc: 0.1852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 139/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 471us/step - loss: 2.1391 - acc: 0.1578 - val_loss: 2.1236 - val_acc: 0.1852\n",
      "\n",
      "Epoch 140/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 517us/step - loss: 2.1385 - acc: 0.1578 - val_loss: 2.1231 - val_acc: 0.1852\n",
      "\n",
      "Epoch 141/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 570us/step - loss: 2.1379 - acc: 0.1578 - val_loss: 2.1226 - val_acc: 0.1852\n",
      "\n",
      "Epoch 142/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 633us/step - loss: 2.1373 - acc: 0.1578 - val_loss: 2.1221 - val_acc: 0.1914\n",
      "\n",
      "Epoch 143/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 551us/step - loss: 2.1367 - acc: 0.1578 - val_loss: 2.1215 - val_acc: 0.1914\n",
      "\n",
      "Epoch 144/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 498us/step - loss: 2.1361 - acc: 0.1595 - val_loss: 2.1210 - val_acc: 0.1914\n",
      "\n",
      "Epoch 145/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 530us/step - loss: 2.1355 - acc: 0.1612 - val_loss: 2.1204 - val_acc: 0.1914\n",
      "\n",
      "Epoch 146/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 569us/step - loss: 2.1348 - acc: 0.1595 - val_loss: 2.1199 - val_acc: 0.1914\n",
      "\n",
      "Epoch 147/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 486us/step - loss: 2.1342 - acc: 0.1612 - val_loss: 2.1193 - val_acc: 0.1914\n",
      "\n",
      "Epoch 148/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 572us/step - loss: 2.1336 - acc: 0.1681 - val_loss: 2.1188 - val_acc: 0.1914\n",
      "\n",
      "Epoch 149/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 576us/step - loss: 2.1329 - acc: 0.1664 - val_loss: 2.1183 - val_acc: 0.1975TA: 0s - loss: 2.1408 - acc: 0.1\n",
      "\n",
      "Epoch 150/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 500us/step - loss: 2.1323 - acc: 0.1664 - val_loss: 2.1176 - val_acc: 0.1975\n",
      "\n",
      "Epoch 151/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 598us/step - loss: 2.1316 - acc: 0.1715 - val_loss: 2.1171 - val_acc: 0.1975\n",
      "\n",
      "Epoch 152/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 671us/step - loss: 2.1310 - acc: 0.1698 - val_loss: 2.1165 - val_acc: 0.1975\n",
      "\n",
      "Epoch 153/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 561us/step - loss: 2.1303 - acc: 0.1715 - val_loss: 2.1159 - val_acc: 0.1975\n",
      "\n",
      "Epoch 154/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 462us/step - loss: 2.1297 - acc: 0.1715 - val_loss: 2.1152 - val_acc: 0.1975\n",
      "\n",
      "Epoch 155/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 486us/step - loss: 2.1290 - acc: 0.1732 - val_loss: 2.1146 - val_acc: 0.1975\n",
      "\n",
      "Epoch 156/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 602us/step - loss: 2.1284 - acc: 0.1732 - val_loss: 2.1140 - val_acc: 0.1975\n",
      "\n",
      "Epoch 157/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 532us/step - loss: 2.1277 - acc: 0.1732 - val_loss: 2.1132 - val_acc: 0.2037\n",
      "\n",
      "Epoch 158/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 571us/step - loss: 2.1270 - acc: 0.1732 - val_loss: 2.1126 - val_acc: 0.2037\n",
      "\n",
      "Epoch 159/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 575us/step - loss: 2.1263 - acc: 0.1732 - val_loss: 2.1118 - val_acc: 0.2099\n",
      "\n",
      "Epoch 160/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 654us/step - loss: 2.1256 - acc: 0.1732 - val_loss: 2.1112 - val_acc: 0.2099\n",
      "\n",
      "Epoch 161/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 529us/step - loss: 2.1250 - acc: 0.1732 - val_loss: 2.1106 - val_acc: 0.2099\n",
      "\n",
      "Epoch 162/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 505us/step - loss: 2.1243 - acc: 0.1750 - val_loss: 2.1100 - val_acc: 0.2037\n",
      "\n",
      "Epoch 163/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 515us/step - loss: 2.1236 - acc: 0.1784 - val_loss: 2.1093 - val_acc: 0.2037\n",
      "\n",
      "Epoch 164/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 526us/step - loss: 2.1230 - acc: 0.1801 - val_loss: 2.1086 - val_acc: 0.2037\n",
      "\n",
      "Epoch 165/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 580us/step - loss: 2.1223 - acc: 0.1801 - val_loss: 2.1081 - val_acc: 0.2037\n",
      "\n",
      "Epoch 166/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 523us/step - loss: 2.1215 - acc: 0.1818 - val_loss: 2.1073 - val_acc: 0.2037\n",
      "\n",
      "Epoch 167/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 509us/step - loss: 2.1208 - acc: 0.1818 - val_loss: 2.1067 - val_acc: 0.2099\n",
      "\n",
      "Epoch 168/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 2.1201 - acc: 0.1835 - val_loss: 2.1060 - val_acc: 0.2099\n",
      "\n",
      "Epoch 169/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 584us/step - loss: 2.1194 - acc: 0.1818 - val_loss: 2.1054 - val_acc: 0.2160\n",
      "\n",
      "Epoch 170/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 532us/step - loss: 2.1187 - acc: 0.1835 - val_loss: 2.1047 - val_acc: 0.2160\n",
      "\n",
      "Epoch 171/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 541us/step - loss: 2.1180 - acc: 0.1835 - val_loss: 2.1039 - val_acc: 0.2160\n",
      "\n",
      "Epoch 172/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 619us/step - loss: 2.1172 - acc: 0.1835 - val_loss: 2.1032 - val_acc: 0.2160\n",
      "\n",
      "Epoch 173/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 724us/step - loss: 2.1165 - acc: 0.1835 - val_loss: 2.1026 - val_acc: 0.2160\n",
      "\n",
      "Epoch 174/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 471us/step - loss: 2.1158 - acc: 0.1870 - val_loss: 2.1018 - val_acc: 0.2222\n",
      "\n",
      "Epoch 175/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 529us/step - loss: 2.1150 - acc: 0.1852 - val_loss: 2.1010 - val_acc: 0.2222\n",
      "\n",
      "Epoch 176/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 511us/step - loss: 2.1142 - acc: 0.1852 - val_loss: 2.1002 - val_acc: 0.2222\n",
      "\n",
      "Epoch 177/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 519us/step - loss: 2.1134 - acc: 0.1870 - val_loss: 2.0994 - val_acc: 0.2222\n",
      "\n",
      "Epoch 178/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 566us/step - loss: 2.1127 - acc: 0.1852 - val_loss: 2.0986 - val_acc: 0.2222\n",
      "\n",
      "Epoch 179/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 572us/step - loss: 2.1119 - acc: 0.1852 - val_loss: 2.0978 - val_acc: 0.2222\n",
      "\n",
      "Epoch 180/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 577us/step - loss: 2.1111 - acc: 0.1852 - val_loss: 2.0970 - val_acc: 0.2222\n",
      "\n",
      "Epoch 181/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 485us/step - loss: 2.1103 - acc: 0.1852 - val_loss: 2.0962 - val_acc: 0.2407\n",
      "\n",
      "Epoch 182/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 597us/step - loss: 2.1095 - acc: 0.1904 - val_loss: 2.0952 - val_acc: 0.2346\n",
      "\n",
      "Epoch 183/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 571us/step - loss: 2.1086 - acc: 0.1852 - val_loss: 2.0945 - val_acc: 0.2346\n",
      "\n",
      "Epoch 184/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 581us/step - loss: 2.1079 - acc: 0.1904 - val_loss: 2.0938 - val_acc: 0.2346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 185/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 511us/step - loss: 2.1070 - acc: 0.1904 - val_loss: 2.0930 - val_acc: 0.2407\n",
      "\n",
      "Epoch 186/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 519us/step - loss: 2.1062 - acc: 0.1904 - val_loss: 2.0922 - val_acc: 0.2407\n",
      "\n",
      "Epoch 187/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 565us/step - loss: 2.1054 - acc: 0.1921 - val_loss: 2.0915 - val_acc: 0.2407\n",
      "\n",
      "Epoch 188/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.1045 - acc: 0.1921 - val_loss: 2.0907 - val_acc: 0.2407\n",
      "\n",
      "Epoch 189/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 508us/step - loss: 2.1037 - acc: 0.1938 - val_loss: 2.0899 - val_acc: 0.2407\n",
      "\n",
      "Epoch 190/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 519us/step - loss: 2.1029 - acc: 0.1938 - val_loss: 2.0892 - val_acc: 0.2407\n",
      "\n",
      "Epoch 191/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 498us/step - loss: 2.1021 - acc: 0.1938 - val_loss: 2.0883 - val_acc: 0.2407\n",
      "\n",
      "Epoch 192/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 531us/step - loss: 2.1012 - acc: 0.1921 - val_loss: 2.0874 - val_acc: 0.2407\n",
      "\n",
      "Epoch 193/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 515us/step - loss: 2.1003 - acc: 0.1921 - val_loss: 2.0866 - val_acc: 0.2407\n",
      "\n",
      "Epoch 194/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 585us/step - loss: 2.0995 - acc: 0.1955 - val_loss: 2.0858 - val_acc: 0.2407\n",
      "\n",
      "Epoch 195/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 521us/step - loss: 2.0986 - acc: 0.1973 - val_loss: 2.0850 - val_acc: 0.2407\n",
      "\n",
      "Epoch 196/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 578us/step - loss: 2.0978 - acc: 0.1973 - val_loss: 2.0841 - val_acc: 0.2407\n",
      "\n",
      "Epoch 197/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 488us/step - loss: 2.0969 - acc: 0.1990 - val_loss: 2.0832 - val_acc: 0.2407\n",
      "\n",
      "Epoch 198/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 593us/step - loss: 2.0960 - acc: 0.1990 - val_loss: 2.0824 - val_acc: 0.2407\n",
      "\n",
      "Epoch 199/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 477us/step - loss: 2.0951 - acc: 0.1990 - val_loss: 2.0816 - val_acc: 0.2407\n",
      "\n",
      "Epoch 200/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 580us/step - loss: 2.0942 - acc: 0.1990 - val_loss: 2.0807 - val_acc: 0.2531\n",
      "\n",
      "65/65 [==============================]65/65 [==============================] - 0s 259us/step\n",
      "\n",
      "Train on 583 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "583/583 [==============================]583/583 [==============================] - 2s 3ms/step - loss: 2.2959 - acc: 0.1046 - val_loss: 2.2604 - val_acc: 0.1605\n",
      "\n",
      "Epoch 2/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 581us/step - loss: 2.2900 - acc: 0.1046 - val_loss: 2.2563 - val_acc: 0.1543\n",
      "\n",
      "Epoch 3/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 541us/step - loss: 2.2847 - acc: 0.1063 - val_loss: 2.2525 - val_acc: 0.1543\n",
      "\n",
      "Epoch 4/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 491us/step - loss: 2.2799 - acc: 0.1115 - val_loss: 2.2486 - val_acc: 0.1481\n",
      "\n",
      "Epoch 5/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 569us/step - loss: 2.2749 - acc: 0.1098 - val_loss: 2.2451 - val_acc: 0.1481\n",
      "\n",
      "Epoch 6/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 508us/step - loss: 2.2702 - acc: 0.1098 - val_loss: 2.2424 - val_acc: 0.1543\n",
      "\n",
      "Epoch 7/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 458us/step - loss: 2.2665 - acc: 0.1098 - val_loss: 2.2399 - val_acc: 0.1543\n",
      "\n",
      "Epoch 8/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 490us/step - loss: 2.2630 - acc: 0.1132 - val_loss: 2.2376 - val_acc: 0.1481\n",
      "\n",
      "Epoch 9/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 545us/step - loss: 2.2597 - acc: 0.1149 - val_loss: 2.2354 - val_acc: 0.1481\n",
      "\n",
      "Epoch 10/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 598us/step - loss: 2.2566 - acc: 0.1166 - val_loss: 2.2331 - val_acc: 0.1420\n",
      "\n",
      "Epoch 11/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 524us/step - loss: 2.2534 - acc: 0.1166 - val_loss: 2.2310 - val_acc: 0.1481\n",
      "\n",
      "Epoch 12/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 564us/step - loss: 2.2506 - acc: 0.1184 - val_loss: 2.2291 - val_acc: 0.1543\n",
      "\n",
      "Epoch 13/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 537us/step - loss: 2.2479 - acc: 0.1166 - val_loss: 2.2272 - val_acc: 0.1605\n",
      "\n",
      "Epoch 14/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 604us/step - loss: 2.2454 - acc: 0.1184 - val_loss: 2.2253 - val_acc: 0.1543\n",
      "\n",
      "Epoch 15/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 684us/step - loss: 2.2427 - acc: 0.1201 - val_loss: 2.2237 - val_acc: 0.1543\n",
      "\n",
      "Epoch 16/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 597us/step - loss: 2.2405 - acc: 0.1184 - val_loss: 2.2221 - val_acc: 0.1605\n",
      "\n",
      "Epoch 17/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 705us/step - loss: 2.2383 - acc: 0.1184 - val_loss: 2.2205 - val_acc: 0.1543\n",
      "\n",
      "Epoch 18/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 502us/step - loss: 2.2361 - acc: 0.1184 - val_loss: 2.2191 - val_acc: 0.1543\n",
      "\n",
      "Epoch 19/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 571us/step - loss: 2.2340 - acc: 0.1201 - val_loss: 2.2176 - val_acc: 0.1728\n",
      "\n",
      "Epoch 20/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 539us/step - loss: 2.2319 - acc: 0.1184 - val_loss: 2.2161 - val_acc: 0.1728\n",
      "\n",
      "Epoch 21/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 503us/step - loss: 2.2300 - acc: 0.1235 - val_loss: 2.2146 - val_acc: 0.1790\n",
      "\n",
      "Epoch 22/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 559us/step - loss: 2.2281 - acc: 0.1269 - val_loss: 2.2130 - val_acc: 0.1914\n",
      "\n",
      "Epoch 23/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 515us/step - loss: 2.2261 - acc: 0.1269 - val_loss: 2.2118 - val_acc: 0.1852\n",
      "\n",
      "Epoch 24/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 541us/step - loss: 2.2244 - acc: 0.1269 - val_loss: 2.2106 - val_acc: 0.1914\n",
      "\n",
      "Epoch 25/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 540us/step - loss: 2.2228 - acc: 0.1321 - val_loss: 2.2096 - val_acc: 0.1975\n",
      "\n",
      "Epoch 26/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 2.2213 - acc: 0.1338 - val_loss: 2.2084 - val_acc: 0.1914\n",
      "\n",
      "Epoch 27/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 2.2197 - acc: 0.1407 - val_loss: 2.2073 - val_acc: 0.1975\n",
      "\n",
      "Epoch 28/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 604us/step - loss: 2.2181 - acc: 0.1424 - val_loss: 2.2063 - val_acc: 0.1975\n",
      "\n",
      "Epoch 29/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 593us/step - loss: 2.2167 - acc: 0.1458 - val_loss: 2.2054 - val_acc: 0.1975\n",
      "\n",
      "Epoch 30/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.2154 - acc: 0.1527 - val_loss: 2.2045 - val_acc: 0.1975\n",
      "\n",
      "Epoch 31/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 570us/step - loss: 2.2141 - acc: 0.1527 - val_loss: 2.2035 - val_acc: 0.1975\n",
      "\n",
      "Epoch 32/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 574us/step - loss: 2.2129 - acc: 0.1527 - val_loss: 2.2027 - val_acc: 0.1914\n",
      "\n",
      "Epoch 33/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 599us/step - loss: 2.2116 - acc: 0.1492 - val_loss: 2.2019 - val_acc: 0.1852\n",
      "\n",
      "Epoch 34/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 566us/step - loss: 2.2105 - acc: 0.1527 - val_loss: 2.2011 - val_acc: 0.1852\n",
      "\n",
      "Epoch 35/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 509us/step - loss: 2.2094 - acc: 0.1527 - val_loss: 2.2003 - val_acc: 0.1852\n",
      "\n",
      "Epoch 36/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 545us/step - loss: 2.2083 - acc: 0.1578 - val_loss: 2.1996 - val_acc: 0.1852\n",
      "\n",
      "Epoch 37/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 610us/step - loss: 2.2072 - acc: 0.1630 - val_loss: 2.1990 - val_acc: 0.1852\n",
      "\n",
      "Epoch 38/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 625us/step - loss: 2.2062 - acc: 0.1681 - val_loss: 2.1983 - val_acc: 0.1852\n",
      "\n",
      "Epoch 39/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 551us/step - loss: 2.2051 - acc: 0.1681 - val_loss: 2.1977 - val_acc: 0.1852\n",
      "\n",
      "Epoch 40/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 619us/step - loss: 2.2041 - acc: 0.1698 - val_loss: 2.1970 - val_acc: 0.1852\n",
      "\n",
      "Epoch 41/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 629us/step - loss: 2.2031 - acc: 0.1715 - val_loss: 2.1965 - val_acc: 0.1790\n",
      "\n",
      "Epoch 42/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 545us/step - loss: 2.2022 - acc: 0.1715 - val_loss: 2.1958 - val_acc: 0.1852\n",
      "\n",
      "Epoch 43/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 596us/step - loss: 2.2012 - acc: 0.1732 - val_loss: 2.1952 - val_acc: 0.1790\n",
      "\n",
      "Epoch 44/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 517us/step - loss: 2.2003 - acc: 0.1732 - val_loss: 2.1946 - val_acc: 0.1728\n",
      "\n",
      "Epoch 45/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 568us/step - loss: 2.1995 - acc: 0.1732 - val_loss: 2.1941 - val_acc: 0.1728\n",
      "\n",
      "Epoch 46/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 505us/step - loss: 2.1986 - acc: 0.1750 - val_loss: 2.1936 - val_acc: 0.1728\n",
      "\n",
      "Epoch 47/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.1978 - acc: 0.1767 - val_loss: 2.1930 - val_acc: 0.1728\n",
      "\n",
      "Epoch 48/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 524us/step - loss: 2.1969 - acc: 0.1801 - val_loss: 2.1924 - val_acc: 0.1790\n",
      "\n",
      "Epoch 49/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 588us/step - loss: 2.1960 - acc: 0.1818 - val_loss: 2.1918 - val_acc: 0.1852\n",
      "\n",
      "Epoch 50/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 505us/step - loss: 2.1953 - acc: 0.1835 - val_loss: 2.1913 - val_acc: 0.1852\n",
      "\n",
      "Epoch 51/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 592us/step - loss: 2.1945 - acc: 0.1835 - val_loss: 2.1906 - val_acc: 0.1852\n",
      "\n",
      "Epoch 52/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 596us/step - loss: 2.1936 - acc: 0.1852 - val_loss: 2.1901 - val_acc: 0.1852\n",
      "\n",
      "Epoch 53/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 518us/step - loss: 2.1928 - acc: 0.1887 - val_loss: 2.1895 - val_acc: 0.1852\n",
      "\n",
      "Epoch 54/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 716us/step - loss: 2.1920 - acc: 0.1887 - val_loss: 2.1890 - val_acc: 0.1914\n",
      "\n",
      "Epoch 55/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 545us/step - loss: 2.1912 - acc: 0.1870 - val_loss: 2.1885 - val_acc: 0.1914\n",
      "\n",
      "Epoch 56/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 513us/step - loss: 2.1905 - acc: 0.1887 - val_loss: 2.1879 - val_acc: 0.1914\n",
      "\n",
      "Epoch 57/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 572us/step - loss: 2.1897 - acc: 0.1887 - val_loss: 2.1873 - val_acc: 0.1975\n",
      "\n",
      "Epoch 58/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 628us/step - loss: 2.1889 - acc: 0.1852 - val_loss: 2.1868 - val_acc: 0.1975\n",
      "\n",
      "Epoch 59/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 506us/step - loss: 2.1882 - acc: 0.1852 - val_loss: 2.1862 - val_acc: 0.1975\n",
      "\n",
      "Epoch 60/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 578us/step - loss: 2.1875 - acc: 0.1835 - val_loss: 2.1856 - val_acc: 0.1975\n",
      "\n",
      "Epoch 61/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 570us/step - loss: 2.1867 - acc: 0.1870 - val_loss: 2.1849 - val_acc: 0.1975\n",
      "\n",
      "Epoch 62/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 550us/step - loss: 2.1859 - acc: 0.1887 - val_loss: 2.1844 - val_acc: 0.1975\n",
      "\n",
      "Epoch 63/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 508us/step - loss: 2.1852 - acc: 0.1887 - val_loss: 2.1839 - val_acc: 0.1975\n",
      "\n",
      "Epoch 64/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 487us/step - loss: 2.1845 - acc: 0.1887 - val_loss: 2.1833 - val_acc: 0.2037\n",
      "\n",
      "Epoch 65/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 607us/step - loss: 2.1836 - acc: 0.1870 - val_loss: 2.1827 - val_acc: 0.2037\n",
      "\n",
      "Epoch 66/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 559us/step - loss: 2.1829 - acc: 0.1887 - val_loss: 2.1821 - val_acc: 0.2037\n",
      "\n",
      "Epoch 67/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 520us/step - loss: 2.1820 - acc: 0.1955 - val_loss: 2.1816 - val_acc: 0.2037\n",
      "\n",
      "Epoch 68/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 604us/step - loss: 2.1812 - acc: 0.1921 - val_loss: 2.1810 - val_acc: 0.2099\n",
      "\n",
      "Epoch 69/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 545us/step - loss: 2.1804 - acc: 0.1955 - val_loss: 2.1804 - val_acc: 0.2099\n",
      "\n",
      "Epoch 70/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 629us/step - loss: 2.1797 - acc: 0.1938 - val_loss: 2.1799 - val_acc: 0.2099\n",
      "\n",
      "Epoch 71/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 586us/step - loss: 2.1789 - acc: 0.1938 - val_loss: 2.1793 - val_acc: 0.2099\n",
      "\n",
      "Epoch 72/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 500us/step - loss: 2.1781 - acc: 0.1955 - val_loss: 2.1787 - val_acc: 0.2099\n",
      "\n",
      "Epoch 73/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.1773 - acc: 0.1973 - val_loss: 2.1782 - val_acc: 0.2099\n",
      "\n",
      "Epoch 74/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.1766 - acc: 0.1973 - val_loss: 2.1776 - val_acc: 0.2099\n",
      "\n",
      "Epoch 75/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 510us/step - loss: 2.1758 - acc: 0.1955 - val_loss: 2.1770 - val_acc: 0.2037\n",
      "\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================]583/583 [==============================] - 0s 518us/step - loss: 2.1750 - acc: 0.1973 - val_loss: 2.1763 - val_acc: 0.2037\n",
      "\n",
      "Epoch 77/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.1742 - acc: 0.1973 - val_loss: 2.1758 - val_acc: 0.2037\n",
      "\n",
      "Epoch 78/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 558us/step - loss: 2.1735 - acc: 0.1955 - val_loss: 2.1751 - val_acc: 0.2037\n",
      "\n",
      "Epoch 79/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 592us/step - loss: 2.1727 - acc: 0.1938 - val_loss: 2.1745 - val_acc: 0.2037\n",
      "\n",
      "Epoch 80/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 588us/step - loss: 2.1720 - acc: 0.1955 - val_loss: 2.1739 - val_acc: 0.2037\n",
      "\n",
      "Epoch 81/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 559us/step - loss: 2.1712 - acc: 0.2007 - val_loss: 2.1732 - val_acc: 0.2037\n",
      "\n",
      "Epoch 82/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 585us/step - loss: 2.1705 - acc: 0.2024 - val_loss: 2.1726 - val_acc: 0.2037\n",
      "\n",
      "Epoch 83/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 621us/step - loss: 2.1697 - acc: 0.2024 - val_loss: 2.1720 - val_acc: 0.2037\n",
      "\n",
      "Epoch 84/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 554us/step - loss: 2.1689 - acc: 0.2024 - val_loss: 2.1714 - val_acc: 0.2099\n",
      "\n",
      "Epoch 85/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 512us/step - loss: 2.1682 - acc: 0.2058 - val_loss: 2.1708 - val_acc: 0.2160\n",
      "\n",
      "Epoch 86/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 594us/step - loss: 2.1674 - acc: 0.2075 - val_loss: 2.1702 - val_acc: 0.2222\n",
      "\n",
      "Epoch 87/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 547us/step - loss: 2.1667 - acc: 0.2075 - val_loss: 2.1697 - val_acc: 0.2222\n",
      "\n",
      "Epoch 88/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 518us/step - loss: 2.1660 - acc: 0.2075 - val_loss: 2.1690 - val_acc: 0.2222\n",
      "\n",
      "Epoch 89/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 540us/step - loss: 2.1653 - acc: 0.2075 - val_loss: 2.1684 - val_acc: 0.2222\n",
      "\n",
      "Epoch 90/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.1646 - acc: 0.2075 - val_loss: 2.1678 - val_acc: 0.2222TA: 0s - loss: 2.1635 - acc: 0.2\n",
      "\n",
      "Epoch 91/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.1639 - acc: 0.2093 - val_loss: 2.1672 - val_acc: 0.2222\n",
      "\n",
      "Epoch 92/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 541us/step - loss: 2.1632 - acc: 0.2075 - val_loss: 2.1666 - val_acc: 0.2346\n",
      "\n",
      "Epoch 93/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 575us/step - loss: 2.1625 - acc: 0.2093 - val_loss: 2.1660 - val_acc: 0.2407\n",
      "\n",
      "Epoch 94/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 575us/step - loss: 2.1618 - acc: 0.2110 - val_loss: 2.1654 - val_acc: 0.2407\n",
      "\n",
      "Epoch 95/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 625us/step - loss: 2.1611 - acc: 0.2110 - val_loss: 2.1648 - val_acc: 0.2407\n",
      "\n",
      "Epoch 96/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 574us/step - loss: 2.1605 - acc: 0.2110 - val_loss: 2.1642 - val_acc: 0.2407\n",
      "\n",
      "Epoch 97/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 523us/step - loss: 2.1598 - acc: 0.2127 - val_loss: 2.1636 - val_acc: 0.2407\n",
      "\n",
      "Epoch 98/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 528us/step - loss: 2.1591 - acc: 0.2127 - val_loss: 2.1629 - val_acc: 0.2407\n",
      "\n",
      "Epoch 99/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 547us/step - loss: 2.1584 - acc: 0.2178 - val_loss: 2.1623 - val_acc: 0.2407\n",
      "\n",
      "Epoch 100/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 446us/step - loss: 2.1578 - acc: 0.2178 - val_loss: 2.1616 - val_acc: 0.2407\n",
      "\n",
      "Epoch 101/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 491us/step - loss: 2.1571 - acc: 0.2178 - val_loss: 2.1610 - val_acc: 0.2407\n",
      "\n",
      "Epoch 102/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 538us/step - loss: 2.1564 - acc: 0.2178 - val_loss: 2.1604 - val_acc: 0.2407\n",
      "\n",
      "Epoch 103/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 553us/step - loss: 2.1557 - acc: 0.2178 - val_loss: 2.1598 - val_acc: 0.2469\n",
      "\n",
      "Epoch 104/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 597us/step - loss: 2.1550 - acc: 0.2178 - val_loss: 2.1592 - val_acc: 0.2469\n",
      "\n",
      "Epoch 105/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 548us/step - loss: 2.1543 - acc: 0.2161 - val_loss: 2.1585 - val_acc: 0.2469\n",
      "\n",
      "Epoch 106/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 488us/step - loss: 2.1536 - acc: 0.2178 - val_loss: 2.1579 - val_acc: 0.2469\n",
      "\n",
      "Epoch 107/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 2.1529 - acc: 0.2178 - val_loss: 2.1573 - val_acc: 0.2469\n",
      "\n",
      "Epoch 108/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 624us/step - loss: 2.1522 - acc: 0.2178 - val_loss: 2.1566 - val_acc: 0.2469\n",
      "\n",
      "Epoch 109/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 547us/step - loss: 2.1515 - acc: 0.2196 - val_loss: 2.1560 - val_acc: 0.2469\n",
      "\n",
      "Epoch 110/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 570us/step - loss: 2.1508 - acc: 0.2196 - val_loss: 2.1553 - val_acc: 0.2469\n",
      "\n",
      "Epoch 111/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 539us/step - loss: 2.1501 - acc: 0.2196 - val_loss: 2.1547 - val_acc: 0.2346\n",
      "\n",
      "Epoch 112/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 563us/step - loss: 2.1494 - acc: 0.2196 - val_loss: 2.1540 - val_acc: 0.2346\n",
      "\n",
      "Epoch 113/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 608us/step - loss: 2.1487 - acc: 0.2196 - val_loss: 2.1534 - val_acc: 0.2346\n",
      "\n",
      "Epoch 114/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 527us/step - loss: 2.1480 - acc: 0.2196 - val_loss: 2.1528 - val_acc: 0.2346\n",
      "\n",
      "Epoch 115/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 550us/step - loss: 2.1474 - acc: 0.2196 - val_loss: 2.1521 - val_acc: 0.2407\n",
      "\n",
      "Epoch 116/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 554us/step - loss: 2.1467 - acc: 0.2196 - val_loss: 2.1515 - val_acc: 0.2407\n",
      "\n",
      "Epoch 117/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 569us/step - loss: 2.1460 - acc: 0.2178 - val_loss: 2.1508 - val_acc: 0.2407\n",
      "\n",
      "Epoch 118/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 512us/step - loss: 2.1453 - acc: 0.2178 - val_loss: 2.1502 - val_acc: 0.2346\n",
      "\n",
      "Epoch 119/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 545us/step - loss: 2.1446 - acc: 0.2196 - val_loss: 2.1495 - val_acc: 0.2407\n",
      "\n",
      "Epoch 120/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 564us/step - loss: 2.1439 - acc: 0.2230 - val_loss: 2.1489 - val_acc: 0.2407\n",
      "\n",
      "Epoch 121/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 510us/step - loss: 2.1432 - acc: 0.2247 - val_loss: 2.1482 - val_acc: 0.2407\n",
      "\n",
      "Epoch 122/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================]583/583 [==============================] - 0s 485us/step - loss: 2.1425 - acc: 0.2230 - val_loss: 2.1475 - val_acc: 0.2407\n",
      "\n",
      "Epoch 123/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 522us/step - loss: 2.1417 - acc: 0.2230 - val_loss: 2.1468 - val_acc: 0.2407\n",
      "\n",
      "Epoch 124/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 547us/step - loss: 2.1410 - acc: 0.2247 - val_loss: 2.1461 - val_acc: 0.2407\n",
      "\n",
      "Epoch 125/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 572us/step - loss: 2.1403 - acc: 0.2230 - val_loss: 2.1454 - val_acc: 0.2407\n",
      "\n",
      "Epoch 126/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 2.1395 - acc: 0.2230 - val_loss: 2.1448 - val_acc: 0.2407\n",
      "\n",
      "Epoch 127/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 541us/step - loss: 2.1388 - acc: 0.2230 - val_loss: 2.1441 - val_acc: 0.2407\n",
      "\n",
      "Epoch 128/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 517us/step - loss: 2.1381 - acc: 0.2230 - val_loss: 2.1434 - val_acc: 0.2469\n",
      "\n",
      "Epoch 129/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 604us/step - loss: 2.1374 - acc: 0.2230 - val_loss: 2.1428 - val_acc: 0.2469\n",
      "\n",
      "Epoch 130/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 620us/step - loss: 2.1367 - acc: 0.2230 - val_loss: 2.1421 - val_acc: 0.2469\n",
      "\n",
      "Epoch 131/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 556us/step - loss: 2.1360 - acc: 0.2213 - val_loss: 2.1414 - val_acc: 0.2469\n",
      "\n",
      "Epoch 132/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 561us/step - loss: 2.1352 - acc: 0.2230 - val_loss: 2.1407 - val_acc: 0.2531\n",
      "\n",
      "Epoch 133/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 572us/step - loss: 2.1345 - acc: 0.2230 - val_loss: 2.1400 - val_acc: 0.2531\n",
      "\n",
      "Epoch 134/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 600us/step - loss: 2.1337 - acc: 0.2230 - val_loss: 2.1392 - val_acc: 0.2531\n",
      "\n",
      "Epoch 135/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 539us/step - loss: 2.1330 - acc: 0.2230 - val_loss: 2.1384 - val_acc: 0.2531\n",
      "\n",
      "Epoch 136/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 571us/step - loss: 2.1322 - acc: 0.2230 - val_loss: 2.1377 - val_acc: 0.2531\n",
      "\n",
      "Epoch 137/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 568us/step - loss: 2.1314 - acc: 0.2230 - val_loss: 2.1369 - val_acc: 0.2531\n",
      "\n",
      "Epoch 138/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 552us/step - loss: 2.1307 - acc: 0.2230 - val_loss: 2.1363 - val_acc: 0.2531\n",
      "\n",
      "Epoch 139/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 551us/step - loss: 2.1299 - acc: 0.2230 - val_loss: 2.1355 - val_acc: 0.2531\n",
      "\n",
      "Epoch 140/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 560us/step - loss: 2.1291 - acc: 0.2230 - val_loss: 2.1348 - val_acc: 0.2531\n",
      "\n",
      "Epoch 141/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.1283 - acc: 0.2247 - val_loss: 2.1340 - val_acc: 0.2531\n",
      "\n",
      "Epoch 142/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 596us/step - loss: 2.1274 - acc: 0.2230 - val_loss: 2.1332 - val_acc: 0.2531\n",
      "\n",
      "Epoch 143/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 629us/step - loss: 2.1266 - acc: 0.2230 - val_loss: 2.1324 - val_acc: 0.2531\n",
      "\n",
      "Epoch 144/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 551us/step - loss: 2.1258 - acc: 0.2213 - val_loss: 2.1317 - val_acc: 0.2531\n",
      "\n",
      "Epoch 145/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 515us/step - loss: 2.1249 - acc: 0.2247 - val_loss: 2.1308 - val_acc: 0.2531\n",
      "\n",
      "Epoch 146/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 481us/step - loss: 2.1241 - acc: 0.2230 - val_loss: 2.1301 - val_acc: 0.2469\n",
      "\n",
      "Epoch 147/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 511us/step - loss: 2.1232 - acc: 0.2247 - val_loss: 2.1293 - val_acc: 0.2469\n",
      "\n",
      "Epoch 148/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 517us/step - loss: 2.1224 - acc: 0.2247 - val_loss: 2.1285 - val_acc: 0.2469\n",
      "\n",
      "Epoch 149/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 601us/step - loss: 2.1216 - acc: 0.2247 - val_loss: 2.1278 - val_acc: 0.2469\n",
      "\n",
      "Epoch 150/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 513us/step - loss: 2.1207 - acc: 0.2264 - val_loss: 2.1270 - val_acc: 0.2469\n",
      "\n",
      "Epoch 151/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 569us/step - loss: 2.1199 - acc: 0.2264 - val_loss: 2.1261 - val_acc: 0.2469\n",
      "\n",
      "Epoch 152/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 541us/step - loss: 2.1190 - acc: 0.2264 - val_loss: 2.1252 - val_acc: 0.2469\n",
      "\n",
      "Epoch 153/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 488us/step - loss: 2.1181 - acc: 0.2264 - val_loss: 2.1244 - val_acc: 0.2469\n",
      "\n",
      "Epoch 154/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 601us/step - loss: 2.1173 - acc: 0.2264 - val_loss: 2.1236 - val_acc: 0.2407\n",
      "\n",
      "Epoch 155/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 487us/step - loss: 2.1164 - acc: 0.2264 - val_loss: 2.1227 - val_acc: 0.2469\n",
      "\n",
      "Epoch 156/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 505us/step - loss: 2.1155 - acc: 0.2264 - val_loss: 2.1218 - val_acc: 0.2469\n",
      "\n",
      "Epoch 157/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 520us/step - loss: 2.1146 - acc: 0.2264 - val_loss: 2.1209 - val_acc: 0.2469\n",
      "\n",
      "Epoch 158/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 601us/step - loss: 2.1137 - acc: 0.2264 - val_loss: 2.1199 - val_acc: 0.2469\n",
      "\n",
      "Epoch 159/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 513us/step - loss: 2.1127 - acc: 0.2264 - val_loss: 2.1191 - val_acc: 0.2407\n",
      "\n",
      "Epoch 160/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 596us/step - loss: 2.1118 - acc: 0.2264 - val_loss: 2.1182 - val_acc: 0.2469\n",
      "\n",
      "Epoch 161/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 517us/step - loss: 2.1109 - acc: 0.2264 - val_loss: 2.1173 - val_acc: 0.2469\n",
      "\n",
      "Epoch 162/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 546us/step - loss: 2.1099 - acc: 0.2264 - val_loss: 2.1162 - val_acc: 0.2469\n",
      "\n",
      "Epoch 163/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 522us/step - loss: 2.1090 - acc: 0.2264 - val_loss: 2.1152 - val_acc: 0.2469\n",
      "\n",
      "Epoch 164/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 570us/step - loss: 2.1080 - acc: 0.2264 - val_loss: 2.1142 - val_acc: 0.2469\n",
      "\n",
      "Epoch 165/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.1071 - acc: 0.2264 - val_loss: 2.1133 - val_acc: 0.2531\n",
      "\n",
      "Epoch 166/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 664us/step - loss: 2.1061 - acc: 0.2264 - val_loss: 2.1123 - val_acc: 0.2531\n",
      "\n",
      "Epoch 167/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 489us/step - loss: 2.1051 - acc: 0.2264 - val_loss: 2.1113 - val_acc: 0.2531\n",
      "\n",
      "Epoch 168/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 494us/step - loss: 2.1041 - acc: 0.2264 - val_loss: 2.1103 - val_acc: 0.2531\n",
      "\n",
      "Epoch 169/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 686us/step - loss: 2.1031 - acc: 0.2264 - val_loss: 2.1092 - val_acc: 0.2531\n",
      "\n",
      "Epoch 170/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 566us/step - loss: 2.1021 - acc: 0.2264 - val_loss: 2.1081 - val_acc: 0.2531\n",
      "\n",
      "Epoch 171/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 577us/step - loss: 2.1011 - acc: 0.2264 - val_loss: 2.1071 - val_acc: 0.2531\n",
      "\n",
      "Epoch 172/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 572us/step - loss: 2.1000 - acc: 0.2264 - val_loss: 2.1061 - val_acc: 0.2531\n",
      "\n",
      "Epoch 173/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 536us/step - loss: 2.0990 - acc: 0.2264 - val_loss: 2.1051 - val_acc: 0.2531\n",
      "\n",
      "Epoch 174/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 478us/step - loss: 2.0980 - acc: 0.2264 - val_loss: 2.1040 - val_acc: 0.2593\n",
      "\n",
      "Epoch 175/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 639us/step - loss: 2.0970 - acc: 0.2264 - val_loss: 2.1028 - val_acc: 0.2593\n",
      "\n",
      "Epoch 176/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 573us/step - loss: 2.0960 - acc: 0.2281 - val_loss: 2.1018 - val_acc: 0.2654\n",
      "\n",
      "Epoch 177/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 522us/step - loss: 2.0950 - acc: 0.2281 - val_loss: 2.1008 - val_acc: 0.2654\n",
      "\n",
      "Epoch 178/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 546us/step - loss: 2.0940 - acc: 0.2281 - val_loss: 2.0998 - val_acc: 0.2654\n",
      "\n",
      "Epoch 179/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 531us/step - loss: 2.0929 - acc: 0.2281 - val_loss: 2.0988 - val_acc: 0.2654\n",
      "\n",
      "Epoch 180/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 541us/step - loss: 2.0919 - acc: 0.2298 - val_loss: 2.0978 - val_acc: 0.2654\n",
      "\n",
      "Epoch 181/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 480us/step - loss: 2.0909 - acc: 0.2316 - val_loss: 2.0967 - val_acc: 0.2654\n",
      "\n",
      "Epoch 182/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 541us/step - loss: 2.0898 - acc: 0.2298 - val_loss: 2.0954 - val_acc: 0.2654\n",
      "\n",
      "Epoch 183/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 583us/step - loss: 2.0888 - acc: 0.2316 - val_loss: 2.0944 - val_acc: 0.2654\n",
      "\n",
      "Epoch 184/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 503us/step - loss: 2.0877 - acc: 0.2316 - val_loss: 2.0932 - val_acc: 0.2654\n",
      "\n",
      "Epoch 185/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 517us/step - loss: 2.0866 - acc: 0.2316 - val_loss: 2.0921 - val_acc: 0.2654\n",
      "\n",
      "Epoch 186/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.0856 - acc: 0.2316 - val_loss: 2.0909 - val_acc: 0.2654\n",
      "\n",
      "Epoch 187/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.0844 - acc: 0.2316 - val_loss: 2.0898 - val_acc: 0.2654\n",
      "\n",
      "Epoch 188/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 616us/step - loss: 2.0833 - acc: 0.2316 - val_loss: 2.0886 - val_acc: 0.2654\n",
      "\n",
      "Epoch 189/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 556us/step - loss: 2.0822 - acc: 0.2316 - val_loss: 2.0872 - val_acc: 0.2654\n",
      "\n",
      "Epoch 190/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.0810 - acc: 0.2316 - val_loss: 2.0860 - val_acc: 0.2654\n",
      "\n",
      "Epoch 191/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 629us/step - loss: 2.0799 - acc: 0.2316 - val_loss: 2.0848 - val_acc: 0.2654\n",
      "\n",
      "Epoch 192/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 541us/step - loss: 2.0787 - acc: 0.2333 - val_loss: 2.0834 - val_acc: 0.2654\n",
      "\n",
      "Epoch 193/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 643us/step - loss: 2.0775 - acc: 0.2333 - val_loss: 2.0821 - val_acc: 0.2654\n",
      "\n",
      "Epoch 194/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 561us/step - loss: 2.0762 - acc: 0.2333 - val_loss: 2.0809 - val_acc: 0.2654\n",
      "\n",
      "Epoch 195/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 510us/step - loss: 2.0750 - acc: 0.2333 - val_loss: 2.0794 - val_acc: 0.2654\n",
      "\n",
      "Epoch 196/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 504us/step - loss: 2.0737 - acc: 0.2333 - val_loss: 2.0781 - val_acc: 0.2654\n",
      "\n",
      "Epoch 197/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 528us/step - loss: 2.0725 - acc: 0.2333 - val_loss: 2.0766 - val_acc: 0.2654\n",
      "\n",
      "Epoch 198/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 634us/step - loss: 2.0712 - acc: 0.2350 - val_loss: 2.0753 - val_acc: 0.2654\n",
      "\n",
      "Epoch 199/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 508us/step - loss: 2.0699 - acc: 0.2367 - val_loss: 2.0740 - val_acc: 0.2654\n",
      "\n",
      "Epoch 200/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.0686 - acc: 0.2367 - val_loss: 2.0726 - val_acc: 0.2654\n",
      "\n",
      "65/65 [==============================]65/65 [==============================] - 0s 310us/step\n",
      "\n",
      "Train on 583 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "583/583 [==============================]583/583 [==============================] - 2s 3ms/step - loss: 2.1995 - acc: 0.1578 - val_loss: 2.1749 - val_acc: 0.1605\n",
      "\n",
      "Epoch 2/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 557us/step - loss: 2.1980 - acc: 0.1612 - val_loss: 2.1738 - val_acc: 0.1605\n",
      "\n",
      "Epoch 3/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 600us/step - loss: 2.1965 - acc: 0.1647 - val_loss: 2.1725 - val_acc: 0.1543\n",
      "\n",
      "Epoch 4/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 616us/step - loss: 2.1950 - acc: 0.1630 - val_loss: 2.1714 - val_acc: 0.1605\n",
      "\n",
      "Epoch 5/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 586us/step - loss: 2.1936 - acc: 0.1647 - val_loss: 2.1703 - val_acc: 0.1667\n",
      "\n",
      "Epoch 6/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 487us/step - loss: 2.1923 - acc: 0.1715 - val_loss: 2.1693 - val_acc: 0.1728\n",
      "\n",
      "Epoch 7/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.1910 - acc: 0.1715 - val_loss: 2.1681 - val_acc: 0.1728\n",
      "\n",
      "Epoch 8/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 513us/step - loss: 2.1897 - acc: 0.1767 - val_loss: 2.1671 - val_acc: 0.1728\n",
      "\n",
      "Epoch 9/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 629us/step - loss: 2.1884 - acc: 0.1784 - val_loss: 2.1661 - val_acc: 0.1728\n",
      "\n",
      "Epoch 10/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 531us/step - loss: 2.1871 - acc: 0.1818 - val_loss: 2.1651 - val_acc: 0.1790\n",
      "\n",
      "Epoch 11/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 552us/step - loss: 2.1858 - acc: 0.1852 - val_loss: 2.1639 - val_acc: 0.1790\n",
      "\n",
      "Epoch 12/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 575us/step - loss: 2.1845 - acc: 0.1938 - val_loss: 2.1628 - val_acc: 0.1914\n",
      "\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================]583/583 [==============================] - 0s 503us/step - loss: 2.1833 - acc: 0.1938 - val_loss: 2.1618 - val_acc: 0.1975\n",
      "\n",
      "Epoch 14/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 478us/step - loss: 2.1821 - acc: 0.1887 - val_loss: 2.1608 - val_acc: 0.1975\n",
      "\n",
      "Epoch 15/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 530us/step - loss: 2.1809 - acc: 0.1904 - val_loss: 2.1596 - val_acc: 0.2099\n",
      "\n",
      "Epoch 16/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 575us/step - loss: 2.1797 - acc: 0.1990 - val_loss: 2.1584 - val_acc: 0.2037\n",
      "\n",
      "Epoch 17/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 540us/step - loss: 2.1784 - acc: 0.2024 - val_loss: 2.1573 - val_acc: 0.2037\n",
      "\n",
      "Epoch 18/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 494us/step - loss: 2.1772 - acc: 0.2041 - val_loss: 2.1563 - val_acc: 0.2160\n",
      "\n",
      "Epoch 19/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 538us/step - loss: 2.1759 - acc: 0.2058 - val_loss: 2.1553 - val_acc: 0.2099\n",
      "\n",
      "Epoch 20/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 597us/step - loss: 2.1746 - acc: 0.2058 - val_loss: 2.1541 - val_acc: 0.2222\n",
      "\n",
      "Epoch 21/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 552us/step - loss: 2.1733 - acc: 0.2093 - val_loss: 2.1531 - val_acc: 0.2222\n",
      "\n",
      "Epoch 22/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 537us/step - loss: 2.1720 - acc: 0.2093 - val_loss: 2.1521 - val_acc: 0.2284\n",
      "\n",
      "Epoch 23/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 624us/step - loss: 2.1708 - acc: 0.2093 - val_loss: 2.1512 - val_acc: 0.2284\n",
      "\n",
      "Epoch 24/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 563us/step - loss: 2.1695 - acc: 0.2075 - val_loss: 2.1503 - val_acc: 0.2346\n",
      "\n",
      "Epoch 25/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 610us/step - loss: 2.1683 - acc: 0.2075 - val_loss: 2.1492 - val_acc: 0.2346\n",
      "\n",
      "Epoch 26/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 517us/step - loss: 2.1670 - acc: 0.2041 - val_loss: 2.1482 - val_acc: 0.2346\n",
      "\n",
      "Epoch 27/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 568us/step - loss: 2.1657 - acc: 0.2041 - val_loss: 2.1472 - val_acc: 0.2284\n",
      "\n",
      "Epoch 28/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 570us/step - loss: 2.1645 - acc: 0.2007 - val_loss: 2.1462 - val_acc: 0.2222\n",
      "\n",
      "Epoch 29/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 598us/step - loss: 2.1632 - acc: 0.2007 - val_loss: 2.1453 - val_acc: 0.2222\n",
      "\n",
      "Epoch 30/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 608us/step - loss: 2.1619 - acc: 0.1990 - val_loss: 2.1444 - val_acc: 0.2222\n",
      "\n",
      "Epoch 31/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 609us/step - loss: 2.1607 - acc: 0.1955 - val_loss: 2.1434 - val_acc: 0.2222\n",
      "\n",
      "Epoch 32/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 565us/step - loss: 2.1595 - acc: 0.2024 - val_loss: 2.1424 - val_acc: 0.2222\n",
      "\n",
      "Epoch 33/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 481us/step - loss: 2.1583 - acc: 0.2024 - val_loss: 2.1415 - val_acc: 0.2222\n",
      "\n",
      "Epoch 34/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 550us/step - loss: 2.1571 - acc: 0.2007 - val_loss: 2.1406 - val_acc: 0.2222\n",
      "\n",
      "Epoch 35/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 530us/step - loss: 2.1560 - acc: 0.2007 - val_loss: 2.1395 - val_acc: 0.2160\n",
      "\n",
      "Epoch 36/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 570us/step - loss: 2.1548 - acc: 0.2024 - val_loss: 2.1387 - val_acc: 0.2099\n",
      "\n",
      "Epoch 37/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 509us/step - loss: 2.1536 - acc: 0.2007 - val_loss: 2.1377 - val_acc: 0.2037\n",
      "\n",
      "Epoch 38/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 518us/step - loss: 2.1524 - acc: 0.1990 - val_loss: 2.1368 - val_acc: 0.2037\n",
      "\n",
      "Epoch 39/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 515us/step - loss: 2.1512 - acc: 0.1990 - val_loss: 2.1358 - val_acc: 0.2037\n",
      "\n",
      "Epoch 40/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 570us/step - loss: 2.1500 - acc: 0.1973 - val_loss: 2.1347 - val_acc: 0.2099\n",
      "\n",
      "Epoch 41/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 555us/step - loss: 2.1488 - acc: 0.1921 - val_loss: 2.1338 - val_acc: 0.2099\n",
      "\n",
      "Epoch 42/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 523us/step - loss: 2.1476 - acc: 0.1938 - val_loss: 2.1329 - val_acc: 0.2099\n",
      "\n",
      "Epoch 43/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 2.1465 - acc: 0.1921 - val_loss: 2.1319 - val_acc: 0.2099\n",
      "\n",
      "Epoch 44/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 522us/step - loss: 2.1452 - acc: 0.1921 - val_loss: 2.1311 - val_acc: 0.2099\n",
      "\n",
      "Epoch 45/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 570us/step - loss: 2.1440 - acc: 0.1921 - val_loss: 2.1299 - val_acc: 0.2037\n",
      "\n",
      "Epoch 46/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 540us/step - loss: 2.1428 - acc: 0.1887 - val_loss: 2.1289 - val_acc: 0.2037\n",
      "\n",
      "Epoch 47/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 603us/step - loss: 2.1415 - acc: 0.1870 - val_loss: 2.1280 - val_acc: 0.2037\n",
      "\n",
      "Epoch 48/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.1403 - acc: 0.1852 - val_loss: 2.1270 - val_acc: 0.2037\n",
      "\n",
      "Epoch 49/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 2.1391 - acc: 0.1818 - val_loss: 2.1259 - val_acc: 0.1975\n",
      "\n",
      "Epoch 50/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 631us/step - loss: 2.1379 - acc: 0.1801 - val_loss: 2.1249 - val_acc: 0.1914\n",
      "\n",
      "Epoch 51/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 552us/step - loss: 2.1366 - acc: 0.1801 - val_loss: 2.1240 - val_acc: 0.1914\n",
      "\n",
      "Epoch 52/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 498us/step - loss: 2.1354 - acc: 0.1801 - val_loss: 2.1230 - val_acc: 0.1852\n",
      "\n",
      "Epoch 53/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 549us/step - loss: 2.1341 - acc: 0.1784 - val_loss: 2.1220 - val_acc: 0.1790\n",
      "\n",
      "Epoch 54/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 596us/step - loss: 2.1328 - acc: 0.1767 - val_loss: 2.1210 - val_acc: 0.1790\n",
      "\n",
      "Epoch 55/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 536us/step - loss: 2.1316 - acc: 0.1767 - val_loss: 2.1199 - val_acc: 0.1790\n",
      "\n",
      "Epoch 56/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 606us/step - loss: 2.1303 - acc: 0.1767 - val_loss: 2.1189 - val_acc: 0.1790\n",
      "\n",
      "Epoch 57/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 513us/step - loss: 2.1291 - acc: 0.1767 - val_loss: 2.1179 - val_acc: 0.1728\n",
      "\n",
      "Epoch 58/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 617us/step - loss: 2.1278 - acc: 0.1750 - val_loss: 2.1168 - val_acc: 0.1728\n",
      "\n",
      "Epoch 59/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 518us/step - loss: 2.1266 - acc: 0.1715 - val_loss: 2.1158 - val_acc: 0.1728\n",
      "\n",
      "Epoch 60/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 552us/step - loss: 2.1252 - acc: 0.1698 - val_loss: 2.1151 - val_acc: 0.1728\n",
      "\n",
      "Epoch 61/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 570us/step - loss: 2.1239 - acc: 0.1681 - val_loss: 2.1142 - val_acc: 0.1728\n",
      "\n",
      "Epoch 62/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 598us/step - loss: 2.1226 - acc: 0.1681 - val_loss: 2.1131 - val_acc: 0.1728\n",
      "\n",
      "Epoch 63/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 605us/step - loss: 2.1213 - acc: 0.1630 - val_loss: 2.1119 - val_acc: 0.1728\n",
      "\n",
      "Epoch 64/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 503us/step - loss: 2.1199 - acc: 0.1647 - val_loss: 2.1108 - val_acc: 0.1728\n",
      "\n",
      "Epoch 65/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 649us/step - loss: 2.1186 - acc: 0.1612 - val_loss: 2.1096 - val_acc: 0.1728\n",
      "\n",
      "Epoch 66/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 586us/step - loss: 2.1173 - acc: 0.1612 - val_loss: 2.1083 - val_acc: 0.1728\n",
      "\n",
      "Epoch 67/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 588us/step - loss: 2.1159 - acc: 0.1612 - val_loss: 2.1069 - val_acc: 0.1728\n",
      "\n",
      "Epoch 68/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 584us/step - loss: 2.1145 - acc: 0.1612 - val_loss: 2.1058 - val_acc: 0.1728\n",
      "\n",
      "Epoch 69/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 486us/step - loss: 2.1131 - acc: 0.1612 - val_loss: 2.1045 - val_acc: 0.1667\n",
      "\n",
      "Epoch 70/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 569us/step - loss: 2.1116 - acc: 0.1612 - val_loss: 2.1034 - val_acc: 0.1605\n",
      "\n",
      "Epoch 71/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 593us/step - loss: 2.1102 - acc: 0.1595 - val_loss: 2.1022 - val_acc: 0.1605\n",
      "\n",
      "Epoch 72/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 579us/step - loss: 2.1088 - acc: 0.1595 - val_loss: 2.1010 - val_acc: 0.1605\n",
      "\n",
      "Epoch 73/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 517us/step - loss: 2.1073 - acc: 0.1595 - val_loss: 2.0998 - val_acc: 0.1605\n",
      "\n",
      "Epoch 74/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 486us/step - loss: 2.1059 - acc: 0.1595 - val_loss: 2.0988 - val_acc: 0.1605\n",
      "\n",
      "Epoch 75/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.1044 - acc: 0.1578 - val_loss: 2.0976 - val_acc: 0.1605\n",
      "\n",
      "Epoch 76/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 550us/step - loss: 2.1029 - acc: 0.1578 - val_loss: 2.0965 - val_acc: 0.1605\n",
      "\n",
      "Epoch 77/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 478us/step - loss: 2.1015 - acc: 0.1561 - val_loss: 2.0951 - val_acc: 0.1605\n",
      "\n",
      "Epoch 78/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 523us/step - loss: 2.0999 - acc: 0.1561 - val_loss: 2.0938 - val_acc: 0.1605\n",
      "\n",
      "Epoch 79/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 556us/step - loss: 2.0984 - acc: 0.1561 - val_loss: 2.0925 - val_acc: 0.1605TA: 0s - loss: 2.0967 - acc: 0.158\n",
      "\n",
      "Epoch 80/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 638us/step - loss: 2.0969 - acc: 0.1561 - val_loss: 2.0913 - val_acc: 0.1605\n",
      "\n",
      "Epoch 81/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 541us/step - loss: 2.0953 - acc: 0.1561 - val_loss: 2.0901 - val_acc: 0.1605\n",
      "\n",
      "Epoch 82/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 541us/step - loss: 2.0940 - acc: 0.1561 - val_loss: 2.0889 - val_acc: 0.1605\n",
      "\n",
      "Epoch 83/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 507us/step - loss: 2.0925 - acc: 0.1561 - val_loss: 2.0877 - val_acc: 0.1605\n",
      "\n",
      "Epoch 84/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 493us/step - loss: 2.0910 - acc: 0.1561 - val_loss: 2.0866 - val_acc: 0.1605\n",
      "\n",
      "Epoch 85/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 644us/step - loss: 2.0896 - acc: 0.1561 - val_loss: 2.0856 - val_acc: 0.1605\n",
      "\n",
      "Epoch 86/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 583us/step - loss: 2.0881 - acc: 0.1578 - val_loss: 2.0844 - val_acc: 0.1605\n",
      "\n",
      "Epoch 87/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 540us/step - loss: 2.0867 - acc: 0.1561 - val_loss: 2.0834 - val_acc: 0.1605\n",
      "\n",
      "Epoch 88/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 482us/step - loss: 2.0852 - acc: 0.1578 - val_loss: 2.0821 - val_acc: 0.1605\n",
      "\n",
      "Epoch 89/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 546us/step - loss: 2.0837 - acc: 0.1561 - val_loss: 2.0811 - val_acc: 0.1605\n",
      "\n",
      "Epoch 90/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 519us/step - loss: 2.0822 - acc: 0.1561 - val_loss: 2.0800 - val_acc: 0.1605\n",
      "\n",
      "Epoch 91/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 502us/step - loss: 2.0806 - acc: 0.1561 - val_loss: 2.0788 - val_acc: 0.1605\n",
      "\n",
      "Epoch 92/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 551us/step - loss: 2.0790 - acc: 0.1561 - val_loss: 2.0774 - val_acc: 0.1605\n",
      "\n",
      "Epoch 93/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 529us/step - loss: 2.0775 - acc: 0.1561 - val_loss: 2.0761 - val_acc: 0.1605\n",
      "\n",
      "Epoch 94/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 529us/step - loss: 2.0759 - acc: 0.1578 - val_loss: 2.0750 - val_acc: 0.1667\n",
      "\n",
      "Epoch 95/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 569us/step - loss: 2.0744 - acc: 0.1578 - val_loss: 2.0740 - val_acc: 0.1667\n",
      "\n",
      "Epoch 96/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 2.0727 - acc: 0.1561 - val_loss: 2.0729 - val_acc: 0.1667\n",
      "\n",
      "Epoch 97/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.0712 - acc: 0.1561 - val_loss: 2.0718 - val_acc: 0.1667\n",
      "\n",
      "Epoch 98/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 559us/step - loss: 2.0696 - acc: 0.1561 - val_loss: 2.0705 - val_acc: 0.1667\n",
      "\n",
      "Epoch 99/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 643us/step - loss: 2.0679 - acc: 0.1561 - val_loss: 2.0692 - val_acc: 0.1667\n",
      "\n",
      "Epoch 100/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 517us/step - loss: 2.0663 - acc: 0.1561 - val_loss: 2.0680 - val_acc: 0.1667\n",
      "\n",
      "Epoch 101/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 541us/step - loss: 2.0646 - acc: 0.1561 - val_loss: 2.0668 - val_acc: 0.1667\n",
      "\n",
      "Epoch 102/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 535us/step - loss: 2.0630 - acc: 0.1561 - val_loss: 2.0656 - val_acc: 0.1667\n",
      "\n",
      "Epoch 103/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 502us/step - loss: 2.0614 - acc: 0.1612 - val_loss: 2.0642 - val_acc: 0.1667\n",
      "\n",
      "Epoch 104/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 497us/step - loss: 2.0597 - acc: 0.1612 - val_loss: 2.0628 - val_acc: 0.1667\n",
      "\n",
      "Epoch 105/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================]583/583 [==============================] - 0s 522us/step - loss: 2.0580 - acc: 0.1595 - val_loss: 2.0612 - val_acc: 0.1728\n",
      "\n",
      "Epoch 106/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 571us/step - loss: 2.0563 - acc: 0.1612 - val_loss: 2.0599 - val_acc: 0.1728\n",
      "\n",
      "Epoch 107/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 2.0547 - acc: 0.1647 - val_loss: 2.0584 - val_acc: 0.1728\n",
      "\n",
      "Epoch 108/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 487us/step - loss: 2.0529 - acc: 0.1647 - val_loss: 2.0570 - val_acc: 0.1790\n",
      "\n",
      "Epoch 109/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 570us/step - loss: 2.0512 - acc: 0.1681 - val_loss: 2.0555 - val_acc: 0.1790\n",
      "\n",
      "Epoch 110/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 573us/step - loss: 2.0495 - acc: 0.1698 - val_loss: 2.0541 - val_acc: 0.1790\n",
      "\n",
      "Epoch 111/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 530us/step - loss: 2.0477 - acc: 0.1698 - val_loss: 2.0528 - val_acc: 0.1790\n",
      "\n",
      "Epoch 112/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 588us/step - loss: 2.0459 - acc: 0.1698 - val_loss: 2.0513 - val_acc: 0.1790\n",
      "\n",
      "Epoch 113/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 540us/step - loss: 2.0441 - acc: 0.1698 - val_loss: 2.0499 - val_acc: 0.1790\n",
      "\n",
      "Epoch 114/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 571us/step - loss: 2.0423 - acc: 0.1698 - val_loss: 2.0486 - val_acc: 0.1790\n",
      "\n",
      "Epoch 115/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 529us/step - loss: 2.0405 - acc: 0.1698 - val_loss: 2.0473 - val_acc: 0.1790\n",
      "\n",
      "Epoch 116/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.0388 - acc: 0.1715 - val_loss: 2.0459 - val_acc: 0.1790\n",
      "\n",
      "Epoch 117/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 611us/step - loss: 2.0369 - acc: 0.1715 - val_loss: 2.0447 - val_acc: 0.1790\n",
      "\n",
      "Epoch 118/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 569us/step - loss: 2.0351 - acc: 0.1715 - val_loss: 2.0432 - val_acc: 0.1852\n",
      "\n",
      "Epoch 119/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 566us/step - loss: 2.0333 - acc: 0.1715 - val_loss: 2.0413 - val_acc: 0.1852\n",
      "\n",
      "Epoch 120/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 546us/step - loss: 2.0314 - acc: 0.1732 - val_loss: 2.0397 - val_acc: 0.1852\n",
      "\n",
      "Epoch 121/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 545us/step - loss: 2.0295 - acc: 0.1767 - val_loss: 2.0380 - val_acc: 0.1852\n",
      "\n",
      "Epoch 122/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 546us/step - loss: 2.0276 - acc: 0.1870 - val_loss: 2.0366 - val_acc: 0.1852\n",
      "\n",
      "Epoch 123/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 626us/step - loss: 2.0257 - acc: 0.1870 - val_loss: 2.0352 - val_acc: 0.1852\n",
      "\n",
      "Epoch 124/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 569us/step - loss: 2.0237 - acc: 0.1852 - val_loss: 2.0338 - val_acc: 0.1852\n",
      "\n",
      "Epoch 125/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 517us/step - loss: 2.0217 - acc: 0.1887 - val_loss: 2.0323 - val_acc: 0.1852\n",
      "\n",
      "Epoch 126/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 524us/step - loss: 2.0197 - acc: 0.1921 - val_loss: 2.0307 - val_acc: 0.1852\n",
      "\n",
      "Epoch 127/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 481us/step - loss: 2.0177 - acc: 0.2024 - val_loss: 2.0291 - val_acc: 0.1852\n",
      "\n",
      "Epoch 128/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 550us/step - loss: 2.0157 - acc: 0.2007 - val_loss: 2.0273 - val_acc: 0.1852\n",
      "\n",
      "Epoch 129/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 496us/step - loss: 2.0136 - acc: 0.2007 - val_loss: 2.0259 - val_acc: 0.1914\n",
      "\n",
      "Epoch 130/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 487us/step - loss: 2.0115 - acc: 0.2024 - val_loss: 2.0241 - val_acc: 0.1975\n",
      "\n",
      "Epoch 131/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.0095 - acc: 0.2058 - val_loss: 2.0223 - val_acc: 0.1914\n",
      "\n",
      "Epoch 132/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 2.0074 - acc: 0.2093 - val_loss: 2.0207 - val_acc: 0.1914\n",
      "\n",
      "Epoch 133/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.0053 - acc: 0.2041 - val_loss: 2.0192 - val_acc: 0.1914\n",
      "\n",
      "Epoch 134/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 590us/step - loss: 2.0031 - acc: 0.2058 - val_loss: 2.0173 - val_acc: 0.1975\n",
      "\n",
      "Epoch 135/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 550us/step - loss: 2.0010 - acc: 0.2110 - val_loss: 2.0155 - val_acc: 0.1975\n",
      "\n",
      "Epoch 136/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 682us/step - loss: 1.9988 - acc: 0.2144 - val_loss: 2.0134 - val_acc: 0.2037\n",
      "\n",
      "Epoch 137/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 522us/step - loss: 1.9967 - acc: 0.2230 - val_loss: 2.0116 - val_acc: 0.2037\n",
      "\n",
      "Epoch 138/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 599us/step - loss: 1.9946 - acc: 0.2213 - val_loss: 2.0099 - val_acc: 0.2037\n",
      "\n",
      "Epoch 139/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 572us/step - loss: 1.9924 - acc: 0.2281 - val_loss: 2.0082 - val_acc: 0.2037\n",
      "\n",
      "Epoch 140/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 518us/step - loss: 1.9902 - acc: 0.2281 - val_loss: 2.0059 - val_acc: 0.2222\n",
      "\n",
      "Epoch 141/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 541us/step - loss: 1.9879 - acc: 0.2367 - val_loss: 2.0042 - val_acc: 0.2284\n",
      "\n",
      "Epoch 142/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 584us/step - loss: 1.9856 - acc: 0.2384 - val_loss: 2.0022 - val_acc: 0.2222TA: 0s - loss: 1.9903 - acc: 0.23\n",
      "\n",
      "Epoch 143/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 530us/step - loss: 1.9834 - acc: 0.2436 - val_loss: 2.0002 - val_acc: 0.2284\n",
      "\n",
      "Epoch 144/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 580us/step - loss: 1.9811 - acc: 0.2487 - val_loss: 1.9982 - val_acc: 0.2284\n",
      "\n",
      "Epoch 145/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 591us/step - loss: 1.9788 - acc: 0.2487 - val_loss: 1.9962 - val_acc: 0.2284\n",
      "\n",
      "Epoch 146/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 554us/step - loss: 1.9764 - acc: 0.2539 - val_loss: 1.9947 - val_acc: 0.2284TA: 0s - loss: 1.9728 - acc: 0.255\n",
      "\n",
      "Epoch 147/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 612us/step - loss: 1.9740 - acc: 0.2539 - val_loss: 1.9924 - val_acc: 0.2284\n",
      "\n",
      "Epoch 148/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 1.9716 - acc: 0.2521 - val_loss: 1.9904 - val_acc: 0.2284\n",
      "\n",
      "Epoch 149/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 496us/step - loss: 1.9691 - acc: 0.2556 - val_loss: 1.9882 - val_acc: 0.2284\n",
      "\n",
      "Epoch 150/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 504us/step - loss: 1.9668 - acc: 0.2556 - val_loss: 1.9859 - val_acc: 0.2407\n",
      "\n",
      "Epoch 151/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 630us/step - loss: 1.9643 - acc: 0.2590 - val_loss: 1.9838 - val_acc: 0.2346\n",
      "\n",
      "Epoch 152/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 594us/step - loss: 1.9618 - acc: 0.2607 - val_loss: 1.9818 - val_acc: 0.2407\n",
      "\n",
      "Epoch 153/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 547us/step - loss: 1.9594 - acc: 0.2642 - val_loss: 1.9795 - val_acc: 0.2469\n",
      "\n",
      "Epoch 154/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 487us/step - loss: 1.9569 - acc: 0.2659 - val_loss: 1.9771 - val_acc: 0.2469\n",
      "\n",
      "Epoch 155/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 500us/step - loss: 1.9544 - acc: 0.2727 - val_loss: 1.9754 - val_acc: 0.2469TA: 0s - loss: 1.9549 - acc: 0.272\n",
      "\n",
      "Epoch 156/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 498us/step - loss: 1.9519 - acc: 0.2744 - val_loss: 1.9727 - val_acc: 0.2469\n",
      "\n",
      "Epoch 157/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 538us/step - loss: 1.9493 - acc: 0.2796 - val_loss: 1.9702 - val_acc: 0.2469\n",
      "\n",
      "Epoch 158/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 632us/step - loss: 1.9468 - acc: 0.2813 - val_loss: 1.9676 - val_acc: 0.2531\n",
      "\n",
      "Epoch 159/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 1.9442 - acc: 0.2830 - val_loss: 1.9656 - val_acc: 0.2531\n",
      "\n",
      "Epoch 160/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 515us/step - loss: 1.9417 - acc: 0.2847 - val_loss: 1.9631 - val_acc: 0.2531\n",
      "\n",
      "Epoch 161/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 531us/step - loss: 1.9390 - acc: 0.2950 - val_loss: 1.9608 - val_acc: 0.2531\n",
      "\n",
      "Epoch 162/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 508us/step - loss: 1.9363 - acc: 0.2950 - val_loss: 1.9584 - val_acc: 0.2531\n",
      "\n",
      "Epoch 163/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 494us/step - loss: 1.9336 - acc: 0.2967 - val_loss: 1.9561 - val_acc: 0.2593\n",
      "\n",
      "Epoch 164/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 605us/step - loss: 1.9309 - acc: 0.2967 - val_loss: 1.9536 - val_acc: 0.2654\n",
      "\n",
      "Epoch 165/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 672us/step - loss: 1.9282 - acc: 0.2985 - val_loss: 1.9513 - val_acc: 0.2654\n",
      "\n",
      "Epoch 166/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 525us/step - loss: 1.9253 - acc: 0.2967 - val_loss: 1.9489 - val_acc: 0.2654\n",
      "\n",
      "Epoch 167/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 515us/step - loss: 1.9226 - acc: 0.3053 - val_loss: 1.9463 - val_acc: 0.2716\n",
      "\n",
      "Epoch 168/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 625us/step - loss: 1.9197 - acc: 0.3087 - val_loss: 1.9434 - val_acc: 0.2716\n",
      "\n",
      "Epoch 169/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 519us/step - loss: 1.9167 - acc: 0.3105 - val_loss: 1.9409 - val_acc: 0.2716\n",
      "\n",
      "Epoch 170/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 569us/step - loss: 1.9137 - acc: 0.3105 - val_loss: 1.9388 - val_acc: 0.2716\n",
      "\n",
      "Epoch 171/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 1.9107 - acc: 0.3122 - val_loss: 1.9362 - val_acc: 0.2778\n",
      "\n",
      "Epoch 172/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 557us/step - loss: 1.9078 - acc: 0.3190 - val_loss: 1.9335 - val_acc: 0.2778\n",
      "\n",
      "Epoch 173/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 531us/step - loss: 1.9047 - acc: 0.3173 - val_loss: 1.9312 - val_acc: 0.2840\n",
      "\n",
      "Epoch 174/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 562us/step - loss: 1.9017 - acc: 0.3173 - val_loss: 1.9285 - val_acc: 0.2778\n",
      "\n",
      "Epoch 175/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 552us/step - loss: 1.8986 - acc: 0.3225 - val_loss: 1.9260 - val_acc: 0.2840\n",
      "\n",
      "Epoch 176/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 540us/step - loss: 1.8953 - acc: 0.3242 - val_loss: 1.9231 - val_acc: 0.2901\n",
      "\n",
      "Epoch 177/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 519us/step - loss: 1.8922 - acc: 0.3225 - val_loss: 1.9205 - val_acc: 0.2963\n",
      "\n",
      "Epoch 178/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 1.8889 - acc: 0.3293 - val_loss: 1.9177 - val_acc: 0.2963\n",
      "\n",
      "Epoch 179/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 569us/step - loss: 1.8857 - acc: 0.3293 - val_loss: 1.9143 - val_acc: 0.3025\n",
      "\n",
      "Epoch 180/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 562us/step - loss: 1.8825 - acc: 0.3328 - val_loss: 1.9113 - val_acc: 0.3086\n",
      "\n",
      "Epoch 181/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 555us/step - loss: 1.8792 - acc: 0.3310 - val_loss: 1.9078 - val_acc: 0.3210\n",
      "\n",
      "Epoch 182/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 1.8758 - acc: 0.3328 - val_loss: 1.9049 - val_acc: 0.3210\n",
      "\n",
      "Epoch 183/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 563us/step - loss: 1.8725 - acc: 0.3362 - val_loss: 1.9015 - val_acc: 0.3148\n",
      "\n",
      "Epoch 184/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 521us/step - loss: 1.8690 - acc: 0.3345 - val_loss: 1.8986 - val_acc: 0.3148\n",
      "\n",
      "Epoch 185/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 567us/step - loss: 1.8654 - acc: 0.3345 - val_loss: 1.8955 - val_acc: 0.3148\n",
      "\n",
      "Epoch 186/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 572us/step - loss: 1.8618 - acc: 0.3345 - val_loss: 1.8923 - val_acc: 0.3148\n",
      "\n",
      "Epoch 187/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 517us/step - loss: 1.8581 - acc: 0.3362 - val_loss: 1.8886 - val_acc: 0.3148TA: 0s - loss: 1.8631 - acc: 0.\n",
      "\n",
      "Epoch 188/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 493us/step - loss: 1.8546 - acc: 0.3413 - val_loss: 1.8853 - val_acc: 0.3148\n",
      "\n",
      "Epoch 189/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 601us/step - loss: 1.8510 - acc: 0.3448 - val_loss: 1.8821 - val_acc: 0.3148\n",
      "\n",
      "Epoch 190/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 566us/step - loss: 1.8474 - acc: 0.3465 - val_loss: 1.8787 - val_acc: 0.3148\n",
      "\n",
      "Epoch 191/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 517us/step - loss: 1.8438 - acc: 0.3448 - val_loss: 1.8754 - val_acc: 0.3148\n",
      "\n",
      "Epoch 192/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 591us/step - loss: 1.8400 - acc: 0.3516 - val_loss: 1.8716 - val_acc: 0.3148\n",
      "\n",
      "Epoch 193/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 575us/step - loss: 1.8363 - acc: 0.3499 - val_loss: 1.8683 - val_acc: 0.3272\n",
      "\n",
      "Epoch 194/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 510us/step - loss: 1.8323 - acc: 0.3551 - val_loss: 1.8649 - val_acc: 0.3272\n",
      "\n",
      "Epoch 195/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================]583/583 [==============================] - 0s 489us/step - loss: 1.8286 - acc: 0.3533 - val_loss: 1.8604 - val_acc: 0.3333\n",
      "\n",
      "Epoch 196/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 583us/step - loss: 1.8244 - acc: 0.3499 - val_loss: 1.8575 - val_acc: 0.3272\n",
      "\n",
      "Epoch 197/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 559us/step - loss: 1.8205 - acc: 0.3551 - val_loss: 1.8536 - val_acc: 0.3333\n",
      "\n",
      "Epoch 198/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 486us/step - loss: 1.8163 - acc: 0.3533 - val_loss: 1.8510 - val_acc: 0.3395\n",
      "\n",
      "Epoch 199/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 540us/step - loss: 1.8121 - acc: 0.3551 - val_loss: 1.8470 - val_acc: 0.3395\n",
      "\n",
      "Epoch 200/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 621us/step - loss: 1.8081 - acc: 0.3568 - val_loss: 1.8429 - val_acc: 0.3333\n",
      "\n",
      "65/65 [==============================]65/65 [==============================] - 0s 298us/step\n",
      "\n",
      "Train on 583 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "583/583 [==============================]583/583 [==============================] - 2s 4ms/step - loss: 2.2551 - acc: 0.1098 - val_loss: 2.2696 - val_acc: 0.1111\n",
      "\n",
      "Epoch 2/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 662us/step - loss: 2.2520 - acc: 0.1098 - val_loss: 2.2665 - val_acc: 0.1111\n",
      "\n",
      "Epoch 3/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 525us/step - loss: 2.2492 - acc: 0.1098 - val_loss: 2.2633 - val_acc: 0.1111\n",
      "\n",
      "Epoch 4/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.2464 - acc: 0.1098 - val_loss: 2.2608 - val_acc: 0.1111\n",
      "\n",
      "Epoch 5/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 515us/step - loss: 2.2440 - acc: 0.1098 - val_loss: 2.2584 - val_acc: 0.1111\n",
      "\n",
      "Epoch 6/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 570us/step - loss: 2.2417 - acc: 0.1098 - val_loss: 2.2560 - val_acc: 0.1111\n",
      "\n",
      "Epoch 7/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 689us/step - loss: 2.2395 - acc: 0.1098 - val_loss: 2.2538 - val_acc: 0.1111\n",
      "\n",
      "Epoch 8/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 689us/step - loss: 2.2375 - acc: 0.1098 - val_loss: 2.2519 - val_acc: 0.1111\n",
      "\n",
      "Epoch 9/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.2356 - acc: 0.1098 - val_loss: 2.2499 - val_acc: 0.1111\n",
      "\n",
      "Epoch 10/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 580us/step - loss: 2.2337 - acc: 0.1098 - val_loss: 2.2480 - val_acc: 0.1111\n",
      "\n",
      "Epoch 11/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 652us/step - loss: 2.2319 - acc: 0.1098 - val_loss: 2.2463 - val_acc: 0.1111\n",
      "\n",
      "Epoch 12/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 532us/step - loss: 2.2300 - acc: 0.1098 - val_loss: 2.2444 - val_acc: 0.1111\n",
      "\n",
      "Epoch 13/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 769us/step - loss: 2.2282 - acc: 0.1098 - val_loss: 2.2428 - val_acc: 0.1111\n",
      "\n",
      "Epoch 14/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 509us/step - loss: 2.2266 - acc: 0.1098 - val_loss: 2.2411 - val_acc: 0.1111\n",
      "\n",
      "Epoch 15/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 562us/step - loss: 2.2249 - acc: 0.1098 - val_loss: 2.2396 - val_acc: 0.1111\n",
      "\n",
      "Epoch 16/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 528us/step - loss: 2.2233 - acc: 0.1098 - val_loss: 2.2381 - val_acc: 0.1111\n",
      "\n",
      "Epoch 17/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 520us/step - loss: 2.2218 - acc: 0.1098 - val_loss: 2.2366 - val_acc: 0.1111\n",
      "\n",
      "Epoch 18/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 539us/step - loss: 2.2203 - acc: 0.1098 - val_loss: 2.2352 - val_acc: 0.1111\n",
      "\n",
      "Epoch 19/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 622us/step - loss: 2.2189 - acc: 0.1098 - val_loss: 2.2338 - val_acc: 0.1111\n",
      "\n",
      "Epoch 20/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 523us/step - loss: 2.2176 - acc: 0.1098 - val_loss: 2.2325 - val_acc: 0.1111\n",
      "\n",
      "Epoch 21/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 2.2163 - acc: 0.1098 - val_loss: 2.2312 - val_acc: 0.1111\n",
      "\n",
      "Epoch 22/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 576us/step - loss: 2.2150 - acc: 0.1098 - val_loss: 2.2298 - val_acc: 0.1111\n",
      "\n",
      "Epoch 23/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 510us/step - loss: 2.2136 - acc: 0.1098 - val_loss: 2.2286 - val_acc: 0.1111\n",
      "\n",
      "Epoch 24/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 539us/step - loss: 2.2125 - acc: 0.1098 - val_loss: 2.2274 - val_acc: 0.1111\n",
      "\n",
      "Epoch 25/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 2.2114 - acc: 0.1098 - val_loss: 2.2263 - val_acc: 0.1111\n",
      "\n",
      "Epoch 26/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 627us/step - loss: 2.2102 - acc: 0.1098 - val_loss: 2.2252 - val_acc: 0.1111\n",
      "\n",
      "Epoch 27/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 607us/step - loss: 2.2091 - acc: 0.1098 - val_loss: 2.2241 - val_acc: 0.1111\n",
      "\n",
      "Epoch 28/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 706us/step - loss: 2.2081 - acc: 0.1098 - val_loss: 2.2230 - val_acc: 0.1111\n",
      "\n",
      "Epoch 29/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 486us/step - loss: 2.2070 - acc: 0.1098 - val_loss: 2.2219 - val_acc: 0.1111\n",
      "\n",
      "Epoch 30/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 569us/step - loss: 2.2060 - acc: 0.1098 - val_loss: 2.2209 - val_acc: 0.1111\n",
      "\n",
      "Epoch 31/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.2050 - acc: 0.1098 - val_loss: 2.2199 - val_acc: 0.1111\n",
      "\n",
      "Epoch 32/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 2.2041 - acc: 0.1098 - val_loss: 2.2189 - val_acc: 0.1111TA: 0s - loss: 2.2093 - acc: 0.09\n",
      "\n",
      "Epoch 33/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 504us/step - loss: 2.2032 - acc: 0.1098 - val_loss: 2.2180 - val_acc: 0.1111\n",
      "\n",
      "Epoch 34/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 497us/step - loss: 2.2022 - acc: 0.1098 - val_loss: 2.2169 - val_acc: 0.1111\n",
      "\n",
      "Epoch 35/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 600us/step - loss: 2.2012 - acc: 0.1098 - val_loss: 2.2159 - val_acc: 0.1111\n",
      "\n",
      "Epoch 36/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 457us/step - loss: 2.2003 - acc: 0.1098 - val_loss: 2.2150 - val_acc: 0.1111\n",
      "\n",
      "Epoch 37/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 489us/step - loss: 2.1993 - acc: 0.1098 - val_loss: 2.2141 - val_acc: 0.1111\n",
      "\n",
      "Epoch 38/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 545us/step - loss: 2.1984 - acc: 0.1098 - val_loss: 2.2132 - val_acc: 0.1111\n",
      "\n",
      "Epoch 39/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 2.1975 - acc: 0.1098 - val_loss: 2.2123 - val_acc: 0.1111\n",
      "\n",
      "Epoch 40/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.1966 - acc: 0.1098 - val_loss: 2.2113 - val_acc: 0.1111\n",
      "\n",
      "Epoch 41/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 590us/step - loss: 2.1957 - acc: 0.1098 - val_loss: 2.2105 - val_acc: 0.1111\n",
      "\n",
      "Epoch 42/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 476us/step - loss: 2.1948 - acc: 0.1098 - val_loss: 2.2097 - val_acc: 0.1111\n",
      "\n",
      "Epoch 43/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 584us/step - loss: 2.1939 - acc: 0.1098 - val_loss: 2.2087 - val_acc: 0.1111\n",
      "\n",
      "Epoch 44/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 487us/step - loss: 2.1930 - acc: 0.1098 - val_loss: 2.2079 - val_acc: 0.1111\n",
      "\n",
      "Epoch 45/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 507us/step - loss: 2.1921 - acc: 0.1098 - val_loss: 2.2071 - val_acc: 0.1111\n",
      "\n",
      "Epoch 46/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 493us/step - loss: 2.1913 - acc: 0.1098 - val_loss: 2.2063 - val_acc: 0.1111\n",
      "\n",
      "Epoch 47/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 512us/step - loss: 2.1904 - acc: 0.1098 - val_loss: 2.2056 - val_acc: 0.1111\n",
      "\n",
      "Epoch 48/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 456us/step - loss: 2.1896 - acc: 0.1098 - val_loss: 2.2048 - val_acc: 0.1111\n",
      "\n",
      "Epoch 49/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 556us/step - loss: 2.1888 - acc: 0.1098 - val_loss: 2.2040 - val_acc: 0.1111\n",
      "\n",
      "Epoch 50/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 558us/step - loss: 2.1880 - acc: 0.1098 - val_loss: 2.2033 - val_acc: 0.1111\n",
      "\n",
      "Epoch 51/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 513us/step - loss: 2.1872 - acc: 0.1098 - val_loss: 2.2026 - val_acc: 0.1111\n",
      "\n",
      "Epoch 52/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 489us/step - loss: 2.1864 - acc: 0.1098 - val_loss: 2.2019 - val_acc: 0.1111\n",
      "\n",
      "Epoch 53/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 2.1857 - acc: 0.1098 - val_loss: 2.2012 - val_acc: 0.1111\n",
      "\n",
      "Epoch 54/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 564us/step - loss: 2.1849 - acc: 0.1098 - val_loss: 2.2004 - val_acc: 0.1111\n",
      "\n",
      "Epoch 55/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 597us/step - loss: 2.1841 - acc: 0.1098 - val_loss: 2.1998 - val_acc: 0.1111\n",
      "\n",
      "Epoch 56/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 468us/step - loss: 2.1833 - acc: 0.1098 - val_loss: 2.1991 - val_acc: 0.1111\n",
      "\n",
      "Epoch 57/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 513us/step - loss: 2.1826 - acc: 0.1098 - val_loss: 2.1984 - val_acc: 0.1111\n",
      "\n",
      "Epoch 58/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 520us/step - loss: 2.1818 - acc: 0.1098 - val_loss: 2.1977 - val_acc: 0.1111\n",
      "\n",
      "Epoch 59/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 534us/step - loss: 2.1810 - acc: 0.1098 - val_loss: 2.1970 - val_acc: 0.1111\n",
      "\n",
      "Epoch 60/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 454us/step - loss: 2.1803 - acc: 0.1098 - val_loss: 2.1963 - val_acc: 0.1111\n",
      "\n",
      "Epoch 61/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 629us/step - loss: 2.1796 - acc: 0.1115 - val_loss: 2.1955 - val_acc: 0.1111\n",
      "\n",
      "Epoch 62/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 575us/step - loss: 2.1788 - acc: 0.1115 - val_loss: 2.1949 - val_acc: 0.1111\n",
      "\n",
      "Epoch 63/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 459us/step - loss: 2.1781 - acc: 0.1115 - val_loss: 2.1942 - val_acc: 0.1111\n",
      "\n",
      "Epoch 64/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 2.1774 - acc: 0.1115 - val_loss: 2.1935 - val_acc: 0.1111\n",
      "\n",
      "Epoch 65/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 595us/step - loss: 2.1766 - acc: 0.1115 - val_loss: 2.1929 - val_acc: 0.1111\n",
      "\n",
      "Epoch 66/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 518us/step - loss: 2.1760 - acc: 0.1115 - val_loss: 2.1922 - val_acc: 0.1111\n",
      "\n",
      "Epoch 67/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 518us/step - loss: 2.1752 - acc: 0.1115 - val_loss: 2.1916 - val_acc: 0.1111\n",
      "\n",
      "Epoch 68/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 470us/step - loss: 2.1745 - acc: 0.1115 - val_loss: 2.1909 - val_acc: 0.1111\n",
      "\n",
      "Epoch 69/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 580us/step - loss: 2.1738 - acc: 0.1115 - val_loss: 2.1902 - val_acc: 0.1111\n",
      "\n",
      "Epoch 70/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 487us/step - loss: 2.1731 - acc: 0.1115 - val_loss: 2.1895 - val_acc: 0.1111\n",
      "\n",
      "Epoch 71/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 490us/step - loss: 2.1725 - acc: 0.1115 - val_loss: 2.1889 - val_acc: 0.1111TA: 0s - loss: 2.1697 - acc: 0.1\n",
      "\n",
      "Epoch 72/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 476us/step - loss: 2.1718 - acc: 0.1115 - val_loss: 2.1883 - val_acc: 0.1111TA: 0s - loss: 2.1763 - acc: 0.102\n",
      "\n",
      "Epoch 73/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 717us/step - loss: 2.1711 - acc: 0.1115 - val_loss: 2.1876 - val_acc: 0.1111\n",
      "\n",
      "Epoch 74/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.1705 - acc: 0.1115 - val_loss: 2.1870 - val_acc: 0.1111\n",
      "\n",
      "Epoch 75/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 452us/step - loss: 2.1698 - acc: 0.1115 - val_loss: 2.1863 - val_acc: 0.1111\n",
      "\n",
      "Epoch 76/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 617us/step - loss: 2.1692 - acc: 0.1115 - val_loss: 2.1857 - val_acc: 0.1111\n",
      "\n",
      "Epoch 77/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 555us/step - loss: 2.1685 - acc: 0.1115 - val_loss: 2.1851 - val_acc: 0.1111TA: 0s - loss: 2.1702 - acc: 0.104\n",
      "\n",
      "Epoch 78/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 490us/step - loss: 2.1679 - acc: 0.1115 - val_loss: 2.1845 - val_acc: 0.1111\n",
      "\n",
      "Epoch 79/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 650us/step - loss: 2.1672 - acc: 0.1115 - val_loss: 2.1838 - val_acc: 0.1111\n",
      "\n",
      "Epoch 80/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 545us/step - loss: 2.1665 - acc: 0.1115 - val_loss: 2.1832 - val_acc: 0.1111\n",
      "\n",
      "Epoch 81/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 623us/step - loss: 2.1659 - acc: 0.1115 - val_loss: 2.1826 - val_acc: 0.1111\n",
      "\n",
      "Epoch 82/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 538us/step - loss: 2.1653 - acc: 0.1115 - val_loss: 2.1819 - val_acc: 0.1111\n",
      "\n",
      "Epoch 83/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 586us/step - loss: 2.1646 - acc: 0.1115 - val_loss: 2.1813 - val_acc: 0.1111\n",
      "\n",
      "Epoch 84/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 564us/step - loss: 2.1640 - acc: 0.1115 - val_loss: 2.1807 - val_acc: 0.1111\n",
      "\n",
      "Epoch 85/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 555us/step - loss: 2.1633 - acc: 0.1115 - val_loss: 2.1799 - val_acc: 0.1111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 86/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 624us/step - loss: 2.1627 - acc: 0.1115 - val_loss: 2.1793 - val_acc: 0.1111\n",
      "\n",
      "Epoch 87/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 505us/step - loss: 2.1621 - acc: 0.1115 - val_loss: 2.1787 - val_acc: 0.1111\n",
      "\n",
      "Epoch 88/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 498us/step - loss: 2.1614 - acc: 0.1132 - val_loss: 2.1782 - val_acc: 0.1111\n",
      "\n",
      "Epoch 89/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 555us/step - loss: 2.1608 - acc: 0.1166 - val_loss: 2.1776 - val_acc: 0.1111\n",
      "\n",
      "Epoch 90/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 518us/step - loss: 2.1602 - acc: 0.1166 - val_loss: 2.1770 - val_acc: 0.1111\n",
      "\n",
      "Epoch 91/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 512us/step - loss: 2.1596 - acc: 0.1166 - val_loss: 2.1765 - val_acc: 0.1111\n",
      "\n",
      "Epoch 92/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 481us/step - loss: 2.1589 - acc: 0.1166 - val_loss: 2.1759 - val_acc: 0.1173\n",
      "\n",
      "Epoch 93/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 541us/step - loss: 2.1583 - acc: 0.1166 - val_loss: 2.1753 - val_acc: 0.1173\n",
      "\n",
      "Epoch 94/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 519us/step - loss: 2.1577 - acc: 0.1166 - val_loss: 2.1747 - val_acc: 0.1173\n",
      "\n",
      "Epoch 95/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 567us/step - loss: 2.1570 - acc: 0.1201 - val_loss: 2.1741 - val_acc: 0.1173\n",
      "\n",
      "Epoch 96/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 519us/step - loss: 2.1565 - acc: 0.1201 - val_loss: 2.1736 - val_acc: 0.1173\n",
      "\n",
      "Epoch 97/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 513us/step - loss: 2.1558 - acc: 0.1201 - val_loss: 2.1730 - val_acc: 0.1235\n",
      "\n",
      "Epoch 98/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 489us/step - loss: 2.1552 - acc: 0.1201 - val_loss: 2.1724 - val_acc: 0.1235\n",
      "\n",
      "Epoch 99/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 512us/step - loss: 2.1546 - acc: 0.1201 - val_loss: 2.1718 - val_acc: 0.1235\n",
      "\n",
      "Epoch 100/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.1539 - acc: 0.1201 - val_loss: 2.1712 - val_acc: 0.1235\n",
      "\n",
      "Epoch 101/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 608us/step - loss: 2.1533 - acc: 0.1201 - val_loss: 2.1706 - val_acc: 0.1235\n",
      "\n",
      "Epoch 102/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 446us/step - loss: 2.1526 - acc: 0.1201 - val_loss: 2.1701 - val_acc: 0.1235\n",
      "\n",
      "Epoch 103/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 546us/step - loss: 2.1520 - acc: 0.1201 - val_loss: 2.1695 - val_acc: 0.1235\n",
      "\n",
      "Epoch 104/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 488us/step - loss: 2.1514 - acc: 0.1201 - val_loss: 2.1688 - val_acc: 0.1235\n",
      "\n",
      "Epoch 105/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.1507 - acc: 0.1201 - val_loss: 2.1685 - val_acc: 0.1235 - ETA: 0s - loss: 2.1617 - acc: 0.097384/583 [==================>...........] - ETA: 0s - loss: 2.1567 - acc: 0.11\n",
      "\n",
      "Epoch 106/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 589us/step - loss: 2.1501 - acc: 0.1201 - val_loss: 2.1678 - val_acc: 0.1296\n",
      "\n",
      "Epoch 107/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 488us/step - loss: 2.1494 - acc: 0.1201 - val_loss: 2.1670 - val_acc: 0.1296\n",
      "\n",
      "Epoch 108/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.1488 - acc: 0.1201 - val_loss: 2.1664 - val_acc: 0.1296\n",
      "\n",
      "Epoch 109/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 486us/step - loss: 2.1481 - acc: 0.1201 - val_loss: 2.1657 - val_acc: 0.1296\n",
      "\n",
      "Epoch 110/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 602us/step - loss: 2.1475 - acc: 0.1201 - val_loss: 2.1651 - val_acc: 0.1296\n",
      "\n",
      "Epoch 111/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 517us/step - loss: 2.1468 - acc: 0.1201 - val_loss: 2.1644 - val_acc: 0.1296\n",
      "\n",
      "Epoch 112/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.1462 - acc: 0.1201 - val_loss: 2.1639 - val_acc: 0.1296\n",
      "\n",
      "Epoch 113/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 567us/step - loss: 2.1456 - acc: 0.1201 - val_loss: 2.1633 - val_acc: 0.1296\n",
      "\n",
      "Epoch 114/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 489us/step - loss: 2.1449 - acc: 0.1201 - val_loss: 2.1626 - val_acc: 0.1296\n",
      "\n",
      "Epoch 115/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 518us/step - loss: 2.1443 - acc: 0.1201 - val_loss: 2.1619 - val_acc: 0.1296\n",
      "\n",
      "Epoch 116/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 602us/step - loss: 2.1436 - acc: 0.1201 - val_loss: 2.1612 - val_acc: 0.1296\n",
      "\n",
      "Epoch 117/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 511us/step - loss: 2.1430 - acc: 0.1201 - val_loss: 2.1607 - val_acc: 0.1296\n",
      "\n",
      "Epoch 118/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 506us/step - loss: 2.1423 - acc: 0.1201 - val_loss: 2.1600 - val_acc: 0.1296\n",
      "\n",
      "Epoch 119/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 495us/step - loss: 2.1417 - acc: 0.1201 - val_loss: 2.1593 - val_acc: 0.1296TA: 0s - loss: 2.1500 - acc: 0.\n",
      "\n",
      "Epoch 120/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 535us/step - loss: 2.1410 - acc: 0.1201 - val_loss: 2.1588 - val_acc: 0.1296\n",
      "\n",
      "Epoch 121/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 570us/step - loss: 2.1404 - acc: 0.1201 - val_loss: 2.1582 - val_acc: 0.1358\n",
      "\n",
      "Epoch 122/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 491us/step - loss: 2.1397 - acc: 0.1201 - val_loss: 2.1575 - val_acc: 0.1358\n",
      "\n",
      "Epoch 123/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 603us/step - loss: 2.1390 - acc: 0.1201 - val_loss: 2.1569 - val_acc: 0.1358\n",
      "\n",
      "Epoch 124/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 573us/step - loss: 2.1383 - acc: 0.1201 - val_loss: 2.1561 - val_acc: 0.1358\n",
      "\n",
      "Epoch 125/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 621us/step - loss: 2.1376 - acc: 0.1201 - val_loss: 2.1555 - val_acc: 0.1358\n",
      "\n",
      "Epoch 126/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 688us/step - loss: 2.1369 - acc: 0.1201 - val_loss: 2.1549 - val_acc: 0.1358\n",
      "\n",
      "Epoch 127/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 657us/step - loss: 2.1362 - acc: 0.1201 - val_loss: 2.1544 - val_acc: 0.1358\n",
      "\n",
      "Epoch 128/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 532us/step - loss: 2.1356 - acc: 0.1201 - val_loss: 2.1537 - val_acc: 0.1358\n",
      "\n",
      "Epoch 129/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.1349 - acc: 0.1201 - val_loss: 2.1531 - val_acc: 0.1358TA: 0s - loss: 2.1312 - acc: 0.12\n",
      "\n",
      "Epoch 130/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 547us/step - loss: 2.1342 - acc: 0.1201 - val_loss: 2.1524 - val_acc: 0.1358\n",
      "\n",
      "Epoch 131/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 2.1335 - acc: 0.1201 - val_loss: 2.1517 - val_acc: 0.1358\n",
      "\n",
      "Epoch 132/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 458us/step - loss: 2.1327 - acc: 0.1201 - val_loss: 2.1511 - val_acc: 0.1358\n",
      "\n",
      "Epoch 133/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 506us/step - loss: 2.1320 - acc: 0.1201 - val_loss: 2.1504 - val_acc: 0.1358\n",
      "\n",
      "Epoch 134/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 497us/step - loss: 2.1313 - acc: 0.1201 - val_loss: 2.1497 - val_acc: 0.1358\n",
      "\n",
      "Epoch 135/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 572us/step - loss: 2.1305 - acc: 0.1201 - val_loss: 2.1491 - val_acc: 0.1358\n",
      "\n",
      "Epoch 136/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 556us/step - loss: 2.1297 - acc: 0.1218 - val_loss: 2.1483 - val_acc: 0.1358\n",
      "\n",
      "Epoch 137/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 467us/step - loss: 2.1290 - acc: 0.1218 - val_loss: 2.1476 - val_acc: 0.1358\n",
      "\n",
      "Epoch 138/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 577us/step - loss: 2.1282 - acc: 0.1201 - val_loss: 2.1470 - val_acc: 0.1358\n",
      "\n",
      "Epoch 139/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 2.1274 - acc: 0.1218 - val_loss: 2.1463 - val_acc: 0.1358\n",
      "\n",
      "Epoch 140/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 455us/step - loss: 2.1266 - acc: 0.1218 - val_loss: 2.1456 - val_acc: 0.1358\n",
      "\n",
      "Epoch 141/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 517us/step - loss: 2.1258 - acc: 0.1218 - val_loss: 2.1448 - val_acc: 0.1358\n",
      "\n",
      "Epoch 142/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 536us/step - loss: 2.1250 - acc: 0.1235 - val_loss: 2.1441 - val_acc: 0.1358TA: 0s - loss: 2.1255 - acc: 0.118 - ETA: 0s - loss: 2.1213 - acc: 0.13\n",
      "\n",
      "Epoch 143/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 517us/step - loss: 2.1242 - acc: 0.1252 - val_loss: 2.1433 - val_acc: 0.1358\n",
      "\n",
      "Epoch 144/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 474us/step - loss: 2.1233 - acc: 0.1252 - val_loss: 2.1425 - val_acc: 0.1358TA: 0s - loss: 2.1388 - acc: 0.\n",
      "\n",
      "Epoch 145/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 528us/step - loss: 2.1225 - acc: 0.1252 - val_loss: 2.1419 - val_acc: 0.1358TA: 0s - loss: 2.1251 - acc: 0.11\n",
      "\n",
      "Epoch 146/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 567us/step - loss: 2.1217 - acc: 0.1252 - val_loss: 2.1410 - val_acc: 0.1358\n",
      "\n",
      "Epoch 147/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 504us/step - loss: 2.1209 - acc: 0.1252 - val_loss: 2.1402 - val_acc: 0.1296\n",
      "\n",
      "Epoch 148/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 654us/step - loss: 2.1200 - acc: 0.1269 - val_loss: 2.1395 - val_acc: 0.1358\n",
      "\n",
      "Epoch 149/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 510us/step - loss: 2.1191 - acc: 0.1269 - val_loss: 2.1388 - val_acc: 0.1358\n",
      "\n",
      "Epoch 150/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 540us/step - loss: 2.1182 - acc: 0.1269 - val_loss: 2.1378 - val_acc: 0.1296\n",
      "\n",
      "Epoch 151/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 600us/step - loss: 2.1173 - acc: 0.1269 - val_loss: 2.1371 - val_acc: 0.1358\n",
      "\n",
      "Epoch 152/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 524us/step - loss: 2.1164 - acc: 0.1304 - val_loss: 2.1361 - val_acc: 0.1296\n",
      "\n",
      "Epoch 153/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 679us/step - loss: 2.1154 - acc: 0.1304 - val_loss: 2.1353 - val_acc: 0.1296\n",
      "\n",
      "Epoch 154/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 535us/step - loss: 2.1145 - acc: 0.1321 - val_loss: 2.1344 - val_acc: 0.1296\n",
      "\n",
      "Epoch 155/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 581us/step - loss: 2.1136 - acc: 0.1338 - val_loss: 2.1334 - val_acc: 0.1296\n",
      "\n",
      "Epoch 156/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 2.1126 - acc: 0.1338 - val_loss: 2.1327 - val_acc: 0.1296\n",
      "\n",
      "Epoch 157/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 533us/step - loss: 2.1116 - acc: 0.1355 - val_loss: 2.1318 - val_acc: 0.1296\n",
      "\n",
      "Epoch 158/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 523us/step - loss: 2.1107 - acc: 0.1407 - val_loss: 2.1308 - val_acc: 0.1296\n",
      "\n",
      "Epoch 159/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 566us/step - loss: 2.1097 - acc: 0.1458 - val_loss: 2.1299 - val_acc: 0.1358\n",
      "\n",
      "Epoch 160/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 518us/step - loss: 2.1087 - acc: 0.1458 - val_loss: 2.1290 - val_acc: 0.1358\n",
      "\n",
      "Epoch 161/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 532us/step - loss: 2.1078 - acc: 0.1458 - val_loss: 2.1280 - val_acc: 0.1358\n",
      "\n",
      "Epoch 162/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 526us/step - loss: 2.1067 - acc: 0.1458 - val_loss: 2.1271 - val_acc: 0.1358\n",
      "\n",
      "Epoch 163/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 576us/step - loss: 2.1057 - acc: 0.1458 - val_loss: 2.1260 - val_acc: 0.1358\n",
      "\n",
      "Epoch 164/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 581us/step - loss: 2.1047 - acc: 0.1458 - val_loss: 2.1250 - val_acc: 0.1420\n",
      "\n",
      "Epoch 165/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 559us/step - loss: 2.1036 - acc: 0.1475 - val_loss: 2.1240 - val_acc: 0.1420\n",
      "\n",
      "Epoch 166/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 531us/step - loss: 2.1027 - acc: 0.1492 - val_loss: 2.1231 - val_acc: 0.1420TA: 0s - loss: 2.1020 - acc: 0.149\n",
      "\n",
      "Epoch 167/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 498us/step - loss: 2.1016 - acc: 0.1492 - val_loss: 2.1222 - val_acc: 0.1420\n",
      "\n",
      "Epoch 168/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 502us/step - loss: 2.1005 - acc: 0.1492 - val_loss: 2.1212 - val_acc: 0.1420\n",
      "\n",
      "Epoch 169/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 525us/step - loss: 2.0995 - acc: 0.1492 - val_loss: 2.1201 - val_acc: 0.1420\n",
      "\n",
      "Epoch 170/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 534us/step - loss: 2.0983 - acc: 0.1492 - val_loss: 2.1191 - val_acc: 0.1420TA: 0s - loss: 2.1094 - acc: 0.12\n",
      "\n",
      "Epoch 171/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 597us/step - loss: 2.0972 - acc: 0.1492 - val_loss: 2.1180 - val_acc: 0.1420\n",
      "\n",
      "Epoch 172/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 470us/step - loss: 2.0961 - acc: 0.1492 - val_loss: 2.1172 - val_acc: 0.1420\n",
      "\n",
      "Epoch 173/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 496us/step - loss: 2.0950 - acc: 0.1492 - val_loss: 2.1160 - val_acc: 0.1420\n",
      "\n",
      "Epoch 174/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 478us/step - loss: 2.0938 - acc: 0.1509 - val_loss: 2.1151 - val_acc: 0.1420\n",
      "\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================]583/583 [==============================] - 0s 577us/step - loss: 2.0927 - acc: 0.1527 - val_loss: 2.1140 - val_acc: 0.1420TA: 0s - loss: 2.0926 - acc: 0.154\n",
      "\n",
      "Epoch 176/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 472us/step - loss: 2.0916 - acc: 0.1544 - val_loss: 2.1130 - val_acc: 0.1420\n",
      "\n",
      "Epoch 177/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 506us/step - loss: 2.0904 - acc: 0.1561 - val_loss: 2.1120 - val_acc: 0.1481\n",
      "\n",
      "Epoch 178/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 488us/step - loss: 2.0893 - acc: 0.1578 - val_loss: 2.1110 - val_acc: 0.1481\n",
      "\n",
      "Epoch 179/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 562us/step - loss: 2.0881 - acc: 0.1578 - val_loss: 2.1098 - val_acc: 0.1481\n",
      "\n",
      "Epoch 180/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 503us/step - loss: 2.0869 - acc: 0.1578 - val_loss: 2.1086 - val_acc: 0.1481\n",
      "\n",
      "Epoch 181/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 557us/step - loss: 2.0856 - acc: 0.1578 - val_loss: 2.1076 - val_acc: 0.1481\n",
      "\n",
      "Epoch 182/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.0845 - acc: 0.1578 - val_loss: 2.1064 - val_acc: 0.1481TA: 0s - loss: 2.0438 - acc: 0.\n",
      "\n",
      "Epoch 183/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.0832 - acc: 0.1595 - val_loss: 2.1052 - val_acc: 0.1481\n",
      "\n",
      "Epoch 184/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 509us/step - loss: 2.0819 - acc: 0.1595 - val_loss: 2.1042 - val_acc: 0.1543\n",
      "\n",
      "Epoch 185/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 466us/step - loss: 2.0806 - acc: 0.1578 - val_loss: 2.1030 - val_acc: 0.1543\n",
      "\n",
      "Epoch 186/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 586us/step - loss: 2.0793 - acc: 0.1612 - val_loss: 2.1018 - val_acc: 0.1543\n",
      "\n",
      "Epoch 187/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 532us/step - loss: 2.0780 - acc: 0.1647 - val_loss: 2.1004 - val_acc: 0.1543\n",
      "\n",
      "Epoch 188/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 556us/step - loss: 2.0767 - acc: 0.1664 - val_loss: 2.0991 - val_acc: 0.1543\n",
      "\n",
      "Epoch 189/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 675us/step - loss: 2.0754 - acc: 0.1664 - val_loss: 2.0979 - val_acc: 0.1543\n",
      "\n",
      "Epoch 190/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 602us/step - loss: 2.0740 - acc: 0.1681 - val_loss: 2.0968 - val_acc: 0.1543\n",
      "\n",
      "Epoch 191/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 729us/step - loss: 2.0726 - acc: 0.1681 - val_loss: 2.0956 - val_acc: 0.1543\n",
      "\n",
      "Epoch 192/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 647us/step - loss: 2.0712 - acc: 0.1715 - val_loss: 2.0944 - val_acc: 0.1605\n",
      "\n",
      "Epoch 193/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 680us/step - loss: 2.0698 - acc: 0.1732 - val_loss: 2.0929 - val_acc: 0.1605TA: 0s - loss: 2.0748 - acc: 0\n",
      "\n",
      "Epoch 194/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 681us/step - loss: 2.0684 - acc: 0.1732 - val_loss: 2.0917 - val_acc: 0.1667\n",
      "\n",
      "Epoch 195/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 585us/step - loss: 2.0669 - acc: 0.1767 - val_loss: 2.0907 - val_acc: 0.1728\n",
      "\n",
      "Epoch 196/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 654us/step - loss: 2.0655 - acc: 0.1767 - val_loss: 2.0896 - val_acc: 0.1728\n",
      "\n",
      "Epoch 197/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 653us/step - loss: 2.0640 - acc: 0.1784 - val_loss: 2.0883 - val_acc: 0.1728\n",
      "\n",
      "Epoch 198/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 720us/step - loss: 2.0624 - acc: 0.1784 - val_loss: 2.0872 - val_acc: 0.1728\n",
      "\n",
      "Epoch 199/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 541us/step - loss: 2.0610 - acc: 0.1784 - val_loss: 2.0855 - val_acc: 0.1728\n",
      "\n",
      "Epoch 200/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 518us/step - loss: 2.0594 - acc: 0.1784 - val_loss: 2.0842 - val_acc: 0.1728\n",
      "\n",
      "65/65 [==============================]65/65 [==============================] - 0s 422us/step\n",
      "\n",
      "Train on 583 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "583/583 [==============================]583/583 [==============================] - 2s 4ms/step - loss: 2.1886 - acc: 0.1012 - val_loss: 2.1718 - val_acc: 0.1543\n",
      "\n",
      "Epoch 2/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 629us/step - loss: 2.1871 - acc: 0.1012 - val_loss: 2.1703 - val_acc: 0.1543\n",
      "\n",
      "Epoch 3/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 657us/step - loss: 2.1856 - acc: 0.1012 - val_loss: 2.1690 - val_acc: 0.1543\n",
      "\n",
      "Epoch 4/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 559us/step - loss: 2.1841 - acc: 0.1012 - val_loss: 2.1675 - val_acc: 0.1543TA: 0s - loss: 2.1823 - acc: 0.1\n",
      "\n",
      "Epoch 5/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 548us/step - loss: 2.1827 - acc: 0.1012 - val_loss: 2.1661 - val_acc: 0.1543\n",
      "\n",
      "Epoch 6/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 553us/step - loss: 2.1813 - acc: 0.0995 - val_loss: 2.1647 - val_acc: 0.1543\n",
      "\n",
      "Epoch 7/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 511us/step - loss: 2.1800 - acc: 0.0995 - val_loss: 2.1633 - val_acc: 0.1543\n",
      "\n",
      "Epoch 8/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 528us/step - loss: 2.1786 - acc: 0.0995 - val_loss: 2.1621 - val_acc: 0.1543\n",
      "\n",
      "Epoch 9/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 521us/step - loss: 2.1774 - acc: 0.0995 - val_loss: 2.1608 - val_acc: 0.1543\n",
      "\n",
      "Epoch 10/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 519us/step - loss: 2.1763 - acc: 0.1012 - val_loss: 2.1597 - val_acc: 0.1543\n",
      "\n",
      "Epoch 11/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 568us/step - loss: 2.1751 - acc: 0.1012 - val_loss: 2.1585 - val_acc: 0.1543\n",
      "\n",
      "Epoch 12/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 473us/step - loss: 2.1739 - acc: 0.1012 - val_loss: 2.1574 - val_acc: 0.1543\n",
      "\n",
      "Epoch 13/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 525us/step - loss: 2.1728 - acc: 0.1012 - val_loss: 2.1562 - val_acc: 0.1543\n",
      "\n",
      "Epoch 14/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 472us/step - loss: 2.1716 - acc: 0.1012 - val_loss: 2.1550 - val_acc: 0.1543\n",
      "\n",
      "Epoch 15/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 586us/step - loss: 2.1705 - acc: 0.1012 - val_loss: 2.1540 - val_acc: 0.1543\n",
      "\n",
      "Epoch 16/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 478us/step - loss: 2.1694 - acc: 0.1012 - val_loss: 2.1527 - val_acc: 0.1543\n",
      "\n",
      "Epoch 17/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 547us/step - loss: 2.1681 - acc: 0.1012 - val_loss: 2.1515 - val_acc: 0.1543\n",
      "\n",
      "Epoch 18/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 485us/step - loss: 2.1670 - acc: 0.1012 - val_loss: 2.1504 - val_acc: 0.1543\n",
      "\n",
      "Epoch 19/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 483us/step - loss: 2.1659 - acc: 0.1012 - val_loss: 2.1491 - val_acc: 0.1481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 481us/step - loss: 2.1648 - acc: 0.1012 - val_loss: 2.1481 - val_acc: 0.1481\n",
      "\n",
      "Epoch 21/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 529us/step - loss: 2.1637 - acc: 0.1012 - val_loss: 2.1471 - val_acc: 0.1481\n",
      "\n",
      "Epoch 22/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 533us/step - loss: 2.1626 - acc: 0.1012 - val_loss: 2.1461 - val_acc: 0.1481\n",
      "\n",
      "Epoch 23/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 570us/step - loss: 2.1616 - acc: 0.1012 - val_loss: 2.1450 - val_acc: 0.1481\n",
      "\n",
      "Epoch 24/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 2.1606 - acc: 0.1012 - val_loss: 2.1440 - val_acc: 0.1481\n",
      "\n",
      "Epoch 25/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 513us/step - loss: 2.1595 - acc: 0.1012 - val_loss: 2.1430 - val_acc: 0.1481\n",
      "\n",
      "Epoch 26/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 517us/step - loss: 2.1585 - acc: 0.1012 - val_loss: 2.1420 - val_acc: 0.1481\n",
      "\n",
      "Epoch 27/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 589us/step - loss: 2.1575 - acc: 0.1029 - val_loss: 2.1410 - val_acc: 0.1481\n",
      "\n",
      "Epoch 28/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 625us/step - loss: 2.1564 - acc: 0.1029 - val_loss: 2.1400 - val_acc: 0.1481\n",
      "\n",
      "Epoch 29/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 527us/step - loss: 2.1554 - acc: 0.1046 - val_loss: 2.1390 - val_acc: 0.1481\n",
      "\n",
      "Epoch 30/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 505us/step - loss: 2.1544 - acc: 0.1046 - val_loss: 2.1380 - val_acc: 0.1481\n",
      "\n",
      "Epoch 31/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 521us/step - loss: 2.1534 - acc: 0.1046 - val_loss: 2.1368 - val_acc: 0.1481\n",
      "\n",
      "Epoch 32/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 546us/step - loss: 2.1524 - acc: 0.1046 - val_loss: 2.1360 - val_acc: 0.1481\n",
      "\n",
      "Epoch 33/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 521us/step - loss: 2.1514 - acc: 0.1046 - val_loss: 2.1349 - val_acc: 0.1481TA: 0s - loss: 2.1528 - acc: 0.10\n",
      "\n",
      "Epoch 34/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 464us/step - loss: 2.1504 - acc: 0.1046 - val_loss: 2.1339 - val_acc: 0.1481\n",
      "\n",
      "Epoch 35/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 464us/step - loss: 2.1494 - acc: 0.1046 - val_loss: 2.1331 - val_acc: 0.1481\n",
      "\n",
      "Epoch 36/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 541us/step - loss: 2.1484 - acc: 0.1046 - val_loss: 2.1321 - val_acc: 0.1481\n",
      "\n",
      "Epoch 37/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 488us/step - loss: 2.1475 - acc: 0.1046 - val_loss: 2.1310 - val_acc: 0.1481\n",
      "\n",
      "Epoch 38/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 491us/step - loss: 2.1465 - acc: 0.1046 - val_loss: 2.1301 - val_acc: 0.1481\n",
      "\n",
      "Epoch 39/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 535us/step - loss: 2.1455 - acc: 0.1046 - val_loss: 2.1291 - val_acc: 0.1481TA: 0s - loss: 2.1479 - acc: 0.105\n",
      "\n",
      "Epoch 40/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.1446 - acc: 0.1046 - val_loss: 2.1280 - val_acc: 0.1481TA: 0s - loss: 2.1523 - acc: 0.097416/583 [====================>.........] - ETA: 0s - loss: 2.1484 - acc: 0.10\n",
      "\n",
      "Epoch 41/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 570us/step - loss: 2.1436 - acc: 0.1063 - val_loss: 2.1270 - val_acc: 0.1481\n",
      "\n",
      "Epoch 42/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 487us/step - loss: 2.1426 - acc: 0.1063 - val_loss: 2.1260 - val_acc: 0.1481\n",
      "\n",
      "Epoch 43/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 541us/step - loss: 2.1415 - acc: 0.1063 - val_loss: 2.1250 - val_acc: 0.1481\n",
      "\n",
      "Epoch 44/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 536us/step - loss: 2.1405 - acc: 0.1063 - val_loss: 2.1241 - val_acc: 0.1481\n",
      "\n",
      "Epoch 45/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 513us/step - loss: 2.1395 - acc: 0.1063 - val_loss: 2.1230 - val_acc: 0.1481\n",
      "\n",
      "Epoch 46/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 520us/step - loss: 2.1385 - acc: 0.1063 - val_loss: 2.1221 - val_acc: 0.1481TA: 0s - loss: 2.1449 - acc: 0.09\n",
      "\n",
      "Epoch 47/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 512us/step - loss: 2.1374 - acc: 0.1063 - val_loss: 2.1212 - val_acc: 0.1481\n",
      "\n",
      "Epoch 48/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 573us/step - loss: 2.1364 - acc: 0.1063 - val_loss: 2.1201 - val_acc: 0.1481\n",
      "\n",
      "Epoch 49/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 489us/step - loss: 2.1354 - acc: 0.1063 - val_loss: 2.1193 - val_acc: 0.1543\n",
      "\n",
      "Epoch 50/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 598us/step - loss: 2.1344 - acc: 0.1063 - val_loss: 2.1184 - val_acc: 0.1543\n",
      "\n",
      "Epoch 51/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 503us/step - loss: 2.1335 - acc: 0.1063 - val_loss: 2.1176 - val_acc: 0.1543\n",
      "\n",
      "Epoch 52/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 471us/step - loss: 2.1324 - acc: 0.1063 - val_loss: 2.1166 - val_acc: 0.1543\n",
      "\n",
      "Epoch 53/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 504us/step - loss: 2.1314 - acc: 0.1063 - val_loss: 2.1157 - val_acc: 0.1543\n",
      "\n",
      "Epoch 54/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 492us/step - loss: 2.1304 - acc: 0.1063 - val_loss: 2.1148 - val_acc: 0.1543\n",
      "\n",
      "Epoch 55/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 540us/step - loss: 2.1294 - acc: 0.1063 - val_loss: 2.1140 - val_acc: 0.1543\n",
      "\n",
      "Epoch 56/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 517us/step - loss: 2.1284 - acc: 0.1063 - val_loss: 2.1131 - val_acc: 0.1543\n",
      "\n",
      "Epoch 57/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 493us/step - loss: 2.1274 - acc: 0.1063 - val_loss: 2.1123 - val_acc: 0.1543\n",
      "\n",
      "Epoch 58/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 508us/step - loss: 2.1264 - acc: 0.1081 - val_loss: 2.1113 - val_acc: 0.1543\n",
      "\n",
      "Epoch 59/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 583us/step - loss: 2.1254 - acc: 0.1081 - val_loss: 2.1104 - val_acc: 0.1543\n",
      "\n",
      "Epoch 60/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 466us/step - loss: 2.1244 - acc: 0.1081 - val_loss: 2.1094 - val_acc: 0.1543\n",
      "\n",
      "Epoch 61/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 2.1233 - acc: 0.1081 - val_loss: 2.1083 - val_acc: 0.1543\n",
      "\n",
      "Epoch 62/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 517us/step - loss: 2.1222 - acc: 0.1081 - val_loss: 2.1075 - val_acc: 0.1543\n",
      "\n",
      "Epoch 63/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.1212 - acc: 0.1098 - val_loss: 2.1065 - val_acc: 0.1543\n",
      "\n",
      "Epoch 64/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.1202 - acc: 0.1098 - val_loss: 2.1057 - val_acc: 0.1543\n",
      "\n",
      "Epoch 65/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 645us/step - loss: 2.1191 - acc: 0.1098 - val_loss: 2.1046 - val_acc: 0.1543\n",
      "\n",
      "Epoch 66/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 582us/step - loss: 2.1180 - acc: 0.1115 - val_loss: 2.1036 - val_acc: 0.1543\n",
      "\n",
      "Epoch 67/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 570us/step - loss: 2.1169 - acc: 0.1132 - val_loss: 2.1025 - val_acc: 0.1543\n",
      "\n",
      "Epoch 68/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 599us/step - loss: 2.1159 - acc: 0.1132 - val_loss: 2.1016 - val_acc: 0.1543\n",
      "\n",
      "Epoch 69/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 614us/step - loss: 2.1148 - acc: 0.1184 - val_loss: 2.1005 - val_acc: 0.1543\n",
      "\n",
      "Epoch 70/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 615us/step - loss: 2.1137 - acc: 0.1184 - val_loss: 2.0995 - val_acc: 0.1605\n",
      "\n",
      "Epoch 71/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 519us/step - loss: 2.1126 - acc: 0.1184 - val_loss: 2.0984 - val_acc: 0.1667\n",
      "\n",
      "Epoch 72/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 548us/step - loss: 2.1115 - acc: 0.1201 - val_loss: 2.0973 - val_acc: 0.1667\n",
      "\n",
      "Epoch 73/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 539us/step - loss: 2.1104 - acc: 0.1235 - val_loss: 2.0963 - val_acc: 0.1667\n",
      "\n",
      "Epoch 74/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 2.1092 - acc: 0.1235 - val_loss: 2.0951 - val_acc: 0.1667\n",
      "\n",
      "Epoch 75/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.1081 - acc: 0.1235 - val_loss: 2.0941 - val_acc: 0.1667\n",
      "\n",
      "Epoch 76/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 570us/step - loss: 2.1070 - acc: 0.1235 - val_loss: 2.0929 - val_acc: 0.1667\n",
      "\n",
      "Epoch 77/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 574us/step - loss: 2.1058 - acc: 0.1235 - val_loss: 2.0918 - val_acc: 0.1667\n",
      "\n",
      "Epoch 78/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 504us/step - loss: 2.1046 - acc: 0.1252 - val_loss: 2.0910 - val_acc: 0.1667\n",
      "\n",
      "Epoch 79/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 581us/step - loss: 2.1035 - acc: 0.1269 - val_loss: 2.0899 - val_acc: 0.1667\n",
      "\n",
      "Epoch 80/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 503us/step - loss: 2.1023 - acc: 0.1269 - val_loss: 2.0891 - val_acc: 0.1667\n",
      "\n",
      "Epoch 81/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 521us/step - loss: 2.1012 - acc: 0.1338 - val_loss: 2.0880 - val_acc: 0.1728\n",
      "\n",
      "Epoch 82/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 2.1000 - acc: 0.1286 - val_loss: 2.0868 - val_acc: 0.1728\n",
      "\n",
      "Epoch 83/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.0988 - acc: 0.1304 - val_loss: 2.0857 - val_acc: 0.1728\n",
      "\n",
      "Epoch 84/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 651us/step - loss: 2.0976 - acc: 0.1321 - val_loss: 2.0846 - val_acc: 0.1790\n",
      "\n",
      "Epoch 85/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.0964 - acc: 0.1338 - val_loss: 2.0833 - val_acc: 0.1790\n",
      "\n",
      "Epoch 86/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 519us/step - loss: 2.0951 - acc: 0.1372 - val_loss: 2.0821 - val_acc: 0.1852\n",
      "\n",
      "Epoch 87/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 515us/step - loss: 2.0939 - acc: 0.1475 - val_loss: 2.0810 - val_acc: 0.1852\n",
      "\n",
      "Epoch 88/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 571us/step - loss: 2.0926 - acc: 0.1509 - val_loss: 2.0797 - val_acc: 0.2037\n",
      "\n",
      "Epoch 89/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 549us/step - loss: 2.0914 - acc: 0.1544 - val_loss: 2.0783 - val_acc: 0.2160\n",
      "\n",
      "Epoch 90/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 515us/step - loss: 2.0900 - acc: 0.1630 - val_loss: 2.0772 - val_acc: 0.2160\n",
      "\n",
      "Epoch 91/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 588us/step - loss: 2.0888 - acc: 0.1612 - val_loss: 2.0760 - val_acc: 0.2222\n",
      "\n",
      "Epoch 92/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 497us/step - loss: 2.0876 - acc: 0.1630 - val_loss: 2.0748 - val_acc: 0.2222\n",
      "\n",
      "Epoch 93/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 591us/step - loss: 2.0862 - acc: 0.1681 - val_loss: 2.0736 - val_acc: 0.2284\n",
      "\n",
      "Epoch 94/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 500us/step - loss: 2.0850 - acc: 0.1681 - val_loss: 2.0724 - val_acc: 0.2284\n",
      "\n",
      "Epoch 95/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 616us/step - loss: 2.0837 - acc: 0.1715 - val_loss: 2.0712 - val_acc: 0.2284\n",
      "\n",
      "Epoch 96/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 546us/step - loss: 2.0825 - acc: 0.1767 - val_loss: 2.0701 - val_acc: 0.2284\n",
      "\n",
      "Epoch 97/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 538us/step - loss: 2.0811 - acc: 0.1784 - val_loss: 2.0689 - val_acc: 0.2284\n",
      "\n",
      "Epoch 98/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 527us/step - loss: 2.0799 - acc: 0.1801 - val_loss: 2.0676 - val_acc: 0.2346\n",
      "\n",
      "Epoch 99/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 526us/step - loss: 2.0785 - acc: 0.1818 - val_loss: 2.0663 - val_acc: 0.2407\n",
      "\n",
      "Epoch 100/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 489us/step - loss: 2.0772 - acc: 0.1818 - val_loss: 2.0652 - val_acc: 0.2407\n",
      "\n",
      "Epoch 101/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 579us/step - loss: 2.0758 - acc: 0.1852 - val_loss: 2.0637 - val_acc: 0.2407\n",
      "\n",
      "Epoch 102/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 478us/step - loss: 2.0744 - acc: 0.1852 - val_loss: 2.0622 - val_acc: 0.2407\n",
      "\n",
      "Epoch 103/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.0731 - acc: 0.1887 - val_loss: 2.0609 - val_acc: 0.2407\n",
      "\n",
      "Epoch 104/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.0716 - acc: 0.1921 - val_loss: 2.0597 - val_acc: 0.2407\n",
      "\n",
      "Epoch 105/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 573us/step - loss: 2.0703 - acc: 0.1921 - val_loss: 2.0583 - val_acc: 0.2469\n",
      "\n",
      "Epoch 106/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 531us/step - loss: 2.0688 - acc: 0.1938 - val_loss: 2.0568 - val_acc: 0.2469\n",
      "\n",
      "Epoch 107/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 569us/step - loss: 2.0674 - acc: 0.1921 - val_loss: 2.0555 - val_acc: 0.2469\n",
      "\n",
      "Epoch 108/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 469us/step - loss: 2.0660 - acc: 0.1921 - val_loss: 2.0536 - val_acc: 0.2469\n",
      "\n",
      "Epoch 109/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 538us/step - loss: 2.0645 - acc: 0.1921 - val_loss: 2.0522 - val_acc: 0.2469\n",
      "\n",
      "Epoch 110/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 614us/step - loss: 2.0630 - acc: 0.1955 - val_loss: 2.0509 - val_acc: 0.2531\n",
      "\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================]583/583 [==============================] - 0s 529us/step - loss: 2.0615 - acc: 0.1990 - val_loss: 2.0496 - val_acc: 0.2531\n",
      "\n",
      "Epoch 112/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 483us/step - loss: 2.0600 - acc: 0.2007 - val_loss: 2.0483 - val_acc: 0.2531\n",
      "\n",
      "Epoch 113/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 491us/step - loss: 2.0585 - acc: 0.2007 - val_loss: 2.0467 - val_acc: 0.2531\n",
      "\n",
      "Epoch 114/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 585us/step - loss: 2.0569 - acc: 0.2110 - val_loss: 2.0452 - val_acc: 0.2531\n",
      "\n",
      "Epoch 115/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 498us/step - loss: 2.0553 - acc: 0.2110 - val_loss: 2.0437 - val_acc: 0.2531\n",
      "\n",
      "Epoch 116/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 483us/step - loss: 2.0537 - acc: 0.2110 - val_loss: 2.0424 - val_acc: 0.2593\n",
      "\n",
      "Epoch 117/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 519us/step - loss: 2.0521 - acc: 0.2127 - val_loss: 2.0407 - val_acc: 0.2593\n",
      "\n",
      "Epoch 118/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 589us/step - loss: 2.0505 - acc: 0.2144 - val_loss: 2.0389 - val_acc: 0.2593\n",
      "\n",
      "Epoch 119/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 523us/step - loss: 2.0489 - acc: 0.2144 - val_loss: 2.0370 - val_acc: 0.2593\n",
      "\n",
      "Epoch 120/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.0473 - acc: 0.2144 - val_loss: 2.0356 - val_acc: 0.2593\n",
      "\n",
      "Epoch 121/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 513us/step - loss: 2.0457 - acc: 0.2178 - val_loss: 2.0340 - val_acc: 0.2593\n",
      "\n",
      "Epoch 122/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 572us/step - loss: 2.0440 - acc: 0.2178 - val_loss: 2.0322 - val_acc: 0.2716\n",
      "\n",
      "Epoch 123/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.0424 - acc: 0.2230 - val_loss: 2.0307 - val_acc: 0.2778\n",
      "\n",
      "Epoch 124/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 549us/step - loss: 2.0407 - acc: 0.2247 - val_loss: 2.0293 - val_acc: 0.2778\n",
      "\n",
      "Epoch 125/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 481us/step - loss: 2.0390 - acc: 0.2247 - val_loss: 2.0275 - val_acc: 0.2778\n",
      "\n",
      "Epoch 126/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 557us/step - loss: 2.0373 - acc: 0.2264 - val_loss: 2.0258 - val_acc: 0.2778\n",
      "\n",
      "Epoch 127/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 529us/step - loss: 2.0356 - acc: 0.2264 - val_loss: 2.0241 - val_acc: 0.2778\n",
      "\n",
      "Epoch 128/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 540us/step - loss: 2.0338 - acc: 0.2264 - val_loss: 2.0222 - val_acc: 0.2778\n",
      "\n",
      "Epoch 129/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 596us/step - loss: 2.0321 - acc: 0.2298 - val_loss: 2.0206 - val_acc: 0.2778\n",
      "\n",
      "Epoch 130/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 481us/step - loss: 2.0304 - acc: 0.2298 - val_loss: 2.0189 - val_acc: 0.2840\n",
      "\n",
      "Epoch 131/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 522us/step - loss: 2.0286 - acc: 0.2298 - val_loss: 2.0171 - val_acc: 0.2901\n",
      "\n",
      "Epoch 132/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 507us/step - loss: 2.0268 - acc: 0.2316 - val_loss: 2.0155 - val_acc: 0.2901\n",
      "\n",
      "Epoch 133/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 520us/step - loss: 2.0250 - acc: 0.2350 - val_loss: 2.0135 - val_acc: 0.2901\n",
      "\n",
      "Epoch 134/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.0232 - acc: 0.2367 - val_loss: 2.0116 - val_acc: 0.2901\n",
      "\n",
      "Epoch 135/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 511us/step - loss: 2.0213 - acc: 0.2367 - val_loss: 2.0097 - val_acc: 0.2901\n",
      "\n",
      "Epoch 136/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 573us/step - loss: 2.0195 - acc: 0.2367 - val_loss: 2.0074 - val_acc: 0.2901\n",
      "\n",
      "Epoch 137/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 629us/step - loss: 2.0176 - acc: 0.2384 - val_loss: 2.0053 - val_acc: 0.2901\n",
      "\n",
      "Epoch 138/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 629us/step - loss: 2.0157 - acc: 0.2384 - val_loss: 2.0033 - val_acc: 0.2963\n",
      "\n",
      "Epoch 139/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 453us/step - loss: 2.0138 - acc: 0.2384 - val_loss: 2.0011 - val_acc: 0.2901\n",
      "\n",
      "Epoch 140/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 518us/step - loss: 2.0118 - acc: 0.2384 - val_loss: 1.9991 - val_acc: 0.2901\n",
      "\n",
      "Epoch 141/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 515us/step - loss: 2.0099 - acc: 0.2419 - val_loss: 1.9975 - val_acc: 0.2963\n",
      "\n",
      "Epoch 142/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 577us/step - loss: 2.0080 - acc: 0.2436 - val_loss: 1.9955 - val_acc: 0.2963\n",
      "\n",
      "Epoch 143/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 566us/step - loss: 2.0061 - acc: 0.2453 - val_loss: 1.9934 - val_acc: 0.2963\n",
      "\n",
      "Epoch 144/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 596us/step - loss: 2.0040 - acc: 0.2436 - val_loss: 1.9914 - val_acc: 0.2963\n",
      "\n",
      "Epoch 145/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 487us/step - loss: 2.0021 - acc: 0.2436 - val_loss: 1.9896 - val_acc: 0.2963\n",
      "\n",
      "Epoch 146/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 541us/step - loss: 2.0000 - acc: 0.2436 - val_loss: 1.9877 - val_acc: 0.2963\n",
      "\n",
      "Epoch 147/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 489us/step - loss: 1.9980 - acc: 0.2453 - val_loss: 1.9855 - val_acc: 0.3025\n",
      "\n",
      "Epoch 148/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 502us/step - loss: 1.9959 - acc: 0.2470 - val_loss: 1.9833 - val_acc: 0.3025\n",
      "\n",
      "Epoch 149/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 489us/step - loss: 1.9939 - acc: 0.2453 - val_loss: 1.9811 - val_acc: 0.2963\n",
      "\n",
      "Epoch 150/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 549us/step - loss: 1.9917 - acc: 0.2470 - val_loss: 1.9790 - val_acc: 0.3025\n",
      "\n",
      "Epoch 151/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 545us/step - loss: 1.9896 - acc: 0.2470 - val_loss: 1.9768 - val_acc: 0.3025\n",
      "\n",
      "Epoch 152/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 540us/step - loss: 1.9875 - acc: 0.2487 - val_loss: 1.9745 - val_acc: 0.2963\n",
      "\n",
      "Epoch 153/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 467us/step - loss: 1.9853 - acc: 0.2487 - val_loss: 1.9724 - val_acc: 0.2963\n",
      "\n",
      "Epoch 154/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 536us/step - loss: 1.9831 - acc: 0.2487 - val_loss: 1.9702 - val_acc: 0.2963\n",
      "\n",
      "Epoch 155/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 1.9809 - acc: 0.2487 - val_loss: 1.9677 - val_acc: 0.2963\n",
      "\n",
      "Epoch 156/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 545us/step - loss: 1.9786 - acc: 0.2487 - val_loss: 1.9653 - val_acc: 0.2963\n",
      "\n",
      "Epoch 157/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 1.9763 - acc: 0.2487 - val_loss: 1.9629 - val_acc: 0.2963\n",
      "\n",
      "Epoch 158/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 512us/step - loss: 1.9739 - acc: 0.2539 - val_loss: 1.9606 - val_acc: 0.2963\n",
      "\n",
      "Epoch 159/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 1.9716 - acc: 0.2539 - val_loss: 1.9585 - val_acc: 0.2963\n",
      "\n",
      "Epoch 160/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 569us/step - loss: 1.9692 - acc: 0.2539 - val_loss: 1.9563 - val_acc: 0.2963\n",
      "\n",
      "Epoch 161/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 547us/step - loss: 1.9669 - acc: 0.2539 - val_loss: 1.9540 - val_acc: 0.2963\n",
      "\n",
      "Epoch 162/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 553us/step - loss: 1.9645 - acc: 0.2573 - val_loss: 1.9518 - val_acc: 0.3025\n",
      "\n",
      "Epoch 163/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 1.9621 - acc: 0.2573 - val_loss: 1.9492 - val_acc: 0.3025\n",
      "\n",
      "Epoch 164/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 506us/step - loss: 1.9596 - acc: 0.2590 - val_loss: 1.9468 - val_acc: 0.3025\n",
      "\n",
      "Epoch 165/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 671us/step - loss: 1.9571 - acc: 0.2573 - val_loss: 1.9442 - val_acc: 0.3025\n",
      "\n",
      "Epoch 166/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 608us/step - loss: 1.9546 - acc: 0.2590 - val_loss: 1.9416 - val_acc: 0.3025\n",
      "\n",
      "Epoch 167/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 577us/step - loss: 1.9521 - acc: 0.2607 - val_loss: 1.9394 - val_acc: 0.3025\n",
      "\n",
      "Epoch 168/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 1.9495 - acc: 0.2624 - val_loss: 1.9366 - val_acc: 0.3025\n",
      "\n",
      "Epoch 169/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 1.9469 - acc: 0.2624 - val_loss: 1.9338 - val_acc: 0.3025\n",
      "\n",
      "Epoch 170/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 1.9444 - acc: 0.2624 - val_loss: 1.9314 - val_acc: 0.3025\n",
      "\n",
      "Epoch 171/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 539us/step - loss: 1.9416 - acc: 0.2642 - val_loss: 1.9288 - val_acc: 0.3025\n",
      "\n",
      "Epoch 172/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 519us/step - loss: 1.9388 - acc: 0.2659 - val_loss: 1.9255 - val_acc: 0.3025\n",
      "\n",
      "Epoch 173/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 506us/step - loss: 1.9361 - acc: 0.2676 - val_loss: 1.9226 - val_acc: 0.3025\n",
      "\n",
      "Epoch 174/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 578us/step - loss: 1.9334 - acc: 0.2693 - val_loss: 1.9197 - val_acc: 0.3025\n",
      "\n",
      "Epoch 175/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 459us/step - loss: 1.9306 - acc: 0.2693 - val_loss: 1.9167 - val_acc: 0.3025\n",
      "\n",
      "Epoch 176/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 1.9279 - acc: 0.2710 - val_loss: 1.9144 - val_acc: 0.3025\n",
      "\n",
      "Epoch 177/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 633us/step - loss: 1.9251 - acc: 0.2744 - val_loss: 1.9118 - val_acc: 0.3086\n",
      "\n",
      "Epoch 178/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 589us/step - loss: 1.9224 - acc: 0.2779 - val_loss: 1.9086 - val_acc: 0.3148\n",
      "\n",
      "Epoch 179/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 574us/step - loss: 1.9194 - acc: 0.2779 - val_loss: 1.9054 - val_acc: 0.3086\n",
      "\n",
      "Epoch 180/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 643us/step - loss: 1.9166 - acc: 0.2864 - val_loss: 1.9026 - val_acc: 0.3148\n",
      "\n",
      "Epoch 181/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 547us/step - loss: 1.9137 - acc: 0.2847 - val_loss: 1.8999 - val_acc: 0.3210\n",
      "\n",
      "Epoch 182/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 556us/step - loss: 1.9108 - acc: 0.2899 - val_loss: 1.8968 - val_acc: 0.3210\n",
      "\n",
      "Epoch 183/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 588us/step - loss: 1.9077 - acc: 0.2916 - val_loss: 1.8939 - val_acc: 0.3210\n",
      "\n",
      "Epoch 184/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 645us/step - loss: 1.9047 - acc: 0.2899 - val_loss: 1.8905 - val_acc: 0.3210\n",
      "\n",
      "Epoch 185/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 601us/step - loss: 1.9014 - acc: 0.2916 - val_loss: 1.8871 - val_acc: 0.3272\n",
      "\n",
      "Epoch 186/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 581us/step - loss: 1.8982 - acc: 0.2916 - val_loss: 1.8841 - val_acc: 0.3210\n",
      "\n",
      "Epoch 187/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 683us/step - loss: 1.8952 - acc: 0.2916 - val_loss: 1.8812 - val_acc: 0.3210\n",
      "\n",
      "Epoch 188/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 630us/step - loss: 1.8919 - acc: 0.2950 - val_loss: 1.8777 - val_acc: 0.3210\n",
      "\n",
      "Epoch 189/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 633us/step - loss: 1.8886 - acc: 0.2916 - val_loss: 1.8743 - val_acc: 0.3210\n",
      "\n",
      "Epoch 190/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 541us/step - loss: 1.8853 - acc: 0.2950 - val_loss: 1.8708 - val_acc: 0.3210\n",
      "\n",
      "Epoch 191/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 538us/step - loss: 1.8818 - acc: 0.2933 - val_loss: 1.8677 - val_acc: 0.3272\n",
      "\n",
      "Epoch 192/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 463us/step - loss: 1.8785 - acc: 0.2950 - val_loss: 1.8645 - val_acc: 0.3272\n",
      "\n",
      "Epoch 193/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 631us/step - loss: 1.8751 - acc: 0.2950 - val_loss: 1.8613 - val_acc: 0.3272\n",
      "\n",
      "Epoch 194/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 512us/step - loss: 1.8717 - acc: 0.2985 - val_loss: 1.8580 - val_acc: 0.3272\n",
      "\n",
      "Epoch 195/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 493us/step - loss: 1.8682 - acc: 0.2985 - val_loss: 1.8549 - val_acc: 0.3333TA: 0s - loss: 1.8589 - acc: 0.31\n",
      "\n",
      "Epoch 196/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 496us/step - loss: 1.8647 - acc: 0.3002 - val_loss: 1.8515 - val_acc: 0.3395\n",
      "\n",
      "Epoch 197/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 523us/step - loss: 1.8613 - acc: 0.3019 - val_loss: 1.8481 - val_acc: 0.3395\n",
      "\n",
      "Epoch 198/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 505us/step - loss: 1.8577 - acc: 0.3070 - val_loss: 1.8446 - val_acc: 0.3395\n",
      "\n",
      "Epoch 199/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 550us/step - loss: 1.8542 - acc: 0.3070 - val_loss: 1.8414 - val_acc: 0.3395\n",
      "\n",
      "Epoch 200/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 549us/step - loss: 1.8506 - acc: 0.3105 - val_loss: 1.8379 - val_acc: 0.3395TA: 0s - loss: 1.8519 - acc: 0.310\n",
      "\n",
      "65/65 [==============================]65/65 [==============================] - 0s 503us/step\n",
      "\n",
      "Train on 583 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "583/583 [==============================]583/583 [==============================] - 2s 4ms/step - loss: 2.3568 - acc: 0.1407 - val_loss: 2.3158 - val_acc: 0.1543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 613us/step - loss: 2.3400 - acc: 0.1492 - val_loss: 2.3016 - val_acc: 0.1420\n",
      "\n",
      "Epoch 3/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 571us/step - loss: 2.3253 - acc: 0.1509 - val_loss: 2.2893 - val_acc: 0.1481\n",
      "\n",
      "Epoch 4/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 489us/step - loss: 2.3126 - acc: 0.1509 - val_loss: 2.2786 - val_acc: 0.1481\n",
      "\n",
      "Epoch 5/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 598us/step - loss: 2.3021 - acc: 0.1544 - val_loss: 2.2698 - val_acc: 0.1481\n",
      "\n",
      "Epoch 6/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 2.2930 - acc: 0.1544 - val_loss: 2.2621 - val_acc: 0.1420TA: 0s - loss: 2.3160 - acc: 0.\n",
      "\n",
      "Epoch 7/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.2849 - acc: 0.1544 - val_loss: 2.2550 - val_acc: 0.1420\n",
      "\n",
      "Epoch 8/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 546us/step - loss: 2.2775 - acc: 0.1544 - val_loss: 2.2492 - val_acc: 0.1481\n",
      "\n",
      "Epoch 9/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 2.2713 - acc: 0.1561 - val_loss: 2.2441 - val_acc: 0.1481\n",
      "\n",
      "Epoch 10/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 569us/step - loss: 2.2659 - acc: 0.1561 - val_loss: 2.2392 - val_acc: 0.1481\n",
      "\n",
      "Epoch 11/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 457us/step - loss: 2.2606 - acc: 0.1561 - val_loss: 2.2350 - val_acc: 0.1481\n",
      "\n",
      "Epoch 12/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 571us/step - loss: 2.2562 - acc: 0.1561 - val_loss: 2.2309 - val_acc: 0.1420\n",
      "\n",
      "Epoch 13/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 482us/step - loss: 2.2517 - acc: 0.1595 - val_loss: 2.2268 - val_acc: 0.1420\n",
      "\n",
      "Epoch 14/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 490us/step - loss: 2.2475 - acc: 0.1595 - val_loss: 2.2235 - val_acc: 0.1420\n",
      "\n",
      "Epoch 15/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 570us/step - loss: 2.2439 - acc: 0.1612 - val_loss: 2.2202 - val_acc: 0.1420\n",
      "\n",
      "Epoch 16/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.2403 - acc: 0.1595 - val_loss: 2.2171 - val_acc: 0.1420\n",
      "\n",
      "Epoch 17/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 571us/step - loss: 2.2368 - acc: 0.1595 - val_loss: 2.2144 - val_acc: 0.1481\n",
      "\n",
      "Epoch 18/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 511us/step - loss: 2.2338 - acc: 0.1612 - val_loss: 2.2118 - val_acc: 0.1481\n",
      "\n",
      "Epoch 19/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 503us/step - loss: 2.2309 - acc: 0.1612 - val_loss: 2.2094 - val_acc: 0.1481\n",
      "\n",
      "Epoch 20/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 557us/step - loss: 2.2281 - acc: 0.1612 - val_loss: 2.2071 - val_acc: 0.1481\n",
      "\n",
      "Epoch 21/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 485us/step - loss: 2.2254 - acc: 0.1612 - val_loss: 2.2049 - val_acc: 0.1543\n",
      "\n",
      "Epoch 22/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 548us/step - loss: 2.2228 - acc: 0.1612 - val_loss: 2.2031 - val_acc: 0.1543\n",
      "\n",
      "Epoch 23/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 551us/step - loss: 2.2205 - acc: 0.1647 - val_loss: 2.2012 - val_acc: 0.1543\n",
      "\n",
      "Epoch 24/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 563us/step - loss: 2.2183 - acc: 0.1647 - val_loss: 2.1995 - val_acc: 0.1543\n",
      "\n",
      "Epoch 25/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 580us/step - loss: 2.2160 - acc: 0.1647 - val_loss: 2.1978 - val_acc: 0.1543\n",
      "\n",
      "Epoch 26/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 607us/step - loss: 2.2139 - acc: 0.1647 - val_loss: 2.1963 - val_acc: 0.1481\n",
      "\n",
      "Epoch 27/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 655us/step - loss: 2.2120 - acc: 0.1664 - val_loss: 2.1948 - val_acc: 0.1481\n",
      "\n",
      "Epoch 28/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 554us/step - loss: 2.2103 - acc: 0.1664 - val_loss: 2.1935 - val_acc: 0.1481\n",
      "\n",
      "Epoch 29/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 520us/step - loss: 2.2085 - acc: 0.1664 - val_loss: 2.1920 - val_acc: 0.1481\n",
      "\n",
      "Epoch 30/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 526us/step - loss: 2.2068 - acc: 0.1664 - val_loss: 2.1907 - val_acc: 0.1481\n",
      "\n",
      "Epoch 31/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 525us/step - loss: 2.2050 - acc: 0.1664 - val_loss: 2.1893 - val_acc: 0.1543\n",
      "\n",
      "Epoch 32/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 539us/step - loss: 2.2034 - acc: 0.1664 - val_loss: 2.1879 - val_acc: 0.1667\n",
      "\n",
      "Epoch 33/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 547us/step - loss: 2.2018 - acc: 0.1664 - val_loss: 2.1866 - val_acc: 0.1667\n",
      "\n",
      "Epoch 34/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 578us/step - loss: 2.2003 - acc: 0.1664 - val_loss: 2.1853 - val_acc: 0.1667\n",
      "\n",
      "Epoch 35/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.1988 - acc: 0.1698 - val_loss: 2.1840 - val_acc: 0.1667\n",
      "\n",
      "Epoch 36/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 538us/step - loss: 2.1973 - acc: 0.1698 - val_loss: 2.1827 - val_acc: 0.1667\n",
      "\n",
      "Epoch 37/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.1959 - acc: 0.1698 - val_loss: 2.1814 - val_acc: 0.1667\n",
      "\n",
      "Epoch 38/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 531us/step - loss: 2.1944 - acc: 0.1698 - val_loss: 2.1802 - val_acc: 0.1790\n",
      "\n",
      "Epoch 39/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 524us/step - loss: 2.1930 - acc: 0.1715 - val_loss: 2.1791 - val_acc: 0.1790\n",
      "\n",
      "Epoch 40/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 504us/step - loss: 2.1916 - acc: 0.1732 - val_loss: 2.1780 - val_acc: 0.1728\n",
      "\n",
      "Epoch 41/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 522us/step - loss: 2.1903 - acc: 0.1767 - val_loss: 2.1769 - val_acc: 0.1790\n",
      "\n",
      "Epoch 42/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 595us/step - loss: 2.1890 - acc: 0.1784 - val_loss: 2.1758 - val_acc: 0.1790\n",
      "\n",
      "Epoch 43/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 525us/step - loss: 2.1876 - acc: 0.1801 - val_loss: 2.1746 - val_acc: 0.1852\n",
      "\n",
      "Epoch 44/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 592us/step - loss: 2.1863 - acc: 0.1801 - val_loss: 2.1735 - val_acc: 0.1914\n",
      "\n",
      "Epoch 45/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 498us/step - loss: 2.1850 - acc: 0.1801 - val_loss: 2.1724 - val_acc: 0.1914\n",
      "\n",
      "Epoch 46/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 486us/step - loss: 2.1837 - acc: 0.1818 - val_loss: 2.1713 - val_acc: 0.1914\n",
      "\n",
      "Epoch 47/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 566us/step - loss: 2.1824 - acc: 0.1818 - val_loss: 2.1702 - val_acc: 0.1914\n",
      "\n",
      "Epoch 48/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 581us/step - loss: 2.1812 - acc: 0.1835 - val_loss: 2.1692 - val_acc: 0.1914\n",
      "\n",
      "Epoch 49/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 520us/step - loss: 2.1799 - acc: 0.1835 - val_loss: 2.1681 - val_acc: 0.1914\n",
      "\n",
      "Epoch 50/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 536us/step - loss: 2.1787 - acc: 0.1835 - val_loss: 2.1670 - val_acc: 0.1914\n",
      "\n",
      "Epoch 51/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 674us/step - loss: 2.1774 - acc: 0.1870 - val_loss: 2.1659 - val_acc: 0.1914\n",
      "\n",
      "Epoch 52/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 586us/step - loss: 2.1762 - acc: 0.1870 - val_loss: 2.1649 - val_acc: 0.1914\n",
      "\n",
      "Epoch 53/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 535us/step - loss: 2.1751 - acc: 0.1887 - val_loss: 2.1639 - val_acc: 0.1914\n",
      "\n",
      "Epoch 54/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 574us/step - loss: 2.1739 - acc: 0.1887 - val_loss: 2.1628 - val_acc: 0.1914\n",
      "\n",
      "Epoch 55/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 547us/step - loss: 2.1728 - acc: 0.1887 - val_loss: 2.1617 - val_acc: 0.1914\n",
      "\n",
      "Epoch 56/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 571us/step - loss: 2.1716 - acc: 0.1887 - val_loss: 2.1607 - val_acc: 0.1852\n",
      "\n",
      "Epoch 57/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.1705 - acc: 0.1887 - val_loss: 2.1597 - val_acc: 0.1852\n",
      "\n",
      "Epoch 58/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.1694 - acc: 0.1887 - val_loss: 2.1587 - val_acc: 0.1852\n",
      "\n",
      "Epoch 59/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 513us/step - loss: 2.1683 - acc: 0.1887 - val_loss: 2.1577 - val_acc: 0.1852\n",
      "\n",
      "Epoch 60/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 572us/step - loss: 2.1672 - acc: 0.1887 - val_loss: 2.1567 - val_acc: 0.1852\n",
      "\n",
      "Epoch 61/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 668us/step - loss: 2.1661 - acc: 0.1887 - val_loss: 2.1556 - val_acc: 0.1852\n",
      "\n",
      "Epoch 62/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 564us/step - loss: 2.1650 - acc: 0.1904 - val_loss: 2.1545 - val_acc: 0.1852\n",
      "\n",
      "Epoch 63/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 564us/step - loss: 2.1639 - acc: 0.1921 - val_loss: 2.1536 - val_acc: 0.1852\n",
      "\n",
      "Epoch 64/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 574us/step - loss: 2.1629 - acc: 0.1904 - val_loss: 2.1525 - val_acc: 0.1852\n",
      "\n",
      "Epoch 65/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 555us/step - loss: 2.1617 - acc: 0.1921 - val_loss: 2.1515 - val_acc: 0.1852\n",
      "\n",
      "Epoch 66/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 468us/step - loss: 2.1606 - acc: 0.1938 - val_loss: 2.1506 - val_acc: 0.1852\n",
      "\n",
      "Epoch 67/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 534us/step - loss: 2.1596 - acc: 0.1938 - val_loss: 2.1496 - val_acc: 0.1852\n",
      "\n",
      "Epoch 68/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 500us/step - loss: 2.1585 - acc: 0.1955 - val_loss: 2.1486 - val_acc: 0.1852\n",
      "\n",
      "Epoch 69/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 481us/step - loss: 2.1574 - acc: 0.1955 - val_loss: 2.1476 - val_acc: 0.1852\n",
      "\n",
      "Epoch 70/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 2.1563 - acc: 0.1990 - val_loss: 2.1466 - val_acc: 0.1914\n",
      "\n",
      "Epoch 71/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 515us/step - loss: 2.1553 - acc: 0.1990 - val_loss: 2.1457 - val_acc: 0.1914\n",
      "\n",
      "Epoch 72/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 530us/step - loss: 2.1542 - acc: 0.2007 - val_loss: 2.1447 - val_acc: 0.1914\n",
      "\n",
      "Epoch 73/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 577us/step - loss: 2.1532 - acc: 0.1990 - val_loss: 2.1438 - val_acc: 0.1914\n",
      "\n",
      "Epoch 74/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 579us/step - loss: 2.1521 - acc: 0.2007 - val_loss: 2.1427 - val_acc: 0.1914\n",
      "\n",
      "Epoch 75/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.1510 - acc: 0.2007 - val_loss: 2.1417 - val_acc: 0.1914\n",
      "\n",
      "Epoch 76/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 540us/step - loss: 2.1498 - acc: 0.2007 - val_loss: 2.1407 - val_acc: 0.1914\n",
      "\n",
      "Epoch 77/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 546us/step - loss: 2.1487 - acc: 0.2007 - val_loss: 2.1397 - val_acc: 0.1914\n",
      "\n",
      "Epoch 78/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 481us/step - loss: 2.1477 - acc: 0.2024 - val_loss: 2.1387 - val_acc: 0.1914\n",
      "\n",
      "Epoch 79/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 547us/step - loss: 2.1466 - acc: 0.2024 - val_loss: 2.1377 - val_acc: 0.1914\n",
      "\n",
      "Epoch 80/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 485us/step - loss: 2.1455 - acc: 0.2024 - val_loss: 2.1367 - val_acc: 0.1914TA: 0s - loss: 2.1627 - acc: 0.1\n",
      "\n",
      "Epoch 81/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 494us/step - loss: 2.1444 - acc: 0.2024 - val_loss: 2.1356 - val_acc: 0.1914\n",
      "\n",
      "Epoch 82/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 501us/step - loss: 2.1433 - acc: 0.2024 - val_loss: 2.1346 - val_acc: 0.1914\n",
      "\n",
      "Epoch 83/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 506us/step - loss: 2.1422 - acc: 0.2041 - val_loss: 2.1335 - val_acc: 0.1914\n",
      "\n",
      "Epoch 84/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 520us/step - loss: 2.1411 - acc: 0.2041 - val_loss: 2.1324 - val_acc: 0.1914\n",
      "\n",
      "Epoch 85/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 518us/step - loss: 2.1400 - acc: 0.2041 - val_loss: 2.1314 - val_acc: 0.1914\n",
      "\n",
      "Epoch 86/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 524us/step - loss: 2.1389 - acc: 0.2041 - val_loss: 2.1304 - val_acc: 0.1975TA: 0s - loss: 2.1304 - acc: 0.20\n",
      "\n",
      "Epoch 87/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 609us/step - loss: 2.1378 - acc: 0.2058 - val_loss: 2.1294 - val_acc: 0.1975TA: 0s - loss: 2.1330 - acc: 0.2\n",
      "\n",
      "Epoch 88/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 578us/step - loss: 2.1367 - acc: 0.2058 - val_loss: 2.1284 - val_acc: 0.1975\n",
      "\n",
      "Epoch 89/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 508us/step - loss: 2.1357 - acc: 0.2058 - val_loss: 2.1273 - val_acc: 0.1975TA: 0s - loss: 2.1389 - acc: 0.20\n",
      "\n",
      "Epoch 90/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 550us/step - loss: 2.1346 - acc: 0.2058 - val_loss: 2.1263 - val_acc: 0.1975\n",
      "\n",
      "Epoch 91/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 483us/step - loss: 2.1335 - acc: 0.2058 - val_loss: 2.1253 - val_acc: 0.1975\n",
      "\n",
      "Epoch 92/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 490us/step - loss: 2.1324 - acc: 0.2058 - val_loss: 2.1243 - val_acc: 0.1975\n",
      "\n",
      "Epoch 93/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================]583/583 [==============================] - 0s 488us/step - loss: 2.1313 - acc: 0.2075 - val_loss: 2.1232 - val_acc: 0.1975\n",
      "\n",
      "Epoch 94/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 597us/step - loss: 2.1302 - acc: 0.2075 - val_loss: 2.1221 - val_acc: 0.1975\n",
      "\n",
      "Epoch 95/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.1291 - acc: 0.2075 - val_loss: 2.1209 - val_acc: 0.1975\n",
      "\n",
      "Epoch 96/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 613us/step - loss: 2.1280 - acc: 0.2075 - val_loss: 2.1198 - val_acc: 0.1975\n",
      "\n",
      "Epoch 97/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 533us/step - loss: 2.1268 - acc: 0.2075 - val_loss: 2.1187 - val_acc: 0.1975\n",
      "\n",
      "Epoch 98/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 566us/step - loss: 2.1258 - acc: 0.2093 - val_loss: 2.1177 - val_acc: 0.1975\n",
      "\n",
      "Epoch 99/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 489us/step - loss: 2.1247 - acc: 0.2127 - val_loss: 2.1165 - val_acc: 0.1975\n",
      "\n",
      "Epoch 100/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 539us/step - loss: 2.1235 - acc: 0.2110 - val_loss: 2.1154 - val_acc: 0.2037\n",
      "\n",
      "Epoch 101/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 518us/step - loss: 2.1224 - acc: 0.2127 - val_loss: 2.1144 - val_acc: 0.2037\n",
      "\n",
      "Epoch 102/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 572us/step - loss: 2.1212 - acc: 0.2127 - val_loss: 2.1132 - val_acc: 0.2037\n",
      "\n",
      "Epoch 103/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.1201 - acc: 0.2127 - val_loss: 2.1121 - val_acc: 0.1975\n",
      "\n",
      "Epoch 104/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 538us/step - loss: 2.1190 - acc: 0.2144 - val_loss: 2.1108 - val_acc: 0.2037TA: 0s - loss: 2.1151 - acc: 0.204416/583 [====================>.........] - ETA: 0s - loss: 2.1145 - acc: 0.21\n",
      "\n",
      "Epoch 105/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.1178 - acc: 0.2144 - val_loss: 2.1096 - val_acc: 0.2037\n",
      "\n",
      "Epoch 106/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 486us/step - loss: 2.1166 - acc: 0.2127 - val_loss: 2.1085 - val_acc: 0.2037\n",
      "\n",
      "Epoch 107/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 519us/step - loss: 2.1155 - acc: 0.2161 - val_loss: 2.1074 - val_acc: 0.2037\n",
      "\n",
      "Epoch 108/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 595us/step - loss: 2.1144 - acc: 0.2161 - val_loss: 2.1061 - val_acc: 0.2160\n",
      "\n",
      "Epoch 109/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 2.1131 - acc: 0.2178 - val_loss: 2.1050 - val_acc: 0.2222TA: 0s - loss: 2.1263 - acc: 0.19\n",
      "\n",
      "Epoch 110/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 434us/step - loss: 2.1119 - acc: 0.2178 - val_loss: 2.1038 - val_acc: 0.2222\n",
      "\n",
      "Epoch 111/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 568us/step - loss: 2.1108 - acc: 0.2213 - val_loss: 2.1026 - val_acc: 0.2222\n",
      "\n",
      "Epoch 112/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 490us/step - loss: 2.1096 - acc: 0.2230 - val_loss: 2.1015 - val_acc: 0.2222\n",
      "\n",
      "Epoch 113/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 501us/step - loss: 2.1084 - acc: 0.2264 - val_loss: 2.1003 - val_acc: 0.2284\n",
      "\n",
      "Epoch 114/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 549us/step - loss: 2.1072 - acc: 0.2281 - val_loss: 2.0990 - val_acc: 0.2284\n",
      "\n",
      "Epoch 115/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 487us/step - loss: 2.1060 - acc: 0.2298 - val_loss: 2.0978 - val_acc: 0.2284\n",
      "\n",
      "Epoch 116/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 518us/step - loss: 2.1047 - acc: 0.2316 - val_loss: 2.0967 - val_acc: 0.2284\n",
      "\n",
      "Epoch 117/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 589us/step - loss: 2.1036 - acc: 0.2333 - val_loss: 2.0956 - val_acc: 0.2284\n",
      "\n",
      "Epoch 118/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 511us/step - loss: 2.1024 - acc: 0.2367 - val_loss: 2.0943 - val_acc: 0.2284\n",
      "\n",
      "Epoch 119/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 490us/step - loss: 2.1012 - acc: 0.2419 - val_loss: 2.0931 - val_acc: 0.2284\n",
      "\n",
      "Epoch 120/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 568us/step - loss: 2.0999 - acc: 0.2419 - val_loss: 2.0919 - val_acc: 0.2284\n",
      "\n",
      "Epoch 121/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 493us/step - loss: 2.0987 - acc: 0.2419 - val_loss: 2.0906 - val_acc: 0.2284\n",
      "\n",
      "Epoch 122/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 465us/step - loss: 2.0974 - acc: 0.2419 - val_loss: 2.0895 - val_acc: 0.2284\n",
      "\n",
      "Epoch 123/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 637us/step - loss: 2.0962 - acc: 0.2419 - val_loss: 2.0881 - val_acc: 0.2284\n",
      "\n",
      "Epoch 124/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 673us/step - loss: 2.0949 - acc: 0.2419 - val_loss: 2.0869 - val_acc: 0.2284\n",
      "\n",
      "Epoch 125/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 666us/step - loss: 2.0936 - acc: 0.2453 - val_loss: 2.0857 - val_acc: 0.2346\n",
      "\n",
      "Epoch 126/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 877us/step - loss: 2.0924 - acc: 0.2470 - val_loss: 2.0844 - val_acc: 0.2346\n",
      "\n",
      "Epoch 127/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 513us/step - loss: 2.0911 - acc: 0.2487 - val_loss: 2.0832 - val_acc: 0.2407\n",
      "\n",
      "Epoch 128/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.0898 - acc: 0.2487 - val_loss: 2.0818 - val_acc: 0.2407\n",
      "\n",
      "Epoch 129/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 553us/step - loss: 2.0884 - acc: 0.2487 - val_loss: 2.0806 - val_acc: 0.2407\n",
      "\n",
      "Epoch 130/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 530us/step - loss: 2.0871 - acc: 0.2504 - val_loss: 2.0791 - val_acc: 0.2407\n",
      "\n",
      "Epoch 131/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 576us/step - loss: 2.0858 - acc: 0.2556 - val_loss: 2.0778 - val_acc: 0.2407\n",
      "\n",
      "Epoch 132/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 564us/step - loss: 2.0844 - acc: 0.2573 - val_loss: 2.0765 - val_acc: 0.2407\n",
      "\n",
      "Epoch 133/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 617us/step - loss: 2.0830 - acc: 0.2607 - val_loss: 2.0752 - val_acc: 0.2407\n",
      "\n",
      "Epoch 134/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 555us/step - loss: 2.0816 - acc: 0.2607 - val_loss: 2.0739 - val_acc: 0.2469\n",
      "\n",
      "Epoch 135/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 574us/step - loss: 2.0802 - acc: 0.2607 - val_loss: 2.0726 - val_acc: 0.2593\n",
      "\n",
      "Epoch 136/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 620us/step - loss: 2.0787 - acc: 0.2607 - val_loss: 2.0712 - val_acc: 0.2593\n",
      "\n",
      "Epoch 137/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 674us/step - loss: 2.0773 - acc: 0.2607 - val_loss: 2.0701 - val_acc: 0.2593\n",
      "\n",
      "Epoch 138/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 614us/step - loss: 2.0759 - acc: 0.2624 - val_loss: 2.0688 - val_acc: 0.2593\n",
      "\n",
      "Epoch 139/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 685us/step - loss: 2.0745 - acc: 0.2676 - val_loss: 2.0675 - val_acc: 0.2593\n",
      "\n",
      "Epoch 140/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 621us/step - loss: 2.0730 - acc: 0.2762 - val_loss: 2.0661 - val_acc: 0.2593\n",
      "\n",
      "Epoch 141/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 550us/step - loss: 2.0716 - acc: 0.2779 - val_loss: 2.0646 - val_acc: 0.2593\n",
      "\n",
      "Epoch 142/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 601us/step - loss: 2.0701 - acc: 0.2796 - val_loss: 2.0631 - val_acc: 0.2654\n",
      "\n",
      "Epoch 143/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.0687 - acc: 0.2830 - val_loss: 2.0617 - val_acc: 0.2654\n",
      "\n",
      "Epoch 144/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 565us/step - loss: 2.0672 - acc: 0.2796 - val_loss: 2.0604 - val_acc: 0.2654\n",
      "\n",
      "Epoch 145/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 520us/step - loss: 2.0658 - acc: 0.2813 - val_loss: 2.0589 - val_acc: 0.2654\n",
      "\n",
      "Epoch 146/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 2.0643 - acc: 0.2813 - val_loss: 2.0575 - val_acc: 0.2654\n",
      "\n",
      "Epoch 147/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 515us/step - loss: 2.0627 - acc: 0.2847 - val_loss: 2.0560 - val_acc: 0.2716\n",
      "\n",
      "Epoch 148/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 509us/step - loss: 2.0612 - acc: 0.2847 - val_loss: 2.0544 - val_acc: 0.2716\n",
      "\n",
      "Epoch 149/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 575us/step - loss: 2.0596 - acc: 0.2864 - val_loss: 2.0529 - val_acc: 0.2778\n",
      "\n",
      "Epoch 150/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 620us/step - loss: 2.0580 - acc: 0.2864 - val_loss: 2.0513 - val_acc: 0.2963\n",
      "\n",
      "Epoch 151/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 646us/step - loss: 2.0564 - acc: 0.2864 - val_loss: 2.0498 - val_acc: 0.3025\n",
      "\n",
      "Epoch 152/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 633us/step - loss: 2.0549 - acc: 0.2882 - val_loss: 2.0483 - val_acc: 0.3025\n",
      "\n",
      "Epoch 153/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.0533 - acc: 0.2933 - val_loss: 2.0468 - val_acc: 0.3025\n",
      "\n",
      "Epoch 154/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 551us/step - loss: 2.0517 - acc: 0.2967 - val_loss: 2.0451 - val_acc: 0.3086\n",
      "\n",
      "Epoch 155/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 569us/step - loss: 2.0501 - acc: 0.3002 - val_loss: 2.0434 - val_acc: 0.3086\n",
      "\n",
      "Epoch 156/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 535us/step - loss: 2.0484 - acc: 0.2967 - val_loss: 2.0418 - val_acc: 0.3086\n",
      "\n",
      "Epoch 157/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 492us/step - loss: 2.0468 - acc: 0.2985 - val_loss: 2.0402 - val_acc: 0.3086\n",
      "\n",
      "Epoch 158/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 500us/step - loss: 2.0451 - acc: 0.2985 - val_loss: 2.0385 - val_acc: 0.3086\n",
      "\n",
      "Epoch 159/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 555us/step - loss: 2.0434 - acc: 0.2985 - val_loss: 2.0368 - val_acc: 0.3086\n",
      "\n",
      "Epoch 160/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 546us/step - loss: 2.0418 - acc: 0.2985 - val_loss: 2.0351 - val_acc: 0.3086\n",
      "\n",
      "Epoch 161/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.0401 - acc: 0.3002 - val_loss: 2.0334 - val_acc: 0.3086\n",
      "\n",
      "Epoch 162/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.0383 - acc: 0.3002 - val_loss: 2.0317 - val_acc: 0.3148\n",
      "\n",
      "Epoch 163/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 652us/step - loss: 2.0366 - acc: 0.3002 - val_loss: 2.0300 - val_acc: 0.3148\n",
      "\n",
      "Epoch 164/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 487us/step - loss: 2.0348 - acc: 0.3002 - val_loss: 2.0282 - val_acc: 0.3148\n",
      "\n",
      "Epoch 165/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 482us/step - loss: 2.0329 - acc: 0.3002 - val_loss: 2.0264 - val_acc: 0.3148\n",
      "\n",
      "Epoch 166/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 517us/step - loss: 2.0310 - acc: 0.3019 - val_loss: 2.0249 - val_acc: 0.3086\n",
      "\n",
      "Epoch 167/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 498us/step - loss: 2.0293 - acc: 0.3019 - val_loss: 2.0232 - val_acc: 0.3086\n",
      "\n",
      "Epoch 168/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 556us/step - loss: 2.0274 - acc: 0.3105 - val_loss: 2.0213 - val_acc: 0.3086\n",
      "\n",
      "Epoch 169/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 518us/step - loss: 2.0255 - acc: 0.3139 - val_loss: 2.0195 - val_acc: 0.3086\n",
      "\n",
      "Epoch 170/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 598us/step - loss: 2.0236 - acc: 0.3156 - val_loss: 2.0177 - val_acc: 0.3086\n",
      "\n",
      "Epoch 171/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 567us/step - loss: 2.0216 - acc: 0.3156 - val_loss: 2.0159 - val_acc: 0.3086\n",
      "\n",
      "Epoch 172/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 522us/step - loss: 2.0197 - acc: 0.3156 - val_loss: 2.0139 - val_acc: 0.3086\n",
      "\n",
      "Epoch 173/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 515us/step - loss: 2.0177 - acc: 0.3173 - val_loss: 2.0121 - val_acc: 0.3148\n",
      "\n",
      "Epoch 174/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 569us/step - loss: 2.0157 - acc: 0.3190 - val_loss: 2.0101 - val_acc: 0.3148\n",
      "\n",
      "Epoch 175/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 504us/step - loss: 2.0137 - acc: 0.3190 - val_loss: 2.0081 - val_acc: 0.3148\n",
      "\n",
      "Epoch 176/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 583us/step - loss: 2.0117 - acc: 0.3190 - val_loss: 2.0060 - val_acc: 0.3148\n",
      "\n",
      "Epoch 177/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 540us/step - loss: 2.0096 - acc: 0.3190 - val_loss: 2.0040 - val_acc: 0.3148\n",
      "\n",
      "Epoch 178/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.0075 - acc: 0.3190 - val_loss: 2.0020 - val_acc: 0.3148\n",
      "\n",
      "Epoch 179/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 524us/step - loss: 2.0054 - acc: 0.3190 - val_loss: 2.0000 - val_acc: 0.3148TA: 0s - loss: 2.0297 - acc: 0.\n",
      "\n",
      "Epoch 180/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 598us/step - loss: 2.0033 - acc: 0.3190 - val_loss: 1.9980 - val_acc: 0.3148\n",
      "\n",
      "Epoch 181/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 571us/step - loss: 2.0012 - acc: 0.3190 - val_loss: 1.9959 - val_acc: 0.3148\n",
      "\n",
      "Epoch 182/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 500us/step - loss: 1.9991 - acc: 0.3190 - val_loss: 1.9938 - val_acc: 0.3210\n",
      "\n",
      "Epoch 183/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 494us/step - loss: 1.9969 - acc: 0.3208 - val_loss: 1.9917 - val_acc: 0.3272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 184/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 508us/step - loss: 1.9948 - acc: 0.3208 - val_loss: 1.9896 - val_acc: 0.3272\n",
      "\n",
      "Epoch 185/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 503us/step - loss: 1.9925 - acc: 0.3208 - val_loss: 1.9875 - val_acc: 0.3210\n",
      "\n",
      "Epoch 186/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 497us/step - loss: 1.9903 - acc: 0.3190 - val_loss: 1.9855 - val_acc: 0.3210\n",
      "\n",
      "Epoch 187/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 573us/step - loss: 1.9880 - acc: 0.3208 - val_loss: 1.9835 - val_acc: 0.3210\n",
      "\n",
      "Epoch 188/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 487us/step - loss: 1.9858 - acc: 0.3242 - val_loss: 1.9812 - val_acc: 0.3272\n",
      "\n",
      "Epoch 189/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 549us/step - loss: 1.9834 - acc: 0.3242 - val_loss: 1.9790 - val_acc: 0.3272\n",
      "\n",
      "Epoch 190/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 506us/step - loss: 1.9809 - acc: 0.3242 - val_loss: 1.9767 - val_acc: 0.3272\n",
      "\n",
      "Epoch 191/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 487us/step - loss: 1.9784 - acc: 0.3259 - val_loss: 1.9743 - val_acc: 0.3272\n",
      "\n",
      "Epoch 192/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 496us/step - loss: 1.9760 - acc: 0.3242 - val_loss: 1.9720 - val_acc: 0.3272\n",
      "\n",
      "Epoch 193/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 529us/step - loss: 1.9736 - acc: 0.3259 - val_loss: 1.9698 - val_acc: 0.3272\n",
      "\n",
      "Epoch 194/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 1.9711 - acc: 0.3259 - val_loss: 1.9674 - val_acc: 0.3272\n",
      "\n",
      "Epoch 195/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 485us/step - loss: 1.9686 - acc: 0.3242 - val_loss: 1.9648 - val_acc: 0.3272\n",
      "\n",
      "Epoch 196/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 457us/step - loss: 1.9660 - acc: 0.3259 - val_loss: 1.9624 - val_acc: 0.3272\n",
      "\n",
      "Epoch 197/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 1.9635 - acc: 0.3259 - val_loss: 1.9602 - val_acc: 0.3210\n",
      "\n",
      "Epoch 198/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 1.9610 - acc: 0.3293 - val_loss: 1.9579 - val_acc: 0.3210\n",
      "\n",
      "Epoch 199/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 473us/step - loss: 1.9585 - acc: 0.3276 - val_loss: 1.9554 - val_acc: 0.3210\n",
      "\n",
      "Epoch 200/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 490us/step - loss: 1.9556 - acc: 0.3310 - val_loss: 1.9531 - val_acc: 0.3210\n",
      "\n",
      "65/65 [==============================]65/65 [==============================] - 0s 383us/step\n",
      "\n",
      "Train on 583 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "583/583 [==============================]583/583 [==============================] - 2s 4ms/step - loss: 2.1835 - acc: 0.1252 - val_loss: 2.1700 - val_acc: 0.1481\n",
      "\n",
      "Epoch 2/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.1826 - acc: 0.1252 - val_loss: 2.1696 - val_acc: 0.1481\n",
      "\n",
      "Epoch 3/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.1818 - acc: 0.1252 - val_loss: 2.1692 - val_acc: 0.1481\n",
      "\n",
      "Epoch 4/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 574us/step - loss: 2.1810 - acc: 0.1252 - val_loss: 2.1687 - val_acc: 0.1481\n",
      "\n",
      "Epoch 5/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 587us/step - loss: 2.1802 - acc: 0.1252 - val_loss: 2.1683 - val_acc: 0.1481\n",
      "\n",
      "Epoch 6/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 602us/step - loss: 2.1794 - acc: 0.1252 - val_loss: 2.1679 - val_acc: 0.1481\n",
      "\n",
      "Epoch 7/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 599us/step - loss: 2.1787 - acc: 0.1252 - val_loss: 2.1675 - val_acc: 0.1481\n",
      "\n",
      "Epoch 8/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.1779 - acc: 0.1252 - val_loss: 2.1671 - val_acc: 0.1481\n",
      "\n",
      "Epoch 9/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 538us/step - loss: 2.1771 - acc: 0.1252 - val_loss: 2.1667 - val_acc: 0.1481\n",
      "\n",
      "Epoch 10/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 602us/step - loss: 2.1763 - acc: 0.1252 - val_loss: 2.1662 - val_acc: 0.1481\n",
      "\n",
      "Epoch 11/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 546us/step - loss: 2.1755 - acc: 0.1252 - val_loss: 2.1658 - val_acc: 0.1420TA: 0s - loss: 2.1837 - acc: 0.11\n",
      "\n",
      "Epoch 12/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 545us/step - loss: 2.1748 - acc: 0.1252 - val_loss: 2.1654 - val_acc: 0.1481\n",
      "\n",
      "Epoch 13/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 476us/step - loss: 2.1740 - acc: 0.1252 - val_loss: 2.1650 - val_acc: 0.1481\n",
      "\n",
      "Epoch 14/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 525us/step - loss: 2.1733 - acc: 0.1252 - val_loss: 2.1645 - val_acc: 0.1481\n",
      "\n",
      "Epoch 15/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 574us/step - loss: 2.1726 - acc: 0.1252 - val_loss: 2.1641 - val_acc: 0.1481\n",
      "\n",
      "Epoch 16/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 566us/step - loss: 2.1719 - acc: 0.1252 - val_loss: 2.1637 - val_acc: 0.1481\n",
      "\n",
      "Epoch 17/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 609us/step - loss: 2.1712 - acc: 0.1252 - val_loss: 2.1632 - val_acc: 0.1481\n",
      "\n",
      "Epoch 18/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 2.1705 - acc: 0.1252 - val_loss: 2.1628 - val_acc: 0.1481\n",
      "\n",
      "Epoch 19/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 580us/step - loss: 2.1698 - acc: 0.1252 - val_loss: 2.1624 - val_acc: 0.1481\n",
      "\n",
      "Epoch 20/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 477us/step - loss: 2.1691 - acc: 0.1252 - val_loss: 2.1621 - val_acc: 0.1481\n",
      "\n",
      "Epoch 21/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 492us/step - loss: 2.1684 - acc: 0.1252 - val_loss: 2.1617 - val_acc: 0.1481TA: 0s - loss: 2.1449 - acc: 0.\n",
      "\n",
      "Epoch 22/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 608us/step - loss: 2.1677 - acc: 0.1252 - val_loss: 2.1612 - val_acc: 0.1481\n",
      "\n",
      "Epoch 23/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 517us/step - loss: 2.1670 - acc: 0.1252 - val_loss: 2.1608 - val_acc: 0.1481\n",
      "\n",
      "Epoch 24/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 487us/step - loss: 2.1663 - acc: 0.1252 - val_loss: 2.1604 - val_acc: 0.1481TA: 0s - loss: 2.1663 - acc: 0.1\n",
      "\n",
      "Epoch 25/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 618us/step - loss: 2.1657 - acc: 0.1252 - val_loss: 2.1601 - val_acc: 0.1481\n",
      "\n",
      "Epoch 26/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 635us/step - loss: 2.1650 - acc: 0.1252 - val_loss: 2.1597 - val_acc: 0.1481\n",
      "\n",
      "Epoch 27/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 575us/step - loss: 2.1643 - acc: 0.1252 - val_loss: 2.1593 - val_acc: 0.1481\n",
      "\n",
      "Epoch 28/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.1637 - acc: 0.1252 - val_loss: 2.1589 - val_acc: 0.1481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 504us/step - loss: 2.1630 - acc: 0.1252 - val_loss: 2.1585 - val_acc: 0.1481\n",
      "\n",
      "Epoch 30/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 550us/step - loss: 2.1623 - acc: 0.1252 - val_loss: 2.1581 - val_acc: 0.1481\n",
      "\n",
      "Epoch 31/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 533us/step - loss: 2.1617 - acc: 0.1252 - val_loss: 2.1577 - val_acc: 0.1481\n",
      "\n",
      "Epoch 32/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 496us/step - loss: 2.1610 - acc: 0.1252 - val_loss: 2.1573 - val_acc: 0.1481\n",
      "\n",
      "Epoch 33/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 533us/step - loss: 2.1604 - acc: 0.1252 - val_loss: 2.1569 - val_acc: 0.1481\n",
      "\n",
      "Epoch 34/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 637us/step - loss: 2.1597 - acc: 0.1252 - val_loss: 2.1566 - val_acc: 0.1481\n",
      "\n",
      "Epoch 35/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.1591 - acc: 0.1252 - val_loss: 2.1562 - val_acc: 0.1481\n",
      "\n",
      "Epoch 36/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 554us/step - loss: 2.1584 - acc: 0.1252 - val_loss: 2.1558 - val_acc: 0.1481\n",
      "\n",
      "Epoch 37/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 500us/step - loss: 2.1577 - acc: 0.1252 - val_loss: 2.1555 - val_acc: 0.1481\n",
      "\n",
      "Epoch 38/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 569us/step - loss: 2.1571 - acc: 0.1252 - val_loss: 2.1551 - val_acc: 0.1481\n",
      "\n",
      "Epoch 39/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 531us/step - loss: 2.1565 - acc: 0.1252 - val_loss: 2.1548 - val_acc: 0.1481\n",
      "\n",
      "Epoch 40/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 528us/step - loss: 2.1558 - acc: 0.1252 - val_loss: 2.1544 - val_acc: 0.1481\n",
      "\n",
      "Epoch 41/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 555us/step - loss: 2.1552 - acc: 0.1252 - val_loss: 2.1540 - val_acc: 0.1481\n",
      "\n",
      "Epoch 42/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 532us/step - loss: 2.1546 - acc: 0.1252 - val_loss: 2.1536 - val_acc: 0.1481\n",
      "\n",
      "Epoch 43/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 501us/step - loss: 2.1539 - acc: 0.1252 - val_loss: 2.1533 - val_acc: 0.1481\n",
      "\n",
      "Epoch 44/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 464us/step - loss: 2.1533 - acc: 0.1252 - val_loss: 2.1528 - val_acc: 0.1481\n",
      "\n",
      "Epoch 45/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 547us/step - loss: 2.1527 - acc: 0.1252 - val_loss: 2.1524 - val_acc: 0.1481\n",
      "\n",
      "Epoch 46/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 599us/step - loss: 2.1521 - acc: 0.1252 - val_loss: 2.1520 - val_acc: 0.1481\n",
      "\n",
      "Epoch 47/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 2.1514 - acc: 0.1252 - val_loss: 2.1515 - val_acc: 0.1481\n",
      "\n",
      "Epoch 48/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 626us/step - loss: 2.1508 - acc: 0.1252 - val_loss: 2.1510 - val_acc: 0.1481\n",
      "\n",
      "Epoch 49/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 631us/step - loss: 2.1502 - acc: 0.1252 - val_loss: 2.1506 - val_acc: 0.1481\n",
      "\n",
      "Epoch 50/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 513us/step - loss: 2.1495 - acc: 0.1252 - val_loss: 2.1503 - val_acc: 0.1481\n",
      "\n",
      "Epoch 51/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 574us/step - loss: 2.1489 - acc: 0.1252 - val_loss: 2.1498 - val_acc: 0.1481\n",
      "\n",
      "Epoch 52/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 567us/step - loss: 2.1483 - acc: 0.1252 - val_loss: 2.1494 - val_acc: 0.1481\n",
      "\n",
      "Epoch 53/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 574us/step - loss: 2.1477 - acc: 0.1252 - val_loss: 2.1490 - val_acc: 0.1481\n",
      "\n",
      "Epoch 54/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 504us/step - loss: 2.1470 - acc: 0.1252 - val_loss: 2.1485 - val_acc: 0.1481TA: 0s - loss: 2.1376 - acc: 0.13\n",
      "\n",
      "Epoch 55/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 498us/step - loss: 2.1464 - acc: 0.1252 - val_loss: 2.1481 - val_acc: 0.1481\n",
      "\n",
      "Epoch 56/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 608us/step - loss: 2.1458 - acc: 0.1252 - val_loss: 2.1477 - val_acc: 0.1481\n",
      "\n",
      "Epoch 57/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 562us/step - loss: 2.1452 - acc: 0.1252 - val_loss: 2.1473 - val_acc: 0.1481\n",
      "\n",
      "Epoch 58/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.1446 - acc: 0.1252 - val_loss: 2.1468 - val_acc: 0.1481\n",
      "\n",
      "Epoch 59/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.1440 - acc: 0.1252 - val_loss: 2.1464 - val_acc: 0.1481\n",
      "\n",
      "Epoch 60/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.1434 - acc: 0.1252 - val_loss: 2.1460 - val_acc: 0.1481\n",
      "\n",
      "Epoch 61/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.1428 - acc: 0.1252 - val_loss: 2.1455 - val_acc: 0.1481\n",
      "\n",
      "Epoch 62/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 613us/step - loss: 2.1421 - acc: 0.1252 - val_loss: 2.1452 - val_acc: 0.1481\n",
      "\n",
      "Epoch 63/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 489us/step - loss: 2.1415 - acc: 0.1252 - val_loss: 2.1448 - val_acc: 0.1481\n",
      "\n",
      "Epoch 64/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 577us/step - loss: 2.1409 - acc: 0.1269 - val_loss: 2.1444 - val_acc: 0.1481 0s - loss: 2.1340 - acc: 0.12\n",
      "\n",
      "Epoch 65/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 522us/step - loss: 2.1403 - acc: 0.1269 - val_loss: 2.1439 - val_acc: 0.1481\n",
      "\n",
      "Epoch 66/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 569us/step - loss: 2.1397 - acc: 0.1269 - val_loss: 2.1435 - val_acc: 0.1481\n",
      "\n",
      "Epoch 67/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 599us/step - loss: 2.1391 - acc: 0.1269 - val_loss: 2.1430 - val_acc: 0.1481\n",
      "\n",
      "Epoch 68/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 488us/step - loss: 2.1385 - acc: 0.1269 - val_loss: 2.1425 - val_acc: 0.1481\n",
      "\n",
      "Epoch 69/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.1379 - acc: 0.1269 - val_loss: 2.1421 - val_acc: 0.1481\n",
      "\n",
      "Epoch 70/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.1373 - acc: 0.1269 - val_loss: 2.1416 - val_acc: 0.1481\n",
      "\n",
      "Epoch 71/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 557us/step - loss: 2.1367 - acc: 0.1269 - val_loss: 2.1412 - val_acc: 0.1481\n",
      "\n",
      "Epoch 72/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 524us/step - loss: 2.1361 - acc: 0.1269 - val_loss: 2.1407 - val_acc: 0.1481\n",
      "\n",
      "Epoch 73/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 545us/step - loss: 2.1354 - acc: 0.1269 - val_loss: 2.1402 - val_acc: 0.1481\n",
      "\n",
      "Epoch 74/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 456us/step - loss: 2.1348 - acc: 0.1269 - val_loss: 2.1397 - val_acc: 0.1481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 75/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 481us/step - loss: 2.1342 - acc: 0.1269 - val_loss: 2.1393 - val_acc: 0.1481\n",
      "\n",
      "Epoch 76/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 484us/step - loss: 2.1336 - acc: 0.1269 - val_loss: 2.1389 - val_acc: 0.1481\n",
      "\n",
      "Epoch 77/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 481us/step - loss: 2.1330 - acc: 0.1269 - val_loss: 2.1384 - val_acc: 0.1481\n",
      "\n",
      "Epoch 78/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 553us/step - loss: 2.1324 - acc: 0.1269 - val_loss: 2.1379 - val_acc: 0.1481\n",
      "\n",
      "Epoch 79/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 576us/step - loss: 2.1318 - acc: 0.1269 - val_loss: 2.1375 - val_acc: 0.1481\n",
      "\n",
      "Epoch 80/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 541us/step - loss: 2.1312 - acc: 0.1269 - val_loss: 2.1370 - val_acc: 0.1481\n",
      "\n",
      "Epoch 81/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 513us/step - loss: 2.1305 - acc: 0.1269 - val_loss: 2.1365 - val_acc: 0.1481\n",
      "\n",
      "Epoch 82/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 473us/step - loss: 2.1299 - acc: 0.1269 - val_loss: 2.1361 - val_acc: 0.1481\n",
      "\n",
      "Epoch 83/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 613us/step - loss: 2.1293 - acc: 0.1269 - val_loss: 2.1356 - val_acc: 0.1481\n",
      "\n",
      "Epoch 84/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 501us/step - loss: 2.1287 - acc: 0.1269 - val_loss: 2.1351 - val_acc: 0.1481\n",
      "\n",
      "Epoch 85/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 525us/step - loss: 2.1280 - acc: 0.1269 - val_loss: 2.1346 - val_acc: 0.1481\n",
      "\n",
      "Epoch 86/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.1274 - acc: 0.1269 - val_loss: 2.1342 - val_acc: 0.1481\n",
      "\n",
      "Epoch 87/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 2.1268 - acc: 0.1269 - val_loss: 2.1337 - val_acc: 0.1481\n",
      "\n",
      "Epoch 88/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 518us/step - loss: 2.1262 - acc: 0.1269 - val_loss: 2.1333 - val_acc: 0.1481\n",
      "\n",
      "Epoch 89/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 526us/step - loss: 2.1255 - acc: 0.1269 - val_loss: 2.1328 - val_acc: 0.1481\n",
      "\n",
      "Epoch 90/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 582us/step - loss: 2.1249 - acc: 0.1269 - val_loss: 2.1323 - val_acc: 0.1481\n",
      "\n",
      "Epoch 91/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 489us/step - loss: 2.1243 - acc: 0.1269 - val_loss: 2.1318 - val_acc: 0.1481\n",
      "\n",
      "Epoch 92/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 487us/step - loss: 2.1236 - acc: 0.1269 - val_loss: 2.1312 - val_acc: 0.1481\n",
      "\n",
      "Epoch 93/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 493us/step - loss: 2.1230 - acc: 0.1269 - val_loss: 2.1308 - val_acc: 0.1481\n",
      "\n",
      "Epoch 94/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 506us/step - loss: 2.1223 - acc: 0.1286 - val_loss: 2.1303 - val_acc: 0.1481\n",
      "\n",
      "Epoch 95/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 580us/step - loss: 2.1217 - acc: 0.1304 - val_loss: 2.1297 - val_acc: 0.1481\n",
      "\n",
      "Epoch 96/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 562us/step - loss: 2.1210 - acc: 0.1304 - val_loss: 2.1293 - val_acc: 0.1481\n",
      "\n",
      "Epoch 97/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 506us/step - loss: 2.1203 - acc: 0.1304 - val_loss: 2.1289 - val_acc: 0.1481\n",
      "\n",
      "Epoch 98/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 495us/step - loss: 2.1197 - acc: 0.1304 - val_loss: 2.1283 - val_acc: 0.1481\n",
      "\n",
      "Epoch 99/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 509us/step - loss: 2.1190 - acc: 0.1321 - val_loss: 2.1278 - val_acc: 0.1481\n",
      "\n",
      "Epoch 100/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 480us/step - loss: 2.1183 - acc: 0.1321 - val_loss: 2.1274 - val_acc: 0.1481\n",
      "\n",
      "Epoch 101/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 603us/step - loss: 2.1177 - acc: 0.1321 - val_loss: 2.1269 - val_acc: 0.1481\n",
      "\n",
      "Epoch 102/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 2.1170 - acc: 0.1338 - val_loss: 2.1265 - val_acc: 0.1481\n",
      "\n",
      "Epoch 103/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 601us/step - loss: 2.1164 - acc: 0.1338 - val_loss: 2.1261 - val_acc: 0.1481\n",
      "\n",
      "Epoch 104/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 630us/step - loss: 2.1156 - acc: 0.1338 - val_loss: 2.1255 - val_acc: 0.1481\n",
      "\n",
      "Epoch 105/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 517us/step - loss: 2.1149 - acc: 0.1321 - val_loss: 2.1251 - val_acc: 0.1481\n",
      "\n",
      "Epoch 106/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 596us/step - loss: 2.1142 - acc: 0.1338 - val_loss: 2.1247 - val_acc: 0.1481\n",
      "\n",
      "Epoch 107/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 589us/step - loss: 2.1135 - acc: 0.1338 - val_loss: 2.1243 - val_acc: 0.1481\n",
      "\n",
      "Epoch 108/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 555us/step - loss: 2.1128 - acc: 0.1338 - val_loss: 2.1239 - val_acc: 0.1481\n",
      "\n",
      "Epoch 109/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 574us/step - loss: 2.1120 - acc: 0.1338 - val_loss: 2.1233 - val_acc: 0.1481\n",
      "\n",
      "Epoch 110/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 484us/step - loss: 2.1113 - acc: 0.1321 - val_loss: 2.1227 - val_acc: 0.1481\n",
      "\n",
      "Epoch 111/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 541us/step - loss: 2.1105 - acc: 0.1355 - val_loss: 2.1222 - val_acc: 0.1481\n",
      "\n",
      "Epoch 112/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 579us/step - loss: 2.1098 - acc: 0.1338 - val_loss: 2.1218 - val_acc: 0.1481\n",
      "\n",
      "Epoch 113/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 479us/step - loss: 2.1091 - acc: 0.1338 - val_loss: 2.1213 - val_acc: 0.1481\n",
      "\n",
      "Epoch 114/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 511us/step - loss: 2.1083 - acc: 0.1338 - val_loss: 2.1207 - val_acc: 0.1481TA: 0s - loss: 2.1034 - acc: 0.14\n",
      "\n",
      "Epoch 115/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 586us/step - loss: 2.1076 - acc: 0.1338 - val_loss: 2.1201 - val_acc: 0.1481TA: 0s - loss: 2.1077 - acc: 0.12\n",
      "\n",
      "Epoch 116/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 531us/step - loss: 2.1068 - acc: 0.1338 - val_loss: 2.1195 - val_acc: 0.1481\n",
      "\n",
      "Epoch 117/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 487us/step - loss: 2.1061 - acc: 0.1338 - val_loss: 2.1190 - val_acc: 0.1481\n",
      "\n",
      "Epoch 118/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 581us/step - loss: 2.1053 - acc: 0.1338 - val_loss: 2.1184 - val_acc: 0.1543\n",
      "\n",
      "Epoch 119/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 491us/step - loss: 2.1045 - acc: 0.1338 - val_loss: 2.1178 - val_acc: 0.1543\n",
      "\n",
      "Epoch 120/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 552us/step - loss: 2.1038 - acc: 0.1338 - val_loss: 2.1172 - val_acc: 0.1543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 121/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 571us/step - loss: 2.1030 - acc: 0.1355 - val_loss: 2.1166 - val_acc: 0.1543\n",
      "\n",
      "Epoch 122/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 502us/step - loss: 2.1023 - acc: 0.1389 - val_loss: 2.1160 - val_acc: 0.1543\n",
      "\n",
      "Epoch 123/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 626us/step - loss: 2.1015 - acc: 0.1372 - val_loss: 2.1154 - val_acc: 0.1605\n",
      "\n",
      "Epoch 124/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 611us/step - loss: 2.1008 - acc: 0.1407 - val_loss: 2.1148 - val_acc: 0.1605\n",
      "\n",
      "Epoch 125/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.1000 - acc: 0.1424 - val_loss: 2.1142 - val_acc: 0.1605\n",
      "\n",
      "Epoch 126/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 546us/step - loss: 2.0993 - acc: 0.1458 - val_loss: 2.1136 - val_acc: 0.1605\n",
      "\n",
      "Epoch 127/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 488us/step - loss: 2.0985 - acc: 0.1458 - val_loss: 2.1130 - val_acc: 0.1605\n",
      "\n",
      "Epoch 128/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 596us/step - loss: 2.0978 - acc: 0.1475 - val_loss: 2.1125 - val_acc: 0.1605\n",
      "\n",
      "Epoch 129/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 520us/step - loss: 2.0969 - acc: 0.1509 - val_loss: 2.1119 - val_acc: 0.1605\n",
      "\n",
      "Epoch 130/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 602us/step - loss: 2.0962 - acc: 0.1544 - val_loss: 2.1113 - val_acc: 0.1605\n",
      "\n",
      "Epoch 131/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 566us/step - loss: 2.0954 - acc: 0.1544 - val_loss: 2.1108 - val_acc: 0.1605\n",
      "\n",
      "Epoch 132/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 2.0946 - acc: 0.1544 - val_loss: 2.1101 - val_acc: 0.1605\n",
      "\n",
      "Epoch 133/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 632us/step - loss: 2.0938 - acc: 0.1595 - val_loss: 2.1094 - val_acc: 0.1605\n",
      "\n",
      "Epoch 134/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 635us/step - loss: 2.0930 - acc: 0.1612 - val_loss: 2.1087 - val_acc: 0.1667\n",
      "\n",
      "Epoch 135/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 560us/step - loss: 2.0921 - acc: 0.1612 - val_loss: 2.1082 - val_acc: 0.1667\n",
      "\n",
      "Epoch 136/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 511us/step - loss: 2.0913 - acc: 0.1612 - val_loss: 2.1074 - val_acc: 0.1667\n",
      "\n",
      "Epoch 137/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 547us/step - loss: 2.0905 - acc: 0.1630 - val_loss: 2.1067 - val_acc: 0.1790\n",
      "\n",
      "Epoch 138/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 592us/step - loss: 2.0896 - acc: 0.1664 - val_loss: 2.1060 - val_acc: 0.1790\n",
      "\n",
      "Epoch 139/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 520us/step - loss: 2.0888 - acc: 0.1715 - val_loss: 2.1053 - val_acc: 0.1790\n",
      "\n",
      "Epoch 140/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 562us/step - loss: 2.0879 - acc: 0.1801 - val_loss: 2.1046 - val_acc: 0.1790\n",
      "\n",
      "Epoch 141/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 554us/step - loss: 2.0870 - acc: 0.1835 - val_loss: 2.1039 - val_acc: 0.1790\n",
      "\n",
      "Epoch 142/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 2.0862 - acc: 0.1835 - val_loss: 2.1032 - val_acc: 0.1790\n",
      "\n",
      "Epoch 143/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 538us/step - loss: 2.0853 - acc: 0.1921 - val_loss: 2.1025 - val_acc: 0.1790\n",
      "\n",
      "Epoch 144/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 600us/step - loss: 2.0844 - acc: 0.1904 - val_loss: 2.1018 - val_acc: 0.1790\n",
      "\n",
      "Epoch 145/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 488us/step - loss: 2.0835 - acc: 0.1973 - val_loss: 2.1011 - val_acc: 0.1790\n",
      "\n",
      "Epoch 146/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 515us/step - loss: 2.0826 - acc: 0.2007 - val_loss: 2.1005 - val_acc: 0.1790\n",
      "\n",
      "Epoch 147/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.0817 - acc: 0.2024 - val_loss: 2.0997 - val_acc: 0.1790\n",
      "\n",
      "Epoch 148/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 602us/step - loss: 2.0808 - acc: 0.2041 - val_loss: 2.0989 - val_acc: 0.1790\n",
      "\n",
      "Epoch 149/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 479us/step - loss: 2.0800 - acc: 0.2058 - val_loss: 2.0980 - val_acc: 0.1852\n",
      "\n",
      "Epoch 150/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 518us/step - loss: 2.0791 - acc: 0.2058 - val_loss: 2.0973 - val_acc: 0.1852\n",
      "\n",
      "Epoch 151/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 600us/step - loss: 2.0781 - acc: 0.2075 - val_loss: 2.0964 - val_acc: 0.1914\n",
      "\n",
      "Epoch 152/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 521us/step - loss: 2.0772 - acc: 0.2161 - val_loss: 2.0956 - val_acc: 0.1914\n",
      "\n",
      "Epoch 153/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 627us/step - loss: 2.0763 - acc: 0.2161 - val_loss: 2.0948 - val_acc: 0.1914\n",
      "\n",
      "Epoch 154/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 549us/step - loss: 2.0754 - acc: 0.2161 - val_loss: 2.0940 - val_acc: 0.1914\n",
      "\n",
      "Epoch 155/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 525us/step - loss: 2.0744 - acc: 0.2213 - val_loss: 2.0933 - val_acc: 0.1914\n",
      "\n",
      "Epoch 156/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 477us/step - loss: 2.0735 - acc: 0.2247 - val_loss: 2.0925 - val_acc: 0.1914\n",
      "\n",
      "Epoch 157/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 524us/step - loss: 2.0726 - acc: 0.2247 - val_loss: 2.0917 - val_acc: 0.1975\n",
      "\n",
      "Epoch 158/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 2.0716 - acc: 0.2264 - val_loss: 2.0910 - val_acc: 0.1975\n",
      "\n",
      "Epoch 159/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 511us/step - loss: 2.0707 - acc: 0.2264 - val_loss: 2.0902 - val_acc: 0.1975\n",
      "\n",
      "Epoch 160/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 518us/step - loss: 2.0697 - acc: 0.2281 - val_loss: 2.0895 - val_acc: 0.2160\n",
      "\n",
      "Epoch 161/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 502us/step - loss: 2.0687 - acc: 0.2264 - val_loss: 2.0885 - val_acc: 0.2160\n",
      "\n",
      "Epoch 162/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.0677 - acc: 0.2298 - val_loss: 2.0878 - val_acc: 0.2160TA: 0s - loss: 2.0852 - acc: 0.2\n",
      "\n",
      "Epoch 163/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 578us/step - loss: 2.0667 - acc: 0.2333 - val_loss: 2.0871 - val_acc: 0.2222\n",
      "\n",
      "Epoch 164/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 558us/step - loss: 2.0657 - acc: 0.2333 - val_loss: 2.0862 - val_acc: 0.2222\n",
      "\n",
      "Epoch 165/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 2.0647 - acc: 0.2350 - val_loss: 2.0853 - val_acc: 0.2222\n",
      "\n",
      "Epoch 166/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 507us/step - loss: 2.0637 - acc: 0.2350 - val_loss: 2.0843 - val_acc: 0.2284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 167/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 554us/step - loss: 2.0626 - acc: 0.2384 - val_loss: 2.0831 - val_acc: 0.2284\n",
      "\n",
      "Epoch 168/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 524us/step - loss: 2.0615 - acc: 0.2401 - val_loss: 2.0824 - val_acc: 0.2346\n",
      "\n",
      "Epoch 169/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 515us/step - loss: 2.0604 - acc: 0.2436 - val_loss: 2.0815 - val_acc: 0.2346\n",
      "\n",
      "Epoch 170/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.0593 - acc: 0.2436 - val_loss: 2.0807 - val_acc: 0.2346TA: 0s - loss: 2.0572 - acc: 0.24\n",
      "\n",
      "Epoch 171/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 480us/step - loss: 2.0582 - acc: 0.2436 - val_loss: 2.0798 - val_acc: 0.2346\n",
      "\n",
      "Epoch 172/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 523us/step - loss: 2.0571 - acc: 0.2436 - val_loss: 2.0789 - val_acc: 0.2531\n",
      "\n",
      "Epoch 173/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 681us/step - loss: 2.0560 - acc: 0.2436 - val_loss: 2.0781 - val_acc: 0.2531\n",
      "\n",
      "Epoch 174/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 491us/step - loss: 2.0549 - acc: 0.2436 - val_loss: 2.0770 - val_acc: 0.2593\n",
      "\n",
      "Epoch 175/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 2.0537 - acc: 0.2436 - val_loss: 2.0761 - val_acc: 0.2593\n",
      "\n",
      "Epoch 176/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 596us/step - loss: 2.0526 - acc: 0.2436 - val_loss: 2.0754 - val_acc: 0.2593\n",
      "\n",
      "Epoch 177/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 600us/step - loss: 2.0514 - acc: 0.2436 - val_loss: 2.0744 - val_acc: 0.2593\n",
      "\n",
      "Epoch 178/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 2.0502 - acc: 0.2436 - val_loss: 2.0736 - val_acc: 0.2593\n",
      "\n",
      "Epoch 179/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 629us/step - loss: 2.0491 - acc: 0.2436 - val_loss: 2.0727 - val_acc: 0.2593\n",
      "\n",
      "Epoch 180/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 471us/step - loss: 2.0478 - acc: 0.2470 - val_loss: 2.0716 - val_acc: 0.2593\n",
      "\n",
      "Epoch 181/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 546us/step - loss: 2.0466 - acc: 0.2470 - val_loss: 2.0706 - val_acc: 0.2593\n",
      "\n",
      "Epoch 182/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 489us/step - loss: 2.0454 - acc: 0.2470 - val_loss: 2.0696 - val_acc: 0.2593\n",
      "\n",
      "Epoch 183/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.0442 - acc: 0.2487 - val_loss: 2.0686 - val_acc: 0.2593\n",
      "\n",
      "Epoch 184/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 492us/step - loss: 2.0429 - acc: 0.2504 - val_loss: 2.0676 - val_acc: 0.2593\n",
      "\n",
      "Epoch 185/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 484us/step - loss: 2.0417 - acc: 0.2504 - val_loss: 2.0664 - val_acc: 0.2593\n",
      "\n",
      "Epoch 186/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.0404 - acc: 0.2504 - val_loss: 2.0652 - val_acc: 0.2593\n",
      "\n",
      "Epoch 187/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.0391 - acc: 0.2504 - val_loss: 2.0641 - val_acc: 0.2593\n",
      "\n",
      "Epoch 188/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 558us/step - loss: 2.0378 - acc: 0.2521 - val_loss: 2.0631 - val_acc: 0.2593\n",
      "\n",
      "Epoch 189/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 608us/step - loss: 2.0365 - acc: 0.2556 - val_loss: 2.0620 - val_acc: 0.2593\n",
      "\n",
      "Epoch 190/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 548us/step - loss: 2.0352 - acc: 0.2539 - val_loss: 2.0608 - val_acc: 0.2593\n",
      "\n",
      "Epoch 191/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 488us/step - loss: 2.0338 - acc: 0.2539 - val_loss: 2.0598 - val_acc: 0.2593\n",
      "\n",
      "Epoch 192/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.0325 - acc: 0.2539 - val_loss: 2.0588 - val_acc: 0.2593\n",
      "\n",
      "Epoch 193/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 487us/step - loss: 2.0311 - acc: 0.2556 - val_loss: 2.0577 - val_acc: 0.2593\n",
      "\n",
      "Epoch 194/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.0298 - acc: 0.2573 - val_loss: 2.0565 - val_acc: 0.2593\n",
      "\n",
      "Epoch 195/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 583us/step - loss: 2.0284 - acc: 0.2573 - val_loss: 2.0554 - val_acc: 0.2593\n",
      "\n",
      "Epoch 196/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 559us/step - loss: 2.0269 - acc: 0.2573 - val_loss: 2.0541 - val_acc: 0.2593\n",
      "\n",
      "Epoch 197/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 499us/step - loss: 2.0254 - acc: 0.2590 - val_loss: 2.0530 - val_acc: 0.2593\n",
      "\n",
      "Epoch 198/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 517us/step - loss: 2.0240 - acc: 0.2590 - val_loss: 2.0519 - val_acc: 0.2593\n",
      "\n",
      "Epoch 199/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 525us/step - loss: 2.0226 - acc: 0.2590 - val_loss: 2.0504 - val_acc: 0.2593\n",
      "\n",
      "Epoch 200/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 474us/step - loss: 2.0210 - acc: 0.2607 - val_loss: 2.0491 - val_acc: 0.2654\n",
      "\n",
      "65/65 [==============================]65/65 [==============================] - 0s 413us/step\n",
      "\n",
      "Train on 583 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "583/583 [==============================]583/583 [==============================] - 2s 4ms/step - loss: 2.2162 - acc: 0.1509 - val_loss: 2.2583 - val_acc: 0.1049\n",
      "\n",
      "Epoch 2/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 617us/step - loss: 2.2141 - acc: 0.1544 - val_loss: 2.2558 - val_acc: 0.1049\n",
      "\n",
      "Epoch 3/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 476us/step - loss: 2.2120 - acc: 0.1561 - val_loss: 2.2531 - val_acc: 0.1111\n",
      "\n",
      "Epoch 4/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 524us/step - loss: 2.2099 - acc: 0.1578 - val_loss: 2.2509 - val_acc: 0.1111\n",
      "\n",
      "Epoch 5/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 597us/step - loss: 2.2080 - acc: 0.1595 - val_loss: 2.2489 - val_acc: 0.1111\n",
      "\n",
      "Epoch 6/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 2.2063 - acc: 0.1647 - val_loss: 2.2468 - val_acc: 0.1173\n",
      "\n",
      "Epoch 7/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 546us/step - loss: 2.2045 - acc: 0.1698 - val_loss: 2.2447 - val_acc: 0.1173\n",
      "\n",
      "Epoch 8/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 596us/step - loss: 2.2028 - acc: 0.1750 - val_loss: 2.2426 - val_acc: 0.1173\n",
      "\n",
      "Epoch 9/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 570us/step - loss: 2.2010 - acc: 0.1681 - val_loss: 2.2407 - val_acc: 0.1173\n",
      "\n",
      "Epoch 10/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 611us/step - loss: 2.1994 - acc: 0.1664 - val_loss: 2.2390 - val_acc: 0.1173\n",
      "\n",
      "Epoch 11/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 566us/step - loss: 2.1978 - acc: 0.1664 - val_loss: 2.2372 - val_acc: 0.1173\n",
      "\n",
      "Epoch 12/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 566us/step - loss: 2.1963 - acc: 0.1647 - val_loss: 2.2354 - val_acc: 0.1173\n",
      "\n",
      "Epoch 13/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 585us/step - loss: 2.1948 - acc: 0.1647 - val_loss: 2.2334 - val_acc: 0.1173\n",
      "\n",
      "Epoch 14/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 529us/step - loss: 2.1932 - acc: 0.1681 - val_loss: 2.2316 - val_acc: 0.1173\n",
      "\n",
      "Epoch 15/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 510us/step - loss: 2.1917 - acc: 0.1698 - val_loss: 2.2298 - val_acc: 0.1235\n",
      "\n",
      "Epoch 16/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 464us/step - loss: 2.1902 - acc: 0.1715 - val_loss: 2.2282 - val_acc: 0.1173\n",
      "\n",
      "Epoch 17/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.1889 - acc: 0.1681 - val_loss: 2.2266 - val_acc: 0.1111\n",
      "\n",
      "Epoch 18/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 481us/step - loss: 2.1877 - acc: 0.1732 - val_loss: 2.2250 - val_acc: 0.1173\n",
      "\n",
      "Epoch 19/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 489us/step - loss: 2.1864 - acc: 0.1732 - val_loss: 2.2234 - val_acc: 0.1173\n",
      "\n",
      "Epoch 20/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 460us/step - loss: 2.1851 - acc: 0.1715 - val_loss: 2.2220 - val_acc: 0.1173\n",
      "\n",
      "Epoch 21/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 489us/step - loss: 2.1839 - acc: 0.1698 - val_loss: 2.2204 - val_acc: 0.1173\n",
      "\n",
      "Epoch 22/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 503us/step - loss: 2.1827 - acc: 0.1698 - val_loss: 2.2189 - val_acc: 0.1111\n",
      "\n",
      "Epoch 23/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 507us/step - loss: 2.1815 - acc: 0.1664 - val_loss: 2.2175 - val_acc: 0.1049\n",
      "\n",
      "Epoch 24/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 610us/step - loss: 2.1803 - acc: 0.1698 - val_loss: 2.2160 - val_acc: 0.1049\n",
      "\n",
      "Epoch 25/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 515us/step - loss: 2.1791 - acc: 0.1698 - val_loss: 2.2146 - val_acc: 0.1049TA: 0s - loss: 2.1863 - acc: 0.1\n",
      "\n",
      "Epoch 26/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 571us/step - loss: 2.1780 - acc: 0.1698 - val_loss: 2.2132 - val_acc: 0.1049\n",
      "\n",
      "Epoch 27/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 486us/step - loss: 2.1768 - acc: 0.1681 - val_loss: 2.2118 - val_acc: 0.1111\n",
      "\n",
      "Epoch 28/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 515us/step - loss: 2.1757 - acc: 0.1715 - val_loss: 2.2105 - val_acc: 0.1111\n",
      "\n",
      "Epoch 29/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 583us/step - loss: 2.1746 - acc: 0.1698 - val_loss: 2.2092 - val_acc: 0.1111\n",
      "\n",
      "Epoch 30/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.1734 - acc: 0.1767 - val_loss: 2.2077 - val_acc: 0.1111\n",
      "\n",
      "Epoch 31/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 492us/step - loss: 2.1723 - acc: 0.1767 - val_loss: 2.2064 - val_acc: 0.1049TA: 0s - loss: 2.1739 - acc: 0.18\n",
      "\n",
      "Epoch 32/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.1712 - acc: 0.1767 - val_loss: 2.2051 - val_acc: 0.1049\n",
      "\n",
      "Epoch 33/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 550us/step - loss: 2.1702 - acc: 0.1767 - val_loss: 2.2039 - val_acc: 0.1049\n",
      "\n",
      "Epoch 34/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 2.1692 - acc: 0.1784 - val_loss: 2.2028 - val_acc: 0.1049\n",
      "\n",
      "Epoch 35/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.1683 - acc: 0.1818 - val_loss: 2.2015 - val_acc: 0.1049\n",
      "\n",
      "Epoch 36/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 486us/step - loss: 2.1672 - acc: 0.1818 - val_loss: 2.2004 - val_acc: 0.1049TA: 0s - loss: 2.1569 - acc: 0.20\n",
      "\n",
      "Epoch 37/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 573us/step - loss: 2.1663 - acc: 0.1818 - val_loss: 2.1994 - val_acc: 0.1049\n",
      "\n",
      "Epoch 38/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 565us/step - loss: 2.1654 - acc: 0.1870 - val_loss: 2.1984 - val_acc: 0.1111\n",
      "\n",
      "Epoch 39/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 492us/step - loss: 2.1644 - acc: 0.1870 - val_loss: 2.1974 - val_acc: 0.1173\n",
      "\n",
      "Epoch 40/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.1635 - acc: 0.1870 - val_loss: 2.1964 - val_acc: 0.1235\n",
      "\n",
      "Epoch 41/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 484us/step - loss: 2.1626 - acc: 0.1852 - val_loss: 2.1955 - val_acc: 0.1235\n",
      "\n",
      "Epoch 42/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 487us/step - loss: 2.1617 - acc: 0.1852 - val_loss: 2.1945 - val_acc: 0.1235\n",
      "\n",
      "Epoch 43/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 579us/step - loss: 2.1608 - acc: 0.1870 - val_loss: 2.1934 - val_acc: 0.1235TA: 0s - loss: 2.1598 - acc: 0.187\n",
      "\n",
      "Epoch 44/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 596us/step - loss: 2.1599 - acc: 0.1870 - val_loss: 2.1924 - val_acc: 0.1235\n",
      "\n",
      "Epoch 45/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 510us/step - loss: 2.1590 - acc: 0.1870 - val_loss: 2.1914 - val_acc: 0.1235\n",
      "\n",
      "Epoch 46/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 612us/step - loss: 2.1581 - acc: 0.1904 - val_loss: 2.1905 - val_acc: 0.1358\n",
      "\n",
      "Epoch 47/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 500us/step - loss: 2.1572 - acc: 0.1904 - val_loss: 2.1897 - val_acc: 0.1358\n",
      "\n",
      "Epoch 48/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.1564 - acc: 0.1887 - val_loss: 2.1886 - val_acc: 0.1358\n",
      "\n",
      "Epoch 49/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 528us/step - loss: 2.1555 - acc: 0.1887 - val_loss: 2.1877 - val_acc: 0.1358\n",
      "\n",
      "Epoch 50/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 503us/step - loss: 2.1547 - acc: 0.1852 - val_loss: 2.1868 - val_acc: 0.1358\n",
      "\n",
      "Epoch 51/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.1538 - acc: 0.1852 - val_loss: 2.1859 - val_acc: 0.1358\n",
      "\n",
      "Epoch 52/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 553us/step - loss: 2.1530 - acc: 0.1801 - val_loss: 2.1850 - val_acc: 0.1358\n",
      "\n",
      "Epoch 53/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 541us/step - loss: 2.1522 - acc: 0.1852 - val_loss: 2.1842 - val_acc: 0.1358\n",
      "\n",
      "Epoch 54/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 601us/step - loss: 2.1514 - acc: 0.1887 - val_loss: 2.1832 - val_acc: 0.1358\n",
      "\n",
      "Epoch 55/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 483us/step - loss: 2.1505 - acc: 0.1870 - val_loss: 2.1825 - val_acc: 0.1358\n",
      "\n",
      "Epoch 56/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 575us/step - loss: 2.1497 - acc: 0.1887 - val_loss: 2.1816 - val_acc: 0.1358\n",
      "\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================]583/583 [==============================] - 0s 651us/step - loss: 2.1488 - acc: 0.1904 - val_loss: 2.1807 - val_acc: 0.1358\n",
      "\n",
      "Epoch 58/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 589us/step - loss: 2.1480 - acc: 0.1904 - val_loss: 2.1799 - val_acc: 0.1420\n",
      "\n",
      "Epoch 59/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 523us/step - loss: 2.1472 - acc: 0.1887 - val_loss: 2.1791 - val_acc: 0.1420\n",
      "\n",
      "Epoch 60/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 603us/step - loss: 2.1464 - acc: 0.1887 - val_loss: 2.1784 - val_acc: 0.1420\n",
      "\n",
      "Epoch 61/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 575us/step - loss: 2.1456 - acc: 0.1921 - val_loss: 2.1776 - val_acc: 0.1420\n",
      "\n",
      "Epoch 62/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 598us/step - loss: 2.1448 - acc: 0.1904 - val_loss: 2.1768 - val_acc: 0.1481\n",
      "\n",
      "Epoch 63/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 546us/step - loss: 2.1440 - acc: 0.1904 - val_loss: 2.1759 - val_acc: 0.1481\n",
      "\n",
      "Epoch 64/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 556us/step - loss: 2.1432 - acc: 0.1904 - val_loss: 2.1751 - val_acc: 0.1481\n",
      "\n",
      "Epoch 65/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 539us/step - loss: 2.1424 - acc: 0.1938 - val_loss: 2.1744 - val_acc: 0.1543\n",
      "\n",
      "Epoch 66/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 532us/step - loss: 2.1417 - acc: 0.1904 - val_loss: 2.1736 - val_acc: 0.1481\n",
      "\n",
      "Epoch 67/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 503us/step - loss: 2.1409 - acc: 0.1938 - val_loss: 2.1729 - val_acc: 0.1481\n",
      "\n",
      "Epoch 68/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 551us/step - loss: 2.1401 - acc: 0.1938 - val_loss: 2.1721 - val_acc: 0.1481\n",
      "\n",
      "Epoch 69/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 556us/step - loss: 2.1392 - acc: 0.1938 - val_loss: 2.1714 - val_acc: 0.1481\n",
      "\n",
      "Epoch 70/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.1384 - acc: 0.1990 - val_loss: 2.1707 - val_acc: 0.1481\n",
      "\n",
      "Epoch 71/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 496us/step - loss: 2.1376 - acc: 0.1955 - val_loss: 2.1700 - val_acc: 0.1481TA: 0s - loss: 2.1371 - acc: 0.19\n",
      "\n",
      "Epoch 72/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 595us/step - loss: 2.1369 - acc: 0.2007 - val_loss: 2.1693 - val_acc: 0.1420\n",
      "\n",
      "Epoch 73/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 667us/step - loss: 2.1361 - acc: 0.1990 - val_loss: 2.1686 - val_acc: 0.1481\n",
      "\n",
      "Epoch 74/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 626us/step - loss: 2.1352 - acc: 0.2024 - val_loss: 2.1678 - val_acc: 0.1420\n",
      "\n",
      "Epoch 75/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 685us/step - loss: 2.1344 - acc: 0.1990 - val_loss: 2.1671 - val_acc: 0.1420\n",
      "\n",
      "Epoch 76/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 686us/step - loss: 2.1336 - acc: 0.2007 - val_loss: 2.1664 - val_acc: 0.1420\n",
      "\n",
      "Epoch 77/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 569us/step - loss: 2.1328 - acc: 0.2024 - val_loss: 2.1656 - val_acc: 0.1420\n",
      "\n",
      "Epoch 78/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 574us/step - loss: 2.1320 - acc: 0.2024 - val_loss: 2.1648 - val_acc: 0.1420\n",
      "\n",
      "Epoch 79/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 600us/step - loss: 2.1312 - acc: 0.2007 - val_loss: 2.1641 - val_acc: 0.1358\n",
      "\n",
      "Epoch 80/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 627us/step - loss: 2.1304 - acc: 0.2007 - val_loss: 2.1633 - val_acc: 0.1358\n",
      "\n",
      "Epoch 81/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 743us/step - loss: 2.1296 - acc: 0.2007 - val_loss: 2.1626 - val_acc: 0.1358\n",
      "\n",
      "Epoch 82/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 847us/step - loss: 2.1288 - acc: 0.1990 - val_loss: 2.1619 - val_acc: 0.1358\n",
      "\n",
      "Epoch 83/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 573us/step - loss: 2.1280 - acc: 0.2007 - val_loss: 2.1612 - val_acc: 0.1358\n",
      "\n",
      "Epoch 84/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 551us/step - loss: 2.1271 - acc: 0.2058 - val_loss: 2.1604 - val_acc: 0.1358\n",
      "\n",
      "Epoch 85/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 513us/step - loss: 2.1263 - acc: 0.2041 - val_loss: 2.1596 - val_acc: 0.1296\n",
      "\n",
      "Epoch 86/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 569us/step - loss: 2.1255 - acc: 0.2041 - val_loss: 2.1588 - val_acc: 0.1296\n",
      "\n",
      "Epoch 87/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 549us/step - loss: 2.1246 - acc: 0.2024 - val_loss: 2.1580 - val_acc: 0.1296\n",
      "\n",
      "Epoch 88/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 505us/step - loss: 2.1237 - acc: 0.2007 - val_loss: 2.1572 - val_acc: 0.1296\n",
      "\n",
      "Epoch 89/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 550us/step - loss: 2.1229 - acc: 0.2007 - val_loss: 2.1565 - val_acc: 0.1296\n",
      "\n",
      "Epoch 90/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 495us/step - loss: 2.1221 - acc: 0.2058 - val_loss: 2.1556 - val_acc: 0.1358\n",
      "\n",
      "Epoch 91/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 505us/step - loss: 2.1212 - acc: 0.2024 - val_loss: 2.1549 - val_acc: 0.1358\n",
      "\n",
      "Epoch 92/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 508us/step - loss: 2.1204 - acc: 0.1990 - val_loss: 2.1541 - val_acc: 0.1420\n",
      "\n",
      "Epoch 93/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 545us/step - loss: 2.1195 - acc: 0.2041 - val_loss: 2.1532 - val_acc: 0.1358\n",
      "\n",
      "Epoch 94/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 509us/step - loss: 2.1186 - acc: 0.2093 - val_loss: 2.1525 - val_acc: 0.1358TA: 0s - loss: 2.1212 - acc: 0.1\n",
      "\n",
      "Epoch 95/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 518us/step - loss: 2.1177 - acc: 0.2110 - val_loss: 2.1517 - val_acc: 0.1543\n",
      "\n",
      "Epoch 96/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.1168 - acc: 0.2144 - val_loss: 2.1509 - val_acc: 0.1543TA: 0s - loss: 2.1188 - acc: 0.2\n",
      "\n",
      "Epoch 97/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 541us/step - loss: 2.1159 - acc: 0.2127 - val_loss: 2.1501 - val_acc: 0.1481\n",
      "\n",
      "Epoch 98/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 547us/step - loss: 2.1150 - acc: 0.2144 - val_loss: 2.1492 - val_acc: 0.1481\n",
      "\n",
      "Epoch 99/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 511us/step - loss: 2.1141 - acc: 0.2127 - val_loss: 2.1483 - val_acc: 0.1543\n",
      "\n",
      "Epoch 100/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 531us/step - loss: 2.1132 - acc: 0.2127 - val_loss: 2.1476 - val_acc: 0.1543\n",
      "\n",
      "Epoch 101/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 2.1123 - acc: 0.2127 - val_loss: 2.1467 - val_acc: 0.1543\n",
      "\n",
      "Epoch 102/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 590us/step - loss: 2.1114 - acc: 0.2093 - val_loss: 2.1459 - val_acc: 0.1605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 103/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 496us/step - loss: 2.1105 - acc: 0.2127 - val_loss: 2.1451 - val_acc: 0.1605\n",
      "\n",
      "Epoch 104/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 454us/step - loss: 2.1095 - acc: 0.2110 - val_loss: 2.1444 - val_acc: 0.1605\n",
      "\n",
      "Epoch 105/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 506us/step - loss: 2.1086 - acc: 0.2058 - val_loss: 2.1435 - val_acc: 0.1667\n",
      "\n",
      "Epoch 106/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 632us/step - loss: 2.1077 - acc: 0.2041 - val_loss: 2.1427 - val_acc: 0.1667\n",
      "\n",
      "Epoch 107/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 513us/step - loss: 2.1068 - acc: 0.2058 - val_loss: 2.1418 - val_acc: 0.1667\n",
      "\n",
      "Epoch 108/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 546us/step - loss: 2.1058 - acc: 0.2075 - val_loss: 2.1409 - val_acc: 0.1667\n",
      "\n",
      "Epoch 109/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 458us/step - loss: 2.1049 - acc: 0.2093 - val_loss: 2.1401 - val_acc: 0.1667\n",
      "\n",
      "Epoch 110/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 541us/step - loss: 2.1039 - acc: 0.2093 - val_loss: 2.1392 - val_acc: 0.1728\n",
      "\n",
      "Epoch 111/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.1029 - acc: 0.2110 - val_loss: 2.1384 - val_acc: 0.1667\n",
      "\n",
      "Epoch 112/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 493us/step - loss: 2.1020 - acc: 0.2127 - val_loss: 2.1376 - val_acc: 0.1667\n",
      "\n",
      "Epoch 113/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 590us/step - loss: 2.1010 - acc: 0.2093 - val_loss: 2.1366 - val_acc: 0.1667\n",
      "\n",
      "Epoch 114/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 804us/step - loss: 2.1001 - acc: 0.2110 - val_loss: 2.1358 - val_acc: 0.1667\n",
      "\n",
      "Epoch 115/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 683us/step - loss: 2.0991 - acc: 0.2127 - val_loss: 2.1349 - val_acc: 0.1543\n",
      "\n",
      "Epoch 116/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 688us/step - loss: 2.0981 - acc: 0.2161 - val_loss: 2.1340 - val_acc: 0.1543\n",
      "\n",
      "Epoch 117/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 499us/step - loss: 2.0971 - acc: 0.2144 - val_loss: 2.1331 - val_acc: 0.1605\n",
      "\n",
      "Epoch 118/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 560us/step - loss: 2.0960 - acc: 0.2178 - val_loss: 2.1322 - val_acc: 0.1667\n",
      "\n",
      "Epoch 119/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 537us/step - loss: 2.0950 - acc: 0.2161 - val_loss: 2.1312 - val_acc: 0.1667\n",
      "\n",
      "Epoch 120/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 772us/step - loss: 2.0940 - acc: 0.2178 - val_loss: 2.1303 - val_acc: 0.1728\n",
      "\n",
      "Epoch 121/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 939us/step - loss: 2.0930 - acc: 0.2161 - val_loss: 2.1293 - val_acc: 0.1728\n",
      "\n",
      "Epoch 122/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 583us/step - loss: 2.0920 - acc: 0.2213 - val_loss: 2.1284 - val_acc: 0.1728\n",
      "\n",
      "Epoch 123/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 564us/step - loss: 2.0910 - acc: 0.2230 - val_loss: 2.1274 - val_acc: 0.1790\n",
      "\n",
      "Epoch 124/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 472us/step - loss: 2.0900 - acc: 0.2230 - val_loss: 2.1265 - val_acc: 0.1852\n",
      "\n",
      "Epoch 125/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 709us/step - loss: 2.0889 - acc: 0.2281 - val_loss: 2.1256 - val_acc: 0.1852\n",
      "\n",
      "Epoch 126/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 660us/step - loss: 2.0879 - acc: 0.2264 - val_loss: 2.1247 - val_acc: 0.1852\n",
      "\n",
      "Epoch 127/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 561us/step - loss: 2.0869 - acc: 0.2230 - val_loss: 2.1238 - val_acc: 0.1852\n",
      "\n",
      "Epoch 128/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.0859 - acc: 0.2230 - val_loss: 2.1229 - val_acc: 0.1852\n",
      "\n",
      "Epoch 129/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 534us/step - loss: 2.0848 - acc: 0.2196 - val_loss: 2.1219 - val_acc: 0.1914\n",
      "\n",
      "Epoch 130/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 521us/step - loss: 2.0838 - acc: 0.2213 - val_loss: 2.1209 - val_acc: 0.1975\n",
      "\n",
      "Epoch 131/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.0827 - acc: 0.2230 - val_loss: 2.1198 - val_acc: 0.2037\n",
      "\n",
      "Epoch 132/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 527us/step - loss: 2.0816 - acc: 0.2196 - val_loss: 2.1188 - val_acc: 0.2099\n",
      "\n",
      "Epoch 133/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 514us/step - loss: 2.0805 - acc: 0.2213 - val_loss: 2.1178 - val_acc: 0.2099\n",
      "\n",
      "Epoch 134/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 552us/step - loss: 2.0795 - acc: 0.2264 - val_loss: 2.1168 - val_acc: 0.2160\n",
      "\n",
      "Epoch 135/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 557us/step - loss: 2.0784 - acc: 0.2264 - val_loss: 2.1157 - val_acc: 0.2099TA: 0s - loss: 2.0941 - acc: 0.\n",
      "\n",
      "Epoch 136/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 467us/step - loss: 2.0772 - acc: 0.2333 - val_loss: 2.1147 - val_acc: 0.2099\n",
      "\n",
      "Epoch 137/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 546us/step - loss: 2.0761 - acc: 0.2333 - val_loss: 2.1137 - val_acc: 0.2160\n",
      "\n",
      "Epoch 138/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 545us/step - loss: 2.0749 - acc: 0.2350 - val_loss: 2.1126 - val_acc: 0.2160\n",
      "\n",
      "Epoch 139/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 506us/step - loss: 2.0737 - acc: 0.2333 - val_loss: 2.1115 - val_acc: 0.2160\n",
      "\n",
      "Epoch 140/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 602us/step - loss: 2.0725 - acc: 0.2333 - val_loss: 2.1104 - val_acc: 0.2160\n",
      "\n",
      "Epoch 141/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 519us/step - loss: 2.0713 - acc: 0.2350 - val_loss: 2.1094 - val_acc: 0.2160\n",
      "\n",
      "Epoch 142/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.0701 - acc: 0.2401 - val_loss: 2.1082 - val_acc: 0.2160\n",
      "\n",
      "Epoch 143/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 515us/step - loss: 2.0690 - acc: 0.2384 - val_loss: 2.1071 - val_acc: 0.2222\n",
      "\n",
      "Epoch 144/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 515us/step - loss: 2.0678 - acc: 0.2384 - val_loss: 2.1060 - val_acc: 0.2222\n",
      "\n",
      "Epoch 145/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 513us/step - loss: 2.0665 - acc: 0.2419 - val_loss: 2.1048 - val_acc: 0.2284\n",
      "\n",
      "Epoch 146/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 599us/step - loss: 2.0653 - acc: 0.2401 - val_loss: 2.1036 - val_acc: 0.2284\n",
      "\n",
      "Epoch 147/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 2.0640 - acc: 0.2384 - val_loss: 2.1023 - val_acc: 0.2284\n",
      "\n",
      "Epoch 148/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 487us/step - loss: 2.0627 - acc: 0.2419 - val_loss: 2.1011 - val_acc: 0.2346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 149/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 567us/step - loss: 2.0614 - acc: 0.2504 - val_loss: 2.1000 - val_acc: 0.2407\n",
      "\n",
      "Epoch 150/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 545us/step - loss: 2.0601 - acc: 0.2487 - val_loss: 2.0988 - val_acc: 0.2531\n",
      "\n",
      "Epoch 151/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 524us/step - loss: 2.0589 - acc: 0.2521 - val_loss: 2.0974 - val_acc: 0.2531\n",
      "\n",
      "Epoch 152/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 586us/step - loss: 2.0576 - acc: 0.2539 - val_loss: 2.0963 - val_acc: 0.2531\n",
      "\n",
      "Epoch 153/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 520us/step - loss: 2.0562 - acc: 0.2556 - val_loss: 2.0950 - val_acc: 0.2531\n",
      "\n",
      "Epoch 154/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 2.0549 - acc: 0.2573 - val_loss: 2.0938 - val_acc: 0.2469\n",
      "\n",
      "Epoch 155/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 541us/step - loss: 2.0536 - acc: 0.2573 - val_loss: 2.0925 - val_acc: 0.2469\n",
      "\n",
      "Epoch 156/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 545us/step - loss: 2.0523 - acc: 0.2573 - val_loss: 2.0912 - val_acc: 0.2469\n",
      "\n",
      "Epoch 157/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 575us/step - loss: 2.0510 - acc: 0.2573 - val_loss: 2.0899 - val_acc: 0.2346\n",
      "\n",
      "Epoch 158/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 627us/step - loss: 2.0495 - acc: 0.2556 - val_loss: 2.0884 - val_acc: 0.2346\n",
      "\n",
      "Epoch 159/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 773us/step - loss: 2.0481 - acc: 0.2590 - val_loss: 2.0872 - val_acc: 0.2284\n",
      "\n",
      "Epoch 160/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 620us/step - loss: 2.0468 - acc: 0.2590 - val_loss: 2.0859 - val_acc: 0.2222\n",
      "\n",
      "Epoch 161/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 588us/step - loss: 2.0454 - acc: 0.2573 - val_loss: 2.0845 - val_acc: 0.2222\n",
      "\n",
      "Epoch 162/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 589us/step - loss: 2.0439 - acc: 0.2624 - val_loss: 2.0833 - val_acc: 0.2222\n",
      "\n",
      "Epoch 163/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 517us/step - loss: 2.0425 - acc: 0.2642 - val_loss: 2.0820 - val_acc: 0.2284\n",
      "\n",
      "Epoch 164/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 597us/step - loss: 2.0410 - acc: 0.2676 - val_loss: 2.0805 - val_acc: 0.2284\n",
      "\n",
      "Epoch 165/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 489us/step - loss: 2.0395 - acc: 0.2642 - val_loss: 2.0791 - val_acc: 0.2346\n",
      "\n",
      "Epoch 166/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 530us/step - loss: 2.0379 - acc: 0.2590 - val_loss: 2.0777 - val_acc: 0.2284\n",
      "\n",
      "Epoch 167/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 553us/step - loss: 2.0364 - acc: 0.2624 - val_loss: 2.0762 - val_acc: 0.2284\n",
      "\n",
      "Epoch 168/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 2.0349 - acc: 0.2573 - val_loss: 2.0749 - val_acc: 0.2346\n",
      "\n",
      "Epoch 169/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 569us/step - loss: 2.0334 - acc: 0.2573 - val_loss: 2.0735 - val_acc: 0.2407\n",
      "\n",
      "Epoch 170/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 513us/step - loss: 2.0320 - acc: 0.2590 - val_loss: 2.0721 - val_acc: 0.2407\n",
      "\n",
      "Epoch 171/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 603us/step - loss: 2.0304 - acc: 0.2607 - val_loss: 2.0707 - val_acc: 0.2407\n",
      "\n",
      "Epoch 172/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 584us/step - loss: 2.0288 - acc: 0.2624 - val_loss: 2.0692 - val_acc: 0.2346\n",
      "\n",
      "Epoch 173/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 503us/step - loss: 2.0272 - acc: 0.2659 - val_loss: 2.0676 - val_acc: 0.2407\n",
      "\n",
      "Epoch 174/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 558us/step - loss: 2.0256 - acc: 0.2659 - val_loss: 2.0662 - val_acc: 0.2469\n",
      "\n",
      "Epoch 175/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 482us/step - loss: 2.0241 - acc: 0.2710 - val_loss: 2.0645 - val_acc: 0.2469\n",
      "\n",
      "Epoch 176/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 2.0224 - acc: 0.2710 - val_loss: 2.0631 - val_acc: 0.2407TA: 0s - loss: 2.0230 - acc: 0.267\n",
      "\n",
      "Epoch 177/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 440us/step - loss: 2.0208 - acc: 0.2676 - val_loss: 2.0614 - val_acc: 0.2407\n",
      "\n",
      "Epoch 178/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 500us/step - loss: 2.0191 - acc: 0.2676 - val_loss: 2.0600 - val_acc: 0.2407\n",
      "\n",
      "Epoch 179/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 471us/step - loss: 2.0175 - acc: 0.2744 - val_loss: 2.0584 - val_acc: 0.2407\n",
      "\n",
      "Epoch 180/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 2.0158 - acc: 0.2779 - val_loss: 2.0569 - val_acc: 0.2469\n",
      "\n",
      "Epoch 181/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 540us/step - loss: 2.0141 - acc: 0.2796 - val_loss: 2.0552 - val_acc: 0.2469\n",
      "\n",
      "Epoch 182/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 546us/step - loss: 2.0124 - acc: 0.2813 - val_loss: 2.0537 - val_acc: 0.2469\n",
      "\n",
      "Epoch 183/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 498us/step - loss: 2.0107 - acc: 0.2830 - val_loss: 2.0521 - val_acc: 0.2469\n",
      "\n",
      "Epoch 184/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 529us/step - loss: 2.0090 - acc: 0.2830 - val_loss: 2.0506 - val_acc: 0.2469\n",
      "\n",
      "Epoch 185/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 622us/step - loss: 2.0073 - acc: 0.2796 - val_loss: 2.0488 - val_acc: 0.2469\n",
      "\n",
      "Epoch 186/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 515us/step - loss: 2.0055 - acc: 0.2847 - val_loss: 2.0473 - val_acc: 0.2531\n",
      "\n",
      "Epoch 187/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 461us/step - loss: 2.0038 - acc: 0.2847 - val_loss: 2.0455 - val_acc: 0.2531\n",
      "\n",
      "Epoch 188/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 497us/step - loss: 2.0019 - acc: 0.2830 - val_loss: 2.0437 - val_acc: 0.2531\n",
      "\n",
      "Epoch 189/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 556us/step - loss: 2.0001 - acc: 0.2830 - val_loss: 2.0421 - val_acc: 0.2531TA: 0s - loss: 2.0039 - acc: 0.\n",
      "\n",
      "Epoch 190/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 1.9983 - acc: 0.2864 - val_loss: 2.0402 - val_acc: 0.2531\n",
      "\n",
      "Epoch 191/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 569us/step - loss: 1.9965 - acc: 0.2830 - val_loss: 2.0385 - val_acc: 0.2469\n",
      "\n",
      "Epoch 192/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 516us/step - loss: 1.9946 - acc: 0.2830 - val_loss: 2.0367 - val_acc: 0.2531\n",
      "\n",
      "Epoch 193/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 542us/step - loss: 1.9927 - acc: 0.2813 - val_loss: 2.0348 - val_acc: 0.2531\n",
      "\n",
      "Epoch 194/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 545us/step - loss: 1.9907 - acc: 0.2830 - val_loss: 2.0329 - val_acc: 0.2531\n",
      "\n",
      "Epoch 195/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 544us/step - loss: 1.9887 - acc: 0.2813 - val_loss: 2.0310 - val_acc: 0.2531\n",
      "\n",
      "Epoch 196/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 581us/step - loss: 1.9868 - acc: 0.2813 - val_loss: 2.0293 - val_acc: 0.2531\n",
      "\n",
      "Epoch 197/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 533us/step - loss: 1.9849 - acc: 0.2796 - val_loss: 2.0273 - val_acc: 0.2531\n",
      "\n",
      "Epoch 198/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 470us/step - loss: 1.9829 - acc: 0.2779 - val_loss: 2.0253 - val_acc: 0.2531\n",
      "\n",
      "Epoch 199/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 530us/step - loss: 1.9810 - acc: 0.2813 - val_loss: 2.0233 - val_acc: 0.2531TA: 0s - loss: 1.9698 - acc: 0.29\n",
      "\n",
      "Epoch 200/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 543us/step - loss: 1.9791 - acc: 0.2813 - val_loss: 2.0214 - val_acc: 0.2531\n",
      "\n",
      "65/65 [==============================]65/65 [==============================] - 0s 282us/step\n",
      "\n",
      "Train on 584 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "584/584 [==============================]584/584 [==============================] - 2s 4ms/step - loss: 2.2400 - acc: 0.1113 - val_loss: 2.2455 - val_acc: 0.0802\n",
      "\n",
      "Epoch 2/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 607us/step - loss: 2.2380 - acc: 0.1113 - val_loss: 2.2437 - val_acc: 0.0926\n",
      "\n",
      "Epoch 3/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 528us/step - loss: 2.2359 - acc: 0.1096 - val_loss: 2.2421 - val_acc: 0.0926\n",
      "\n",
      "Epoch 4/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 515us/step - loss: 2.2340 - acc: 0.1113 - val_loss: 2.2405 - val_acc: 0.0926\n",
      "\n",
      "Epoch 5/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 535us/step - loss: 2.2322 - acc: 0.1096 - val_loss: 2.2390 - val_acc: 0.0926\n",
      "\n",
      "Epoch 6/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 546us/step - loss: 2.2304 - acc: 0.1147 - val_loss: 2.2377 - val_acc: 0.0988\n",
      "\n",
      "Epoch 7/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 570us/step - loss: 2.2288 - acc: 0.1216 - val_loss: 2.2365 - val_acc: 0.0988\n",
      "\n",
      "Epoch 8/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 574us/step - loss: 2.2273 - acc: 0.1250 - val_loss: 2.2353 - val_acc: 0.1049\n",
      "\n",
      "Epoch 9/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 515us/step - loss: 2.2259 - acc: 0.1267 - val_loss: 2.2342 - val_acc: 0.1049\n",
      "\n",
      "Epoch 10/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 542us/step - loss: 2.2245 - acc: 0.1250 - val_loss: 2.2330 - val_acc: 0.1049\n",
      "\n",
      "Epoch 11/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 504us/step - loss: 2.2231 - acc: 0.1233 - val_loss: 2.2319 - val_acc: 0.1049\n",
      "\n",
      "Epoch 12/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 564us/step - loss: 2.2218 - acc: 0.1233 - val_loss: 2.2310 - val_acc: 0.1049\n",
      "\n",
      "Epoch 13/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 522us/step - loss: 2.2206 - acc: 0.1267 - val_loss: 2.2301 - val_acc: 0.1049\n",
      "\n",
      "Epoch 14/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 552us/step - loss: 2.2194 - acc: 0.1301 - val_loss: 2.2291 - val_acc: 0.1111\n",
      "\n",
      "Epoch 15/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 506us/step - loss: 2.2183 - acc: 0.1301 - val_loss: 2.2283 - val_acc: 0.1111\n",
      "\n",
      "Epoch 16/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 498us/step - loss: 2.2172 - acc: 0.1370 - val_loss: 2.2274 - val_acc: 0.1111\n",
      "\n",
      "Epoch 17/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 564us/step - loss: 2.2161 - acc: 0.1404 - val_loss: 2.2266 - val_acc: 0.1173\n",
      "\n",
      "Epoch 18/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 533us/step - loss: 2.2151 - acc: 0.1438 - val_loss: 2.2258 - val_acc: 0.1173\n",
      "\n",
      "Epoch 19/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 520us/step - loss: 2.2141 - acc: 0.1421 - val_loss: 2.2251 - val_acc: 0.1173\n",
      "\n",
      "Epoch 20/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 537us/step - loss: 2.2131 - acc: 0.1438 - val_loss: 2.2243 - val_acc: 0.1173\n",
      "\n",
      "Epoch 21/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 568us/step - loss: 2.2122 - acc: 0.1455 - val_loss: 2.2236 - val_acc: 0.1235\n",
      "\n",
      "Epoch 22/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 485us/step - loss: 2.2113 - acc: 0.1473 - val_loss: 2.2228 - val_acc: 0.1358\n",
      "\n",
      "Epoch 23/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 569us/step - loss: 2.2103 - acc: 0.1541 - val_loss: 2.2222 - val_acc: 0.1358\n",
      "\n",
      "Epoch 24/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 562us/step - loss: 2.2095 - acc: 0.1558 - val_loss: 2.2215 - val_acc: 0.1358\n",
      "\n",
      "Epoch 25/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 492us/step - loss: 2.2086 - acc: 0.1575 - val_loss: 2.2209 - val_acc: 0.1358\n",
      "\n",
      "Epoch 26/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 569us/step - loss: 2.2079 - acc: 0.1610 - val_loss: 2.2202 - val_acc: 0.1358\n",
      "\n",
      "Epoch 27/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 521us/step - loss: 2.2071 - acc: 0.1644 - val_loss: 2.2196 - val_acc: 0.1420\n",
      "\n",
      "Epoch 28/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 542us/step - loss: 2.2064 - acc: 0.1644 - val_loss: 2.2191 - val_acc: 0.1481\n",
      "\n",
      "Epoch 29/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 537us/step - loss: 2.2056 - acc: 0.1661 - val_loss: 2.2185 - val_acc: 0.1481\n",
      "\n",
      "Epoch 30/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 547us/step - loss: 2.2049 - acc: 0.1678 - val_loss: 2.2180 - val_acc: 0.1481\n",
      "\n",
      "Epoch 31/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 514us/step - loss: 2.2041 - acc: 0.1712 - val_loss: 2.2174 - val_acc: 0.1481\n",
      "\n",
      "Epoch 32/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 507us/step - loss: 2.2034 - acc: 0.1712 - val_loss: 2.2168 - val_acc: 0.1543\n",
      "\n",
      "Epoch 33/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 574us/step - loss: 2.2027 - acc: 0.1729 - val_loss: 2.2163 - val_acc: 0.1543\n",
      "\n",
      "Epoch 34/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 522us/step - loss: 2.2020 - acc: 0.1764 - val_loss: 2.2157 - val_acc: 0.1543\n",
      "\n",
      "Epoch 35/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 474us/step - loss: 2.2014 - acc: 0.1764 - val_loss: 2.2152 - val_acc: 0.1543\n",
      "\n",
      "Epoch 36/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 514us/step - loss: 2.2007 - acc: 0.1764 - val_loss: 2.2147 - val_acc: 0.1543\n",
      "\n",
      "Epoch 37/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 568us/step - loss: 2.2001 - acc: 0.1747 - val_loss: 2.2141 - val_acc: 0.1605\n",
      "\n",
      "Epoch 38/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 515us/step - loss: 2.1994 - acc: 0.1695 - val_loss: 2.2136 - val_acc: 0.1605\n",
      "\n",
      "Epoch 39/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584/584 [==============================]584/584 [==============================] - 0s 497us/step - loss: 2.1988 - acc: 0.1695 - val_loss: 2.2130 - val_acc: 0.1605\n",
      "\n",
      "Epoch 40/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 499us/step - loss: 2.1981 - acc: 0.1712 - val_loss: 2.2125 - val_acc: 0.1667\n",
      "\n",
      "Epoch 41/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 515us/step - loss: 2.1975 - acc: 0.1712 - val_loss: 2.2119 - val_acc: 0.1667\n",
      "\n",
      "Epoch 42/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 513us/step - loss: 2.1968 - acc: 0.1712 - val_loss: 2.2114 - val_acc: 0.1667\n",
      "\n",
      "Epoch 43/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 548us/step - loss: 2.1962 - acc: 0.1729 - val_loss: 2.2109 - val_acc: 0.1667TA: 0s - loss: 2.1945 - acc: 0.1\n",
      "\n",
      "Epoch 44/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 497us/step - loss: 2.1955 - acc: 0.1747 - val_loss: 2.2104 - val_acc: 0.1667\n",
      "\n",
      "Epoch 45/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 493us/step - loss: 2.1949 - acc: 0.1764 - val_loss: 2.2098 - val_acc: 0.1667\n",
      "\n",
      "Epoch 46/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 483us/step - loss: 2.1942 - acc: 0.1764 - val_loss: 2.2093 - val_acc: 0.1605\n",
      "\n",
      "Epoch 47/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 490us/step - loss: 2.1936 - acc: 0.1729 - val_loss: 2.2088 - val_acc: 0.1605\n",
      "\n",
      "Epoch 48/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 623us/step - loss: 2.1930 - acc: 0.1747 - val_loss: 2.2083 - val_acc: 0.1605\n",
      "\n",
      "Epoch 49/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 487us/step - loss: 2.1923 - acc: 0.1729 - val_loss: 2.2077 - val_acc: 0.1605\n",
      "\n",
      "Epoch 50/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 568us/step - loss: 2.1917 - acc: 0.1747 - val_loss: 2.2072 - val_acc: 0.1605\n",
      "\n",
      "Epoch 51/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 576us/step - loss: 2.1910 - acc: 0.1747 - val_loss: 2.2067 - val_acc: 0.1605\n",
      "\n",
      "Epoch 52/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 487us/step - loss: 2.1904 - acc: 0.1747 - val_loss: 2.2062 - val_acc: 0.1605\n",
      "\n",
      "Epoch 53/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 480us/step - loss: 2.1898 - acc: 0.1747 - val_loss: 2.2056 - val_acc: 0.1605\n",
      "\n",
      "Epoch 54/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 512us/step - loss: 2.1892 - acc: 0.1747 - val_loss: 2.2051 - val_acc: 0.1605\n",
      "\n",
      "Epoch 55/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 582us/step - loss: 2.1885 - acc: 0.1747 - val_loss: 2.2045 - val_acc: 0.1605\n",
      "\n",
      "Epoch 56/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 610us/step - loss: 2.1879 - acc: 0.1747 - val_loss: 2.2040 - val_acc: 0.1605\n",
      "\n",
      "Epoch 57/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 517us/step - loss: 2.1872 - acc: 0.1781 - val_loss: 2.2035 - val_acc: 0.1605\n",
      "\n",
      "Epoch 58/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 517us/step - loss: 2.1866 - acc: 0.1798 - val_loss: 2.2029 - val_acc: 0.1605\n",
      "\n",
      "Epoch 59/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 535us/step - loss: 2.1860 - acc: 0.1798 - val_loss: 2.2023 - val_acc: 0.1605\n",
      "\n",
      "Epoch 60/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 683us/step - loss: 2.1854 - acc: 0.1798 - val_loss: 2.2018 - val_acc: 0.1605\n",
      "\n",
      "Epoch 61/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 528us/step - loss: 2.1848 - acc: 0.1832 - val_loss: 2.2013 - val_acc: 0.1605\n",
      "\n",
      "Epoch 62/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 533us/step - loss: 2.1842 - acc: 0.1832 - val_loss: 2.2008 - val_acc: 0.1605\n",
      "\n",
      "Epoch 63/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 592us/step - loss: 2.1836 - acc: 0.1866 - val_loss: 2.2003 - val_acc: 0.1605\n",
      "\n",
      "Epoch 64/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 610us/step - loss: 2.1830 - acc: 0.1884 - val_loss: 2.1998 - val_acc: 0.1605\n",
      "\n",
      "Epoch 65/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 473us/step - loss: 2.1824 - acc: 0.1884 - val_loss: 2.1992 - val_acc: 0.1605\n",
      "\n",
      "Epoch 66/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 544us/step - loss: 2.1818 - acc: 0.1884 - val_loss: 2.1987 - val_acc: 0.1605\n",
      "\n",
      "Epoch 67/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 498us/step - loss: 2.1812 - acc: 0.1884 - val_loss: 2.1982 - val_acc: 0.1605\n",
      "\n",
      "Epoch 68/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 637us/step - loss: 2.1806 - acc: 0.1901 - val_loss: 2.1977 - val_acc: 0.1605\n",
      "\n",
      "Epoch 69/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 531us/step - loss: 2.1800 - acc: 0.1918 - val_loss: 2.1972 - val_acc: 0.1605\n",
      "\n",
      "Epoch 70/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 533us/step - loss: 2.1794 - acc: 0.1901 - val_loss: 2.1966 - val_acc: 0.1605\n",
      "\n",
      "Epoch 71/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 535us/step - loss: 2.1788 - acc: 0.1918 - val_loss: 2.1961 - val_acc: 0.1605\n",
      "\n",
      "Epoch 72/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 520us/step - loss: 2.1782 - acc: 0.1918 - val_loss: 2.1956 - val_acc: 0.1605\n",
      "\n",
      "Epoch 73/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 562us/step - loss: 2.1776 - acc: 0.1935 - val_loss: 2.1950 - val_acc: 0.1667\n",
      "\n",
      "Epoch 74/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 541us/step - loss: 2.1770 - acc: 0.1969 - val_loss: 2.1944 - val_acc: 0.1667\n",
      "\n",
      "Epoch 75/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 511us/step - loss: 2.1764 - acc: 0.1986 - val_loss: 2.1939 - val_acc: 0.1667\n",
      "\n",
      "Epoch 76/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 495us/step - loss: 2.1758 - acc: 0.1952 - val_loss: 2.1934 - val_acc: 0.1667\n",
      "\n",
      "Epoch 77/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 506us/step - loss: 2.1752 - acc: 0.2003 - val_loss: 2.1929 - val_acc: 0.1667\n",
      "\n",
      "Epoch 78/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 495us/step - loss: 2.1746 - acc: 0.2003 - val_loss: 2.1923 - val_acc: 0.1667\n",
      "\n",
      "Epoch 79/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 583us/step - loss: 2.1740 - acc: 0.2003 - val_loss: 2.1919 - val_acc: 0.1667\n",
      "\n",
      "Epoch 80/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 599us/step - loss: 2.1735 - acc: 0.2021 - val_loss: 2.1914 - val_acc: 0.1667\n",
      "\n",
      "Epoch 81/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 502us/step - loss: 2.1729 - acc: 0.2021 - val_loss: 2.1909 - val_acc: 0.1667\n",
      "\n",
      "Epoch 82/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 500us/step - loss: 2.1723 - acc: 0.2038 - val_loss: 2.1904 - val_acc: 0.1667\n",
      "\n",
      "Epoch 83/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 488us/step - loss: 2.1717 - acc: 0.2038 - val_loss: 2.1899 - val_acc: 0.1667\n",
      "\n",
      "Epoch 84/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 541us/step - loss: 2.1711 - acc: 0.2038 - val_loss: 2.1894 - val_acc: 0.1667\n",
      "\n",
      "Epoch 85/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 568us/step - loss: 2.1706 - acc: 0.2038 - val_loss: 2.1890 - val_acc: 0.1667\n",
      "\n",
      "Epoch 86/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 618us/step - loss: 2.1699 - acc: 0.2038 - val_loss: 2.1885 - val_acc: 0.1667\n",
      "\n",
      "Epoch 87/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 516us/step - loss: 2.1694 - acc: 0.2089 - val_loss: 2.1880 - val_acc: 0.1667\n",
      "\n",
      "Epoch 88/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 661us/step - loss: 2.1688 - acc: 0.2089 - val_loss: 2.1875 - val_acc: 0.1667\n",
      "\n",
      "Epoch 89/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 512us/step - loss: 2.1682 - acc: 0.2089 - val_loss: 2.1870 - val_acc: 0.1667\n",
      "\n",
      "Epoch 90/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 510us/step - loss: 2.1675 - acc: 0.2089 - val_loss: 2.1865 - val_acc: 0.1667\n",
      "\n",
      "Epoch 91/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 486us/step - loss: 2.1669 - acc: 0.2089 - val_loss: 2.1860 - val_acc: 0.1667\n",
      "\n",
      "Epoch 92/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 569us/step - loss: 2.1663 - acc: 0.2106 - val_loss: 2.1855 - val_acc: 0.1667\n",
      "\n",
      "Epoch 93/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 489us/step - loss: 2.1657 - acc: 0.2089 - val_loss: 2.1851 - val_acc: 0.1667TA: 0s - loss: 2.1628 - acc: 0.22\n",
      "\n",
      "Epoch 94/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 451us/step - loss: 2.1651 - acc: 0.2089 - val_loss: 2.1846 - val_acc: 0.1667\n",
      "\n",
      "Epoch 95/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 574us/step - loss: 2.1645 - acc: 0.2106 - val_loss: 2.1840 - val_acc: 0.1667\n",
      "\n",
      "Epoch 96/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 454us/step - loss: 2.1639 - acc: 0.2106 - val_loss: 2.1835 - val_acc: 0.1667\n",
      "\n",
      "Epoch 97/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 598us/step - loss: 2.1633 - acc: 0.2123 - val_loss: 2.1830 - val_acc: 0.1667\n",
      "\n",
      "Epoch 98/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 627us/step - loss: 2.1627 - acc: 0.2123 - val_loss: 2.1825 - val_acc: 0.1667TA: 0s - loss: 2.1587 - acc: 0.21\n",
      "\n",
      "Epoch 99/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 628us/step - loss: 2.1621 - acc: 0.2106 - val_loss: 2.1820 - val_acc: 0.1667\n",
      "\n",
      "Epoch 100/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 628us/step - loss: 2.1615 - acc: 0.2106 - val_loss: 2.1814 - val_acc: 0.1667\n",
      "\n",
      "Epoch 101/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 483us/step - loss: 2.1608 - acc: 0.2140 - val_loss: 2.1809 - val_acc: 0.1667TA: 0s - loss: 2.1707 - acc: 0.\n",
      "\n",
      "Epoch 102/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 572us/step - loss: 2.1602 - acc: 0.2106 - val_loss: 2.1804 - val_acc: 0.1667\n",
      "\n",
      "Epoch 103/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 486us/step - loss: 2.1596 - acc: 0.2106 - val_loss: 2.1799 - val_acc: 0.1667\n",
      "\n",
      "Epoch 104/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 523us/step - loss: 2.1589 - acc: 0.2106 - val_loss: 2.1794 - val_acc: 0.1667\n",
      "\n",
      "Epoch 105/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 568us/step - loss: 2.1582 - acc: 0.2106 - val_loss: 2.1789 - val_acc: 0.1667\n",
      "\n",
      "Epoch 106/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 506us/step - loss: 2.1576 - acc: 0.2123 - val_loss: 2.1784 - val_acc: 0.1667\n",
      "\n",
      "Epoch 107/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 541us/step - loss: 2.1569 - acc: 0.2106 - val_loss: 2.1779 - val_acc: 0.1667\n",
      "\n",
      "Epoch 108/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 541us/step - loss: 2.1562 - acc: 0.2123 - val_loss: 2.1773 - val_acc: 0.1667\n",
      "\n",
      "Epoch 109/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 487us/step - loss: 2.1555 - acc: 0.2123 - val_loss: 2.1768 - val_acc: 0.1667\n",
      "\n",
      "Epoch 110/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 514us/step - loss: 2.1548 - acc: 0.2123 - val_loss: 2.1763 - val_acc: 0.1667\n",
      "\n",
      "Epoch 111/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 509us/step - loss: 2.1541 - acc: 0.2123 - val_loss: 2.1758 - val_acc: 0.1667\n",
      "\n",
      "Epoch 112/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 543us/step - loss: 2.1535 - acc: 0.2123 - val_loss: 2.1752 - val_acc: 0.1667\n",
      "\n",
      "Epoch 113/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 543us/step - loss: 2.1528 - acc: 0.2123 - val_loss: 2.1746 - val_acc: 0.1667\n",
      "\n",
      "Epoch 114/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 511us/step - loss: 2.1521 - acc: 0.2123 - val_loss: 2.1740 - val_acc: 0.1667\n",
      "\n",
      "Epoch 115/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 488us/step - loss: 2.1514 - acc: 0.2123 - val_loss: 2.1735 - val_acc: 0.1667\n",
      "\n",
      "Epoch 116/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 597us/step - loss: 2.1507 - acc: 0.2106 - val_loss: 2.1730 - val_acc: 0.1667TA: 0s - loss: 2.1472 - acc: 0.22\n",
      "\n",
      "Epoch 117/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 568us/step - loss: 2.1500 - acc: 0.2106 - val_loss: 2.1724 - val_acc: 0.1667\n",
      "\n",
      "Epoch 118/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 515us/step - loss: 2.1494 - acc: 0.2106 - val_loss: 2.1719 - val_acc: 0.1667\n",
      "\n",
      "Epoch 119/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 431us/step - loss: 2.1487 - acc: 0.2106 - val_loss: 2.1713 - val_acc: 0.1667\n",
      "\n",
      "Epoch 120/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 522us/step - loss: 2.1480 - acc: 0.2106 - val_loss: 2.1708 - val_acc: 0.1667\n",
      "\n",
      "Epoch 121/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 509us/step - loss: 2.1474 - acc: 0.2106 - val_loss: 2.1703 - val_acc: 0.1667\n",
      "\n",
      "Epoch 122/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 533us/step - loss: 2.1467 - acc: 0.2106 - val_loss: 2.1698 - val_acc: 0.1667\n",
      "\n",
      "Epoch 123/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 573us/step - loss: 2.1460 - acc: 0.2106 - val_loss: 2.1693 - val_acc: 0.1667\n",
      "\n",
      "Epoch 124/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 538us/step - loss: 2.1453 - acc: 0.2106 - val_loss: 2.1688 - val_acc: 0.1667\n",
      "\n",
      "Epoch 125/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 500us/step - loss: 2.1446 - acc: 0.2106 - val_loss: 2.1683 - val_acc: 0.1667TA: 0s - loss: 2.1441 - acc: 0.2\n",
      "\n",
      "Epoch 126/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 473us/step - loss: 2.1440 - acc: 0.2106 - val_loss: 2.1678 - val_acc: 0.1667\n",
      "\n",
      "Epoch 127/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 539us/step - loss: 2.1433 - acc: 0.2106 - val_loss: 2.1672 - val_acc: 0.1667\n",
      "\n",
      "Epoch 128/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 571us/step - loss: 2.1426 - acc: 0.2106 - val_loss: 2.1667 - val_acc: 0.1667\n",
      "\n",
      "Epoch 129/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 497us/step - loss: 2.1420 - acc: 0.2123 - val_loss: 2.1662 - val_acc: 0.1667TA: 0s - loss: 2.1486 - acc: 0.\n",
      "\n",
      "Epoch 130/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584/584 [==============================]584/584 [==============================] - 0s 533us/step - loss: 2.1413 - acc: 0.2123 - val_loss: 2.1657 - val_acc: 0.1667\n",
      "\n",
      "Epoch 131/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 483us/step - loss: 2.1406 - acc: 0.2123 - val_loss: 2.1652 - val_acc: 0.1667\n",
      "\n",
      "Epoch 132/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 522us/step - loss: 2.1399 - acc: 0.2123 - val_loss: 2.1646 - val_acc: 0.1667\n",
      "\n",
      "Epoch 133/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 529us/step - loss: 2.1393 - acc: 0.2140 - val_loss: 2.1641 - val_acc: 0.1667\n",
      "\n",
      "Epoch 134/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 572us/step - loss: 2.1386 - acc: 0.2123 - val_loss: 2.1635 - val_acc: 0.1667\n",
      "\n",
      "Epoch 135/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 570us/step - loss: 2.1379 - acc: 0.2140 - val_loss: 2.1629 - val_acc: 0.1667\n",
      "\n",
      "Epoch 136/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 473us/step - loss: 2.1373 - acc: 0.2140 - val_loss: 2.1624 - val_acc: 0.1667\n",
      "\n",
      "Epoch 137/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 556us/step - loss: 2.1366 - acc: 0.2140 - val_loss: 2.1618 - val_acc: 0.1667\n",
      "\n",
      "Epoch 138/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 538us/step - loss: 2.1359 - acc: 0.2140 - val_loss: 2.1613 - val_acc: 0.1667\n",
      "\n",
      "Epoch 139/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 504us/step - loss: 2.1352 - acc: 0.2140 - val_loss: 2.1608 - val_acc: 0.1667\n",
      "\n",
      "Epoch 140/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 547us/step - loss: 2.1345 - acc: 0.2140 - val_loss: 2.1602 - val_acc: 0.1667\n",
      "\n",
      "Epoch 141/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 667us/step - loss: 2.1338 - acc: 0.2140 - val_loss: 2.1597 - val_acc: 0.1667\n",
      "\n",
      "Epoch 142/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 597us/step - loss: 2.1331 - acc: 0.2140 - val_loss: 2.1592 - val_acc: 0.1667\n",
      "\n",
      "Epoch 143/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 521us/step - loss: 2.1325 - acc: 0.2158 - val_loss: 2.1587 - val_acc: 0.1728\n",
      "\n",
      "Epoch 144/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 608us/step - loss: 2.1318 - acc: 0.2158 - val_loss: 2.1581 - val_acc: 0.1728\n",
      "\n",
      "Epoch 145/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 520us/step - loss: 2.1311 - acc: 0.2158 - val_loss: 2.1576 - val_acc: 0.1728\n",
      "\n",
      "Epoch 146/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 542us/step - loss: 2.1304 - acc: 0.2158 - val_loss: 2.1570 - val_acc: 0.1728\n",
      "\n",
      "Epoch 147/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 504us/step - loss: 2.1297 - acc: 0.2140 - val_loss: 2.1564 - val_acc: 0.1728\n",
      "\n",
      "Epoch 148/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 549us/step - loss: 2.1290 - acc: 0.2158 - val_loss: 2.1558 - val_acc: 0.1728TA: 0s - loss: 2.1328 - acc: 0.193288/584 [=============>................] - ETA: 0s - loss: 2.1312 - acc: 0.1\n",
      "\n",
      "Epoch 149/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 512us/step - loss: 2.1283 - acc: 0.2158 - val_loss: 2.1554 - val_acc: 0.1728\n",
      "\n",
      "Epoch 150/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 681us/step - loss: 2.1276 - acc: 0.2158 - val_loss: 2.1548 - val_acc: 0.1728\n",
      "\n",
      "Epoch 151/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 518us/step - loss: 2.1269 - acc: 0.2158 - val_loss: 2.1543 - val_acc: 0.1728TA: 0s - loss: 2.1186 - acc: 0.\n",
      "\n",
      "Epoch 152/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 538us/step - loss: 2.1262 - acc: 0.2158 - val_loss: 2.1538 - val_acc: 0.1728\n",
      "\n",
      "Epoch 153/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 517us/step - loss: 2.1254 - acc: 0.2158 - val_loss: 2.1533 - val_acc: 0.1728\n",
      "\n",
      "Epoch 154/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 514us/step - loss: 2.1247 - acc: 0.2158 - val_loss: 2.1527 - val_acc: 0.1728\n",
      "\n",
      "Epoch 155/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 513us/step - loss: 2.1240 - acc: 0.2140 - val_loss: 2.1521 - val_acc: 0.1728\n",
      "\n",
      "Epoch 156/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 506us/step - loss: 2.1232 - acc: 0.2140 - val_loss: 2.1515 - val_acc: 0.1728\n",
      "\n",
      "Epoch 157/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 636us/step - loss: 2.1224 - acc: 0.2140 - val_loss: 2.1508 - val_acc: 0.1728\n",
      "\n",
      "Epoch 158/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 512us/step - loss: 2.1216 - acc: 0.2158 - val_loss: 2.1503 - val_acc: 0.1728\n",
      "\n",
      "Epoch 159/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 565us/step - loss: 2.1209 - acc: 0.2158 - val_loss: 2.1497 - val_acc: 0.1728\n",
      "\n",
      "Epoch 160/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 585us/step - loss: 2.1201 - acc: 0.2158 - val_loss: 2.1491 - val_acc: 0.1728\n",
      "\n",
      "Epoch 161/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 498us/step - loss: 2.1193 - acc: 0.2158 - val_loss: 2.1485 - val_acc: 0.1728\n",
      "\n",
      "Epoch 162/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 562us/step - loss: 2.1185 - acc: 0.2158 - val_loss: 2.1478 - val_acc: 0.1728\n",
      "\n",
      "Epoch 163/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 551us/step - loss: 2.1178 - acc: 0.2158 - val_loss: 2.1472 - val_acc: 0.1728\n",
      "\n",
      "Epoch 164/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 540us/step - loss: 2.1170 - acc: 0.2158 - val_loss: 2.1466 - val_acc: 0.1728\n",
      "\n",
      "Epoch 165/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 460us/step - loss: 2.1162 - acc: 0.2175 - val_loss: 2.1461 - val_acc: 0.1728\n",
      "\n",
      "Epoch 166/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 533us/step - loss: 2.1155 - acc: 0.2175 - val_loss: 2.1454 - val_acc: 0.1728\n",
      "\n",
      "Epoch 167/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 521us/step - loss: 2.1147 - acc: 0.2192 - val_loss: 2.1447 - val_acc: 0.1728\n",
      "\n",
      "Epoch 168/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 513us/step - loss: 2.1138 - acc: 0.2192 - val_loss: 2.1440 - val_acc: 0.1728TA: 0s - loss: 2.1164 - acc: 0.21\n",
      "\n",
      "Epoch 169/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 494us/step - loss: 2.1130 - acc: 0.2192 - val_loss: 2.1433 - val_acc: 0.1728\n",
      "\n",
      "Epoch 170/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 503us/step - loss: 2.1121 - acc: 0.2209 - val_loss: 2.1427 - val_acc: 0.1728\n",
      "\n",
      "Epoch 171/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 568us/step - loss: 2.1113 - acc: 0.2192 - val_loss: 2.1421 - val_acc: 0.1728\n",
      "\n",
      "Epoch 172/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 514us/step - loss: 2.1105 - acc: 0.2192 - val_loss: 2.1414 - val_acc: 0.1728\n",
      "\n",
      "Epoch 173/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 487us/step - loss: 2.1096 - acc: 0.2175 - val_loss: 2.1408 - val_acc: 0.1728\n",
      "\n",
      "Epoch 174/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 644us/step - loss: 2.1087 - acc: 0.2192 - val_loss: 2.1401 - val_acc: 0.1728\n",
      "\n",
      "Epoch 175/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 578us/step - loss: 2.1079 - acc: 0.2192 - val_loss: 2.1395 - val_acc: 0.1728\n",
      "\n",
      "Epoch 176/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 639us/step - loss: 2.1070 - acc: 0.2175 - val_loss: 2.1389 - val_acc: 0.1728\n",
      "\n",
      "Epoch 177/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 530us/step - loss: 2.1061 - acc: 0.2175 - val_loss: 2.1382 - val_acc: 0.1728\n",
      "\n",
      "Epoch 178/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 572us/step - loss: 2.1053 - acc: 0.2209 - val_loss: 2.1376 - val_acc: 0.1728\n",
      "\n",
      "Epoch 179/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 542us/step - loss: 2.1044 - acc: 0.2209 - val_loss: 2.1370 - val_acc: 0.1728\n",
      "\n",
      "Epoch 180/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 599us/step - loss: 2.1035 - acc: 0.2226 - val_loss: 2.1362 - val_acc: 0.1728\n",
      "\n",
      "Epoch 181/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 516us/step - loss: 2.1026 - acc: 0.2209 - val_loss: 2.1355 - val_acc: 0.1728\n",
      "\n",
      "Epoch 182/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 669us/step - loss: 2.1017 - acc: 0.2209 - val_loss: 2.1348 - val_acc: 0.1728\n",
      "\n",
      "Epoch 183/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 664us/step - loss: 2.1008 - acc: 0.2226 - val_loss: 2.1341 - val_acc: 0.1728\n",
      "\n",
      "Epoch 184/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 601us/step - loss: 2.0999 - acc: 0.2209 - val_loss: 2.1333 - val_acc: 0.1728\n",
      "\n",
      "Epoch 185/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 569us/step - loss: 2.0989 - acc: 0.2226 - val_loss: 2.1326 - val_acc: 0.1728\n",
      "\n",
      "Epoch 186/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 604us/step - loss: 2.0979 - acc: 0.2209 - val_loss: 2.1318 - val_acc: 0.1728\n",
      "\n",
      "Epoch 187/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 519us/step - loss: 2.0970 - acc: 0.2226 - val_loss: 2.1310 - val_acc: 0.1728\n",
      "\n",
      "Epoch 188/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 526us/step - loss: 2.0961 - acc: 0.2209 - val_loss: 2.1302 - val_acc: 0.1728\n",
      "\n",
      "Epoch 189/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 520us/step - loss: 2.0951 - acc: 0.2209 - val_loss: 2.1295 - val_acc: 0.1728\n",
      "\n",
      "Epoch 190/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 512us/step - loss: 2.0941 - acc: 0.2192 - val_loss: 2.1288 - val_acc: 0.1728\n",
      "\n",
      "Epoch 191/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 540us/step - loss: 2.0931 - acc: 0.2175 - val_loss: 2.1280 - val_acc: 0.1728\n",
      "\n",
      "Epoch 192/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 545us/step - loss: 2.0921 - acc: 0.2175 - val_loss: 2.1273 - val_acc: 0.1728\n",
      "\n",
      "Epoch 193/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 559us/step - loss: 2.0911 - acc: 0.2192 - val_loss: 2.1265 - val_acc: 0.1728\n",
      "\n",
      "Epoch 194/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 489us/step - loss: 2.0901 - acc: 0.2192 - val_loss: 2.1257 - val_acc: 0.1790\n",
      "\n",
      "Epoch 195/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 575us/step - loss: 2.0891 - acc: 0.2192 - val_loss: 2.1249 - val_acc: 0.1790\n",
      "\n",
      "Epoch 196/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 547us/step - loss: 2.0881 - acc: 0.2192 - val_loss: 2.1240 - val_acc: 0.1790\n",
      "\n",
      "Epoch 197/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 463us/step - loss: 2.0870 - acc: 0.2192 - val_loss: 2.1232 - val_acc: 0.1790\n",
      "\n",
      "Epoch 198/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 643us/step - loss: 2.0860 - acc: 0.2192 - val_loss: 2.1223 - val_acc: 0.1790\n",
      "\n",
      "Epoch 199/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 488us/step - loss: 2.0849 - acc: 0.2192 - val_loss: 2.1215 - val_acc: 0.1790\n",
      "\n",
      "Epoch 200/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 571us/step - loss: 2.0839 - acc: 0.2175 - val_loss: 2.1206 - val_acc: 0.1790\n",
      "\n",
      "64/64 [==============================]64/64 [==============================] - 0s 253us/step\n",
      "\n",
      "Train on 584 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "584/584 [==============================]584/584 [==============================] - 2s 4ms/step - loss: 2.2231 - acc: 0.0993 - val_loss: 2.2189 - val_acc: 0.1605\n",
      "\n",
      "Epoch 2/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 605us/step - loss: 2.2214 - acc: 0.0993 - val_loss: 2.2174 - val_acc: 0.1543\n",
      "\n",
      "Epoch 3/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 569us/step - loss: 2.2197 - acc: 0.0993 - val_loss: 2.2160 - val_acc: 0.1543\n",
      "\n",
      "Epoch 4/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 516us/step - loss: 2.2181 - acc: 0.0993 - val_loss: 2.2145 - val_acc: 0.1543\n",
      "\n",
      "Epoch 5/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 623us/step - loss: 2.2165 - acc: 0.0976 - val_loss: 2.2132 - val_acc: 0.1543\n",
      "\n",
      "Epoch 6/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 542us/step - loss: 2.2149 - acc: 0.0976 - val_loss: 2.2119 - val_acc: 0.1543\n",
      "\n",
      "Epoch 7/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 576us/step - loss: 2.2135 - acc: 0.1010 - val_loss: 2.2106 - val_acc: 0.1543\n",
      "\n",
      "Epoch 8/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 525us/step - loss: 2.2120 - acc: 0.1010 - val_loss: 2.2093 - val_acc: 0.1543\n",
      "\n",
      "Epoch 9/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 526us/step - loss: 2.2107 - acc: 0.1010 - val_loss: 2.2081 - val_acc: 0.1543\n",
      "\n",
      "Epoch 10/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 493us/step - loss: 2.2093 - acc: 0.0993 - val_loss: 2.2068 - val_acc: 0.1543\n",
      "\n",
      "Epoch 11/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 588us/step - loss: 2.2080 - acc: 0.1010 - val_loss: 2.2056 - val_acc: 0.1481\n",
      "\n",
      "Epoch 12/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 571us/step - loss: 2.2067 - acc: 0.1010 - val_loss: 2.2042 - val_acc: 0.1481\n",
      "\n",
      "Epoch 13/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 492us/step - loss: 2.2053 - acc: 0.0976 - val_loss: 2.2031 - val_acc: 0.1481\n",
      "\n",
      "Epoch 14/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 598us/step - loss: 2.2040 - acc: 0.0976 - val_loss: 2.2019 - val_acc: 0.1481\n",
      "\n",
      "Epoch 15/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 490us/step - loss: 2.2028 - acc: 0.0976 - val_loss: 2.2008 - val_acc: 0.1481\n",
      "\n",
      "Epoch 16/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 557us/step - loss: 2.2017 - acc: 0.0959 - val_loss: 2.1998 - val_acc: 0.1481\n",
      "\n",
      "Epoch 17/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 516us/step - loss: 2.2005 - acc: 0.0959 - val_loss: 2.1988 - val_acc: 0.1481\n",
      "\n",
      "Epoch 18/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 515us/step - loss: 2.1994 - acc: 0.0959 - val_loss: 2.1978 - val_acc: 0.1420\n",
      "\n",
      "Epoch 19/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 574us/step - loss: 2.1983 - acc: 0.0959 - val_loss: 2.1968 - val_acc: 0.1420\n",
      "\n",
      "Epoch 20/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584/584 [==============================]584/584 [==============================] - 0s 567us/step - loss: 2.1972 - acc: 0.0942 - val_loss: 2.1959 - val_acc: 0.1420\n",
      "\n",
      "Epoch 21/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 542us/step - loss: 2.1962 - acc: 0.0925 - val_loss: 2.1949 - val_acc: 0.1420\n",
      "\n",
      "Epoch 22/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 526us/step - loss: 2.1952 - acc: 0.0925 - val_loss: 2.1941 - val_acc: 0.1358\n",
      "\n",
      "Epoch 23/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 555us/step - loss: 2.1942 - acc: 0.0925 - val_loss: 2.1932 - val_acc: 0.1358\n",
      "\n",
      "Epoch 24/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 657us/step - loss: 2.1933 - acc: 0.0925 - val_loss: 2.1923 - val_acc: 0.1420\n",
      "\n",
      "Epoch 25/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 575us/step - loss: 2.1924 - acc: 0.0959 - val_loss: 2.1915 - val_acc: 0.1358\n",
      "\n",
      "Epoch 26/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 539us/step - loss: 2.1915 - acc: 0.0993 - val_loss: 2.1907 - val_acc: 0.1420\n",
      "\n",
      "Epoch 27/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 572us/step - loss: 2.1906 - acc: 0.1010 - val_loss: 2.1897 - val_acc: 0.1420\n",
      "\n",
      "Epoch 28/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 518us/step - loss: 2.1897 - acc: 0.1045 - val_loss: 2.1888 - val_acc: 0.1420\n",
      "\n",
      "Epoch 29/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 554us/step - loss: 2.1888 - acc: 0.1027 - val_loss: 2.1879 - val_acc: 0.1420\n",
      "\n",
      "Epoch 30/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 580us/step - loss: 2.1879 - acc: 0.1027 - val_loss: 2.1871 - val_acc: 0.1420\n",
      "\n",
      "Epoch 31/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 506us/step - loss: 2.1871 - acc: 0.1027 - val_loss: 2.1862 - val_acc: 0.1420\n",
      "\n",
      "Epoch 32/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 548us/step - loss: 2.1862 - acc: 0.1010 - val_loss: 2.1854 - val_acc: 0.1420\n",
      "\n",
      "Epoch 33/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 547us/step - loss: 2.1855 - acc: 0.1027 - val_loss: 2.1844 - val_acc: 0.1420\n",
      "\n",
      "Epoch 34/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 540us/step - loss: 2.1845 - acc: 0.1010 - val_loss: 2.1837 - val_acc: 0.1420\n",
      "\n",
      "Epoch 35/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 514us/step - loss: 2.1838 - acc: 0.1027 - val_loss: 2.1829 - val_acc: 0.1420\n",
      "\n",
      "Epoch 36/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 494us/step - loss: 2.1829 - acc: 0.1027 - val_loss: 2.1822 - val_acc: 0.1420\n",
      "\n",
      "Epoch 37/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 505us/step - loss: 2.1822 - acc: 0.1027 - val_loss: 2.1815 - val_acc: 0.1420\n",
      "\n",
      "Epoch 38/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 541us/step - loss: 2.1814 - acc: 0.1027 - val_loss: 2.1808 - val_acc: 0.1420\n",
      "\n",
      "Epoch 39/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 595us/step - loss: 2.1807 - acc: 0.1027 - val_loss: 2.1801 - val_acc: 0.1420\n",
      "\n",
      "Epoch 40/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 523us/step - loss: 2.1799 - acc: 0.1027 - val_loss: 2.1794 - val_acc: 0.1420\n",
      "\n",
      "Epoch 41/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 596us/step - loss: 2.1791 - acc: 0.1027 - val_loss: 2.1788 - val_acc: 0.1420\n",
      "\n",
      "Epoch 42/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 510us/step - loss: 2.1785 - acc: 0.1062 - val_loss: 2.1781 - val_acc: 0.1420\n",
      "\n",
      "Epoch 43/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 625us/step - loss: 2.1777 - acc: 0.1079 - val_loss: 2.1775 - val_acc: 0.1420\n",
      "\n",
      "Epoch 44/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 515us/step - loss: 2.1770 - acc: 0.1079 - val_loss: 2.1769 - val_acc: 0.1420\n",
      "\n",
      "Epoch 45/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 554us/step - loss: 2.1763 - acc: 0.1062 - val_loss: 2.1762 - val_acc: 0.1358\n",
      "\n",
      "Epoch 46/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 542us/step - loss: 2.1756 - acc: 0.1079 - val_loss: 2.1757 - val_acc: 0.1358\n",
      "\n",
      "Epoch 47/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 487us/step - loss: 2.1749 - acc: 0.1062 - val_loss: 2.1750 - val_acc: 0.1358\n",
      "\n",
      "Epoch 48/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 557us/step - loss: 2.1741 - acc: 0.1062 - val_loss: 2.1744 - val_acc: 0.1420\n",
      "\n",
      "Epoch 49/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 542us/step - loss: 2.1734 - acc: 0.1096 - val_loss: 2.1737 - val_acc: 0.1420\n",
      "\n",
      "Epoch 50/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 487us/step - loss: 2.1727 - acc: 0.1079 - val_loss: 2.1731 - val_acc: 0.1420\n",
      "\n",
      "Epoch 51/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 542us/step - loss: 2.1721 - acc: 0.1096 - val_loss: 2.1724 - val_acc: 0.1420\n",
      "\n",
      "Epoch 52/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 519us/step - loss: 2.1714 - acc: 0.1113 - val_loss: 2.1718 - val_acc: 0.1420\n",
      "\n",
      "Epoch 53/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 589us/step - loss: 2.1707 - acc: 0.1113 - val_loss: 2.1713 - val_acc: 0.1481\n",
      "\n",
      "Epoch 54/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 546us/step - loss: 2.1701 - acc: 0.1113 - val_loss: 2.1707 - val_acc: 0.1481\n",
      "\n",
      "Epoch 55/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 428us/step - loss: 2.1694 - acc: 0.1113 - val_loss: 2.1701 - val_acc: 0.1481\n",
      "\n",
      "Epoch 56/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 509us/step - loss: 2.1687 - acc: 0.1130 - val_loss: 2.1696 - val_acc: 0.1481TA: 0s - loss: 2.1735 - acc: 0.11\n",
      "\n",
      "Epoch 57/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 497us/step - loss: 2.1681 - acc: 0.1096 - val_loss: 2.1691 - val_acc: 0.1481\n",
      "\n",
      "Epoch 58/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 504us/step - loss: 2.1675 - acc: 0.1096 - val_loss: 2.1686 - val_acc: 0.1481\n",
      "\n",
      "Epoch 59/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 545us/step - loss: 2.1669 - acc: 0.1096 - val_loss: 2.1680 - val_acc: 0.1481\n",
      "\n",
      "Epoch 60/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 603us/step - loss: 2.1662 - acc: 0.1113 - val_loss: 2.1675 - val_acc: 0.1481\n",
      "\n",
      "Epoch 61/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 510us/step - loss: 2.1656 - acc: 0.1130 - val_loss: 2.1670 - val_acc: 0.1543\n",
      "\n",
      "Epoch 62/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 505us/step - loss: 2.1650 - acc: 0.1113 - val_loss: 2.1665 - val_acc: 0.1667\n",
      "\n",
      "Epoch 63/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 520us/step - loss: 2.1644 - acc: 0.1113 - val_loss: 2.1660 - val_acc: 0.1605\n",
      "\n",
      "Epoch 64/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 596us/step - loss: 2.1638 - acc: 0.1130 - val_loss: 2.1656 - val_acc: 0.1605\n",
      "\n",
      "Epoch 65/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 616us/step - loss: 2.1632 - acc: 0.1130 - val_loss: 2.1650 - val_acc: 0.1605\n",
      "\n",
      "Epoch 66/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 572us/step - loss: 2.1626 - acc: 0.1130 - val_loss: 2.1645 - val_acc: 0.1605\n",
      "\n",
      "Epoch 67/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 552us/step - loss: 2.1620 - acc: 0.1130 - val_loss: 2.1640 - val_acc: 0.1605\n",
      "\n",
      "Epoch 68/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 547us/step - loss: 2.1613 - acc: 0.1130 - val_loss: 2.1635 - val_acc: 0.1605\n",
      "\n",
      "Epoch 69/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 542us/step - loss: 2.1607 - acc: 0.1130 - val_loss: 2.1630 - val_acc: 0.1605\n",
      "\n",
      "Epoch 70/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 514us/step - loss: 2.1601 - acc: 0.1147 - val_loss: 2.1624 - val_acc: 0.1605\n",
      "\n",
      "Epoch 71/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 540us/step - loss: 2.1595 - acc: 0.1182 - val_loss: 2.1618 - val_acc: 0.1605\n",
      "\n",
      "Epoch 72/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 569us/step - loss: 2.1589 - acc: 0.1164 - val_loss: 2.1613 - val_acc: 0.1605\n",
      "\n",
      "Epoch 73/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 588us/step - loss: 2.1583 - acc: 0.1164 - val_loss: 2.1609 - val_acc: 0.1605\n",
      "\n",
      "Epoch 74/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 504us/step - loss: 2.1577 - acc: 0.1147 - val_loss: 2.1604 - val_acc: 0.1605\n",
      "\n",
      "Epoch 75/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 591us/step - loss: 2.1571 - acc: 0.1113 - val_loss: 2.1598 - val_acc: 0.1605\n",
      "\n",
      "Epoch 76/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 570us/step - loss: 2.1565 - acc: 0.1130 - val_loss: 2.1594 - val_acc: 0.1667\n",
      "\n",
      "Epoch 77/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 546us/step - loss: 2.1560 - acc: 0.1113 - val_loss: 2.1588 - val_acc: 0.1667\n",
      "\n",
      "Epoch 78/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 522us/step - loss: 2.1553 - acc: 0.1130 - val_loss: 2.1583 - val_acc: 0.1667\n",
      "\n",
      "Epoch 79/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 574us/step - loss: 2.1548 - acc: 0.1130 - val_loss: 2.1578 - val_acc: 0.1667\n",
      "\n",
      "Epoch 80/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 506us/step - loss: 2.1542 - acc: 0.1130 - val_loss: 2.1573 - val_acc: 0.1667\n",
      "\n",
      "Epoch 81/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 525us/step - loss: 2.1537 - acc: 0.1164 - val_loss: 2.1568 - val_acc: 0.1667\n",
      "\n",
      "Epoch 82/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 620us/step - loss: 2.1531 - acc: 0.1164 - val_loss: 2.1563 - val_acc: 0.1667\n",
      "\n",
      "Epoch 83/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 582us/step - loss: 2.1525 - acc: 0.1147 - val_loss: 2.1558 - val_acc: 0.1667\n",
      "\n",
      "Epoch 84/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 627us/step - loss: 2.1520 - acc: 0.1147 - val_loss: 2.1552 - val_acc: 0.1667\n",
      "\n",
      "Epoch 85/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 502us/step - loss: 2.1514 - acc: 0.1164 - val_loss: 2.1547 - val_acc: 0.1667\n",
      "\n",
      "Epoch 86/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 523us/step - loss: 2.1509 - acc: 0.1164 - val_loss: 2.1542 - val_acc: 0.1667\n",
      "\n",
      "Epoch 87/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 595us/step - loss: 2.1503 - acc: 0.1199 - val_loss: 2.1538 - val_acc: 0.1667\n",
      "\n",
      "Epoch 88/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 575us/step - loss: 2.1497 - acc: 0.1216 - val_loss: 2.1533 - val_acc: 0.1790\n",
      "\n",
      "Epoch 89/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 581us/step - loss: 2.1492 - acc: 0.1199 - val_loss: 2.1528 - val_acc: 0.1790\n",
      "\n",
      "Epoch 90/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 529us/step - loss: 2.1486 - acc: 0.1199 - val_loss: 2.1522 - val_acc: 0.1790\n",
      "\n",
      "Epoch 91/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 600us/step - loss: 2.1481 - acc: 0.1233 - val_loss: 2.1517 - val_acc: 0.1790\n",
      "\n",
      "Epoch 92/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 541us/step - loss: 2.1475 - acc: 0.1216 - val_loss: 2.1512 - val_acc: 0.1790\n",
      "\n",
      "Epoch 93/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 561us/step - loss: 2.1469 - acc: 0.1250 - val_loss: 2.1507 - val_acc: 0.1790\n",
      "\n",
      "Epoch 94/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 516us/step - loss: 2.1464 - acc: 0.1216 - val_loss: 2.1501 - val_acc: 0.1790\n",
      "\n",
      "Epoch 95/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 502us/step - loss: 2.1458 - acc: 0.1216 - val_loss: 2.1496 - val_acc: 0.1790\n",
      "\n",
      "Epoch 96/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 552us/step - loss: 2.1453 - acc: 0.1233 - val_loss: 2.1491 - val_acc: 0.1790\n",
      "\n",
      "Epoch 97/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 487us/step - loss: 2.1447 - acc: 0.1267 - val_loss: 2.1485 - val_acc: 0.1790\n",
      "\n",
      "Epoch 98/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 554us/step - loss: 2.1442 - acc: 0.1267 - val_loss: 2.1479 - val_acc: 0.1790\n",
      "\n",
      "Epoch 99/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 487us/step - loss: 2.1436 - acc: 0.1318 - val_loss: 2.1474 - val_acc: 0.1790\n",
      "\n",
      "Epoch 100/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 600us/step - loss: 2.1431 - acc: 0.1353 - val_loss: 2.1467 - val_acc: 0.1790\n",
      "\n",
      "Epoch 101/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 578us/step - loss: 2.1424 - acc: 0.1353 - val_loss: 2.1461 - val_acc: 0.1790\n",
      "\n",
      "Epoch 102/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 572us/step - loss: 2.1419 - acc: 0.1353 - val_loss: 2.1456 - val_acc: 0.1790\n",
      "\n",
      "Epoch 103/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 516us/step - loss: 2.1413 - acc: 0.1353 - val_loss: 2.1450 - val_acc: 0.1790\n",
      "\n",
      "Epoch 104/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 495us/step - loss: 2.1407 - acc: 0.1353 - val_loss: 2.1445 - val_acc: 0.1852\n",
      "\n",
      "Epoch 105/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 528us/step - loss: 2.1401 - acc: 0.1353 - val_loss: 2.1439 - val_acc: 0.1852\n",
      "\n",
      "Epoch 106/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 543us/step - loss: 2.1396 - acc: 0.1370 - val_loss: 2.1433 - val_acc: 0.1852\n",
      "\n",
      "Epoch 107/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 547us/step - loss: 2.1390 - acc: 0.1370 - val_loss: 2.1426 - val_acc: 0.1852\n",
      "\n",
      "Epoch 108/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 646us/step - loss: 2.1384 - acc: 0.1404 - val_loss: 2.1420 - val_acc: 0.1852\n",
      "\n",
      "Epoch 109/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 491us/step - loss: 2.1378 - acc: 0.1438 - val_loss: 2.1414 - val_acc: 0.1852\n",
      "\n",
      "Epoch 110/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 541us/step - loss: 2.1371 - acc: 0.1455 - val_loss: 2.1408 - val_acc: 0.1852\n",
      "\n",
      "Epoch 111/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 542us/step - loss: 2.1365 - acc: 0.1473 - val_loss: 2.1401 - val_acc: 0.1852\n",
      "\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584/584 [==============================]584/584 [==============================] - 0s 505us/step - loss: 2.1359 - acc: 0.1507 - val_loss: 2.1396 - val_acc: 0.1852\n",
      "\n",
      "Epoch 113/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 523us/step - loss: 2.1353 - acc: 0.1507 - val_loss: 2.1390 - val_acc: 0.1852\n",
      "\n",
      "Epoch 114/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 513us/step - loss: 2.1347 - acc: 0.1507 - val_loss: 2.1385 - val_acc: 0.1914\n",
      "\n",
      "Epoch 115/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 543us/step - loss: 2.1341 - acc: 0.1524 - val_loss: 2.1379 - val_acc: 0.1914\n",
      "\n",
      "Epoch 116/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 541us/step - loss: 2.1335 - acc: 0.1541 - val_loss: 2.1373 - val_acc: 0.1975\n",
      "\n",
      "Epoch 117/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 540us/step - loss: 2.1329 - acc: 0.1558 - val_loss: 2.1366 - val_acc: 0.1975\n",
      "\n",
      "Epoch 118/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 516us/step - loss: 2.1323 - acc: 0.1558 - val_loss: 2.1361 - val_acc: 0.1975TA: 0s - loss: 2.1222 - acc: 0.1\n",
      "\n",
      "Epoch 119/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 517us/step - loss: 2.1317 - acc: 0.1575 - val_loss: 2.1354 - val_acc: 0.1975\n",
      "\n",
      "Epoch 120/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 567us/step - loss: 2.1310 - acc: 0.1558 - val_loss: 2.1347 - val_acc: 0.1975\n",
      "\n",
      "Epoch 121/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 537us/step - loss: 2.1304 - acc: 0.1558 - val_loss: 2.1341 - val_acc: 0.1975\n",
      "\n",
      "Epoch 122/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 606us/step - loss: 2.1298 - acc: 0.1558 - val_loss: 2.1335 - val_acc: 0.1975\n",
      "\n",
      "Epoch 123/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 573us/step - loss: 2.1292 - acc: 0.1575 - val_loss: 2.1329 - val_acc: 0.1914\n",
      "\n",
      "Epoch 124/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 511us/step - loss: 2.1285 - acc: 0.1575 - val_loss: 2.1324 - val_acc: 0.1914\n",
      "\n",
      "Epoch 125/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 541us/step - loss: 2.1279 - acc: 0.1575 - val_loss: 2.1318 - val_acc: 0.1914\n",
      "\n",
      "Epoch 126/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 544us/step - loss: 2.1273 - acc: 0.1575 - val_loss: 2.1312 - val_acc: 0.1914TA: 0s - loss: 2.1239 - acc: 0.14\n",
      "\n",
      "Epoch 127/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 596us/step - loss: 2.1267 - acc: 0.1575 - val_loss: 2.1306 - val_acc: 0.1914\n",
      "\n",
      "Epoch 128/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 489us/step - loss: 2.1261 - acc: 0.1575 - val_loss: 2.1299 - val_acc: 0.1914\n",
      "\n",
      "Epoch 129/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 485us/step - loss: 2.1254 - acc: 0.1575 - val_loss: 2.1294 - val_acc: 0.1914\n",
      "\n",
      "Epoch 130/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 567us/step - loss: 2.1248 - acc: 0.1575 - val_loss: 2.1288 - val_acc: 0.1914\n",
      "\n",
      "Epoch 131/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 520us/step - loss: 2.1242 - acc: 0.1575 - val_loss: 2.1282 - val_acc: 0.1914\n",
      "\n",
      "Epoch 132/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 576us/step - loss: 2.1236 - acc: 0.1592 - val_loss: 2.1275 - val_acc: 0.2037\n",
      "\n",
      "Epoch 133/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 474us/step - loss: 2.1229 - acc: 0.1575 - val_loss: 2.1269 - val_acc: 0.2037\n",
      "\n",
      "Epoch 134/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 546us/step - loss: 2.1222 - acc: 0.1575 - val_loss: 2.1262 - val_acc: 0.2037\n",
      "\n",
      "Epoch 135/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 552us/step - loss: 2.1215 - acc: 0.1610 - val_loss: 2.1255 - val_acc: 0.2037\n",
      "\n",
      "Epoch 136/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 577us/step - loss: 2.1208 - acc: 0.1592 - val_loss: 2.1249 - val_acc: 0.2037\n",
      "\n",
      "Epoch 137/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 558us/step - loss: 2.1201 - acc: 0.1592 - val_loss: 2.1242 - val_acc: 0.2037\n",
      "\n",
      "Epoch 138/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 533us/step - loss: 2.1195 - acc: 0.1592 - val_loss: 2.1235 - val_acc: 0.2037\n",
      "\n",
      "Epoch 139/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 575us/step - loss: 2.1187 - acc: 0.1627 - val_loss: 2.1228 - val_acc: 0.2037\n",
      "\n",
      "Epoch 140/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 548us/step - loss: 2.1180 - acc: 0.1627 - val_loss: 2.1221 - val_acc: 0.2099\n",
      "\n",
      "Epoch 141/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 578us/step - loss: 2.1173 - acc: 0.1627 - val_loss: 2.1214 - val_acc: 0.2099\n",
      "\n",
      "Epoch 142/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 616us/step - loss: 2.1166 - acc: 0.1644 - val_loss: 2.1207 - val_acc: 0.2099\n",
      "\n",
      "Epoch 143/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 581us/step - loss: 2.1158 - acc: 0.1644 - val_loss: 2.1199 - val_acc: 0.2099\n",
      "\n",
      "Epoch 144/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 583us/step - loss: 2.1151 - acc: 0.1661 - val_loss: 2.1191 - val_acc: 0.2222\n",
      "\n",
      "Epoch 145/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 626us/step - loss: 2.1143 - acc: 0.1644 - val_loss: 2.1183 - val_acc: 0.2222\n",
      "\n",
      "Epoch 146/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 802us/step - loss: 2.1135 - acc: 0.1678 - val_loss: 2.1176 - val_acc: 0.2284\n",
      "\n",
      "Epoch 147/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 505us/step - loss: 2.1128 - acc: 0.1678 - val_loss: 2.1169 - val_acc: 0.2284\n",
      "\n",
      "Epoch 148/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 589us/step - loss: 2.1121 - acc: 0.1695 - val_loss: 2.1161 - val_acc: 0.2284\n",
      "\n",
      "Epoch 149/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 604us/step - loss: 2.1114 - acc: 0.1678 - val_loss: 2.1154 - val_acc: 0.2284\n",
      "\n",
      "Epoch 150/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 586us/step - loss: 2.1106 - acc: 0.1678 - val_loss: 2.1145 - val_acc: 0.2284\n",
      "\n",
      "Epoch 151/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 556us/step - loss: 2.1098 - acc: 0.1678 - val_loss: 2.1138 - val_acc: 0.2284\n",
      "\n",
      "Epoch 152/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 671us/step - loss: 2.1091 - acc: 0.1695 - val_loss: 2.1131 - val_acc: 0.2346\n",
      "\n",
      "Epoch 153/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 615us/step - loss: 2.1083 - acc: 0.1678 - val_loss: 2.1123 - val_acc: 0.2346\n",
      "\n",
      "Epoch 154/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 554us/step - loss: 2.1076 - acc: 0.1678 - val_loss: 2.1116 - val_acc: 0.2407\n",
      "\n",
      "Epoch 155/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 581us/step - loss: 2.1068 - acc: 0.1678 - val_loss: 2.1108 - val_acc: 0.2407\n",
      "\n",
      "Epoch 156/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 571us/step - loss: 2.1060 - acc: 0.1678 - val_loss: 2.1100 - val_acc: 0.2407\n",
      "\n",
      "Epoch 157/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 541us/step - loss: 2.1052 - acc: 0.1678 - val_loss: 2.1091 - val_acc: 0.2469\n",
      "\n",
      "Epoch 158/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 476us/step - loss: 2.1045 - acc: 0.1678 - val_loss: 2.1083 - val_acc: 0.2469\n",
      "\n",
      "Epoch 159/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 554us/step - loss: 2.1036 - acc: 0.1695 - val_loss: 2.1074 - val_acc: 0.2469\n",
      "\n",
      "Epoch 160/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 549us/step - loss: 2.1028 - acc: 0.1729 - val_loss: 2.1066 - val_acc: 0.2469\n",
      "\n",
      "Epoch 161/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 532us/step - loss: 2.1020 - acc: 0.1747 - val_loss: 2.1058 - val_acc: 0.2469\n",
      "\n",
      "Epoch 162/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 538us/step - loss: 2.1011 - acc: 0.1747 - val_loss: 2.1050 - val_acc: 0.2469\n",
      "\n",
      "Epoch 163/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 620us/step - loss: 2.1003 - acc: 0.1747 - val_loss: 2.1042 - val_acc: 0.2469\n",
      "\n",
      "Epoch 164/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 514us/step - loss: 2.0995 - acc: 0.1747 - val_loss: 2.1033 - val_acc: 0.2469\n",
      "\n",
      "Epoch 165/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 578us/step - loss: 2.0987 - acc: 0.1747 - val_loss: 2.1026 - val_acc: 0.2469TA: 0s - loss: 2.1007 - acc: 0.18\n",
      "\n",
      "Epoch 166/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 506us/step - loss: 2.0979 - acc: 0.1764 - val_loss: 2.1016 - val_acc: 0.2469\n",
      "\n",
      "Epoch 167/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 581us/step - loss: 2.0970 - acc: 0.1781 - val_loss: 2.1009 - val_acc: 0.2469\n",
      "\n",
      "Epoch 168/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 495us/step - loss: 2.0962 - acc: 0.1781 - val_loss: 2.1000 - val_acc: 0.2469\n",
      "\n",
      "Epoch 169/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 555us/step - loss: 2.0953 - acc: 0.1781 - val_loss: 2.0991 - val_acc: 0.2469\n",
      "\n",
      "Epoch 170/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 457us/step - loss: 2.0944 - acc: 0.1764 - val_loss: 2.0981 - val_acc: 0.2469\n",
      "\n",
      "Epoch 171/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 502us/step - loss: 2.0936 - acc: 0.1798 - val_loss: 2.0972 - val_acc: 0.2469\n",
      "\n",
      "Epoch 172/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 526us/step - loss: 2.0926 - acc: 0.1798 - val_loss: 2.0963 - val_acc: 0.2469\n",
      "\n",
      "Epoch 173/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 626us/step - loss: 2.0917 - acc: 0.1781 - val_loss: 2.0955 - val_acc: 0.2469\n",
      "\n",
      "Epoch 174/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 659us/step - loss: 2.0909 - acc: 0.1798 - val_loss: 2.0944 - val_acc: 0.2469\n",
      "\n",
      "Epoch 175/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 517us/step - loss: 2.0900 - acc: 0.1781 - val_loss: 2.0936 - val_acc: 0.2469\n",
      "\n",
      "Epoch 176/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 488us/step - loss: 2.0891 - acc: 0.1798 - val_loss: 2.0927 - val_acc: 0.2469\n",
      "\n",
      "Epoch 177/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 502us/step - loss: 2.0883 - acc: 0.1798 - val_loss: 2.0918 - val_acc: 0.2469\n",
      "\n",
      "Epoch 178/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 567us/step - loss: 2.0874 - acc: 0.1798 - val_loss: 2.0908 - val_acc: 0.2469\n",
      "\n",
      "Epoch 179/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 571us/step - loss: 2.0865 - acc: 0.1798 - val_loss: 2.0898 - val_acc: 0.2469\n",
      "\n",
      "Epoch 180/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 485us/step - loss: 2.0856 - acc: 0.1781 - val_loss: 2.0889 - val_acc: 0.2469\n",
      "\n",
      "Epoch 181/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 542us/step - loss: 2.0847 - acc: 0.1798 - val_loss: 2.0880 - val_acc: 0.2469\n",
      "\n",
      "Epoch 182/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 543us/step - loss: 2.0838 - acc: 0.1781 - val_loss: 2.0872 - val_acc: 0.2407\n",
      "\n",
      "Epoch 183/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 590us/step - loss: 2.0830 - acc: 0.1815 - val_loss: 2.0861 - val_acc: 0.2407\n",
      "\n",
      "Epoch 184/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 580us/step - loss: 2.0821 - acc: 0.1832 - val_loss: 2.0852 - val_acc: 0.2407\n",
      "\n",
      "Epoch 185/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 537us/step - loss: 2.0811 - acc: 0.1849 - val_loss: 2.0843 - val_acc: 0.2407\n",
      "\n",
      "Epoch 186/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 490us/step - loss: 2.0802 - acc: 0.1849 - val_loss: 2.0833 - val_acc: 0.2407\n",
      "\n",
      "Epoch 187/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 507us/step - loss: 2.0793 - acc: 0.1849 - val_loss: 2.0824 - val_acc: 0.2469\n",
      "\n",
      "Epoch 188/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 601us/step - loss: 2.0784 - acc: 0.1849 - val_loss: 2.0814 - val_acc: 0.2469\n",
      "\n",
      "Epoch 189/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 514us/step - loss: 2.0774 - acc: 0.1832 - val_loss: 2.0804 - val_acc: 0.2407\n",
      "\n",
      "Epoch 190/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 513us/step - loss: 2.0765 - acc: 0.1815 - val_loss: 2.0793 - val_acc: 0.2407\n",
      "\n",
      "Epoch 191/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 576us/step - loss: 2.0755 - acc: 0.1798 - val_loss: 2.0783 - val_acc: 0.2407\n",
      "\n",
      "Epoch 192/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 492us/step - loss: 2.0746 - acc: 0.1815 - val_loss: 2.0772 - val_acc: 0.2407\n",
      "\n",
      "Epoch 193/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 509us/step - loss: 2.0736 - acc: 0.1798 - val_loss: 2.0762 - val_acc: 0.2346\n",
      "\n",
      "Epoch 194/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 570us/step - loss: 2.0725 - acc: 0.1815 - val_loss: 2.0752 - val_acc: 0.2346TA: 0s - loss: 2.0788 - acc: 0.1\n",
      "\n",
      "Epoch 195/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 535us/step - loss: 2.0715 - acc: 0.1815 - val_loss: 2.0742 - val_acc: 0.2346\n",
      "\n",
      "Epoch 196/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 686us/step - loss: 2.0705 - acc: 0.1798 - val_loss: 2.0732 - val_acc: 0.2407\n",
      "\n",
      "Epoch 197/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 506us/step - loss: 2.0695 - acc: 0.1798 - val_loss: 2.0723 - val_acc: 0.2346\n",
      "\n",
      "Epoch 198/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 533us/step - loss: 2.0685 - acc: 0.1815 - val_loss: 2.0714 - val_acc: 0.2346\n",
      "\n",
      "Epoch 199/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 501us/step - loss: 2.0675 - acc: 0.1815 - val_loss: 2.0703 - val_acc: 0.2346\n",
      "\n",
      "Epoch 200/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 566us/step - loss: 2.0665 - acc: 0.1815 - val_loss: 2.0693 - val_acc: 0.2407\n",
      "\n",
      "64/64 [==============================]64/64 [==============================] - 0s 411us/step\n",
      "\n",
      "Train on 583 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "583/583 [==============================]583/583 [==============================] - 3s 5ms/step - loss: 5.3624 - acc: 0.1132 - val_loss: 5.4034 - val_acc: 0.1049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 877us/step - loss: 5.2777 - acc: 0.1184 - val_loss: 5.3616 - val_acc: 0.1049TA: 0s - loss: 5.2109 - acc: 0.119\n",
      "\n",
      "Epoch 3/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 5.1945 - acc: 0.1184 - val_loss: 5.3224 - val_acc: 0.1111\n",
      "\n",
      "Epoch 4/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 983us/step - loss: 5.1156 - acc: 0.1235 - val_loss: 5.2844 - val_acc: 0.1111\n",
      "\n",
      "Epoch 5/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 882us/step - loss: 5.0387 - acc: 0.1252 - val_loss: 5.2474 - val_acc: 0.1111\n",
      "\n",
      "Epoch 6/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 917us/step - loss: 4.9613 - acc: 0.1269 - val_loss: 5.2128 - val_acc: 0.1111: 0s - loss: 4.9258 - acc: 0.\n",
      "\n",
      "Epoch 7/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 4.8875 - acc: 0.1269 - val_loss: 5.1778 - val_acc: 0.1111\n",
      "\n",
      "Epoch 8/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 4.8160 - acc: 0.1321 - val_loss: 5.1442 - val_acc: 0.1049\n",
      "\n",
      "Epoch 9/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 901us/step - loss: 4.7464 - acc: 0.1304 - val_loss: 5.1124 - val_acc: 0.1111\n",
      "\n",
      "Epoch 10/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 4.6805 - acc: 0.1338 - val_loss: 5.0825 - val_acc: 0.1173\n",
      "\n",
      "Epoch 11/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 891us/step - loss: 4.6169 - acc: 0.1355 - val_loss: 5.0518 - val_acc: 0.1173\n",
      "\n",
      "Epoch 12/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 972us/step - loss: 4.5531 - acc: 0.1389 - val_loss: 5.0219 - val_acc: 0.1173\n",
      "\n",
      "Epoch 13/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 959us/step - loss: 4.4924 - acc: 0.1475 - val_loss: 4.9941 - val_acc: 0.1173\n",
      "\n",
      "Epoch 14/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 915us/step - loss: 4.4325 - acc: 0.1492 - val_loss: 4.9660 - val_acc: 0.1173\n",
      "\n",
      "Epoch 15/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 906us/step - loss: 4.3736 - acc: 0.1527 - val_loss: 4.9389 - val_acc: 0.1235\n",
      "\n",
      "Epoch 16/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 977us/step - loss: 4.3163 - acc: 0.1595 - val_loss: 4.9148 - val_acc: 0.1235\n",
      "\n",
      "Epoch 17/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 804us/step - loss: 4.2614 - acc: 0.1647 - val_loss: 4.8920 - val_acc: 0.1235\n",
      "\n",
      "Epoch 18/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 935us/step - loss: 4.2089 - acc: 0.1647 - val_loss: 4.8684 - val_acc: 0.1235TA: 0s - loss: 4.1615 - acc: 0.195 - ETA: 0s - loss: 4.0622 - acc: 0.1\n",
      "\n",
      "Epoch 19/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 974us/step - loss: 4.1568 - acc: 0.1715 - val_loss: 4.8468 - val_acc: 0.1296\n",
      "\n",
      "Epoch 20/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 837us/step - loss: 4.1063 - acc: 0.1732 - val_loss: 4.8229 - val_acc: 0.1296\n",
      "\n",
      "Epoch 21/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 938us/step - loss: 4.0552 - acc: 0.1767 - val_loss: 4.8019 - val_acc: 0.1358\n",
      "\n",
      "Epoch 22/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 4.0063 - acc: 0.1767 - val_loss: 4.7817 - val_acc: 0.1420\n",
      "\n",
      "Epoch 23/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 817us/step - loss: 3.9577 - acc: 0.1852 - val_loss: 4.7605 - val_acc: 0.1420\n",
      "\n",
      "Epoch 24/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 973us/step - loss: 3.9109 - acc: 0.1921 - val_loss: 4.7414 - val_acc: 0.1481TA: 0s - loss: 3.8780 - acc: 0.19\n",
      "\n",
      "Epoch 25/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 847us/step - loss: 3.8646 - acc: 0.1955 - val_loss: 4.7220 - val_acc: 0.1420TA: 0s - loss: 3.9623 - acc: 0.1\n",
      "\n",
      "Epoch 26/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 895us/step - loss: 3.8206 - acc: 0.2041 - val_loss: 4.7027 - val_acc: 0.1420\n",
      "\n",
      "Epoch 27/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 827us/step - loss: 3.7764 - acc: 0.2058 - val_loss: 4.6834 - val_acc: 0.1420\n",
      "\n",
      "Epoch 28/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 3.7332 - acc: 0.2093 - val_loss: 4.6655 - val_acc: 0.1420\n",
      "\n",
      "Epoch 29/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 833us/step - loss: 3.6912 - acc: 0.2110 - val_loss: 4.6469 - val_acc: 0.1420\n",
      "\n",
      "Epoch 30/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 908us/step - loss: 3.6503 - acc: 0.2161 - val_loss: 4.6290 - val_acc: 0.1420\n",
      "\n",
      "Epoch 31/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 861us/step - loss: 3.6105 - acc: 0.2196 - val_loss: 4.6119 - val_acc: 0.1420\n",
      "\n",
      "Epoch 32/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 869us/step - loss: 3.5712 - acc: 0.2264 - val_loss: 4.5947 - val_acc: 0.1420\n",
      "\n",
      "Epoch 33/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 803us/step - loss: 3.5327 - acc: 0.2316 - val_loss: 4.5780 - val_acc: 0.1420\n",
      "\n",
      "Epoch 34/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 837us/step - loss: 3.4951 - acc: 0.2316 - val_loss: 4.5615 - val_acc: 0.1420\n",
      "\n",
      "Epoch 35/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 805us/step - loss: 3.4583 - acc: 0.2350 - val_loss: 4.5455 - val_acc: 0.1481\n",
      "\n",
      "Epoch 36/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 819us/step - loss: 3.4218 - acc: 0.2401 - val_loss: 4.5305 - val_acc: 0.1481TA: 0s - loss: 3.4456 - acc: 0.23\n",
      "\n",
      "Epoch 37/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 836us/step - loss: 3.3866 - acc: 0.2453 - val_loss: 4.5154 - val_acc: 0.1481\n",
      "\n",
      "Epoch 38/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 833us/step - loss: 3.3521 - acc: 0.2470 - val_loss: 4.5002 - val_acc: 0.1420\n",
      "\n",
      "Epoch 39/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 889us/step - loss: 3.3180 - acc: 0.2470 - val_loss: 4.4855 - val_acc: 0.1420TA: 0s - loss: 3.3061 - acc: 0.248\n",
      "\n",
      "Epoch 40/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 915us/step - loss: 3.2842 - acc: 0.2539 - val_loss: 4.4719 - val_acc: 0.1420\n",
      "\n",
      "Epoch 41/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 884us/step - loss: 3.2522 - acc: 0.2590 - val_loss: 4.4588 - val_acc: 0.1420\n",
      "\n",
      "Epoch 42/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 896us/step - loss: 3.2203 - acc: 0.2607 - val_loss: 4.4457 - val_acc: 0.1420\n",
      "\n",
      "Epoch 43/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 822us/step - loss: 3.1888 - acc: 0.2642 - val_loss: 4.4331 - val_acc: 0.1481TA: 0s - loss: 3.1838 - acc: 0.2\n",
      "\n",
      "Epoch 44/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 968us/step - loss: 3.1584 - acc: 0.2676 - val_loss: 4.4204 - val_acc: 0.1481\n",
      "\n",
      "Epoch 45/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 796us/step - loss: 3.1292 - acc: 0.2727 - val_loss: 4.4086 - val_acc: 0.1481\n",
      "\n",
      "Epoch 46/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 908us/step - loss: 3.0994 - acc: 0.2727 - val_loss: 4.3956 - val_acc: 0.1481\n",
      "\n",
      "Epoch 47/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 893us/step - loss: 3.0697 - acc: 0.2779 - val_loss: 4.3837 - val_acc: 0.1481\n",
      "\n",
      "Epoch 48/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 997us/step - loss: 3.0407 - acc: 0.2796 - val_loss: 4.3710 - val_acc: 0.1543\n",
      "\n",
      "Epoch 49/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 3.0122 - acc: 0.2864 - val_loss: 4.3597 - val_acc: 0.1605\n",
      "\n",
      "Epoch 50/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 862us/step - loss: 2.9841 - acc: 0.2916 - val_loss: 4.3488 - val_acc: 0.1543\n",
      "\n",
      "Epoch 51/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 942us/step - loss: 2.9563 - acc: 0.2950 - val_loss: 4.3375 - val_acc: 0.1543TA: 0s - loss: 3.0631 - acc: \n",
      "\n",
      "Epoch 52/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 898us/step - loss: 2.9291 - acc: 0.3002 - val_loss: 4.3266 - val_acc: 0.1543\n",
      "\n",
      "Epoch 53/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 2.9029 - acc: 0.3036 - val_loss: 4.3163 - val_acc: 0.1605\n",
      "\n",
      "Epoch 54/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 961us/step - loss: 2.8769 - acc: 0.3053 - val_loss: 4.3060 - val_acc: 0.1667\n",
      "\n",
      "Epoch 55/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 905us/step - loss: 2.8515 - acc: 0.3139 - val_loss: 4.2955 - val_acc: 0.1667\n",
      "\n",
      "Epoch 56/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 2.8256 - acc: 0.3173 - val_loss: 4.2858 - val_acc: 0.1667\n",
      "\n",
      "Epoch 57/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 898us/step - loss: 2.8007 - acc: 0.3225 - val_loss: 4.2754 - val_acc: 0.1667\n",
      "\n",
      "Epoch 58/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 2.7761 - acc: 0.3242 - val_loss: 4.2651 - val_acc: 0.1667\n",
      "\n",
      "Epoch 59/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 884us/step - loss: 2.7515 - acc: 0.3259 - val_loss: 4.2558 - val_acc: 0.1667\n",
      "\n",
      "Epoch 60/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 915us/step - loss: 2.7272 - acc: 0.3276 - val_loss: 4.2463 - val_acc: 0.1667\n",
      "\n",
      "Epoch 61/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 2.7035 - acc: 0.3328 - val_loss: 4.2373 - val_acc: 0.1667\n",
      "\n",
      "Epoch 62/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 2.6801 - acc: 0.3362 - val_loss: 4.2287 - val_acc: 0.1605\n",
      "\n",
      "Epoch 63/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 976us/step - loss: 2.6575 - acc: 0.3413 - val_loss: 4.2197 - val_acc: 0.1605\n",
      "\n",
      "Epoch 64/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 880us/step - loss: 2.6352 - acc: 0.3431 - val_loss: 4.2111 - val_acc: 0.1605\n",
      "\n",
      "Epoch 65/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 943us/step - loss: 2.6125 - acc: 0.3413 - val_loss: 4.2028 - val_acc: 0.1605\n",
      "\n",
      "Epoch 66/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 826us/step - loss: 2.5907 - acc: 0.3448 - val_loss: 4.1941 - val_acc: 0.1605\n",
      "\n",
      "Epoch 67/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 803us/step - loss: 2.5688 - acc: 0.3482 - val_loss: 4.1855 - val_acc: 0.1605\n",
      "\n",
      "Epoch 68/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 849us/step - loss: 2.5475 - acc: 0.3533 - val_loss: 4.1770 - val_acc: 0.1605\n",
      "\n",
      "Epoch 69/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 949us/step - loss: 2.5263 - acc: 0.3551 - val_loss: 4.1684 - val_acc: 0.1605\n",
      "\n",
      "Epoch 70/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 2.5052 - acc: 0.3568 - val_loss: 4.1597 - val_acc: 0.1605\n",
      "\n",
      "Epoch 71/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 911us/step - loss: 2.4854 - acc: 0.3585 - val_loss: 4.1513 - val_acc: 0.1605\n",
      "\n",
      "Epoch 72/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 828us/step - loss: 2.4655 - acc: 0.3619 - val_loss: 4.1431 - val_acc: 0.1605\n",
      "\n",
      "Epoch 73/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 2.4453 - acc: 0.3619 - val_loss: 4.1349 - val_acc: 0.1543TA: 0s - loss: 2.4082 - acc: 0.\n",
      "\n",
      "Epoch 74/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 2.4255 - acc: 0.3774 - val_loss: 4.1269 - val_acc: 0.1543\n",
      "\n",
      "Epoch 75/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 945us/step - loss: 2.4061 - acc: 0.3859 - val_loss: 4.1193 - val_acc: 0.1543\n",
      "\n",
      "Epoch 76/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 914us/step - loss: 2.3872 - acc: 0.3859 - val_loss: 4.1116 - val_acc: 0.1543\n",
      "\n",
      "Epoch 77/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 829us/step - loss: 2.3688 - acc: 0.3928 - val_loss: 4.1050 - val_acc: 0.1543\n",
      "\n",
      "Epoch 78/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.3504 - acc: 0.3962 - val_loss: 4.0973 - val_acc: 0.1543\n",
      "\n",
      "Epoch 79/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.3325 - acc: 0.3979 - val_loss: 4.0893 - val_acc: 0.1543\n",
      "\n",
      "Epoch 80/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.3149 - acc: 0.4014 - val_loss: 4.0821 - val_acc: 0.1543\n",
      "\n",
      "Epoch 81/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.2972 - acc: 0.4048 - val_loss: 4.0752 - val_acc: 0.1543\n",
      "\n",
      "Epoch 82/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 969us/step - loss: 2.2796 - acc: 0.4099 - val_loss: 4.0686 - val_acc: 0.1543\n",
      "\n",
      "Epoch 83/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.2627 - acc: 0.4099 - val_loss: 4.0613 - val_acc: 0.1543\n",
      "\n",
      "Epoch 84/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 947us/step - loss: 2.2453 - acc: 0.4134 - val_loss: 4.0554 - val_acc: 0.1543\n",
      "\n",
      "Epoch 85/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 964us/step - loss: 2.2288 - acc: 0.4168 - val_loss: 4.0487 - val_acc: 0.1605\n",
      "\n",
      "Epoch 86/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 977us/step - loss: 2.2120 - acc: 0.4185 - val_loss: 4.0411 - val_acc: 0.1605\n",
      "\n",
      "Epoch 87/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.1955 - acc: 0.4220 - val_loss: 4.0341 - val_acc: 0.1605\n",
      "\n",
      "Epoch 88/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.1794 - acc: 0.4237 - val_loss: 4.0276 - val_acc: 0.1605\n",
      "\n",
      "Epoch 89/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 928us/step - loss: 2.1636 - acc: 0.4288 - val_loss: 4.0220 - val_acc: 0.1605\n",
      "\n",
      "Epoch 90/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.1481 - acc: 0.4288 - val_loss: 4.0155 - val_acc: 0.1667\n",
      "\n",
      "Epoch 91/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 802us/step - loss: 2.1322 - acc: 0.4288 - val_loss: 4.0094 - val_acc: 0.1667\n",
      "\n",
      "Epoch 92/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================]583/583 [==============================] - 1s 963us/step - loss: 2.1169 - acc: 0.4322 - val_loss: 4.0033 - val_acc: 0.1667\n",
      "\n",
      "Epoch 93/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 950us/step - loss: 2.1019 - acc: 0.4374 - val_loss: 3.9967 - val_acc: 0.1667\n",
      "\n",
      "Epoch 94/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 884us/step - loss: 2.0869 - acc: 0.4374 - val_loss: 3.9909 - val_acc: 0.1728\n",
      "\n",
      "Epoch 95/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 830us/step - loss: 2.0721 - acc: 0.4391 - val_loss: 3.9852 - val_acc: 0.1728TA: 0s - loss: 2.0686 - acc: 0.441\n",
      "\n",
      "Epoch 96/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 854us/step - loss: 2.0576 - acc: 0.4425 - val_loss: 3.9791 - val_acc: 0.1728\n",
      "\n",
      "Epoch 97/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 861us/step - loss: 2.0432 - acc: 0.4460 - val_loss: 3.9724 - val_acc: 0.1728\n",
      "\n",
      "Epoch 98/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 928us/step - loss: 2.0287 - acc: 0.4494 - val_loss: 3.9663 - val_acc: 0.1728TA: 0s - loss: 2.0254 - acc: 0.45\n",
      "\n",
      "Epoch 99/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 984us/step - loss: 2.0145 - acc: 0.4528 - val_loss: 3.9598 - val_acc: 0.1728\n",
      "\n",
      "Epoch 100/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 932us/step - loss: 2.0000 - acc: 0.4528 - val_loss: 3.9541 - val_acc: 0.1790\n",
      "\n",
      "Epoch 101/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 958us/step - loss: 1.9861 - acc: 0.4597 - val_loss: 3.9479 - val_acc: 0.1790\n",
      "\n",
      "Epoch 102/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.9721 - acc: 0.4683 - val_loss: 3.9421 - val_acc: 0.1790\n",
      "\n",
      "Epoch 103/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.9585 - acc: 0.4700 - val_loss: 3.9366 - val_acc: 0.1852\n",
      "\n",
      "Epoch 104/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 977us/step - loss: 1.9447 - acc: 0.4700 - val_loss: 3.9308 - val_acc: 0.1852\n",
      "\n",
      "Epoch 105/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 912us/step - loss: 1.9316 - acc: 0.4700 - val_loss: 3.9247 - val_acc: 0.1790\n",
      "\n",
      "Epoch 106/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.9184 - acc: 0.4734 - val_loss: 3.9193 - val_acc: 0.1852\n",
      "\n",
      "Epoch 107/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.9056 - acc: 0.4820 - val_loss: 3.9135 - val_acc: 0.1914\n",
      "\n",
      "Epoch 108/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.8927 - acc: 0.4837 - val_loss: 3.9083 - val_acc: 0.1914\n",
      "\n",
      "Epoch 109/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 903us/step - loss: 1.8798 - acc: 0.4871 - val_loss: 3.9026 - val_acc: 0.1914\n",
      "\n",
      "Epoch 110/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 906us/step - loss: 1.8673 - acc: 0.4889 - val_loss: 3.8970 - val_acc: 0.1914\n",
      "\n",
      "Epoch 111/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 865us/step - loss: 1.8548 - acc: 0.4923 - val_loss: 3.8922 - val_acc: 0.1914TA: 0s - loss: 1.8109 - acc: 0.\n",
      "\n",
      "Epoch 112/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 802us/step - loss: 1.8427 - acc: 0.4957 - val_loss: 3.8868 - val_acc: 0.1914\n",
      "\n",
      "Epoch 113/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 854us/step - loss: 1.8305 - acc: 0.4957 - val_loss: 3.8818 - val_acc: 0.1914\n",
      "\n",
      "Epoch 114/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 829us/step - loss: 1.8186 - acc: 0.5043 - val_loss: 3.8765 - val_acc: 0.1975\n",
      "\n",
      "Epoch 115/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 862us/step - loss: 1.8068 - acc: 0.5077 - val_loss: 3.8714 - val_acc: 0.1975\n",
      "\n",
      "Epoch 116/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 973us/step - loss: 1.7948 - acc: 0.5111 - val_loss: 3.8661 - val_acc: 0.1975\n",
      "\n",
      "Epoch 117/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 1.7831 - acc: 0.5197 - val_loss: 3.8613 - val_acc: 0.1975\n",
      "\n",
      "Epoch 118/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 889us/step - loss: 1.7718 - acc: 0.5197 - val_loss: 3.8566 - val_acc: 0.1975TA: 0s - loss: 1.8427 - acc: 0\n",
      "\n",
      "Epoch 119/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 812us/step - loss: 1.7604 - acc: 0.5266 - val_loss: 3.8515 - val_acc: 0.1914TA: 0s - loss: 1.8407 - acc: 0.\n",
      "\n",
      "Epoch 120/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 880us/step - loss: 1.7492 - acc: 0.5317 - val_loss: 3.8470 - val_acc: 0.1914\n",
      "\n",
      "Epoch 121/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 843us/step - loss: 1.7380 - acc: 0.5352 - val_loss: 3.8423 - val_acc: 0.1852\n",
      "\n",
      "Epoch 122/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 901us/step - loss: 1.7270 - acc: 0.5352 - val_loss: 3.8385 - val_acc: 0.1852\n",
      "\n",
      "Epoch 123/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 833us/step - loss: 1.7165 - acc: 0.5352 - val_loss: 3.8335 - val_acc: 0.1852TA: 0s - loss: 1.8243 - acc: \n",
      "\n",
      "Epoch 124/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 1.7057 - acc: 0.5369 - val_loss: 3.8295 - val_acc: 0.1852\n",
      "\n",
      "Epoch 125/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 1.6953 - acc: 0.5386 - val_loss: 3.8253 - val_acc: 0.1852TA: 0s - loss: 1.5437 - acc: 0.\n",
      "\n",
      "Epoch 126/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 808us/step - loss: 1.6849 - acc: 0.5437 - val_loss: 3.8210 - val_acc: 0.1852\n",
      "\n",
      "Epoch 127/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 941us/step - loss: 1.6746 - acc: 0.5420 - val_loss: 3.8167 - val_acc: 0.1852\n",
      "\n",
      "Epoch 128/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 833us/step - loss: 1.6647 - acc: 0.5420 - val_loss: 3.8124 - val_acc: 0.1852\n",
      "\n",
      "Epoch 129/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 1.6546 - acc: 0.5455 - val_loss: 3.8079 - val_acc: 0.1852TA: 0s - loss: 1.6355 - acc: 0.5\n",
      "\n",
      "Epoch 130/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 1.6444 - acc: 0.5455 - val_loss: 3.8037 - val_acc: 0.1852\n",
      "\n",
      "Epoch 131/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 913us/step - loss: 1.6346 - acc: 0.5472 - val_loss: 3.7994 - val_acc: 0.1914\n",
      "\n",
      "Epoch 132/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 877us/step - loss: 1.6248 - acc: 0.5489 - val_loss: 3.7952 - val_acc: 0.1914TA: 0s - loss: 1.7007 - acc: \n",
      "\n",
      "Epoch 133/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 890us/step - loss: 1.6150 - acc: 0.5523 - val_loss: 3.7913 - val_acc: 0.1852\n",
      "\n",
      "Epoch 134/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 828us/step - loss: 1.6053 - acc: 0.5575 - val_loss: 3.7871 - val_acc: 0.1852\n",
      "\n",
      "Epoch 135/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 915us/step - loss: 1.5957 - acc: 0.5592 - val_loss: 3.7828 - val_acc: 0.1914\n",
      "\n",
      "Epoch 136/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 909us/step - loss: 1.5863 - acc: 0.5626 - val_loss: 3.7788 - val_acc: 0.1914TA: 0s - loss: 1.5628 - acc: 0.56\n",
      "\n",
      "Epoch 137/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 833us/step - loss: 1.5768 - acc: 0.5626 - val_loss: 3.7746 - val_acc: 0.1852\n",
      "\n",
      "Epoch 138/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 1.5672 - acc: 0.5626 - val_loss: 3.7714 - val_acc: 0.1852\n",
      "\n",
      "Epoch 139/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 891us/step - loss: 1.5581 - acc: 0.5643 - val_loss: 3.7676 - val_acc: 0.1852\n",
      "\n",
      "Epoch 140/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 960us/step - loss: 1.5489 - acc: 0.5678 - val_loss: 3.7640 - val_acc: 0.1852TA: 0s - loss: 1.5081 - acc: \n",
      "\n",
      "Epoch 141/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 856us/step - loss: 1.5395 - acc: 0.5695 - val_loss: 3.7606 - val_acc: 0.1852\n",
      "\n",
      "Epoch 142/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 861us/step - loss: 1.5307 - acc: 0.5746 - val_loss: 3.7570 - val_acc: 0.1852\n",
      "\n",
      "Epoch 143/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 833us/step - loss: 1.5218 - acc: 0.5798 - val_loss: 3.7535 - val_acc: 0.1852\n",
      "\n",
      "Epoch 144/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 843us/step - loss: 1.5131 - acc: 0.5849 - val_loss: 3.7500 - val_acc: 0.1852TA: 0s - loss: 1.6585 - acc: \n",
      "\n",
      "Epoch 145/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 897us/step - loss: 1.5045 - acc: 0.5866 - val_loss: 3.7463 - val_acc: 0.1852TA: 0s - loss: 1.4786 - acc: 0\n",
      "\n",
      "Epoch 146/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 942us/step - loss: 1.4960 - acc: 0.5866 - val_loss: 3.7430 - val_acc: 0.1852\n",
      "\n",
      "Epoch 147/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 1.4873 - acc: 0.5866 - val_loss: 3.7400 - val_acc: 0.1852\n",
      "\n",
      "Epoch 148/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 830us/step - loss: 1.4788 - acc: 0.5883 - val_loss: 3.7363 - val_acc: 0.1852\n",
      "\n",
      "Epoch 149/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 913us/step - loss: 1.4704 - acc: 0.5883 - val_loss: 3.7325 - val_acc: 0.1852TA: 0s - loss: 1.2654 - acc:\n",
      "\n",
      "Epoch 150/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 941us/step - loss: 1.4623 - acc: 0.5918 - val_loss: 3.7292 - val_acc: 0.1852\n",
      "\n",
      "Epoch 151/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 1.4540 - acc: 0.5952 - val_loss: 3.7255 - val_acc: 0.1852\n",
      "\n",
      "Epoch 152/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 925us/step - loss: 1.4460 - acc: 0.5986 - val_loss: 3.7223 - val_acc: 0.1852\n",
      "\n",
      "Epoch 153/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 833us/step - loss: 1.4376 - acc: 0.6038 - val_loss: 3.7188 - val_acc: 0.1852\n",
      "\n",
      "Epoch 154/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 815us/step - loss: 1.4297 - acc: 0.6055 - val_loss: 3.7154 - val_acc: 0.1852\n",
      "\n",
      "Epoch 155/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 901us/step - loss: 1.4216 - acc: 0.6072 - val_loss: 3.7120 - val_acc: 0.1852\n",
      "\n",
      "Epoch 156/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 875us/step - loss: 1.4137 - acc: 0.6072 - val_loss: 3.7088 - val_acc: 0.1852\n",
      "\n",
      "Epoch 157/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 827us/step - loss: 1.4061 - acc: 0.6072 - val_loss: 3.7053 - val_acc: 0.1852TA: 0s - loss: 1.4044 - acc: 0.602\n",
      "\n",
      "Epoch 158/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.3984 - acc: 0.6072 - val_loss: 3.7021 - val_acc: 0.1852\n",
      "\n",
      "Epoch 159/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 946us/step - loss: 1.3908 - acc: 0.6089 - val_loss: 3.6987 - val_acc: 0.1852TA: 0s - loss: 1.3215 - acc: 0.576/583 [============================>.] - ETA: 0s - loss: 1.3805 - acc: 0.611\n",
      "\n",
      "Epoch 160/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 1.3829 - acc: 0.6089 - val_loss: 3.6956 - val_acc: 0.1852\n",
      "\n",
      "Epoch 161/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 894us/step - loss: 1.3754 - acc: 0.6141 - val_loss: 3.6921 - val_acc: 0.1852\n",
      "\n",
      "Epoch 162/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 971us/step - loss: 1.3678 - acc: 0.6175 - val_loss: 3.6894 - val_acc: 0.1852\n",
      "\n",
      "Epoch 163/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 948us/step - loss: 1.3603 - acc: 0.6226 - val_loss: 3.6865 - val_acc: 0.1852\n",
      "\n",
      "Epoch 164/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 934us/step - loss: 1.3530 - acc: 0.6278 - val_loss: 3.6833 - val_acc: 0.1852\n",
      "\n",
      "Epoch 165/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 828us/step - loss: 1.3455 - acc: 0.6295 - val_loss: 3.6799 - val_acc: 0.1852\n",
      "\n",
      "Epoch 166/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 830us/step - loss: 1.3382 - acc: 0.6312 - val_loss: 3.6763 - val_acc: 0.1852TA: 0s - loss: 1.4706 - acc: \n",
      "\n",
      "Epoch 167/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 885us/step - loss: 1.3309 - acc: 0.6312 - val_loss: 3.6730 - val_acc: 0.1852\n",
      "\n",
      "Epoch 168/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 916us/step - loss: 1.3238 - acc: 0.6312 - val_loss: 3.6707 - val_acc: 0.1852TA: 0s - loss: 1.3556 - acc: 0.625\n",
      "\n",
      "Epoch 169/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 856us/step - loss: 1.3168 - acc: 0.6329 - val_loss: 3.6681 - val_acc: 0.1852TA: 0s - loss: 1.1829 - acc: 0.7 - ETA: 0s - loss: 1.3244 - acc: 0.6\n",
      "\n",
      "Epoch 170/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 1.3097 - acc: 0.6346 - val_loss: 3.6650 - val_acc: 0.1852\n",
      "\n",
      "Epoch 171/200\n",
      "583/583 [==============================]512/583 [=========================>....] - ETA: 0s - loss: 1.2421 - acc: 0.644548/583 [======================>.......] - ETA: 0s - loss: 1.2663 - acc: 0.63583/583 [==============================] - 0s 801us/step - loss: 1.3029 - acc: 0.6346 - val_loss: 3.6623 - val_acc: 0.1852\n",
      "\n",
      "Epoch 172/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 803us/step - loss: 1.2958 - acc: 0.6346 - val_loss: 3.6595 - val_acc: 0.1852\n",
      "\n",
      "Epoch 173/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 796us/step - loss: 1.2888 - acc: 0.6346 - val_loss: 3.6571 - val_acc: 0.1852\n",
      "\n",
      "Epoch 174/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 803us/step - loss: 1.2821 - acc: 0.6364 - val_loss: 3.6545 - val_acc: 0.1852\n",
      "\n",
      "Epoch 175/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 939us/step - loss: 1.2753 - acc: 0.6381 - val_loss: 3.6518 - val_acc: 0.1852\n",
      "\n",
      "Epoch 176/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 804us/step - loss: 1.2686 - acc: 0.6432 - val_loss: 3.6488 - val_acc: 0.1852TA: 0s - loss: 1.2588 - acc: 0.6\n",
      "\n",
      "Epoch 177/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 909us/step - loss: 1.2619 - acc: 0.6449 - val_loss: 3.6461 - val_acc: 0.1852TA: 0s - loss: 1.2674 - acc: 0.64\n",
      "\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================]583/583 [==============================] - 0s 778us/step - loss: 1.2554 - acc: 0.6501 - val_loss: 3.6436 - val_acc: 0.1852TA: 0s - loss: 1.1866 - acc: 0.\n",
      "\n",
      "Epoch 179/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 819us/step - loss: 1.2487 - acc: 0.6501 - val_loss: 3.6410 - val_acc: 0.1852\n",
      "\n",
      "Epoch 180/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 806us/step - loss: 1.2422 - acc: 0.6518 - val_loss: 3.6383 - val_acc: 0.1852\n",
      "\n",
      "Epoch 181/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 834us/step - loss: 1.2357 - acc: 0.6518 - val_loss: 3.6354 - val_acc: 0.1852\n",
      "\n",
      "Epoch 182/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 1.2294 - acc: 0.6535 - val_loss: 3.6333 - val_acc: 0.1852\n",
      "\n",
      "Epoch 183/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 916us/step - loss: 1.2228 - acc: 0.6552 - val_loss: 3.6302 - val_acc: 0.1852TA: 0s - loss: 1.3958 - acc:\n",
      "\n",
      "Epoch 184/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 1.2165 - acc: 0.6552 - val_loss: 3.6278 - val_acc: 0.1852\n",
      "\n",
      "Epoch 185/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 978us/step - loss: 1.2102 - acc: 0.6587 - val_loss: 3.6250 - val_acc: 0.1852\n",
      "\n",
      "Epoch 186/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 1.2039 - acc: 0.6604 - val_loss: 3.6222 - val_acc: 0.1852\n",
      "\n",
      "Epoch 187/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 995us/step - loss: 1.1976 - acc: 0.6638 - val_loss: 3.6194 - val_acc: 0.1790\n",
      "\n",
      "Epoch 188/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 825us/step - loss: 1.1915 - acc: 0.6638 - val_loss: 3.6166 - val_acc: 0.1790\n",
      "\n",
      "Epoch 189/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 958us/step - loss: 1.1854 - acc: 0.6655 - val_loss: 3.6136 - val_acc: 0.1790\n",
      "\n",
      "Epoch 190/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.1792 - acc: 0.6672 - val_loss: 3.6113 - val_acc: 0.1790\n",
      "\n",
      "Epoch 191/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 1.1732 - acc: 0.6672 - val_loss: 3.6088 - val_acc: 0.1790\n",
      "\n",
      "Epoch 192/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 834us/step - loss: 1.1672 - acc: 0.6690 - val_loss: 3.6066 - val_acc: 0.1790TA: 0s - loss: 1.2028 - acc: 0.6\n",
      "\n",
      "Epoch 193/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 829us/step - loss: 1.1613 - acc: 0.6724 - val_loss: 3.6043 - val_acc: 0.1790\n",
      "\n",
      "Epoch 194/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 949us/step - loss: 1.1555 - acc: 0.6724 - val_loss: 3.6017 - val_acc: 0.1790\n",
      "\n",
      "Epoch 195/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 911us/step - loss: 1.1498 - acc: 0.6741 - val_loss: 3.5993 - val_acc: 0.1790\n",
      "\n",
      "Epoch 196/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 1.1440 - acc: 0.6741 - val_loss: 3.5970 - val_acc: 0.1790\n",
      "\n",
      "Epoch 197/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 862us/step - loss: 1.1381 - acc: 0.6758 - val_loss: 3.5946 - val_acc: 0.1790TA: 0s - loss: 1.2245 - acc: \n",
      "\n",
      "Epoch 198/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 827us/step - loss: 1.1320 - acc: 0.6792 - val_loss: 3.5922 - val_acc: 0.17903 [======================>.......] - ETA: 0s - loss: 1.1179 - acc: 0.68\n",
      "\n",
      "Epoch 199/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 854us/step - loss: 1.1261 - acc: 0.6792 - val_loss: 3.5896 - val_acc: 0.1790\n",
      "\n",
      "Epoch 200/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 932us/step - loss: 1.1204 - acc: 0.6827 - val_loss: 3.5870 - val_acc: 0.1790TA: 0s - loss: 1.1384 - acc: 0.676\n",
      "\n",
      "65/65 [==============================]65/65 [==============================] - 0s 275us/step\n",
      "\n",
      "Train on 583 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "583/583 [==============================]583/583 [==============================] - 3s 5ms/step - loss: 5.8395 - acc: 0.1458 - val_loss: 5.8467 - val_acc: 0.1049\n",
      "\n",
      "Epoch 2/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 973us/step - loss: 5.7565 - acc: 0.1458 - val_loss: 5.7912 - val_acc: 0.1049\n",
      "\n",
      "Epoch 3/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 942us/step - loss: 5.6747 - acc: 0.1492 - val_loss: 5.7392 - val_acc: 0.1173\n",
      "\n",
      "Epoch 4/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 861us/step - loss: 5.5970 - acc: 0.1527 - val_loss: 5.6902 - val_acc: 0.1235\n",
      "\n",
      "Epoch 5/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 857us/step - loss: 5.5212 - acc: 0.1527 - val_loss: 5.6416 - val_acc: 0.1235\n",
      "\n",
      "Epoch 6/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 943us/step - loss: 5.4485 - acc: 0.1544 - val_loss: 5.5945 - val_acc: 0.1296\n",
      "\n",
      "Epoch 7/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 895us/step - loss: 5.3772 - acc: 0.1509 - val_loss: 5.5496 - val_acc: 0.1420\n",
      "\n",
      "Epoch 8/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 988us/step - loss: 5.3068 - acc: 0.1544 - val_loss: 5.5069 - val_acc: 0.1420\n",
      "\n",
      "Epoch 9/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 929us/step - loss: 5.2390 - acc: 0.1527 - val_loss: 5.4619 - val_acc: 0.1420TA: 0s - loss: 5.2911 - acc: 0.1 - ETA: 0s - loss: 5.2181 - acc: 0.15\n",
      "\n",
      "Epoch 10/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 861us/step - loss: 5.1692 - acc: 0.1561 - val_loss: 5.4187 - val_acc: 0.1420\n",
      "\n",
      "Epoch 11/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 833us/step - loss: 5.1031 - acc: 0.1612 - val_loss: 5.3787 - val_acc: 0.1420TA: 0s - loss: 5.2290 - acc: 0.16 - ETA: 0s - loss: 5.2120 - acc: 0.\n",
      "\n",
      "Epoch 12/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 835us/step - loss: 5.0400 - acc: 0.1630 - val_loss: 5.3399 - val_acc: 0.1481\n",
      "\n",
      "Epoch 13/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 4.9794 - acc: 0.1664 - val_loss: 5.2994 - val_acc: 0.1481\n",
      "\n",
      "Epoch 14/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 4.9173 - acc: 0.1681 - val_loss: 5.2613 - val_acc: 0.1481 ETA: 0s - loss: 5.0647 - acc: 0.16\n",
      "\n",
      "Epoch 15/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 965us/step - loss: 4.8579 - acc: 0.1715 - val_loss: 5.2248 - val_acc: 0.1481\n",
      "\n",
      "Epoch 16/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 892us/step - loss: 4.8000 - acc: 0.1715 - val_loss: 5.1892 - val_acc: 0.1481 [============>.................] - ETA: 0s - loss: 4.7796 - acc: 0\n",
      "\n",
      "Epoch 17/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 773us/step - loss: 4.7441 - acc: 0.1750 - val_loss: 5.1553 - val_acc: 0.1481\n",
      "\n",
      "Epoch 18/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 914us/step - loss: 4.6893 - acc: 0.1767 - val_loss: 5.1220 - val_acc: 0.1481\n",
      "\n",
      "Epoch 19/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 885us/step - loss: 4.6362 - acc: 0.1784 - val_loss: 5.0874 - val_acc: 0.1481\n",
      "\n",
      "Epoch 20/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 4.5831 - acc: 0.1801 - val_loss: 5.0547 - val_acc: 0.1543TA: 0s - loss: 4.2757 - acc: 0.\n",
      "\n",
      "Epoch 21/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 897us/step - loss: 4.5322 - acc: 0.1818 - val_loss: 5.0217 - val_acc: 0.1543\n",
      "\n",
      "Epoch 22/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 960us/step - loss: 4.4812 - acc: 0.1818 - val_loss: 4.9914 - val_acc: 0.1605\n",
      "\n",
      "Epoch 23/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 856us/step - loss: 4.4320 - acc: 0.1870 - val_loss: 4.9639 - val_acc: 0.1605\n",
      "\n",
      "Epoch 24/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 914us/step - loss: 4.3865 - acc: 0.1887 - val_loss: 4.9348 - val_acc: 0.1605\n",
      "\n",
      "Epoch 25/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 834us/step - loss: 4.3403 - acc: 0.1904 - val_loss: 4.9058 - val_acc: 0.1543\n",
      "\n",
      "Epoch 26/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 978us/step - loss: 4.2936 - acc: 0.1904 - val_loss: 4.8792 - val_acc: 0.1543\n",
      "\n",
      "Epoch 27/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 910us/step - loss: 4.2489 - acc: 0.1938 - val_loss: 4.8520 - val_acc: 0.1543TA: 0s - loss: 4.2590 - acc: 0.18\n",
      "\n",
      "Epoch 28/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 4.2053 - acc: 0.1955 - val_loss: 4.8256 - val_acc: 0.1481\n",
      "\n",
      "Epoch 29/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 974us/step - loss: 4.1626 - acc: 0.1990 - val_loss: 4.8005 - val_acc: 0.1481\n",
      "\n",
      "Epoch 30/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 908us/step - loss: 4.1197 - acc: 0.2024 - val_loss: 4.7762 - val_acc: 0.1481\n",
      "\n",
      "Epoch 31/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 871us/step - loss: 4.0783 - acc: 0.2024 - val_loss: 4.7514 - val_acc: 0.1481\n",
      "\n",
      "Epoch 32/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 823us/step - loss: 4.0368 - acc: 0.2041 - val_loss: 4.7273 - val_acc: 0.1543\n",
      "\n",
      "Epoch 33/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 3.9968 - acc: 0.2041 - val_loss: 4.7024 - val_acc: 0.1543\n",
      "\n",
      "Epoch 34/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 868us/step - loss: 3.9559 - acc: 0.2075 - val_loss: 4.6793 - val_acc: 0.1543\n",
      "\n",
      "Epoch 35/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 916us/step - loss: 3.9174 - acc: 0.2144 - val_loss: 4.6568 - val_acc: 0.1543\n",
      "\n",
      "Epoch 36/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 3.8794 - acc: 0.2144 - val_loss: 4.6333 - val_acc: 0.1605\n",
      "\n",
      "Epoch 37/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 3.8418 - acc: 0.2161 - val_loss: 4.6116 - val_acc: 0.1605TA: 0s - loss: 3.8752 - acc: 0.215\n",
      "\n",
      "Epoch 38/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 897us/step - loss: 3.8046 - acc: 0.2178 - val_loss: 4.5902 - val_acc: 0.1605\n",
      "\n",
      "Epoch 39/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 885us/step - loss: 3.7689 - acc: 0.2178 - val_loss: 4.5702 - val_acc: 0.1605\n",
      "\n",
      "Epoch 40/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 906us/step - loss: 3.7336 - acc: 0.2178 - val_loss: 4.5487 - val_acc: 0.1605\n",
      "\n",
      "Epoch 41/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 927us/step - loss: 3.6977 - acc: 0.2196 - val_loss: 4.5283 - val_acc: 0.1605\n",
      "\n",
      "Epoch 42/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 941us/step - loss: 3.6638 - acc: 0.2213 - val_loss: 4.5093 - val_acc: 0.1667TA: 0s - loss: 3.5895 - acc: 0\n",
      "\n",
      "Epoch 43/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 922us/step - loss: 3.6305 - acc: 0.2247 - val_loss: 4.4887 - val_acc: 0.1667\n",
      "\n",
      "Epoch 44/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 852us/step - loss: 3.5970 - acc: 0.2264 - val_loss: 4.4695 - val_acc: 0.1790TA: 0s - loss: 3.6113 - acc: 0.22\n",
      "\n",
      "Epoch 45/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 839us/step - loss: 3.5645 - acc: 0.2298 - val_loss: 4.4504 - val_acc: 0.1790\n",
      "\n",
      "Epoch 46/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 3.5321 - acc: 0.2316 - val_loss: 4.4319 - val_acc: 0.1790\n",
      "\n",
      "Epoch 47/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 899us/step - loss: 3.5005 - acc: 0.2316 - val_loss: 4.4136 - val_acc: 0.1790\n",
      "\n",
      "Epoch 48/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 3.4693 - acc: 0.2367 - val_loss: 4.3942 - val_acc: 0.1790\n",
      "\n",
      "Epoch 49/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 800us/step - loss: 3.4367 - acc: 0.2453 - val_loss: 4.3763 - val_acc: 0.1728TA: 0s - loss: 3.3673 - acc: 0.\n",
      "\n",
      "Epoch 50/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 970us/step - loss: 3.4058 - acc: 0.2521 - val_loss: 4.3589 - val_acc: 0.1728\n",
      "\n",
      "Epoch 51/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 825us/step - loss: 3.3755 - acc: 0.2521 - val_loss: 4.3417 - val_acc: 0.1728\n",
      "\n",
      "Epoch 52/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 775us/step - loss: 3.3455 - acc: 0.2521 - val_loss: 4.3232 - val_acc: 0.1728TA: 0s - loss: 3.3644 - acc: 0.512/583 [=========================>....] - ETA: 0s - loss: 3.3170 - acc: 0.252\n",
      "\n",
      "Epoch 53/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 3.3147 - acc: 0.2573 - val_loss: 4.3059 - val_acc: 0.1728\n",
      "\n",
      "Epoch 54/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 885us/step - loss: 3.2845 - acc: 0.2573 - val_loss: 4.2888 - val_acc: 0.1728\n",
      "\n",
      "Epoch 55/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 911us/step - loss: 3.2542 - acc: 0.2590 - val_loss: 4.2725 - val_acc: 0.1728\n",
      "\n",
      "Epoch 56/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 804us/step - loss: 3.2249 - acc: 0.2573 - val_loss: 4.2555 - val_acc: 0.1728\n",
      "\n",
      "Epoch 57/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 3.1958 - acc: 0.2659 - val_loss: 4.2393 - val_acc: 0.1728\n",
      "\n",
      "Epoch 58/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 910us/step - loss: 3.1677 - acc: 0.2659 - val_loss: 4.2230 - val_acc: 0.1728\n",
      "\n",
      "Epoch 59/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 851us/step - loss: 3.1394 - acc: 0.2659 - val_loss: 4.2075 - val_acc: 0.1790\n",
      "\n",
      "Epoch 60/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 919us/step - loss: 3.1119 - acc: 0.2676 - val_loss: 4.1912 - val_acc: 0.1790\n",
      "\n",
      "Epoch 61/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 857us/step - loss: 3.0844 - acc: 0.2693 - val_loss: 4.1763 - val_acc: 0.1790\n",
      "\n",
      "Epoch 62/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 3.0576 - acc: 0.2710 - val_loss: 4.1619 - val_acc: 0.1790\n",
      "\n",
      "Epoch 63/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 948us/step - loss: 3.0306 - acc: 0.2744 - val_loss: 4.1465 - val_acc: 0.1790\n",
      "\n",
      "Epoch 64/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================]583/583 [==============================] - 1s 949us/step - loss: 3.0044 - acc: 0.2762 - val_loss: 4.1317 - val_acc: 0.1852\n",
      "\n",
      "Epoch 65/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 911us/step - loss: 2.9778 - acc: 0.2762 - val_loss: 4.1170 - val_acc: 0.1914\n",
      "\n",
      "Epoch 66/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 852us/step - loss: 2.9522 - acc: 0.2762 - val_loss: 4.1029 - val_acc: 0.1914\n",
      "\n",
      "Epoch 67/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 808us/step - loss: 2.9269 - acc: 0.2762 - val_loss: 4.0895 - val_acc: 0.1852\n",
      "\n",
      "Epoch 68/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 890us/step - loss: 2.9019 - acc: 0.2847 - val_loss: 4.0750 - val_acc: 0.1852\n",
      "\n",
      "Epoch 69/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 833us/step - loss: 2.8765 - acc: 0.2864 - val_loss: 4.0605 - val_acc: 0.1852\n",
      "\n",
      "Epoch 70/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 961us/step - loss: 2.8521 - acc: 0.2933 - val_loss: 4.0467 - val_acc: 0.1852\n",
      "\n",
      "Epoch 71/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.8275 - acc: 0.2967 - val_loss: 4.0327 - val_acc: 0.1852\n",
      "\n",
      "Epoch 72/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 918us/step - loss: 2.8035 - acc: 0.2967 - val_loss: 4.0194 - val_acc: 0.1852\n",
      "\n",
      "Epoch 73/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 917us/step - loss: 2.7795 - acc: 0.2985 - val_loss: 4.0053 - val_acc: 0.1852\n",
      "\n",
      "Epoch 74/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 880us/step - loss: 2.7560 - acc: 0.3019 - val_loss: 3.9921 - val_acc: 0.1852\n",
      "\n",
      "Epoch 75/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 917us/step - loss: 2.7320 - acc: 0.3019 - val_loss: 3.9789 - val_acc: 0.1852\n",
      "\n",
      "Epoch 76/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 916us/step - loss: 2.7093 - acc: 0.3070 - val_loss: 3.9663 - val_acc: 0.1852\n",
      "\n",
      "Epoch 77/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 2.6871 - acc: 0.3087 - val_loss: 3.9547 - val_acc: 0.1975\n",
      "\n",
      "Epoch 78/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 939us/step - loss: 2.6646 - acc: 0.3156 - val_loss: 3.9431 - val_acc: 0.1975\n",
      "\n",
      "Epoch 79/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 856us/step - loss: 2.6419 - acc: 0.3208 - val_loss: 3.9309 - val_acc: 0.1975\n",
      "\n",
      "Epoch 80/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 780us/step - loss: 2.6194 - acc: 0.3225 - val_loss: 3.9190 - val_acc: 0.1975\n",
      "\n",
      "Epoch 81/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 935us/step - loss: 2.5973 - acc: 0.3225 - val_loss: 3.9072 - val_acc: 0.1975\n",
      "\n",
      "Epoch 82/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 985us/step - loss: 2.5757 - acc: 0.3259 - val_loss: 3.8962 - val_acc: 0.2037\n",
      "\n",
      "Epoch 83/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 954us/step - loss: 2.5547 - acc: 0.3276 - val_loss: 3.8834 - val_acc: 0.2037TA: 0s - loss: 2.5029 - acc: 0.34\n",
      "\n",
      "Epoch 84/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 991us/step - loss: 2.5330 - acc: 0.3293 - val_loss: 3.8721 - val_acc: 0.2037\n",
      "\n",
      "Epoch 85/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 885us/step - loss: 2.5122 - acc: 0.3293 - val_loss: 3.8599 - val_acc: 0.2037\n",
      "\n",
      "Epoch 86/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 924us/step - loss: 2.4915 - acc: 0.3310 - val_loss: 3.8499 - val_acc: 0.2037\n",
      "\n",
      "Epoch 87/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 2.4718 - acc: 0.3362 - val_loss: 3.8387 - val_acc: 0.2037TA: 0s - loss: 2.4320 - acc: 0.3\n",
      "\n",
      "Epoch 88/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 2.4517 - acc: 0.3396 - val_loss: 3.8303 - val_acc: 0.2037\n",
      "\n",
      "Epoch 89/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 913us/step - loss: 2.4325 - acc: 0.3396 - val_loss: 3.8202 - val_acc: 0.2037\n",
      "\n",
      "Epoch 90/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.4132 - acc: 0.3448 - val_loss: 3.8100 - val_acc: 0.2037\n",
      "\n",
      "Epoch 91/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 2.3941 - acc: 0.3499 - val_loss: 3.8011 - val_acc: 0.2037\n",
      "\n",
      "Epoch 92/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 914us/step - loss: 2.3749 - acc: 0.3533 - val_loss: 3.7907 - val_acc: 0.2037\n",
      "\n",
      "Epoch 93/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 856us/step - loss: 2.3553 - acc: 0.3602 - val_loss: 3.7815 - val_acc: 0.2037\n",
      "\n",
      "Epoch 94/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 882us/step - loss: 2.3363 - acc: 0.3636 - val_loss: 3.7724 - val_acc: 0.2037\n",
      "\n",
      "Epoch 95/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 930us/step - loss: 2.3175 - acc: 0.3671 - val_loss: 3.7636 - val_acc: 0.2037\n",
      "\n",
      "Epoch 96/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 930us/step - loss: 2.2993 - acc: 0.3688 - val_loss: 3.7547 - val_acc: 0.2037\n",
      "\n",
      "Epoch 97/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 963us/step - loss: 2.2811 - acc: 0.3722 - val_loss: 3.7460 - val_acc: 0.2037\n",
      "\n",
      "Epoch 98/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 919us/step - loss: 2.2633 - acc: 0.3774 - val_loss: 3.7365 - val_acc: 0.2037\n",
      "\n",
      "Epoch 99/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 2.2456 - acc: 0.3825 - val_loss: 3.7278 - val_acc: 0.2037TA: 0s - loss: 2.2154 - acc: 0.\n",
      "\n",
      "Epoch 100/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 948us/step - loss: 2.2279 - acc: 0.3825 - val_loss: 3.7194 - val_acc: 0.2037\n",
      "\n",
      "Epoch 101/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 826us/step - loss: 2.2104 - acc: 0.3877 - val_loss: 3.7105 - val_acc: 0.2037\n",
      "\n",
      "Epoch 102/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 920us/step - loss: 2.1924 - acc: 0.3928 - val_loss: 3.7015 - val_acc: 0.2037\n",
      "\n",
      "Epoch 103/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 912us/step - loss: 2.1749 - acc: 0.3945 - val_loss: 3.6938 - val_acc: 0.2099TA: 0s - loss: 2.3112 - acc: 0.\n",
      "\n",
      "Epoch 104/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 825us/step - loss: 2.1580 - acc: 0.4014 - val_loss: 3.6854 - val_acc: 0.2099\n",
      "\n",
      "Epoch 105/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 2.1414 - acc: 0.4031 - val_loss: 3.6767 - val_acc: 0.2099\n",
      "\n",
      "Epoch 106/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 913us/step - loss: 2.1251 - acc: 0.4065 - val_loss: 3.6690 - val_acc: 0.2099\n",
      "\n",
      "Epoch 107/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 905us/step - loss: 2.1088 - acc: 0.4082 - val_loss: 3.6622 - val_acc: 0.2099\n",
      "\n",
      "Epoch 108/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 869us/step - loss: 2.0932 - acc: 0.4117 - val_loss: 3.6540 - val_acc: 0.2099TA: 0s - loss: 2.0580 - acc: 0.42\n",
      "\n",
      "Epoch 109/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 830us/step - loss: 2.0778 - acc: 0.4134 - val_loss: 3.6465 - val_acc: 0.2099\n",
      "\n",
      "Epoch 110/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 879us/step - loss: 2.0621 - acc: 0.4185 - val_loss: 3.6388 - val_acc: 0.2099\n",
      "\n",
      "Epoch 111/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.0466 - acc: 0.4237 - val_loss: 3.6320 - val_acc: 0.2099\n",
      "\n",
      "Epoch 112/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 2.0312 - acc: 0.4237 - val_loss: 3.6241 - val_acc: 0.2099\n",
      "\n",
      "Epoch 113/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 824us/step - loss: 2.0161 - acc: 0.4254 - val_loss: 3.6166 - val_acc: 0.2099TA: 0s - loss: 2.0090 - acc: \n",
      "\n",
      "Epoch 114/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 896us/step - loss: 2.0007 - acc: 0.4271 - val_loss: 3.6091 - val_acc: 0.2160\n",
      "\n",
      "Epoch 115/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 913us/step - loss: 1.9859 - acc: 0.4322 - val_loss: 3.6021 - val_acc: 0.2160TA: 0s - loss: 1.9691 - acc: 0.429352/583 [=================>............] - ETA: 0s - loss: 1.9673 - acc: 0.417416/583 [====================>.........] - ETA: 0s - loss: 1.9374 - acc: 0.43\n",
      "\n",
      "Epoch 116/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.9712 - acc: 0.4322 - val_loss: 3.5946 - val_acc: 0.2160\n",
      "\n",
      "Epoch 117/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 995us/step - loss: 1.9568 - acc: 0.4374 - val_loss: 3.5871 - val_acc: 0.2160TA: 0s - loss: 1.8925 - acc: 0\n",
      "\n",
      "Epoch 118/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 880us/step - loss: 1.9424 - acc: 0.4408 - val_loss: 3.5798 - val_acc: 0.2160\n",
      "\n",
      "Epoch 119/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 841us/step - loss: 1.9283 - acc: 0.4511 - val_loss: 3.5735 - val_acc: 0.2160\n",
      "\n",
      "Epoch 120/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 871us/step - loss: 1.9149 - acc: 0.4511 - val_loss: 3.5665 - val_acc: 0.2160TA: 0s - loss: 1.9113 - acc: 0.44\n",
      "\n",
      "Epoch 121/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 912us/step - loss: 1.9013 - acc: 0.4614 - val_loss: 3.5606 - val_acc: 0.2160TA: 0s - loss: 1.8109 - acc: 0.500 - ETA: 0s - loss: 1.8831 - acc: 0.\n",
      "\n",
      "Epoch 122/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 1.8877 - acc: 0.4597 - val_loss: 3.5541 - val_acc: 0.2160\n",
      "\n",
      "Epoch 123/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 889us/step - loss: 1.8743 - acc: 0.4631 - val_loss: 3.5479 - val_acc: 0.2160\n",
      "\n",
      "Epoch 124/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 856us/step - loss: 1.8612 - acc: 0.4648 - val_loss: 3.5414 - val_acc: 0.2160\n",
      "\n",
      "Epoch 125/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 854us/step - loss: 1.8481 - acc: 0.4683 - val_loss: 3.5342 - val_acc: 0.2160\n",
      "\n",
      "Epoch 126/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 1.8350 - acc: 0.4734 - val_loss: 3.5290 - val_acc: 0.2160\n",
      "\n",
      "Epoch 127/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 1.8223 - acc: 0.4751 - val_loss: 3.5228 - val_acc: 0.2222\n",
      "\n",
      "Epoch 128/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 1.8095 - acc: 0.4734 - val_loss: 3.5166 - val_acc: 0.2222TA: 0s - loss: 1.8235 - acc: 0.\n",
      "\n",
      "Epoch 129/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 925us/step - loss: 1.7969 - acc: 0.4786 - val_loss: 3.5110 - val_acc: 0.2222\n",
      "\n",
      "Epoch 130/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 846us/step - loss: 1.7844 - acc: 0.4803 - val_loss: 3.5058 - val_acc: 0.2222\n",
      "\n",
      "Epoch 131/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 926us/step - loss: 1.7723 - acc: 0.4820 - val_loss: 3.4995 - val_acc: 0.2222\n",
      "\n",
      "Epoch 132/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 804us/step - loss: 1.7603 - acc: 0.4871 - val_loss: 3.4943 - val_acc: 0.2222\n",
      "\n",
      "Epoch 133/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 842us/step - loss: 1.7484 - acc: 0.4906 - val_loss: 3.4887 - val_acc: 0.2222TA: 0s - loss: 1.7533 - acc: 0.489\n",
      "\n",
      "Epoch 134/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 908us/step - loss: 1.7366 - acc: 0.4940 - val_loss: 3.4823 - val_acc: 0.2222 [======================>.......] - ETA: 0s - loss: 1.6954 - acc: 0.50\n",
      "\n",
      "Epoch 135/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 1.7244 - acc: 0.4974 - val_loss: 3.4774 - val_acc: 0.2222\n",
      "\n",
      "Epoch 136/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 805us/step - loss: 1.7130 - acc: 0.5026 - val_loss: 3.4721 - val_acc: 0.2222\n",
      "\n",
      "Epoch 137/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 801us/step - loss: 1.7016 - acc: 0.5060 - val_loss: 3.4658 - val_acc: 0.2222\n",
      "\n",
      "Epoch 138/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 971us/step - loss: 1.6901 - acc: 0.5111 - val_loss: 3.4605 - val_acc: 0.2222\n",
      "\n",
      "Epoch 139/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 2ms/step - loss: 1.6789 - acc: 0.5146 - val_loss: 3.4556 - val_acc: 0.2222\n",
      "\n",
      "Epoch 140/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.6678 - acc: 0.5180 - val_loss: 3.4503 - val_acc: 0.2222\n",
      "\n",
      "Epoch 141/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 857us/step - loss: 1.6569 - acc: 0.5197 - val_loss: 3.4451 - val_acc: 0.2222\n",
      "\n",
      "Epoch 142/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 1.6462 - acc: 0.5249 - val_loss: 3.4399 - val_acc: 0.2222TA: 0s - loss: 1.7531 - acc: 0.\n",
      "\n",
      "Epoch 143/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 1.6353 - acc: 0.5283 - val_loss: 3.4351 - val_acc: 0.2222TA: 0s - loss: 1.6213 - acc: 0.51288/583 [=============>................] - ETA: 0s - loss: 1.5550 - acc: 0.\n",
      "\n",
      "Epoch 144/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 1.6248 - acc: 0.5352 - val_loss: 3.4292 - val_acc: 0.2222\n",
      "\n",
      "Epoch 145/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 829us/step - loss: 1.6140 - acc: 0.5386 - val_loss: 3.4240 - val_acc: 0.2222\n",
      "\n",
      "Epoch 146/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 911us/step - loss: 1.6036 - acc: 0.5403 - val_loss: 3.4178 - val_acc: 0.2160\n",
      "\n",
      "Epoch 147/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 1.5927 - acc: 0.5437 - val_loss: 3.4129 - val_acc: 0.2160\n",
      "\n",
      "Epoch 148/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 892us/step - loss: 1.5825 - acc: 0.5455 - val_loss: 3.4087 - val_acc: 0.2160TA: 0s - loss: 1.5759 - acc: 0.54\n",
      "\n",
      "Epoch 149/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 915us/step - loss: 1.5725 - acc: 0.5472 - val_loss: 3.4035 - val_acc: 0.2160\n",
      "\n",
      "Epoch 150/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 856us/step - loss: 1.5623 - acc: 0.5506 - val_loss: 3.3992 - val_acc: 0.2160\n",
      "\n",
      "Epoch 151/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================]583/583 [==============================] - 1s 884us/step - loss: 1.5523 - acc: 0.5506 - val_loss: 3.3950 - val_acc: 0.2160\n",
      "\n",
      "Epoch 152/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 804us/step - loss: 1.5423 - acc: 0.5506 - val_loss: 3.3910 - val_acc: 0.2160\n",
      "\n",
      "Epoch 153/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 942us/step - loss: 1.5325 - acc: 0.5506 - val_loss: 3.3858 - val_acc: 0.2160\n",
      "\n",
      "Epoch 154/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 833us/step - loss: 1.5225 - acc: 0.5557 - val_loss: 3.3815 - val_acc: 0.2160\n",
      "\n",
      "Epoch 155/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 881us/step - loss: 1.5128 - acc: 0.5592 - val_loss: 3.3768 - val_acc: 0.2160\n",
      "\n",
      "Epoch 156/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 1.5033 - acc: 0.5592 - val_loss: 3.3731 - val_acc: 0.2160\n",
      "\n",
      "Epoch 157/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 981us/step - loss: 1.4939 - acc: 0.5626 - val_loss: 3.3685 - val_acc: 0.2160\n",
      "\n",
      "Epoch 158/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 802us/step - loss: 1.4846 - acc: 0.5660 - val_loss: 3.3651 - val_acc: 0.2160\n",
      "\n",
      "Epoch 159/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 852us/step - loss: 1.4752 - acc: 0.5660 - val_loss: 3.3607 - val_acc: 0.2160\n",
      "\n",
      "Epoch 160/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 1.4662 - acc: 0.5695 - val_loss: 3.3562 - val_acc: 0.2099\n",
      "\n",
      "Epoch 161/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 947us/step - loss: 1.4567 - acc: 0.5712 - val_loss: 3.3520 - val_acc: 0.2099\n",
      "\n",
      "Epoch 162/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 916us/step - loss: 1.4477 - acc: 0.5746 - val_loss: 3.3477 - val_acc: 0.2099\n",
      "\n",
      "Epoch 163/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 968us/step - loss: 1.4387 - acc: 0.5763 - val_loss: 3.3435 - val_acc: 0.2099\n",
      "\n",
      "Epoch 164/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 855us/step - loss: 1.4299 - acc: 0.5763 - val_loss: 3.3401 - val_acc: 0.2099\n",
      "\n",
      "Epoch 165/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 907us/step - loss: 1.4213 - acc: 0.5763 - val_loss: 3.3360 - val_acc: 0.2099TA: 0s - loss: 1.3763 - acc: 0.5\n",
      "\n",
      "Epoch 166/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 897us/step - loss: 1.4128 - acc: 0.5763 - val_loss: 3.3320 - val_acc: 0.2099TA: 0s - loss: 1.4895 - acc:\n",
      "\n",
      "Epoch 167/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 914us/step - loss: 1.4040 - acc: 0.5832 - val_loss: 3.3277 - val_acc: 0.2099\n",
      "\n",
      "Epoch 168/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 915us/step - loss: 1.3957 - acc: 0.5815 - val_loss: 3.3234 - val_acc: 0.2099\n",
      "\n",
      "Epoch 169/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.3873 - acc: 0.5901 - val_loss: 3.3193 - val_acc: 0.2099\n",
      "\n",
      "Epoch 170/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 943us/step - loss: 1.3789 - acc: 0.5918 - val_loss: 3.3152 - val_acc: 0.2099\n",
      "\n",
      "Epoch 171/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 952us/step - loss: 1.3707 - acc: 0.5918 - val_loss: 3.3116 - val_acc: 0.2099\n",
      "\n",
      "Epoch 172/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 968us/step - loss: 1.3626 - acc: 0.5935 - val_loss: 3.3086 - val_acc: 0.2099\n",
      "\n",
      "Epoch 173/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 924us/step - loss: 1.3546 - acc: 0.5952 - val_loss: 3.3052 - val_acc: 0.2099\n",
      "\n",
      "Epoch 174/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 955us/step - loss: 1.3468 - acc: 0.6021 - val_loss: 3.3016 - val_acc: 0.2099TA: 0s - loss: 1.3492 - acc: 0.61\n",
      "\n",
      "Epoch 175/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 1.3388 - acc: 0.6021 - val_loss: 3.2986 - val_acc: 0.2160\n",
      "\n",
      "Epoch 176/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 1.3311 - acc: 0.6038 - val_loss: 3.2948 - val_acc: 0.2160\n",
      "\n",
      "Epoch 177/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 880us/step - loss: 1.3233 - acc: 0.6072 - val_loss: 3.2916 - val_acc: 0.2160\n",
      "\n",
      "Epoch 178/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 1.3158 - acc: 0.6089 - val_loss: 3.2876 - val_acc: 0.2160\n",
      "\n",
      "Epoch 179/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 1.3083 - acc: 0.6106 - val_loss: 3.2846 - val_acc: 0.2160TA: 0s - loss: 1.4015 - acc: 0.\n",
      "\n",
      "Epoch 180/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 826us/step - loss: 1.3010 - acc: 0.6158 - val_loss: 3.2815 - val_acc: 0.2160\n",
      "\n",
      "Epoch 181/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 1.2938 - acc: 0.6192 - val_loss: 3.2776 - val_acc: 0.2160\n",
      "\n",
      "Epoch 182/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 953us/step - loss: 1.2865 - acc: 0.6226 - val_loss: 3.2745 - val_acc: 0.2160TA: 0s - loss: 1.3412 - acc: 0.604544/583 [==========================>...] - ETA: 0s - loss: 1.3017 - acc: 0.615\n",
      "\n",
      "Epoch 183/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 848us/step - loss: 1.2792 - acc: 0.6261 - val_loss: 3.2714 - val_acc: 0.2160TA: 0s - loss: 1.2171 - acc: 0.\n",
      "\n",
      "Epoch 184/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 972us/step - loss: 1.2720 - acc: 0.6278 - val_loss: 3.2684 - val_acc: 0.2160\n",
      "\n",
      "Epoch 185/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 885us/step - loss: 1.2649 - acc: 0.6312 - val_loss: 3.2649 - val_acc: 0.2160\n",
      "\n",
      "Epoch 186/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 803us/step - loss: 1.2578 - acc: 0.6312 - val_loss: 3.2617 - val_acc: 0.2160\n",
      "\n",
      "Epoch 187/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 890us/step - loss: 1.2508 - acc: 0.6312 - val_loss: 3.2582 - val_acc: 0.2160\n",
      "\n",
      "Epoch 188/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 997us/step - loss: 1.2439 - acc: 0.6329 - val_loss: 3.2553 - val_acc: 0.2160\n",
      "\n",
      "Epoch 189/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 890us/step - loss: 1.2371 - acc: 0.6346 - val_loss: 3.2514 - val_acc: 0.2160TA: 0s - loss: 1.1355 - acc: 0.\n",
      "\n",
      "Epoch 190/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 823us/step - loss: 1.2302 - acc: 0.6381 - val_loss: 3.2486 - val_acc: 0.2160\n",
      "\n",
      "Epoch 191/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 834us/step - loss: 1.2236 - acc: 0.6398 - val_loss: 3.2445 - val_acc: 0.2160\n",
      "\n",
      "Epoch 192/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.2169 - acc: 0.6415 - val_loss: 3.2409 - val_acc: 0.2160\n",
      "\n",
      "Epoch 193/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 931us/step - loss: 1.2100 - acc: 0.6449 - val_loss: 3.2381 - val_acc: 0.2160\n",
      "\n",
      "Epoch 194/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 1.2035 - acc: 0.6449 - val_loss: 3.2351 - val_acc: 0.2160TA: 0s - loss: 1.1633 - acc: \n",
      "\n",
      "Epoch 195/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 830us/step - loss: 1.1969 - acc: 0.6484 - val_loss: 3.2326 - val_acc: 0.2160\n",
      "\n",
      "Epoch 196/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 895us/step - loss: 1.1906 - acc: 0.6501 - val_loss: 3.2297 - val_acc: 0.2222\n",
      "\n",
      "Epoch 197/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 849us/step - loss: 1.1841 - acc: 0.6535 - val_loss: 3.2272 - val_acc: 0.2284TA: 0s - loss: 1.1761 - acc: 0\n",
      "\n",
      "Epoch 198/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 911us/step - loss: 1.1779 - acc: 0.6535 - val_loss: 3.2238 - val_acc: 0.2222\n",
      "\n",
      "Epoch 199/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 940us/step - loss: 1.1716 - acc: 0.6552 - val_loss: 3.2212 - val_acc: 0.2222\n",
      "\n",
      "Epoch 200/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 893us/step - loss: 1.1655 - acc: 0.6587 - val_loss: 3.2188 - val_acc: 0.2222\n",
      "\n",
      "65/65 [==============================]65/65 [==============================] - 0s 421us/step\n",
      "\n",
      "Train on 583 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "583/583 [==============================]583/583 [==============================] - 3s 6ms/step - loss: 5.2634 - acc: 0.1184 - val_loss: 4.9146 - val_acc: 0.1235\n",
      "\n",
      "Epoch 2/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 952us/step - loss: 5.1961 - acc: 0.1201 - val_loss: 4.8948 - val_acc: 0.1173TA: 0s - loss: 5.1675 - acc: 0.125\n",
      "\n",
      "Epoch 3/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 905us/step - loss: 5.1291 - acc: 0.1218 - val_loss: 4.8726 - val_acc: 0.1296\n",
      "\n",
      "Epoch 4/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 924us/step - loss: 5.0632 - acc: 0.1252 - val_loss: 4.8525 - val_acc: 0.1358\n",
      "\n",
      "Epoch 5/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 950us/step - loss: 4.9990 - acc: 0.1269 - val_loss: 4.8330 - val_acc: 0.1420\n",
      "\n",
      "Epoch 6/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 4.9361 - acc: 0.1286 - val_loss: 4.8137 - val_acc: 0.1481\n",
      "\n",
      "Epoch 7/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 925us/step - loss: 4.8751 - acc: 0.1286 - val_loss: 4.7951 - val_acc: 0.1481\n",
      "\n",
      "Epoch 8/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 4.8150 - acc: 0.1321 - val_loss: 4.7762 - val_acc: 0.1543\n",
      "\n",
      "Epoch 9/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 965us/step - loss: 4.7564 - acc: 0.1321 - val_loss: 4.7582 - val_acc: 0.1543\n",
      "\n",
      "Epoch 10/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 868us/step - loss: 4.6981 - acc: 0.1338 - val_loss: 4.7415 - val_acc: 0.1543\n",
      "\n",
      "Epoch 11/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 882us/step - loss: 4.6389 - acc: 0.1372 - val_loss: 4.7256 - val_acc: 0.1543TA: 0s - loss: 4.6671 - acc: 0.13\n",
      "\n",
      "Epoch 12/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 857us/step - loss: 4.5830 - acc: 0.1407 - val_loss: 4.7090 - val_acc: 0.1543TA: 0s - loss: 4.7413 - acc: 0\n",
      "\n",
      "Epoch 13/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 868us/step - loss: 4.5281 - acc: 0.1407 - val_loss: 4.6919 - val_acc: 0.1543\n",
      "\n",
      "Epoch 14/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 981us/step - loss: 4.4742 - acc: 0.1407 - val_loss: 4.6736 - val_acc: 0.1543\n",
      "\n",
      "Epoch 15/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 950us/step - loss: 4.4201 - acc: 0.1424 - val_loss: 4.6587 - val_acc: 0.1543TA: 0s - loss: 4.4252 - acc: 0.\n",
      "\n",
      "Epoch 16/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 835us/step - loss: 4.3680 - acc: 0.1492 - val_loss: 4.6447 - val_acc: 0.1481\n",
      "\n",
      "Epoch 17/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 828us/step - loss: 4.3180 - acc: 0.1509 - val_loss: 4.6308 - val_acc: 0.1481TA: 0s - loss: 4.3553 - acc: 0.137544/583 [==========================>...] - ETA: 0s - loss: 4.3074 - acc: 0.150\n",
      "\n",
      "Epoch 18/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 991us/step - loss: 4.2694 - acc: 0.1578 - val_loss: 4.6164 - val_acc: 0.1481\n",
      "\n",
      "Epoch 19/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 835us/step - loss: 4.2218 - acc: 0.1595 - val_loss: 4.6025 - val_acc: 0.1481\n",
      "\n",
      "Epoch 20/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 829us/step - loss: 4.1747 - acc: 0.1647 - val_loss: 4.5885 - val_acc: 0.1481TA: 0s - loss: 4.3300 - acc: 0.\n",
      "\n",
      "Epoch 21/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 803us/step - loss: 4.1286 - acc: 0.1681 - val_loss: 4.5735 - val_acc: 0.1481\n",
      "\n",
      "Epoch 22/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 976us/step - loss: 4.0821 - acc: 0.1681 - val_loss: 4.5592 - val_acc: 0.1481\n",
      "\n",
      "Epoch 23/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 4.0369 - acc: 0.1715 - val_loss: 4.5454 - val_acc: 0.1543TA: 0s - loss: 4.1026 - acc: 0.1\n",
      "\n",
      "Epoch 24/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 861us/step - loss: 3.9919 - acc: 0.1732 - val_loss: 4.5318 - val_acc: 0.1543TA: 0s - loss: 3.9990 - acc: 0.1\n",
      "\n",
      "Epoch 25/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 902us/step - loss: 3.9484 - acc: 0.1732 - val_loss: 4.5182 - val_acc: 0.1481\n",
      "\n",
      "Epoch 26/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 825us/step - loss: 3.9061 - acc: 0.1801 - val_loss: 4.5043 - val_acc: 0.1481\n",
      "\n",
      "Epoch 27/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 919us/step - loss: 3.8644 - acc: 0.1852 - val_loss: 4.4901 - val_acc: 0.1481TA: 0s - loss: 4.2356 - acc:\n",
      "\n",
      "Epoch 28/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 856us/step - loss: 3.8226 - acc: 0.1904 - val_loss: 4.4761 - val_acc: 0.1481\n",
      "\n",
      "Epoch 29/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 918us/step - loss: 3.7825 - acc: 0.1938 - val_loss: 4.4627 - val_acc: 0.1481 [=======================>......] - ETA: 0s - loss: 3.7262 - acc: 0.19\n",
      "\n",
      "Epoch 30/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 855us/step - loss: 3.7432 - acc: 0.1955 - val_loss: 4.4490 - val_acc: 0.1481\n",
      "\n",
      "Epoch 31/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 912us/step - loss: 3.7044 - acc: 0.1973 - val_loss: 4.4367 - val_acc: 0.1481\n",
      "\n",
      "Epoch 32/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 916us/step - loss: 3.6669 - acc: 0.1955 - val_loss: 4.4241 - val_acc: 0.1481\n",
      "\n",
      "Epoch 33/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 803us/step - loss: 3.6303 - acc: 0.1955 - val_loss: 4.4112 - val_acc: 0.1481TA: 0s - loss: 3.5769 - acc: \n",
      "\n",
      "Epoch 34/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 883us/step - loss: 3.5940 - acc: 0.1973 - val_loss: 4.3993 - val_acc: 0.1481\n",
      "\n",
      "Epoch 35/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 865us/step - loss: 3.5581 - acc: 0.2007 - val_loss: 4.3864 - val_acc: 0.1481\n",
      "\n",
      "Epoch 36/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 958us/step - loss: 3.5217 - acc: 0.2041 - val_loss: 4.3743 - val_acc: 0.1481\n",
      "\n",
      "Epoch 37/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 3.4873 - acc: 0.2093 - val_loss: 4.3604 - val_acc: 0.1481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 977us/step - loss: 3.4526 - acc: 0.2127 - val_loss: 4.3480 - val_acc: 0.1481\n",
      "\n",
      "Epoch 39/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 913us/step - loss: 3.4191 - acc: 0.2144 - val_loss: 4.3351 - val_acc: 0.1481\n",
      "\n",
      "Epoch 40/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 854us/step - loss: 3.3848 - acc: 0.2127 - val_loss: 4.3221 - val_acc: 0.1481\n",
      "\n",
      "Epoch 41/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 3.3520 - acc: 0.2161 - val_loss: 4.3085 - val_acc: 0.1481\n",
      "\n",
      "Epoch 42/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 918us/step - loss: 3.3190 - acc: 0.2196 - val_loss: 4.2969 - val_acc: 0.1481\n",
      "\n",
      "Epoch 43/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 3.2870 - acc: 0.2213 - val_loss: 4.2849 - val_acc: 0.1481TA: 0s - loss: 3.2416 - acc: 0.230\n",
      "\n",
      "Epoch 44/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 962us/step - loss: 3.2553 - acc: 0.2230 - val_loss: 4.2725 - val_acc: 0.1481\n",
      "\n",
      "Epoch 45/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 805us/step - loss: 3.2248 - acc: 0.2230 - val_loss: 4.2606 - val_acc: 0.1481\n",
      "\n",
      "Epoch 46/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 3.1944 - acc: 0.2247 - val_loss: 4.2488 - val_acc: 0.15433 [=========================>....] - ETA: 0s - loss: 3.2278 - acc: 0.212\n",
      "\n",
      "Epoch 47/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 884us/step - loss: 3.1647 - acc: 0.2247 - val_loss: 4.2364 - val_acc: 0.1543\n",
      "\n",
      "Epoch 48/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 962us/step - loss: 3.1353 - acc: 0.2281 - val_loss: 4.2247 - val_acc: 0.1543\n",
      "\n",
      "Epoch 49/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 3.1063 - acc: 0.2333 - val_loss: 4.2129 - val_acc: 0.15433 [==========================>...] - ETA: 0s - loss: 3.1386 - acc: 0.227\n",
      "\n",
      "Epoch 50/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 835us/step - loss: 3.0774 - acc: 0.2350 - val_loss: 4.2011 - val_acc: 0.1543\n",
      "\n",
      "Epoch 51/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 863us/step - loss: 3.0492 - acc: 0.2384 - val_loss: 4.1896 - val_acc: 0.1543\n",
      "\n",
      "Epoch 52/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 857us/step - loss: 3.0213 - acc: 0.2401 - val_loss: 4.1780 - val_acc: 0.1543\n",
      "\n",
      "Epoch 53/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 2.9937 - acc: 0.2453 - val_loss: 4.1675 - val_acc: 0.1543\n",
      "\n",
      "Epoch 54/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 876us/step - loss: 2.9662 - acc: 0.2521 - val_loss: 4.1544 - val_acc: 0.1605TA: 0s - loss: 2.8598 - acc: 0.\n",
      "\n",
      "Epoch 55/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.9387 - acc: 0.2573 - val_loss: 4.1431 - val_acc: 0.1667\n",
      "\n",
      "Epoch 56/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.9120 - acc: 0.2573 - val_loss: 4.1324 - val_acc: 0.1667\n",
      "\n",
      "Epoch 57/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.8853 - acc: 0.2607 - val_loss: 4.1228 - val_acc: 0.1667\n",
      "\n",
      "Epoch 58/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 917us/step - loss: 2.8591 - acc: 0.2624 - val_loss: 4.1129 - val_acc: 0.1667\n",
      "\n",
      "Epoch 59/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 971us/step - loss: 2.8333 - acc: 0.2676 - val_loss: 4.1018 - val_acc: 0.1667\n",
      "\n",
      "Epoch 60/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 929us/step - loss: 2.8076 - acc: 0.2710 - val_loss: 4.0913 - val_acc: 0.1728TA: 0s - loss: 2.6110 - acc: \n",
      "\n",
      "Epoch 61/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 956us/step - loss: 2.7820 - acc: 0.2727 - val_loss: 4.0822 - val_acc: 0.1728\n",
      "\n",
      "Epoch 62/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 907us/step - loss: 2.7567 - acc: 0.2744 - val_loss: 4.0705 - val_acc: 0.1728\n",
      "\n",
      "Epoch 63/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 902us/step - loss: 2.7322 - acc: 0.2796 - val_loss: 4.0611 - val_acc: 0.1728\n",
      "\n",
      "Epoch 64/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 925us/step - loss: 2.7080 - acc: 0.2847 - val_loss: 4.0525 - val_acc: 0.1728\n",
      "\n",
      "Epoch 65/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 912us/step - loss: 2.6832 - acc: 0.2899 - val_loss: 4.0435 - val_acc: 0.1728\n",
      "\n",
      "Epoch 66/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 2.6590 - acc: 0.2933 - val_loss: 4.0348 - val_acc: 0.1728TA: 0s - loss: 2.6422 - acc: 0.310\n",
      "\n",
      "Epoch 67/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 920us/step - loss: 2.6354 - acc: 0.2950 - val_loss: 4.0257 - val_acc: 0.1728\n",
      "\n",
      "Epoch 68/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 2.6121 - acc: 0.3019 - val_loss: 4.0153 - val_acc: 0.1728\n",
      "\n",
      "Epoch 69/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 974us/step - loss: 2.5883 - acc: 0.3019 - val_loss: 4.0071 - val_acc: 0.1728\n",
      "\n",
      "Epoch 70/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 999us/step - loss: 2.5650 - acc: 0.3036 - val_loss: 3.9989 - val_acc: 0.1790\n",
      "\n",
      "Epoch 71/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.5418 - acc: 0.3105 - val_loss: 3.9891 - val_acc: 0.1852\n",
      "\n",
      "Epoch 72/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.5189 - acc: 0.3122 - val_loss: 3.9800 - val_acc: 0.1852\n",
      "\n",
      "Epoch 73/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 914us/step - loss: 2.4972 - acc: 0.3122 - val_loss: 3.9709 - val_acc: 0.1852\n",
      "\n",
      "Epoch 74/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 958us/step - loss: 2.4756 - acc: 0.3173 - val_loss: 3.9619 - val_acc: 0.1852\n",
      "\n",
      "Epoch 75/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 2.4538 - acc: 0.3190 - val_loss: 3.9528 - val_acc: 0.1852\n",
      "\n",
      "Epoch 76/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 906us/step - loss: 2.4330 - acc: 0.3225 - val_loss: 3.9436 - val_acc: 0.1852\n",
      "\n",
      "Epoch 77/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 926us/step - loss: 2.4127 - acc: 0.3259 - val_loss: 3.9354 - val_acc: 0.1852\n",
      "\n",
      "Epoch 78/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 914us/step - loss: 2.3921 - acc: 0.3345 - val_loss: 3.9274 - val_acc: 0.1852\n",
      "\n",
      "Epoch 79/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 944us/step - loss: 2.3723 - acc: 0.3379 - val_loss: 3.9196 - val_acc: 0.1852\n",
      "\n",
      "Epoch 80/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 2.3527 - acc: 0.3396 - val_loss: 3.9114 - val_acc: 0.1790\n",
      "\n",
      "Epoch 81/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.3332 - acc: 0.3413 - val_loss: 3.9029 - val_acc: 0.1852\n",
      "\n",
      "Epoch 82/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.3139 - acc: 0.3431 - val_loss: 3.8941 - val_acc: 0.1852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 83/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 938us/step - loss: 2.2951 - acc: 0.3448 - val_loss: 3.8864 - val_acc: 0.1914\n",
      "\n",
      "Epoch 84/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 943us/step - loss: 2.2767 - acc: 0.3465 - val_loss: 3.8778 - val_acc: 0.1975\n",
      "\n",
      "Epoch 85/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 994us/step - loss: 2.2583 - acc: 0.3465 - val_loss: 3.8706 - val_acc: 0.1975\n",
      "\n",
      "Epoch 86/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 941us/step - loss: 2.2402 - acc: 0.3482 - val_loss: 3.8626 - val_acc: 0.1975TA: 0s - loss: 2.2680 - acc: 0.33\n",
      "\n",
      "Epoch 87/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 2.2219 - acc: 0.3516 - val_loss: 3.8547 - val_acc: 0.1975\n",
      "\n",
      "Epoch 88/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 923us/step - loss: 2.2038 - acc: 0.3533 - val_loss: 3.8465 - val_acc: 0.1975\n",
      "\n",
      "Epoch 89/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 915us/step - loss: 2.1863 - acc: 0.3568 - val_loss: 3.8402 - val_acc: 0.2037\n",
      "\n",
      "Epoch 90/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 864us/step - loss: 2.1696 - acc: 0.3602 - val_loss: 3.8323 - val_acc: 0.1975TA: 0s - loss: 2.1727 - acc: 0.359\n",
      "\n",
      "Epoch 91/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 871us/step - loss: 2.1523 - acc: 0.3688 - val_loss: 3.8254 - val_acc: 0.1975TA: 0s - loss: 2.2142 - acc: \n",
      "\n",
      "Epoch 92/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 2.1355 - acc: 0.3688 - val_loss: 3.8183 - val_acc: 0.2037\n",
      "\n",
      "Epoch 93/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 891us/step - loss: 2.1189 - acc: 0.3705 - val_loss: 3.8107 - val_acc: 0.2037[=========================>....] - ETA: 0s - loss: 2.1003 - acc: 0.37\n",
      "\n",
      "Epoch 94/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 2.1023 - acc: 0.3756 - val_loss: 3.8037 - val_acc: 0.2037TA: 0s - loss: 2.1130 - acc: 0.3\n",
      "\n",
      "Epoch 95/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 869us/step - loss: 2.0855 - acc: 0.3808 - val_loss: 3.7968 - val_acc: 0.2037TA: 0s - loss: 2.1151 - acc: \n",
      "\n",
      "Epoch 96/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 861us/step - loss: 2.0694 - acc: 0.3877 - val_loss: 3.7910 - val_acc: 0.2160\n",
      "\n",
      "Epoch 97/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 2.0536 - acc: 0.3911 - val_loss: 3.7844 - val_acc: 0.2160TA: 0s - loss: 2.1363 - acc: 0.480/583 [=======================>......] - ETA: 0s - loss: 2.0386 - acc: 0.406544/583 [==========================>...] - ETA: 0s - loss: 2.0548 - acc: 0.391\n",
      "\n",
      "Epoch 98/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 867us/step - loss: 2.0380 - acc: 0.3979 - val_loss: 3.7775 - val_acc: 0.2160\n",
      "\n",
      "Epoch 99/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 824us/step - loss: 2.0225 - acc: 0.3997 - val_loss: 3.7707 - val_acc: 0.2160TA: 0s - loss: 2.1565 - acc: \n",
      "\n",
      "Epoch 100/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 2.0073 - acc: 0.4031 - val_loss: 3.7640 - val_acc: 0.2160TA: 0s - loss: 2.0191 - acc: 0.404\n",
      "\n",
      "Epoch 101/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 1.9922 - acc: 0.4048 - val_loss: 3.7571 - val_acc: 0.2222\n",
      "\n",
      "Epoch 102/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 945us/step - loss: 1.9770 - acc: 0.4117 - val_loss: 3.7505 - val_acc: 0.2160\n",
      "\n",
      "Epoch 103/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 1.9618 - acc: 0.4151 - val_loss: 3.7448 - val_acc: 0.2160\n",
      "\n",
      "Epoch 104/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 885us/step - loss: 1.9472 - acc: 0.4168 - val_loss: 3.7384 - val_acc: 0.2160\n",
      "\n",
      "Epoch 105/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 883us/step - loss: 1.9323 - acc: 0.4202 - val_loss: 3.7320 - val_acc: 0.2160\n",
      "\n",
      "Epoch 106/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 1.9178 - acc: 0.4220 - val_loss: 3.7261 - val_acc: 0.2160TA: 0s - loss: 1.9213 - acc: 0.413\n",
      "\n",
      "Epoch 107/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 1.9033 - acc: 0.4271 - val_loss: 3.7195 - val_acc: 0.2160\n",
      "\n",
      "Epoch 108/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 885us/step - loss: 1.8890 - acc: 0.4288 - val_loss: 3.7137 - val_acc: 0.2160TA: 0s - loss: 1.7695 - acc: 0\n",
      "\n",
      "Epoch 109/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 803us/step - loss: 1.8751 - acc: 0.4340 - val_loss: 3.7067 - val_acc: 0.2160\n",
      "\n",
      "Epoch 110/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 883us/step - loss: 1.8613 - acc: 0.4408 - val_loss: 3.7013 - val_acc: 0.2160\n",
      "\n",
      "Epoch 111/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 861us/step - loss: 1.8477 - acc: 0.4425 - val_loss: 3.6954 - val_acc: 0.2160\n",
      "\n",
      "Epoch 112/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 908us/step - loss: 1.8344 - acc: 0.4477 - val_loss: 3.6895 - val_acc: 0.2160TA: 0s - loss: 1.7232 - acc: 0.47448/583 [======================>.......] - ETA: 0s - loss: 1.7521 - acc: 0.464544/583 [==========================>...] - ETA: 0s - loss: 1.7781 - acc: 0.455\n",
      "\n",
      "Epoch 113/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 919us/step - loss: 1.8211 - acc: 0.4511 - val_loss: 3.6840 - val_acc: 0.2160\n",
      "\n",
      "Epoch 114/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 1.8078 - acc: 0.4580 - val_loss: 3.6783 - val_acc: 0.2160\n",
      "\n",
      "Epoch 115/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 857us/step - loss: 1.7948 - acc: 0.4614 - val_loss: 3.6736 - val_acc: 0.2160TA: 0s - loss: 1.7368 - acc: 0.4\n",
      "\n",
      "Epoch 116/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 911us/step - loss: 1.7819 - acc: 0.4614 - val_loss: 3.6681 - val_acc: 0.2160\n",
      "\n",
      "Epoch 117/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 833us/step - loss: 1.7693 - acc: 0.4683 - val_loss: 3.6625 - val_acc: 0.2160TA: 0s - loss: 1.9290 - acc: 0.448448/583 [======================>.......] - ETA: 0s - loss: 1.8499 - acc: 0.45\n",
      "\n",
      "Epoch 118/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 959us/step - loss: 1.7571 - acc: 0.4700 - val_loss: 3.6566 - val_acc: 0.2160TA: 0s - loss: 1.7158 - acc: 0.479\n",
      "\n",
      "Epoch 119/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 1.7445 - acc: 0.4768 - val_loss: 3.6509 - val_acc: 0.2160\n",
      "\n",
      "Epoch 120/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 869us/step - loss: 1.7321 - acc: 0.4803 - val_loss: 3.6458 - val_acc: 0.2160\n",
      "\n",
      "Epoch 121/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 915us/step - loss: 1.7199 - acc: 0.4871 - val_loss: 3.6411 - val_acc: 0.2160\n",
      "\n",
      "Epoch 122/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 935us/step - loss: 1.7080 - acc: 0.4889 - val_loss: 3.6358 - val_acc: 0.2160\n",
      "\n",
      "Epoch 123/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 1.6960 - acc: 0.4889 - val_loss: 3.6314 - val_acc: 0.2160\n",
      "\n",
      "Epoch 124/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================]583/583 [==============================] - 0s 774us/step - loss: 1.6844 - acc: 0.4906 - val_loss: 3.6264 - val_acc: 0.2160\n",
      "\n",
      "Epoch 125/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 1.6728 - acc: 0.4957 - val_loss: 3.6216 - val_acc: 0.2160\n",
      "\n",
      "Epoch 126/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 1.6612 - acc: 0.4991 - val_loss: 3.6164 - val_acc: 0.2160\n",
      "\n",
      "Epoch 127/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 856us/step - loss: 1.6500 - acc: 0.5009 - val_loss: 3.6110 - val_acc: 0.2160\n",
      "\n",
      "Epoch 128/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 1.6385 - acc: 0.5060 - val_loss: 3.6064 - val_acc: 0.2160\n",
      "\n",
      "Epoch 129/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 833us/step - loss: 1.6272 - acc: 0.5111 - val_loss: 3.6015 - val_acc: 0.2160TA: 0s - loss: 1.5866 - acc: 0.5\n",
      "\n",
      "Epoch 130/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 880us/step - loss: 1.6162 - acc: 0.5146 - val_loss: 3.5968 - val_acc: 0.2160\n",
      "\n",
      "Epoch 131/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 1.6050 - acc: 0.5146 - val_loss: 3.5919 - val_acc: 0.2160TA: 0s - loss: 1.4597 - acc:\n",
      "\n",
      "Epoch 132/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 970us/step - loss: 1.5943 - acc: 0.5180 - val_loss: 3.5873 - val_acc: 0.2160\n",
      "\n",
      "Epoch 133/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 848us/step - loss: 1.5834 - acc: 0.5197 - val_loss: 3.5827 - val_acc: 0.2160\n",
      "\n",
      "Epoch 134/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 787us/step - loss: 1.5729 - acc: 0.5197 - val_loss: 3.5784 - val_acc: 0.2160\n",
      "\n",
      "Epoch 135/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 996us/step - loss: 1.5620 - acc: 0.5232 - val_loss: 3.5735 - val_acc: 0.2160\n",
      "\n",
      "Epoch 136/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 914us/step - loss: 1.5514 - acc: 0.5266 - val_loss: 3.5685 - val_acc: 0.2160\n",
      "\n",
      "Epoch 137/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 921us/step - loss: 1.5409 - acc: 0.5300 - val_loss: 3.5638 - val_acc: 0.2160\n",
      "\n",
      "Epoch 138/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 879us/step - loss: 1.5306 - acc: 0.5300 - val_loss: 3.5596 - val_acc: 0.2160\n",
      "\n",
      "Epoch 139/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 885us/step - loss: 1.5203 - acc: 0.5283 - val_loss: 3.5551 - val_acc: 0.2160\n",
      "\n",
      "Epoch 140/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 807us/step - loss: 1.5102 - acc: 0.5369 - val_loss: 3.5514 - val_acc: 0.2222\n",
      "\n",
      "Epoch 141/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 919us/step - loss: 1.5002 - acc: 0.5403 - val_loss: 3.5465 - val_acc: 0.2284TA: 0s - loss: 1.5171 - acc: \n",
      "\n",
      "Epoch 142/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 883us/step - loss: 1.4901 - acc: 0.5437 - val_loss: 3.5423 - val_acc: 0.2284\n",
      "\n",
      "Epoch 143/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 912us/step - loss: 1.4803 - acc: 0.5472 - val_loss: 3.5380 - val_acc: 0.2284\n",
      "\n",
      "Epoch 144/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 823us/step - loss: 1.4705 - acc: 0.5506 - val_loss: 3.5333 - val_acc: 0.2284\n",
      "\n",
      "Epoch 145/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 892us/step - loss: 1.4610 - acc: 0.5575 - val_loss: 3.5294 - val_acc: 0.2284\n",
      "\n",
      "Epoch 146/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 826us/step - loss: 1.4511 - acc: 0.5592 - val_loss: 3.5249 - val_acc: 0.2284\n",
      "\n",
      "Epoch 147/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 1.4416 - acc: 0.5609 - val_loss: 3.5207 - val_acc: 0.2284\n",
      "\n",
      "Epoch 148/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 919us/step - loss: 1.4324 - acc: 0.5626 - val_loss: 3.5168 - val_acc: 0.2284TA: 0s - loss: 1.4625 - acc: 0.\n",
      "\n",
      "Epoch 149/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 829us/step - loss: 1.4233 - acc: 0.5626 - val_loss: 3.5131 - val_acc: 0.2284\n",
      "\n",
      "Epoch 150/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 1.4139 - acc: 0.5643 - val_loss: 3.5090 - val_acc: 0.2284\n",
      "\n",
      "Epoch 151/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 911us/step - loss: 1.4046 - acc: 0.5678 - val_loss: 3.5043 - val_acc: 0.2284TA: 0s - loss: 1.3941 - acc: 0.5\n",
      "\n",
      "Epoch 152/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 862us/step - loss: 1.3958 - acc: 0.5712 - val_loss: 3.4994 - val_acc: 0.2284\n",
      "\n",
      "Epoch 153/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 883us/step - loss: 1.3868 - acc: 0.5729 - val_loss: 3.4954 - val_acc: 0.2284\n",
      "\n",
      "Epoch 154/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 829us/step - loss: 1.3781 - acc: 0.5729 - val_loss: 3.4913 - val_acc: 0.2284\n",
      "\n",
      "Epoch 155/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 912us/step - loss: 1.3696 - acc: 0.5780 - val_loss: 3.4871 - val_acc: 0.2346\n",
      "\n",
      "Epoch 156/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 966us/step - loss: 1.3610 - acc: 0.5832 - val_loss: 3.4830 - val_acc: 0.2346\n",
      "\n",
      "Epoch 157/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 894us/step - loss: 1.3524 - acc: 0.5849 - val_loss: 3.4788 - val_acc: 0.2346\n",
      "\n",
      "Epoch 158/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 1.3441 - acc: 0.5866 - val_loss: 3.4742 - val_acc: 0.2346\n",
      "\n",
      "Epoch 159/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 856us/step - loss: 1.3359 - acc: 0.5901 - val_loss: 3.4703 - val_acc: 0.2346\n",
      "\n",
      "Epoch 160/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 802us/step - loss: 1.3277 - acc: 0.5918 - val_loss: 3.4660 - val_acc: 0.2407TA: 0s - loss: 1.3155 - acc: 0.59\n",
      "\n",
      "Epoch 161/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 909us/step - loss: 1.3197 - acc: 0.5935 - val_loss: 3.4625 - val_acc: 0.2346\n",
      "\n",
      "Epoch 162/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 835us/step - loss: 1.3119 - acc: 0.5986 - val_loss: 3.4588 - val_acc: 0.2346\n",
      "\n",
      "Epoch 163/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 909us/step - loss: 1.3037 - acc: 0.6003 - val_loss: 3.4549 - val_acc: 0.2346\n",
      "\n",
      "Epoch 164/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 881us/step - loss: 1.2959 - acc: 0.6003 - val_loss: 3.4507 - val_acc: 0.2284TA: 0s - loss: 1.3380 - acc: \n",
      "\n",
      "Epoch 165/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 837us/step - loss: 1.2879 - acc: 0.6021 - val_loss: 3.4466 - val_acc: 0.2284\n",
      "\n",
      "Epoch 166/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 861us/step - loss: 1.2803 - acc: 0.6038 - val_loss: 3.4431 - val_acc: 0.2284\n",
      "\n",
      "Epoch 167/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 827us/step - loss: 1.2727 - acc: 0.6038 - val_loss: 3.4389 - val_acc: 0.2284\n",
      "\n",
      "Epoch 168/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 804us/step - loss: 1.2651 - acc: 0.6055 - val_loss: 3.4349 - val_acc: 0.2284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 169/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 871us/step - loss: 1.2575 - acc: 0.6106 - val_loss: 3.4314 - val_acc: 0.2284\n",
      "\n",
      "Epoch 170/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 805us/step - loss: 1.2500 - acc: 0.6158 - val_loss: 3.4278 - val_acc: 0.2284\n",
      "\n",
      "Epoch 171/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 827us/step - loss: 1.2427 - acc: 0.6175 - val_loss: 3.4244 - val_acc: 0.2284TA: 0s - loss: 1.2673 - acc: 0.61\n",
      "\n",
      "Epoch 172/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 789us/step - loss: 1.2353 - acc: 0.6209 - val_loss: 3.4198 - val_acc: 0.2284\n",
      "\n",
      "Epoch 173/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 811us/step - loss: 1.2278 - acc: 0.6226 - val_loss: 3.4165 - val_acc: 0.2284\n",
      "\n",
      "Epoch 174/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 812us/step - loss: 1.2207 - acc: 0.6278 - val_loss: 3.4128 - val_acc: 0.2284\n",
      "\n",
      "Epoch 175/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 825us/step - loss: 1.2135 - acc: 0.6329 - val_loss: 3.4096 - val_acc: 0.2284\n",
      "\n",
      "Epoch 176/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 948us/step - loss: 1.2064 - acc: 0.6346 - val_loss: 3.4060 - val_acc: 0.2284\n",
      "\n",
      "Epoch 177/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 877us/step - loss: 1.1991 - acc: 0.6346 - val_loss: 3.4026 - val_acc: 0.2284\n",
      "\n",
      "Epoch 178/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 926us/step - loss: 1.1922 - acc: 0.6398 - val_loss: 3.3994 - val_acc: 0.2284\n",
      "\n",
      "Epoch 179/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 1.1852 - acc: 0.6449 - val_loss: 3.3956 - val_acc: 0.2346\n",
      "\n",
      "Epoch 180/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 968us/step - loss: 1.1782 - acc: 0.6501 - val_loss: 3.3922 - val_acc: 0.2346\n",
      "\n",
      "Epoch 181/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 900us/step - loss: 1.1713 - acc: 0.6569 - val_loss: 3.3886 - val_acc: 0.2346\n",
      "\n",
      "Epoch 182/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 905us/step - loss: 1.1647 - acc: 0.6621 - val_loss: 3.3850 - val_acc: 0.2346============================>.] - ETA: 0s - loss: 1.1678 - acc: 0.663\n",
      "\n",
      "Epoch 183/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 890us/step - loss: 1.1580 - acc: 0.6638 - val_loss: 3.3817 - val_acc: 0.2346TA: 0s - loss: 1.1366 - acc: 0.6\n",
      "\n",
      "Epoch 184/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 904us/step - loss: 1.1515 - acc: 0.6655 - val_loss: 3.3786 - val_acc: 0.2346\n",
      "\n",
      "Epoch 185/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 842us/step - loss: 1.1450 - acc: 0.6690 - val_loss: 3.3752 - val_acc: 0.2346\n",
      "\n",
      "Epoch 186/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 921us/step - loss: 1.1383 - acc: 0.6690 - val_loss: 3.3716 - val_acc: 0.2346\n",
      "\n",
      "Epoch 187/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 828us/step - loss: 1.1317 - acc: 0.6775 - val_loss: 3.3687 - val_acc: 0.2346\n",
      "\n",
      "Epoch 188/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 944us/step - loss: 1.1252 - acc: 0.6775 - val_loss: 3.3654 - val_acc: 0.2346\n",
      "\n",
      "Epoch 189/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 945us/step - loss: 1.1190 - acc: 0.6792 - val_loss: 3.3624 - val_acc: 0.2346\n",
      "\n",
      "Epoch 190/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 1.1127 - acc: 0.6810 - val_loss: 3.3593 - val_acc: 0.2346\n",
      "\n",
      "Epoch 191/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 1.1065 - acc: 0.6810 - val_loss: 3.3562 - val_acc: 0.2346\n",
      "\n",
      "Epoch 192/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 883us/step - loss: 1.1003 - acc: 0.6827 - val_loss: 3.3531 - val_acc: 0.2346\n",
      "\n",
      "Epoch 193/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 856us/step - loss: 1.0941 - acc: 0.6878 - val_loss: 3.3501 - val_acc: 0.2346\n",
      "\n",
      "Epoch 194/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 954us/step - loss: 1.0879 - acc: 0.6913 - val_loss: 3.3465 - val_acc: 0.2346TA: 0s - loss: 1.0576 - acc: 0.6\n",
      "\n",
      "Epoch 195/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 930us/step - loss: 1.0816 - acc: 0.6947 - val_loss: 3.3435 - val_acc: 0.2346\n",
      "\n",
      "Epoch 196/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 802us/step - loss: 1.0757 - acc: 0.6981 - val_loss: 3.3409 - val_acc: 0.2346\n",
      "\n",
      "Epoch 197/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 942us/step - loss: 1.0698 - acc: 0.6998 - val_loss: 3.3378 - val_acc: 0.2346\n",
      "\n",
      "Epoch 198/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 853us/step - loss: 1.0640 - acc: 0.7033 - val_loss: 3.3346 - val_acc: 0.2407\n",
      "\n",
      "Epoch 199/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 1.0583 - acc: 0.7050 - val_loss: 3.3313 - val_acc: 0.2469\n",
      "\n",
      "Epoch 200/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 889us/step - loss: 1.0526 - acc: 0.7084 - val_loss: 3.3288 - val_acc: 0.2531\n",
      "\n",
      "65/65 [==============================]65/65 [==============================] - 0s 460us/step\n",
      "\n",
      "Train on 583 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "583/583 [==============================]583/583 [==============================] - 3s 6ms/step - loss: 5.3797 - acc: 0.1046 - val_loss: 5.6986 - val_acc: 0.0988\n",
      "\n",
      "Epoch 2/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 979us/step - loss: 5.2806 - acc: 0.1063 - val_loss: 5.6666 - val_acc: 0.0988\n",
      "\n",
      "Epoch 3/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 919us/step - loss: 5.1825 - acc: 0.1115 - val_loss: 5.6366 - val_acc: 0.0988\n",
      "\n",
      "Epoch 4/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 5.0857 - acc: 0.1132 - val_loss: 5.6039 - val_acc: 0.0988\n",
      "\n",
      "Epoch 5/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 948us/step - loss: 4.9923 - acc: 0.1184 - val_loss: 5.5712 - val_acc: 0.0988\n",
      "\n",
      "Epoch 6/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 4.9031 - acc: 0.1201 - val_loss: 5.5413 - val_acc: 0.0864\n",
      "\n",
      "Epoch 7/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 912us/step - loss: 4.8167 - acc: 0.1235 - val_loss: 5.5109 - val_acc: 0.0926\n",
      "\n",
      "Epoch 8/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 884us/step - loss: 4.7309 - acc: 0.1286 - val_loss: 5.4785 - val_acc: 0.0926\n",
      "\n",
      "Epoch 9/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 944us/step - loss: 4.6476 - acc: 0.1355 - val_loss: 5.4488 - val_acc: 0.0926\n",
      "\n",
      "Epoch 10/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 4.5698 - acc: 0.1441 - val_loss: 5.4218 - val_acc: 0.0926s - loss: 4.6235 - acc: 0.13576/583 [============================>.] - ETA: 0s - loss: 4.5579 - acc: 0.142\n",
      "\n",
      "Epoch 11/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 913us/step - loss: 4.4945 - acc: 0.1509 - val_loss: 5.3950 - val_acc: 0.0926\n",
      "\n",
      "Epoch 12/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 970us/step - loss: 4.4219 - acc: 0.1578 - val_loss: 5.3699 - val_acc: 0.0988\n",
      "\n",
      "Epoch 13/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 4.3524 - acc: 0.1647 - val_loss: 5.3450 - val_acc: 0.1049\n",
      "\n",
      "Epoch 14/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 970us/step - loss: 4.2824 - acc: 0.1647 - val_loss: 5.3210 - val_acc: 0.1049\n",
      "\n",
      "Epoch 15/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 889us/step - loss: 4.2157 - acc: 0.1664 - val_loss: 5.2978 - val_acc: 0.1049TA: 0s - loss: 4.2047 - acc: 0.1512/583 [=========================>....] - ETA: 0s - loss: 4.1984 - acc: 0.16\n",
      "\n",
      "Epoch 16/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 979us/step - loss: 4.1521 - acc: 0.1698 - val_loss: 5.2762 - val_acc: 0.1049TA: 0s - loss: 4.2145 - acc: 0.\n",
      "\n",
      "Epoch 17/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 4.0902 - acc: 0.1750 - val_loss: 5.2542 - val_acc: 0.1049\n",
      "\n",
      "Epoch 18/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 4.0304 - acc: 0.1801 - val_loss: 5.2317 - val_acc: 0.1049\n",
      "\n",
      "Epoch 19/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 3.9725 - acc: 0.1801 - val_loss: 5.2113 - val_acc: 0.1049\n",
      "\n",
      "Epoch 20/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 877us/step - loss: 3.9170 - acc: 0.1801 - val_loss: 5.1929 - val_acc: 0.1049TA: 0s - loss: 3.7151 - acc:\n",
      "\n",
      "Epoch 21/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 915us/step - loss: 3.8652 - acc: 0.1835 - val_loss: 5.1719 - val_acc: 0.1049\n",
      "\n",
      "Epoch 22/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 958us/step - loss: 3.8120 - acc: 0.1852 - val_loss: 5.1537 - val_acc: 0.1049\n",
      "\n",
      "Epoch 23/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 3.7599 - acc: 0.1852 - val_loss: 5.1339 - val_acc: 0.1111\n",
      "\n",
      "Epoch 24/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 3.7099 - acc: 0.1904 - val_loss: 5.1159 - val_acc: 0.1111\n",
      "\n",
      "Epoch 25/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 891us/step - loss: 3.6618 - acc: 0.1938 - val_loss: 5.0986 - val_acc: 0.1111\n",
      "\n",
      "Epoch 26/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 3.6133 - acc: 0.2024 - val_loss: 5.0812 - val_acc: 0.1111\n",
      "\n",
      "Epoch 27/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 802us/step - loss: 3.5643 - acc: 0.2058 - val_loss: 5.0652 - val_acc: 0.1111\n",
      "\n",
      "Epoch 28/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 856us/step - loss: 3.5177 - acc: 0.2093 - val_loss: 5.0501 - val_acc: 0.1111TA: 0s - loss: 3.4600 - acc: 0.512/583 [=========================>....] - ETA: 0s - loss: 3.5404 - acc: 0.207\n",
      "\n",
      "Epoch 29/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 950us/step - loss: 3.4714 - acc: 0.2144 - val_loss: 5.0353 - val_acc: 0.1111TA: 0s - loss: 3.4689 - acc:\n",
      "\n",
      "Epoch 30/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 907us/step - loss: 3.4278 - acc: 0.2230 - val_loss: 5.0186 - val_acc: 0.1173\n",
      "\n",
      "Epoch 31/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 3.3836 - acc: 0.2281 - val_loss: 5.0042 - val_acc: 0.1173583 [======================>.......] - ETA: 0s - loss: 3.3655 - acc: 0.22\n",
      "\n",
      "Epoch 32/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 875us/step - loss: 3.3408 - acc: 0.2298 - val_loss: 4.9895 - val_acc: 0.1173\n",
      "\n",
      "Epoch 33/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 790us/step - loss: 3.2998 - acc: 0.2333 - val_loss: 4.9741 - val_acc: 0.1173\n",
      "\n",
      "Epoch 34/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 3.2579 - acc: 0.2350 - val_loss: 4.9619 - val_acc: 0.1111TA: 0s - loss: 3.2625 - acc: 0.232\n",
      "\n",
      "Epoch 35/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 833us/step - loss: 3.2174 - acc: 0.2401 - val_loss: 4.9481 - val_acc: 0.1111\n",
      "\n",
      "Epoch 36/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 895us/step - loss: 3.1785 - acc: 0.2487 - val_loss: 4.9342 - val_acc: 0.1111TA: 0s - loss: 3.2487 - acc: 0.2576/583 [============================>.] - ETA: 0s - loss: 3.1389 - acc: 0.250\n",
      "\n",
      "Epoch 37/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 823us/step - loss: 3.1387 - acc: 0.2539 - val_loss: 4.9208 - val_acc: 0.1111\n",
      "\n",
      "Epoch 38/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 3.1003 - acc: 0.2521 - val_loss: 4.9076 - val_acc: 0.1173\n",
      "\n",
      "Epoch 39/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 826us/step - loss: 3.0622 - acc: 0.2539 - val_loss: 4.8955 - val_acc: 0.1173\n",
      "\n",
      "Epoch 40/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 862us/step - loss: 3.0239 - acc: 0.2556 - val_loss: 4.8800 - val_acc: 0.1173\n",
      "\n",
      "Epoch 41/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 943us/step - loss: 2.9874 - acc: 0.2607 - val_loss: 4.8690 - val_acc: 0.1235\n",
      "\n",
      "Epoch 42/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 897us/step - loss: 2.9512 - acc: 0.2659 - val_loss: 4.8600 - val_acc: 0.1235\n",
      "\n",
      "Epoch 43/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 2.9156 - acc: 0.2762 - val_loss: 4.8484 - val_acc: 0.1235TA: 0s - loss: 2.7170 - acc: \n",
      "\n",
      "Epoch 44/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 952us/step - loss: 2.8813 - acc: 0.2779 - val_loss: 4.8375 - val_acc: 0.1296\n",
      "\n",
      "Epoch 45/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 893us/step - loss: 2.8472 - acc: 0.2847 - val_loss: 4.8277 - val_acc: 0.1296\n",
      "\n",
      "Epoch 46/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 999us/step - loss: 2.8144 - acc: 0.2899 - val_loss: 4.8188 - val_acc: 0.1296 - loss: 2.8058 - acc: 0.285\n",
      "\n",
      "Epoch 47/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 974us/step - loss: 2.7825 - acc: 0.2933 - val_loss: 4.8085 - val_acc: 0.1296\n",
      "\n",
      "Epoch 48/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.7510 - acc: 0.3036 - val_loss: 4.7978 - val_acc: 0.1296\n",
      "\n",
      "Epoch 49/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 921us/step - loss: 2.7201 - acc: 0.3139 - val_loss: 4.7889 - val_acc: 0.1296\n",
      "\n",
      "Epoch 50/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 878us/step - loss: 2.6887 - acc: 0.3173 - val_loss: 4.7788 - val_acc: 0.1296\n",
      "\n",
      "Epoch 51/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 828us/step - loss: 2.6583 - acc: 0.3276 - val_loss: 4.7699 - val_acc: 0.1296\n",
      "\n",
      "Epoch 52/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 943us/step - loss: 2.6287 - acc: 0.3328 - val_loss: 4.7604 - val_acc: 0.1296\n",
      "\n",
      "Epoch 53/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 942us/step - loss: 2.5995 - acc: 0.3413 - val_loss: 4.7503 - val_acc: 0.1296\n",
      "\n",
      "Epoch 54/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================]583/583 [==============================] - 1s 910us/step - loss: 2.5709 - acc: 0.3448 - val_loss: 4.7417 - val_acc: 0.1296TA: 0s - loss: 2.4706 - acc: 0.36\n",
      "\n",
      "Epoch 55/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 974us/step - loss: 2.5425 - acc: 0.3482 - val_loss: 4.7330 - val_acc: 0.1296\n",
      "\n",
      "Epoch 56/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 2.5140 - acc: 0.3551 - val_loss: 4.7246 - val_acc: 0.1296\n",
      "\n",
      "Epoch 57/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.4863 - acc: 0.3551 - val_loss: 4.7150 - val_acc: 0.1358\n",
      "\n",
      "Epoch 58/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 924us/step - loss: 2.4584 - acc: 0.3568 - val_loss: 4.7073 - val_acc: 0.1358\n",
      "\n",
      "Epoch 59/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 908us/step - loss: 2.4312 - acc: 0.3619 - val_loss: 4.6991 - val_acc: 0.1358\n",
      "\n",
      "Epoch 60/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.4050 - acc: 0.3739 - val_loss: 4.6904 - val_acc: 0.1358 ETA: 0s - loss: 2.4033 - acc: 0.379 - ETA: 0s - loss: 2.3819 - acc: 0.380\n",
      "\n",
      "Epoch 61/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.3791 - acc: 0.3722 - val_loss: 4.6810 - val_acc: 0.1358\n",
      "\n",
      "Epoch 62/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 916us/step - loss: 2.3530 - acc: 0.3774 - val_loss: 4.6736 - val_acc: 0.1358\n",
      "\n",
      "Epoch 63/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 927us/step - loss: 2.3278 - acc: 0.3825 - val_loss: 4.6675 - val_acc: 0.1296\n",
      "\n",
      "Epoch 64/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 924us/step - loss: 2.3033 - acc: 0.3842 - val_loss: 4.6596 - val_acc: 0.1296\n",
      "\n",
      "Epoch 65/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 912us/step - loss: 2.2791 - acc: 0.3894 - val_loss: 4.6522 - val_acc: 0.1296\n",
      "\n",
      "Epoch 66/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 978us/step - loss: 2.2551 - acc: 0.3911 - val_loss: 4.6451 - val_acc: 0.1296\n",
      "\n",
      "Epoch 67/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 911us/step - loss: 2.2323 - acc: 0.3928 - val_loss: 4.6374 - val_acc: 0.1296\n",
      "\n",
      "Epoch 68/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 2.2088 - acc: 0.4014 - val_loss: 4.6306 - val_acc: 0.1296\n",
      "\n",
      "Epoch 69/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 2.1867 - acc: 0.4065 - val_loss: 4.6231 - val_acc: 0.1296\n",
      "\n",
      "Epoch 70/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 896us/step - loss: 2.1649 - acc: 0.4099 - val_loss: 4.6165 - val_acc: 0.1296\n",
      "\n",
      "Epoch 71/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 2.1441 - acc: 0.4117 - val_loss: 4.6103 - val_acc: 0.1358\n",
      "\n",
      "Epoch 72/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 2.1235 - acc: 0.4134 - val_loss: 4.6044 - val_acc: 0.1296\n",
      "\n",
      "Epoch 73/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 927us/step - loss: 2.1031 - acc: 0.4185 - val_loss: 4.5985 - val_acc: 0.1296\n",
      "\n",
      "Epoch 74/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 847us/step - loss: 2.0825 - acc: 0.4220 - val_loss: 4.5918 - val_acc: 0.1296\n",
      "\n",
      "Epoch 75/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 891us/step - loss: 2.0621 - acc: 0.4271 - val_loss: 4.5860 - val_acc: 0.1296\n",
      "\n",
      "Epoch 76/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 862us/step - loss: 2.0428 - acc: 0.4322 - val_loss: 4.5795 - val_acc: 0.1296\n",
      "\n",
      "Epoch 77/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 2.0234 - acc: 0.4357 - val_loss: 4.5741 - val_acc: 0.1296\n",
      "\n",
      "Epoch 78/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 922us/step - loss: 2.0045 - acc: 0.4374 - val_loss: 4.5676 - val_acc: 0.1296\n",
      "\n",
      "Epoch 79/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 1.9854 - acc: 0.4391 - val_loss: 4.5618 - val_acc: 0.1296\n",
      "\n",
      "Epoch 80/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 817us/step - loss: 1.9669 - acc: 0.4408 - val_loss: 4.5559 - val_acc: 0.1296\n",
      "\n",
      "Epoch 81/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 1.9489 - acc: 0.4443 - val_loss: 4.5498 - val_acc: 0.1296TA: 0s - loss: 1.9311 - acc:\n",
      "\n",
      "Epoch 82/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 935us/step - loss: 1.9304 - acc: 0.4477 - val_loss: 4.5444 - val_acc: 0.1296\n",
      "\n",
      "Epoch 83/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 810us/step - loss: 1.9129 - acc: 0.4477 - val_loss: 4.5388 - val_acc: 0.1296\n",
      "\n",
      "Epoch 84/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 800us/step - loss: 1.8950 - acc: 0.4580 - val_loss: 4.5343 - val_acc: 0.1296\n",
      "\n",
      "Epoch 85/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 800us/step - loss: 1.8777 - acc: 0.4614 - val_loss: 4.5284 - val_acc: 0.1296TA: 0s - loss: 1.8891 - acc: 0.457\n",
      "\n",
      "Epoch 86/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 912us/step - loss: 1.8611 - acc: 0.4666 - val_loss: 4.5231 - val_acc: 0.1296\n",
      "\n",
      "Epoch 87/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 943us/step - loss: 1.8450 - acc: 0.4734 - val_loss: 4.5184 - val_acc: 0.1296\n",
      "\n",
      "Epoch 88/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.8288 - acc: 0.4803 - val_loss: 4.5125 - val_acc: 0.1296\n",
      "\n",
      "Epoch 89/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 826us/step - loss: 1.8130 - acc: 0.4837 - val_loss: 4.5068 - val_acc: 0.1296\n",
      "\n",
      "Epoch 90/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 857us/step - loss: 1.7972 - acc: 0.4837 - val_loss: 4.5007 - val_acc: 0.1296\n",
      "\n",
      "Epoch 91/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 925us/step - loss: 1.7815 - acc: 0.4871 - val_loss: 4.4944 - val_acc: 0.1296TA: 0s - loss: 1.8985 - acc: 0\n",
      "\n",
      "Epoch 92/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 929us/step - loss: 1.7659 - acc: 0.4957 - val_loss: 4.4886 - val_acc: 0.1296\n",
      "\n",
      "Epoch 93/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 885us/step - loss: 1.7505 - acc: 0.4957 - val_loss: 4.4837 - val_acc: 0.1296\n",
      "\n",
      "Epoch 94/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 802us/step - loss: 1.7355 - acc: 0.5026 - val_loss: 4.4785 - val_acc: 0.1296\n",
      "\n",
      "Epoch 95/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 946us/step - loss: 1.7210 - acc: 0.5043 - val_loss: 4.4731 - val_acc: 0.1296\n",
      "\n",
      "Epoch 96/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 914us/step - loss: 1.7064 - acc: 0.5060 - val_loss: 4.4681 - val_acc: 0.1296\n",
      "\n",
      "Epoch 97/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 857us/step - loss: 1.6921 - acc: 0.5180 - val_loss: 4.4624 - val_acc: 0.1296\n",
      "\n",
      "Epoch 98/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 863us/step - loss: 1.6779 - acc: 0.5232 - val_loss: 4.4564 - val_acc: 0.1296\n",
      "\n",
      "Epoch 99/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 854us/step - loss: 1.6640 - acc: 0.5232 - val_loss: 4.4521 - val_acc: 0.1296TA: 0s - loss: 1.6000 - acc: 0\n",
      "\n",
      "Epoch 100/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 865us/step - loss: 1.6503 - acc: 0.5232 - val_loss: 4.4471 - val_acc: 0.1296\n",
      "\n",
      "Epoch 101/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 894us/step - loss: 1.6369 - acc: 0.5266 - val_loss: 4.4417 - val_acc: 0.1296\n",
      "\n",
      "Epoch 102/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 950us/step - loss: 1.6233 - acc: 0.5283 - val_loss: 4.4368 - val_acc: 0.1296\n",
      "\n",
      "Epoch 103/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 1.6098 - acc: 0.5317 - val_loss: 4.4325 - val_acc: 0.1296\n",
      "\n",
      "Epoch 104/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 1.5967 - acc: 0.5334 - val_loss: 4.4273 - val_acc: 0.1296\n",
      "\n",
      "Epoch 105/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 971us/step - loss: 1.5834 - acc: 0.5386 - val_loss: 4.4226 - val_acc: 0.1296TA: 0s - loss: 1.5943 - acc: 0.52\n",
      "\n",
      "Epoch 106/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 852us/step - loss: 1.5707 - acc: 0.5420 - val_loss: 4.4186 - val_acc: 0.1296\n",
      "\n",
      "Epoch 107/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 919us/step - loss: 1.5581 - acc: 0.5420 - val_loss: 4.4146 - val_acc: 0.1296TA: 0s - loss: 1.6208 - acc: 0.5\n",
      "\n",
      "Epoch 108/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 889us/step - loss: 1.5457 - acc: 0.5472 - val_loss: 4.4108 - val_acc: 0.1296\n",
      "\n",
      "Epoch 109/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 919us/step - loss: 1.5334 - acc: 0.5506 - val_loss: 4.4072 - val_acc: 0.1296TA: 0s - loss: 1.5134 - acc: 0.\n",
      "\n",
      "Epoch 110/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 993us/step - loss: 1.5214 - acc: 0.5557 - val_loss: 4.4037 - val_acc: 0.1296\n",
      "\n",
      "Epoch 111/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 967us/step - loss: 1.5089 - acc: 0.5609 - val_loss: 4.4007 - val_acc: 0.1296\n",
      "\n",
      "Epoch 112/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 938us/step - loss: 1.4969 - acc: 0.5678 - val_loss: 4.3959 - val_acc: 0.1296\n",
      "\n",
      "Epoch 113/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 1.4851 - acc: 0.5746 - val_loss: 4.3923 - val_acc: 0.1296\n",
      "\n",
      "Epoch 114/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 928us/step - loss: 1.4739 - acc: 0.5798 - val_loss: 4.3881 - val_acc: 0.1296\n",
      "\n",
      "Epoch 115/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.4624 - acc: 0.5866 - val_loss: 4.3846 - val_acc: 0.1296\n",
      "\n",
      "Epoch 116/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 866us/step - loss: 1.4510 - acc: 0.5866 - val_loss: 4.3799 - val_acc: 0.1296\n",
      "\n",
      "Epoch 117/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 823us/step - loss: 1.4395 - acc: 0.5866 - val_loss: 4.3758 - val_acc: 0.1296\n",
      "\n",
      "Epoch 118/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 787us/step - loss: 1.4284 - acc: 0.5918 - val_loss: 4.3723 - val_acc: 0.1296\n",
      "\n",
      "Epoch 119/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 994us/step - loss: 1.4174 - acc: 0.5935 - val_loss: 4.3678 - val_acc: 0.1296\n",
      "\n",
      "Epoch 120/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 964us/step - loss: 1.4065 - acc: 0.5935 - val_loss: 4.3647 - val_acc: 0.1296\n",
      "\n",
      "Epoch 121/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 1.3959 - acc: 0.5952 - val_loss: 4.3614 - val_acc: 0.1358TA: 0s - loss: 1.4742 - acc: 0.\n",
      "\n",
      "Epoch 122/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 884us/step - loss: 1.3853 - acc: 0.5986 - val_loss: 4.3586 - val_acc: 0.1358\n",
      "\n",
      "Epoch 123/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 861us/step - loss: 1.3750 - acc: 0.5986 - val_loss: 4.3554 - val_acc: 0.1358\n",
      "\n",
      "Epoch 124/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 882us/step - loss: 1.3645 - acc: 0.6038 - val_loss: 4.3528 - val_acc: 0.1358\n",
      "\n",
      "Epoch 125/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 908us/step - loss: 1.3543 - acc: 0.6038 - val_loss: 4.3497 - val_acc: 0.1358\n",
      "\n",
      "Epoch 126/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 1.3444 - acc: 0.6055 - val_loss: 4.3466 - val_acc: 0.1358\n",
      "\n",
      "Epoch 127/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 811us/step - loss: 1.3346 - acc: 0.6089 - val_loss: 4.3439 - val_acc: 0.1358TA: 0s - loss: 1.3154 - acc: 0.6\n",
      "\n",
      "Epoch 128/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 909us/step - loss: 1.3249 - acc: 0.6123 - val_loss: 4.3405 - val_acc: 0.1358\n",
      "\n",
      "Epoch 129/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 911us/step - loss: 1.3152 - acc: 0.6123 - val_loss: 4.3377 - val_acc: 0.1358\n",
      "\n",
      "Epoch 130/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 953us/step - loss: 1.3059 - acc: 0.6141 - val_loss: 4.3348 - val_acc: 0.1358\n",
      "\n",
      "Epoch 131/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 1.2965 - acc: 0.6158 - val_loss: 4.3313 - val_acc: 0.1358\n",
      "\n",
      "Epoch 132/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 941us/step - loss: 1.2874 - acc: 0.6158 - val_loss: 4.3282 - val_acc: 0.1358\n",
      "\n",
      "Epoch 133/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 883us/step - loss: 1.2783 - acc: 0.6192 - val_loss: 4.3251 - val_acc: 0.1358TA: 0s - loss: 1.2251 - acc: 0.6\n",
      "\n",
      "Epoch 134/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 889us/step - loss: 1.2693 - acc: 0.6192 - val_loss: 4.3220 - val_acc: 0.1358\n",
      "\n",
      "Epoch 135/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 851us/step - loss: 1.2604 - acc: 0.6192 - val_loss: 4.3194 - val_acc: 0.1358\n",
      "\n",
      "Epoch 136/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 961us/step - loss: 1.2514 - acc: 0.6261 - val_loss: 4.3158 - val_acc: 0.1358\n",
      "\n",
      "Epoch 137/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 898us/step - loss: 1.2427 - acc: 0.6261 - val_loss: 4.3130 - val_acc: 0.13580s - loss: 1.2980 - acc: 0.60\n",
      "\n",
      "Epoch 138/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 914us/step - loss: 1.2340 - acc: 0.6278 - val_loss: 4.3101 - val_acc: 0.1420\n",
      "\n",
      "Epoch 139/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 913us/step - loss: 1.2250 - acc: 0.6329 - val_loss: 4.3069 - val_acc: 0.1420\n",
      "\n",
      "Epoch 140/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 1.2166 - acc: 0.6364 - val_loss: 4.3038 - val_acc: 0.1420\n",
      "\n",
      "Epoch 141/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 890us/step - loss: 1.2079 - acc: 0.6381 - val_loss: 4.3007 - val_acc: 0.1420TA: 0s - loss: 1.1740 - acc: 0.63448/583 [======================>.......] - ETA: 0s - loss: 1.2479 - acc: 0.6\n",
      "\n",
      "Epoch 142/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 935us/step - loss: 1.1996 - acc: 0.6415 - val_loss: 4.2983 - val_acc: 0.1420\n",
      "\n",
      "Epoch 143/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================]583/583 [==============================] - 1s 878us/step - loss: 1.1913 - acc: 0.6432 - val_loss: 4.2952 - val_acc: 0.1420\n",
      "\n",
      "Epoch 144/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 858us/step - loss: 1.1832 - acc: 0.6449 - val_loss: 4.2927 - val_acc: 0.1420\n",
      "\n",
      "Epoch 145/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 943us/step - loss: 1.1754 - acc: 0.6484 - val_loss: 4.2909 - val_acc: 0.1420\n",
      "\n",
      "Epoch 146/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 936us/step - loss: 1.1676 - acc: 0.6501 - val_loss: 4.2879 - val_acc: 0.1420\n",
      "\n",
      "Epoch 147/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 838us/step - loss: 1.1597 - acc: 0.6501 - val_loss: 4.2857 - val_acc: 0.1420TA: 0s - loss: 1.2709 - acc: 0\n",
      "\n",
      "Epoch 148/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 912us/step - loss: 1.1517 - acc: 0.6552 - val_loss: 4.2827 - val_acc: 0.1420\n",
      "\n",
      "Epoch 149/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 803us/step - loss: 1.1440 - acc: 0.6535 - val_loss: 4.2799 - val_acc: 0.1420\n",
      "\n",
      "Epoch 150/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 942us/step - loss: 1.1363 - acc: 0.6604 - val_loss: 4.2769 - val_acc: 0.1420\n",
      "\n",
      "Epoch 151/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 830us/step - loss: 1.1287 - acc: 0.6655 - val_loss: 4.2740 - val_acc: 0.1420\n",
      "\n",
      "Epoch 152/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 883us/step - loss: 1.1210 - acc: 0.6655 - val_loss: 4.2719 - val_acc: 0.1420TA: 0s - loss: 1.0149 - acc: 0\n",
      "\n",
      "Epoch 153/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 889us/step - loss: 1.1135 - acc: 0.6690 - val_loss: 4.2697 - val_acc: 0.1420TA: 0s - loss: 1.1111 - acc: 0.\n",
      "\n",
      "Epoch 154/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 928us/step - loss: 1.1061 - acc: 0.6690 - val_loss: 4.2660 - val_acc: 0.1420\n",
      "\n",
      "Epoch 155/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 926us/step - loss: 1.0985 - acc: 0.6724 - val_loss: 4.2637 - val_acc: 0.1420\n",
      "\n",
      "Epoch 156/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 1.0912 - acc: 0.6758 - val_loss: 4.2610 - val_acc: 0.1481\n",
      "\n",
      "Epoch 157/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 1.0837 - acc: 0.6775 - val_loss: 4.2578 - val_acc: 0.1481\n",
      "\n",
      "Epoch 158/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 1.0763 - acc: 0.6792 - val_loss: 4.2561 - val_acc: 0.1481\n",
      "\n",
      "Epoch 159/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 970us/step - loss: 1.0692 - acc: 0.6827 - val_loss: 4.2537 - val_acc: 0.1481\n",
      "\n",
      "Epoch 160/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 1.0622 - acc: 0.6861 - val_loss: 4.2511 - val_acc: 0.1481\n",
      "\n",
      "Epoch 161/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 1.0554 - acc: 0.6861 - val_loss: 4.2493 - val_acc: 0.1481\n",
      "\n",
      "Epoch 162/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.0484 - acc: 0.6895 - val_loss: 4.2465 - val_acc: 0.1543\n",
      "\n",
      "Epoch 163/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 1.0416 - acc: 0.6895 - val_loss: 4.2439 - val_acc: 0.1543\n",
      "\n",
      "Epoch 164/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 795us/step - loss: 1.0346 - acc: 0.6913 - val_loss: 4.2408 - val_acc: 0.1543\n",
      "\n",
      "Epoch 165/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 857us/step - loss: 1.0278 - acc: 0.6947 - val_loss: 4.2378 - val_acc: 0.1543\n",
      "\n",
      "Epoch 166/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 956us/step - loss: 1.0211 - acc: 0.6947 - val_loss: 4.2353 - val_acc: 0.1543\n",
      "\n",
      "Epoch 167/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 1.0145 - acc: 0.6947 - val_loss: 4.2332 - val_acc: 0.1543\n",
      "\n",
      "Epoch 168/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 894us/step - loss: 1.0079 - acc: 0.6981 - val_loss: 4.2307 - val_acc: 0.1543TA: 0s - loss: 0.8640 - acc: \n",
      "\n",
      "Epoch 169/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 889us/step - loss: 1.0015 - acc: 0.6981 - val_loss: 4.2290 - val_acc: 0.1543\n",
      "\n",
      "Epoch 170/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 966us/step - loss: 0.9951 - acc: 0.7015 - val_loss: 4.2266 - val_acc: 0.1543\n",
      "\n",
      "Epoch 171/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 780us/step - loss: 0.9889 - acc: 0.7015 - val_loss: 4.2245 - val_acc: 0.1543\n",
      "\n",
      "Epoch 172/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 0.9827 - acc: 0.7050 - val_loss: 4.2224 - val_acc: 0.1543\n",
      "\n",
      "Epoch 173/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 854us/step - loss: 0.9765 - acc: 0.7067 - val_loss: 4.2201 - val_acc: 0.1543\n",
      "\n",
      "Epoch 174/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 834us/step - loss: 0.9704 - acc: 0.7170 - val_loss: 4.2177 - val_acc: 0.1543\n",
      "\n",
      "Epoch 175/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 884us/step - loss: 0.9642 - acc: 0.7153 - val_loss: 4.2161 - val_acc: 0.1543\n",
      "\n",
      "Epoch 176/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 827us/step - loss: 0.9583 - acc: 0.7170 - val_loss: 4.2143 - val_acc: 0.1543\n",
      "\n",
      "Epoch 177/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 0.9525 - acc: 0.7221 - val_loss: 4.2121 - val_acc: 0.1543\n",
      "\n",
      "Epoch 178/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 933us/step - loss: 0.9464 - acc: 0.7273 - val_loss: 4.2106 - val_acc: 0.1543\n",
      "\n",
      "Epoch 179/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 861us/step - loss: 0.9404 - acc: 0.7290 - val_loss: 4.2091 - val_acc: 0.1543\n",
      "\n",
      "Epoch 180/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 872us/step - loss: 0.9346 - acc: 0.7324 - val_loss: 4.2075 - val_acc: 0.1543\n",
      "\n",
      "Epoch 181/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 0.9289 - acc: 0.7341 - val_loss: 4.2058 - val_acc: 0.1543\n",
      "\n",
      "Epoch 182/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 849us/step - loss: 0.9233 - acc: 0.7358 - val_loss: 4.2034 - val_acc: 0.1543\n",
      "\n",
      "Epoch 183/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 0.9175 - acc: 0.7376 - val_loss: 4.2020 - val_acc: 0.1543\n",
      "\n",
      "Epoch 184/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 833us/step - loss: 0.9121 - acc: 0.7376 - val_loss: 4.2000 - val_acc: 0.1605\n",
      "\n",
      "Epoch 185/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 825us/step - loss: 0.9066 - acc: 0.7410 - val_loss: 4.1979 - val_acc: 0.1605\n",
      "\n",
      "Epoch 186/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 0.9013 - acc: 0.7427 - val_loss: 4.1959 - val_acc: 0.1605\n",
      "\n",
      "Epoch 187/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 892us/step - loss: 0.8959 - acc: 0.7427 - val_loss: 4.1938 - val_acc: 0.1605\n",
      "\n",
      "Epoch 188/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 881us/step - loss: 0.8905 - acc: 0.7444 - val_loss: 4.1917 - val_acc: 0.1605\n",
      "\n",
      "Epoch 189/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 972us/step - loss: 0.8852 - acc: 0.7461 - val_loss: 4.1897 - val_acc: 0.1605\n",
      "\n",
      "Epoch 190/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 772us/step - loss: 0.8799 - acc: 0.7479 - val_loss: 4.1881 - val_acc: 0.1605\n",
      "\n",
      "Epoch 191/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 884us/step - loss: 0.8747 - acc: 0.7530 - val_loss: 4.1864 - val_acc: 0.1605\n",
      "\n",
      "Epoch 192/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 0.8696 - acc: 0.7547 - val_loss: 4.1850 - val_acc: 0.1605\n",
      "\n",
      "Epoch 193/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 0.8645 - acc: 0.7564 - val_loss: 4.1831 - val_acc: 0.1605TA: 0s - loss: 0.8575 - acc: 0.76 - ETA: 0s - loss: 0.8587 - acc: 0.75\n",
      "\n",
      "Epoch 194/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 0.8593 - acc: 0.7564 - val_loss: 4.1813 - val_acc: 0.1605 ETA: 0s - loss: 0.8430 - acc:\n",
      "\n",
      "Epoch 195/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 842us/step - loss: 0.8542 - acc: 0.7581 - val_loss: 4.1795 - val_acc: 0.1605TA: 0s - loss: 0.8510 - acc: 0.758\n",
      "\n",
      "Epoch 196/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 830us/step - loss: 0.8493 - acc: 0.7616 - val_loss: 4.1775 - val_acc: 0.1605\n",
      "\n",
      "Epoch 197/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 853us/step - loss: 0.8445 - acc: 0.7616 - val_loss: 4.1758 - val_acc: 0.1605\n",
      "\n",
      "Epoch 198/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 951us/step - loss: 0.8396 - acc: 0.7633 - val_loss: 4.1740 - val_acc: 0.1605\n",
      "\n",
      "Epoch 199/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 915us/step - loss: 0.8349 - acc: 0.7650 - val_loss: 4.1724 - val_acc: 0.1605\n",
      "\n",
      "Epoch 200/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 906us/step - loss: 0.8301 - acc: 0.7667 - val_loss: 4.1705 - val_acc: 0.1605\n",
      "\n",
      "65/65 [==============================]65/65 [==============================] - 0s 321us/step\n",
      "\n",
      "Train on 583 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "583/583 [==============================]583/583 [==============================] - 3s 6ms/step - loss: 5.1114 - acc: 0.1218 - val_loss: 5.3154 - val_acc: 0.0988\n",
      "\n",
      "Epoch 2/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 5.0350 - acc: 0.1218 - val_loss: 5.2873 - val_acc: 0.0988\n",
      "\n",
      "Epoch 3/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 4.9612 - acc: 0.1252 - val_loss: 5.2609 - val_acc: 0.0988\n",
      "\n",
      "Epoch 4/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 885us/step - loss: 4.8888 - acc: 0.1286 - val_loss: 5.2359 - val_acc: 0.1049\n",
      "\n",
      "Epoch 5/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 915us/step - loss: 4.8191 - acc: 0.1304 - val_loss: 5.2113 - val_acc: 0.1111\n",
      "\n",
      "Epoch 6/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 884us/step - loss: 4.7508 - acc: 0.1321 - val_loss: 5.1870 - val_acc: 0.1111\n",
      "\n",
      "Epoch 7/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 863us/step - loss: 4.6830 - acc: 0.1338 - val_loss: 5.1621 - val_acc: 0.1111\n",
      "\n",
      "Epoch 8/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 942us/step - loss: 4.6171 - acc: 0.1389 - val_loss: 5.1370 - val_acc: 0.1111\n",
      "\n",
      "Epoch 9/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 847us/step - loss: 4.5515 - acc: 0.1389 - val_loss: 5.1129 - val_acc: 0.1173TA: 0s - loss: 4.4746 - acc: 0.138\n",
      "\n",
      "Epoch 10/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 868us/step - loss: 4.4888 - acc: 0.1407 - val_loss: 5.0899 - val_acc: 0.1235\n",
      "\n",
      "Epoch 11/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 911us/step - loss: 4.4247 - acc: 0.1424 - val_loss: 5.0657 - val_acc: 0.1235\n",
      "\n",
      "Epoch 12/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 4.3645 - acc: 0.1458 - val_loss: 5.0419 - val_acc: 0.1235\n",
      "\n",
      "Epoch 13/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 4.3048 - acc: 0.1509 - val_loss: 5.0186 - val_acc: 0.1235\n",
      "\n",
      "Epoch 14/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 4.2472 - acc: 0.1509 - val_loss: 4.9956 - val_acc: 0.1235\n",
      "\n",
      "Epoch 15/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 854us/step - loss: 4.1908 - acc: 0.1527 - val_loss: 4.9742 - val_acc: 0.1235TA: 0s - loss: 4.1630 - acc: 0.14\n",
      "\n",
      "Epoch 16/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 911us/step - loss: 4.1352 - acc: 0.1561 - val_loss: 4.9544 - val_acc: 0.1235TA: 0s - loss: 4.2170 - acc: 0.15\n",
      "\n",
      "Epoch 17/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 864us/step - loss: 4.0806 - acc: 0.1578 - val_loss: 4.9332 - val_acc: 0.1235\n",
      "\n",
      "Epoch 18/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 852us/step - loss: 4.0274 - acc: 0.1595 - val_loss: 4.9131 - val_acc: 0.1235TA: 0s - loss: 4.1473 - acc: 0.1\n",
      "\n",
      "Epoch 19/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 936us/step - loss: 3.9728 - acc: 0.1595 - val_loss: 4.8912 - val_acc: 0.1235\n",
      "\n",
      "Epoch 20/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 894us/step - loss: 3.9192 - acc: 0.1612 - val_loss: 4.8728 - val_acc: 0.1235TA: 0s - loss: 3.9690 - acc: 0.152\n",
      "\n",
      "Epoch 21/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 910us/step - loss: 3.8687 - acc: 0.1630 - val_loss: 4.8553 - val_acc: 0.1235\n",
      "\n",
      "Epoch 22/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 3.8190 - acc: 0.1664 - val_loss: 4.8369 - val_acc: 0.1235\n",
      "\n",
      "Epoch 23/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 3.7703 - acc: 0.1715 - val_loss: 4.8196 - val_acc: 0.1235\n",
      "\n",
      "Epoch 24/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 881us/step - loss: 3.7223 - acc: 0.1750 - val_loss: 4.8022 - val_acc: 0.1235TA: 0s - loss: 3.7576 - acc: 0.168\n",
      "\n",
      "Epoch 25/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 896us/step - loss: 3.6764 - acc: 0.1750 - val_loss: 4.7855 - val_acc: 0.1235\n",
      "\n",
      "Epoch 26/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 795us/step - loss: 3.6308 - acc: 0.1835 - val_loss: 4.7688 - val_acc: 0.1235\n",
      "\n",
      "Epoch 27/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 885us/step - loss: 3.5849 - acc: 0.1852 - val_loss: 4.7543 - val_acc: 0.1235\n",
      "\n",
      "Epoch 28/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 3.5421 - acc: 0.1852 - val_loss: 4.7404 - val_acc: 0.1235\n",
      "\n",
      "Epoch 29/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 925us/step - loss: 3.5008 - acc: 0.1921 - val_loss: 4.7264 - val_acc: 0.1235TA: 0s - loss: 3.5337 - acc: 0.193\n",
      "\n",
      "Epoch 30/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 919us/step - loss: 3.4596 - acc: 0.1990 - val_loss: 4.7129 - val_acc: 0.1296\n",
      "\n",
      "Epoch 31/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================]583/583 [==============================] - 1s 911us/step - loss: 3.4196 - acc: 0.1973 - val_loss: 4.6987 - val_acc: 0.1296\n",
      "\n",
      "Epoch 32/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 862us/step - loss: 3.3791 - acc: 0.2007 - val_loss: 4.6834 - val_acc: 0.1296\n",
      "\n",
      "Epoch 33/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 889us/step - loss: 3.3393 - acc: 0.2075 - val_loss: 4.6688 - val_acc: 0.1296\n",
      "\n",
      "Epoch 34/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 881us/step - loss: 3.3005 - acc: 0.2110 - val_loss: 4.6542 - val_acc: 0.1296TA: 0s - loss: 3.1809 - acc:\n",
      "\n",
      "Epoch 35/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 943us/step - loss: 3.2624 - acc: 0.2127 - val_loss: 4.6421 - val_acc: 0.1235\n",
      "\n",
      "Epoch 36/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 772us/step - loss: 3.2251 - acc: 0.2161 - val_loss: 4.6298 - val_acc: 0.1235\n",
      "\n",
      "Epoch 37/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 957us/step - loss: 3.1889 - acc: 0.2247 - val_loss: 4.6164 - val_acc: 0.1235\n",
      "\n",
      "Epoch 38/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 3.1528 - acc: 0.2247 - val_loss: 4.6039 - val_acc: 0.1235\n",
      "\n",
      "Epoch 39/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 842us/step - loss: 3.1176 - acc: 0.2247 - val_loss: 4.5914 - val_acc: 0.1235\n",
      "\n",
      "Epoch 40/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 937us/step - loss: 3.0825 - acc: 0.2281 - val_loss: 4.5786 - val_acc: 0.1235\n",
      "\n",
      "Epoch 41/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 972us/step - loss: 3.0483 - acc: 0.2316 - val_loss: 4.5656 - val_acc: 0.1235\n",
      "\n",
      "Epoch 42/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 975us/step - loss: 3.0139 - acc: 0.2333 - val_loss: 4.5535 - val_acc: 0.1235\n",
      "\n",
      "Epoch 43/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 922us/step - loss: 2.9809 - acc: 0.2367 - val_loss: 4.5403 - val_acc: 0.1235\n",
      "\n",
      "Epoch 44/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 908us/step - loss: 2.9481 - acc: 0.2384 - val_loss: 4.5291 - val_acc: 0.1235\n",
      "\n",
      "Epoch 45/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 861us/step - loss: 2.9166 - acc: 0.2401 - val_loss: 4.5187 - val_acc: 0.1358\n",
      "\n",
      "Epoch 46/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 862us/step - loss: 2.8858 - acc: 0.2470 - val_loss: 4.5065 - val_acc: 0.1420\n",
      "\n",
      "Epoch 47/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 804us/step - loss: 2.8544 - acc: 0.2504 - val_loss: 4.4960 - val_acc: 0.1420\n",
      "\n",
      "Epoch 48/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 914us/step - loss: 2.8235 - acc: 0.2556 - val_loss: 4.4855 - val_acc: 0.1420\n",
      "\n",
      "Epoch 49/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 2.7938 - acc: 0.2676 - val_loss: 4.4754 - val_acc: 0.1420TA: 0s - loss: 2.7684 - acc: 0.265\n",
      "\n",
      "Epoch 50/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 806us/step - loss: 2.7648 - acc: 0.2693 - val_loss: 4.4661 - val_acc: 0.1420TA: 0s - loss: 2.6989 - acc: \n",
      "\n",
      "Epoch 51/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 2.7364 - acc: 0.2779 - val_loss: 4.4569 - val_acc: 0.1420\n",
      "\n",
      "Epoch 52/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 2.7077 - acc: 0.2813 - val_loss: 4.4471 - val_acc: 0.1420TA: 0s - loss: 2.7241 - acc: 0.\n",
      "\n",
      "Epoch 53/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 810us/step - loss: 2.6799 - acc: 0.2864 - val_loss: 4.4371 - val_acc: 0.1420\n",
      "\n",
      "Epoch 54/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 857us/step - loss: 2.6526 - acc: 0.2882 - val_loss: 4.4276 - val_acc: 0.1420\n",
      "\n",
      "Epoch 55/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 857us/step - loss: 2.6261 - acc: 0.2950 - val_loss: 4.4186 - val_acc: 0.1420\n",
      "\n",
      "Epoch 56/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 915us/step - loss: 2.5992 - acc: 0.2985 - val_loss: 4.4085 - val_acc: 0.1420\n",
      "\n",
      "Epoch 57/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 890us/step - loss: 2.5732 - acc: 0.3002 - val_loss: 4.3989 - val_acc: 0.1420\n",
      "\n",
      "Epoch 58/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 882us/step - loss: 2.5467 - acc: 0.3070 - val_loss: 4.3895 - val_acc: 0.1420TA: 0s - loss: 2.4594 - acc: 0.3\n",
      "\n",
      "Epoch 59/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 2.5211 - acc: 0.3105 - val_loss: 4.3806 - val_acc: 0.1420\n",
      "\n",
      "Epoch 60/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 861us/step - loss: 2.4959 - acc: 0.3122 - val_loss: 4.3722 - val_acc: 0.1420\n",
      "\n",
      "Epoch 61/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 857us/step - loss: 2.4714 - acc: 0.3173 - val_loss: 4.3607 - val_acc: 0.1420\n",
      "\n",
      "Epoch 62/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 810us/step - loss: 2.4456 - acc: 0.3225 - val_loss: 4.3507 - val_acc: 0.1420\n",
      "\n",
      "Epoch 63/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 862us/step - loss: 2.4206 - acc: 0.3259 - val_loss: 4.3426 - val_acc: 0.1420\n",
      "\n",
      "Epoch 64/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 867us/step - loss: 2.3967 - acc: 0.3345 - val_loss: 4.3344 - val_acc: 0.1420TA: 0s - loss: 2.4566 - acc: 0\n",
      "\n",
      "Epoch 65/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 939us/step - loss: 2.3729 - acc: 0.3379 - val_loss: 4.3241 - val_acc: 0.1420\n",
      "\n",
      "Epoch 66/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 975us/step - loss: 2.3497 - acc: 0.3431 - val_loss: 4.3164 - val_acc: 0.1420\n",
      "\n",
      "Epoch 67/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 2.3266 - acc: 0.3465 - val_loss: 4.3073 - val_acc: 0.1420\n",
      "\n",
      "Epoch 68/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 830us/step - loss: 2.3043 - acc: 0.3516 - val_loss: 4.2986 - val_acc: 0.1420\n",
      "\n",
      "Epoch 69/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 940us/step - loss: 2.2816 - acc: 0.3551 - val_loss: 4.2898 - val_acc: 0.1420TA: 0s - loss: 2.3243 - acc: 0.3\n",
      "\n",
      "Epoch 70/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 2.2591 - acc: 0.3602 - val_loss: 4.2817 - val_acc: 0.1420\n",
      "\n",
      "Epoch 71/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 2.2377 - acc: 0.3619 - val_loss: 4.2744 - val_acc: 0.1420\n",
      "\n",
      "Epoch 72/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 883us/step - loss: 2.2164 - acc: 0.3688 - val_loss: 4.2673 - val_acc: 0.1420TA: 0s - loss: 2.2178 - acc: 0.366\n",
      "\n",
      "Epoch 73/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 803us/step - loss: 2.1955 - acc: 0.3722 - val_loss: 4.2597 - val_acc: 0.1420\n",
      "\n",
      "Epoch 74/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 829us/step - loss: 2.1747 - acc: 0.3756 - val_loss: 4.2520 - val_acc: 0.1420\n",
      "\n",
      "Epoch 75/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 916us/step - loss: 2.1547 - acc: 0.3859 - val_loss: 4.2448 - val_acc: 0.1420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 76/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 900us/step - loss: 2.1342 - acc: 0.3894 - val_loss: 4.2375 - val_acc: 0.1420\n",
      "\n",
      "Epoch 77/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 912us/step - loss: 2.1144 - acc: 0.3945 - val_loss: 4.2299 - val_acc: 0.1420\n",
      "\n",
      "Epoch 78/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.0947 - acc: 0.3997 - val_loss: 4.2231 - val_acc: 0.1420\n",
      "\n",
      "Epoch 79/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 828us/step - loss: 2.0758 - acc: 0.4031 - val_loss: 4.2143 - val_acc: 0.1420\n",
      "\n",
      "Epoch 80/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 913us/step - loss: 2.0570 - acc: 0.4082 - val_loss: 4.2082 - val_acc: 0.1420TA: 0s - loss: 1.8411 - acc:\n",
      "\n",
      "Epoch 81/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 943us/step - loss: 2.0389 - acc: 0.4099 - val_loss: 4.2017 - val_acc: 0.1420\n",
      "\n",
      "Epoch 82/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 916us/step - loss: 2.0208 - acc: 0.4134 - val_loss: 4.1959 - val_acc: 0.1420\n",
      "\n",
      "Epoch 83/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 939us/step - loss: 2.0029 - acc: 0.4168 - val_loss: 4.1899 - val_acc: 0.1420\n",
      "\n",
      "Epoch 84/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.9848 - acc: 0.4220 - val_loss: 4.1836 - val_acc: 0.1420\n",
      "\n",
      "Epoch 85/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 952us/step - loss: 1.9665 - acc: 0.4305 - val_loss: 4.1773 - val_acc: 0.1420\n",
      "\n",
      "Epoch 86/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 914us/step - loss: 1.9493 - acc: 0.4340 - val_loss: 4.1712 - val_acc: 0.1420\n",
      "\n",
      "Epoch 87/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 822us/step - loss: 1.9324 - acc: 0.4374 - val_loss: 4.1656 - val_acc: 0.1420\n",
      "\n",
      "Epoch 88/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 817us/step - loss: 1.9154 - acc: 0.4408 - val_loss: 4.1601 - val_acc: 0.1420\n",
      "\n",
      "Epoch 89/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 869us/step - loss: 1.8988 - acc: 0.4425 - val_loss: 4.1544 - val_acc: 0.1420\n",
      "\n",
      "Epoch 90/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 1.8824 - acc: 0.4460 - val_loss: 4.1469 - val_acc: 0.1420\n",
      "\n",
      "Epoch 91/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 941us/step - loss: 1.8655 - acc: 0.4460 - val_loss: 4.1414 - val_acc: 0.1420\n",
      "\n",
      "Epoch 92/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 907us/step - loss: 1.8494 - acc: 0.4477 - val_loss: 4.1364 - val_acc: 0.1420\n",
      "\n",
      "Epoch 93/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 837us/step - loss: 1.8332 - acc: 0.4563 - val_loss: 4.1299 - val_acc: 0.1420\n",
      "\n",
      "Epoch 94/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 1.8171 - acc: 0.4563 - val_loss: 4.1253 - val_acc: 0.1481\n",
      "\n",
      "Epoch 95/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 806us/step - loss: 1.8011 - acc: 0.4614 - val_loss: 4.1200 - val_acc: 0.1481\n",
      "\n",
      "Epoch 96/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 862us/step - loss: 1.7857 - acc: 0.4614 - val_loss: 4.1142 - val_acc: 0.1481\n",
      "\n",
      "Epoch 97/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 933us/step - loss: 1.7702 - acc: 0.4648 - val_loss: 4.1087 - val_acc: 0.1481\n",
      "\n",
      "Epoch 98/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 1.7552 - acc: 0.4683 - val_loss: 4.1030 - val_acc: 0.1481TA: 0s - loss: 1.7194 - acc: 0.4\n",
      "\n",
      "Epoch 99/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 942us/step - loss: 1.7403 - acc: 0.4768 - val_loss: 4.0976 - val_acc: 0.1481\n",
      "\n",
      "Epoch 100/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 856us/step - loss: 1.7254 - acc: 0.4837 - val_loss: 4.0922 - val_acc: 0.1481\n",
      "\n",
      "Epoch 101/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 944us/step - loss: 1.7106 - acc: 0.4871 - val_loss: 4.0860 - val_acc: 0.1481\n",
      "\n",
      "Epoch 102/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 1.6966 - acc: 0.4871 - val_loss: 4.0812 - val_acc: 0.1481\n",
      "\n",
      "Epoch 103/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 883us/step - loss: 1.6823 - acc: 0.4923 - val_loss: 4.0758 - val_acc: 0.1481\n",
      "\n",
      "Epoch 104/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 1.6683 - acc: 0.4923 - val_loss: 4.0703 - val_acc: 0.1481TA: 0s - loss: 1.6659 - acc: 0.48\n",
      "\n",
      "Epoch 105/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 833us/step - loss: 1.6544 - acc: 0.4940 - val_loss: 4.0650 - val_acc: 0.1481TA: 0s - loss: 1.6834 - acc: 0.49\n",
      "\n",
      "Epoch 106/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 834us/step - loss: 1.6405 - acc: 0.4957 - val_loss: 4.0603 - val_acc: 0.1543\n",
      "\n",
      "Epoch 107/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 1.6269 - acc: 0.5009 - val_loss: 4.0550 - val_acc: 0.1543\n",
      "\n",
      "Epoch 108/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 791us/step - loss: 1.6136 - acc: 0.5043 - val_loss: 4.0500 - val_acc: 0.1543\n",
      "\n",
      "Epoch 109/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 857us/step - loss: 1.6002 - acc: 0.5111 - val_loss: 4.0446 - val_acc: 0.1543TA: 0s - loss: 1.5298 - acc: 0.513544/583 [==========================>...] - ETA: 0s - loss: 1.5684 - acc: 0.518\n",
      "\n",
      "Epoch 110/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 932us/step - loss: 1.5860 - acc: 0.5163 - val_loss: 4.0394 - val_acc: 0.1543TA: 0s - loss: 1.5826 - acc: 0.519\n",
      "\n",
      "Epoch 111/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 893us/step - loss: 1.5726 - acc: 0.5197 - val_loss: 4.0349 - val_acc: 0.1543\n",
      "\n",
      "Epoch 112/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 1.5596 - acc: 0.5283 - val_loss: 4.0301 - val_acc: 0.1543TA: 0s - loss: 1.5806 - acc: 0.5\n",
      "\n",
      "Epoch 113/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 913us/step - loss: 1.5471 - acc: 0.5283 - val_loss: 4.0247 - val_acc: 0.1543TA: 0s - loss: 1.5674 - acc: 0.52\n",
      "\n",
      "Epoch 114/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 1.5348 - acc: 0.5317 - val_loss: 4.0196 - val_acc: 0.1605\n",
      "\n",
      "Epoch 115/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 972us/step - loss: 1.5224 - acc: 0.5386 - val_loss: 4.0145 - val_acc: 0.1605\n",
      "\n",
      "Epoch 116/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 1.5102 - acc: 0.5420 - val_loss: 4.0107 - val_acc: 0.1667TA: 0s - loss: 1.4697 - acc: 0.\n",
      "\n",
      "Epoch 117/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 911us/step - loss: 1.4981 - acc: 0.5472 - val_loss: 4.0064 - val_acc: 0.1667\n",
      "\n",
      "Epoch 118/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 830us/step - loss: 1.4863 - acc: 0.5489 - val_loss: 4.0024 - val_acc: 0.1667\n",
      "\n",
      "Epoch 119/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 856us/step - loss: 1.4747 - acc: 0.5506 - val_loss: 3.9981 - val_acc: 0.1667\n",
      "\n",
      "Epoch 120/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 957us/step - loss: 1.4636 - acc: 0.5575 - val_loss: 3.9943 - val_acc: 0.1667\n",
      "\n",
      "Epoch 121/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 814us/step - loss: 1.4524 - acc: 0.5575 - val_loss: 3.9908 - val_acc: 0.1667\n",
      "\n",
      "Epoch 122/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 889us/step - loss: 1.4414 - acc: 0.5592 - val_loss: 3.9869 - val_acc: 0.1667\n",
      "\n",
      "Epoch 123/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 904us/step - loss: 1.4305 - acc: 0.5626 - val_loss: 3.9834 - val_acc: 0.1728\n",
      "\n",
      "Epoch 124/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 950us/step - loss: 1.4196 - acc: 0.5626 - val_loss: 3.9794 - val_acc: 0.1728\n",
      "\n",
      "Epoch 125/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 914us/step - loss: 1.4088 - acc: 0.5626 - val_loss: 3.9753 - val_acc: 0.1728TA: 0s - loss: 1.5530 - acc: 0\n",
      "\n",
      "Epoch 126/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 857us/step - loss: 1.3982 - acc: 0.5643 - val_loss: 3.9715 - val_acc: 0.1728\n",
      "\n",
      "Epoch 127/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 890us/step - loss: 1.3873 - acc: 0.5660 - val_loss: 3.9675 - val_acc: 0.1728\n",
      "\n",
      "Epoch 128/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 861us/step - loss: 1.3770 - acc: 0.5695 - val_loss: 3.9635 - val_acc: 0.1728TA: 0s - loss: 1.4470 - acc: 0.552512/583 [=========================>....] - ETA: 0s - loss: 1.3705 - acc: 0.56\n",
      "\n",
      "Epoch 129/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.3670 - acc: 0.5746 - val_loss: 3.9600 - val_acc: 0.1667 ETA: 0s - loss: 1.3591 - acc: 0.576\n",
      "\n",
      "Epoch 130/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 912us/step - loss: 1.3568 - acc: 0.5763 - val_loss: 3.9556 - val_acc: 0.1667\n",
      "\n",
      "Epoch 131/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 885us/step - loss: 1.3468 - acc: 0.5780 - val_loss: 3.9522 - val_acc: 0.1667\n",
      "\n",
      "Epoch 132/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 1.3365 - acc: 0.5815 - val_loss: 3.9481 - val_acc: 0.1667\n",
      "\n",
      "Epoch 133/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 778us/step - loss: 1.3266 - acc: 0.5815 - val_loss: 3.9445 - val_acc: 0.1667\n",
      "\n",
      "Epoch 134/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 1.3168 - acc: 0.5832 - val_loss: 3.9414 - val_acc: 0.1667TA: 0s - loss: 1.2978 - acc: 0.58\n",
      "\n",
      "Epoch 135/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.3073 - acc: 0.5952 - val_loss: 3.9377 - val_acc: 0.1667\n",
      "\n",
      "Epoch 136/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 945us/step - loss: 1.2978 - acc: 0.6003 - val_loss: 3.9344 - val_acc: 0.1667\n",
      "\n",
      "Epoch 137/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 940us/step - loss: 1.2885 - acc: 0.6055 - val_loss: 3.9311 - val_acc: 0.1667\n",
      "\n",
      "Epoch 138/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 878us/step - loss: 1.2793 - acc: 0.6106 - val_loss: 3.9277 - val_acc: 0.1667\n",
      "\n",
      "Epoch 139/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 813us/step - loss: 1.2702 - acc: 0.6158 - val_loss: 3.9244 - val_acc: 0.1667\n",
      "\n",
      "Epoch 140/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 856us/step - loss: 1.2609 - acc: 0.6192 - val_loss: 3.9218 - val_acc: 0.1667\n",
      "\n",
      "Epoch 141/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 911us/step - loss: 1.2519 - acc: 0.6244 - val_loss: 3.9184 - val_acc: 0.1728TA: 0s - loss: 1.2829 - acc: 0. - ETA: 0s - loss: 1.2890 - acc: 0.61\n",
      "\n",
      "Epoch 142/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 913us/step - loss: 1.2429 - acc: 0.6244 - val_loss: 3.9151 - val_acc: 0.1728TA: 0s - loss: 1.2675 - acc: \n",
      "\n",
      "Epoch 143/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 1.2342 - acc: 0.6244 - val_loss: 3.9117 - val_acc: 0.1790\n",
      "\n",
      "Epoch 144/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 833us/step - loss: 1.2254 - acc: 0.6278 - val_loss: 3.9084 - val_acc: 0.1790\n",
      "\n",
      "Epoch 145/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 1.2170 - acc: 0.6381 - val_loss: 3.9053 - val_acc: 0.1790TA: 0s - loss: 1.2538 - acc: 0.617\n",
      "\n",
      "Epoch 146/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 884us/step - loss: 1.2085 - acc: 0.6415 - val_loss: 3.9019 - val_acc: 0.1790\n",
      "\n",
      "Epoch 147/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 889us/step - loss: 1.2001 - acc: 0.6415 - val_loss: 3.8988 - val_acc: 0.1790\n",
      "\n",
      "Epoch 148/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 827us/step - loss: 1.1918 - acc: 0.6432 - val_loss: 3.8959 - val_acc: 0.1790\n",
      "\n",
      "Epoch 149/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 883us/step - loss: 1.1836 - acc: 0.6432 - val_loss: 3.8928 - val_acc: 0.1790\n",
      "\n",
      "Epoch 150/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 885us/step - loss: 1.1755 - acc: 0.6467 - val_loss: 3.8898 - val_acc: 0.1790TA: 0s - loss: 1.1841 - acc: 0.65\n",
      "\n",
      "Epoch 151/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 882us/step - loss: 1.1674 - acc: 0.6467 - val_loss: 3.8866 - val_acc: 0.1790TA: 0s - loss: 1.2808 - acc: \n",
      "\n",
      "Epoch 152/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 940us/step - loss: 1.1595 - acc: 0.6484 - val_loss: 3.8840 - val_acc: 0.1790TA: 0s - loss: 1.1422 - acc: \n",
      "\n",
      "Epoch 153/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 922us/step - loss: 1.1516 - acc: 0.6501 - val_loss: 3.8818 - val_acc: 0.1790\n",
      "\n",
      "Epoch 154/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 825us/step - loss: 1.1439 - acc: 0.6569 - val_loss: 3.8786 - val_acc: 0.1790\n",
      "\n",
      "Epoch 155/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 891us/step - loss: 1.1361 - acc: 0.6604 - val_loss: 3.8755 - val_acc: 0.1790\n",
      "\n",
      "Epoch 156/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 857us/step - loss: 1.1284 - acc: 0.6621 - val_loss: 3.8728 - val_acc: 0.1790\n",
      "\n",
      "Epoch 157/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 884us/step - loss: 1.1205 - acc: 0.6638 - val_loss: 3.8696 - val_acc: 0.1790\n",
      "\n",
      "Epoch 158/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 896us/step - loss: 1.1130 - acc: 0.6672 - val_loss: 3.8667 - val_acc: 0.1790\n",
      "\n",
      "Epoch 159/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 847us/step - loss: 1.1056 - acc: 0.6672 - val_loss: 3.8636 - val_acc: 0.1790\n",
      "\n",
      "Epoch 160/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 817us/step - loss: 1.0983 - acc: 0.6707 - val_loss: 3.8612 - val_acc: 0.1790\n",
      "\n",
      "Epoch 161/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 885us/step - loss: 1.0910 - acc: 0.6707 - val_loss: 3.8580 - val_acc: 0.1790\n",
      "\n",
      "Epoch 162/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 905us/step - loss: 1.0838 - acc: 0.6741 - val_loss: 3.8556 - val_acc: 0.1790\n",
      "\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================]583/583 [==============================] - 1s 895us/step - loss: 1.0768 - acc: 0.6741 - val_loss: 3.8529 - val_acc: 0.1790\n",
      "\n",
      "Epoch 164/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 915us/step - loss: 1.0699 - acc: 0.6758 - val_loss: 3.8499 - val_acc: 0.1790\n",
      "\n",
      "Epoch 165/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 943us/step - loss: 1.0627 - acc: 0.6775 - val_loss: 3.8469 - val_acc: 0.1790\n",
      "\n",
      "Epoch 166/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 973us/step - loss: 1.0557 - acc: 0.6792 - val_loss: 3.8444 - val_acc: 0.1790\n",
      "\n",
      "Epoch 167/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 975us/step - loss: 1.0484 - acc: 0.6827 - val_loss: 3.8422 - val_acc: 0.1852\n",
      "\n",
      "Epoch 168/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 925us/step - loss: 1.0415 - acc: 0.6827 - val_loss: 3.8395 - val_acc: 0.1852\n",
      "\n",
      "Epoch 169/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 961us/step - loss: 1.0346 - acc: 0.6861 - val_loss: 3.8371 - val_acc: 0.1852\n",
      "\n",
      "Epoch 170/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 894us/step - loss: 1.0280 - acc: 0.6895 - val_loss: 3.8345 - val_acc: 0.1852\n",
      "\n",
      "Epoch 171/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 898us/step - loss: 1.0213 - acc: 0.6930 - val_loss: 3.8325 - val_acc: 0.1852\n",
      "\n",
      "Epoch 172/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 924us/step - loss: 1.0144 - acc: 0.6947 - val_loss: 3.8301 - val_acc: 0.1852TA: 0s - loss: 0.9842 - acc: 0.71384/583 [==================>...........] - ETA: 0s - loss: 1.0115 - acc: 0.6\n",
      "\n",
      "Epoch 173/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 828us/step - loss: 1.0077 - acc: 0.6947 - val_loss: 3.8272 - val_acc: 0.1852TA: 0s - loss: 1.1992 - acc: 0.6384/583 [==================>...........] - ETA: 0s - loss: 1.0479 - acc: 0.6\n",
      "\n",
      "Epoch 174/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 1.0013 - acc: 0.6964 - val_loss: 3.8241 - val_acc: 0.1852\n",
      "\n",
      "Epoch 175/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 964us/step - loss: 0.9948 - acc: 0.6981 - val_loss: 3.8214 - val_acc: 0.1852\n",
      "\n",
      "Epoch 176/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 949us/step - loss: 0.9882 - acc: 0.7033 - val_loss: 3.8187 - val_acc: 0.1975\n",
      "\n",
      "Epoch 177/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 913us/step - loss: 0.9818 - acc: 0.7067 - val_loss: 3.8166 - val_acc: 0.2037\n",
      "\n",
      "Epoch 178/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 803us/step - loss: 0.9755 - acc: 0.7101 - val_loss: 3.8142 - val_acc: 0.2037\n",
      "\n",
      "Epoch 179/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 952us/step - loss: 0.9691 - acc: 0.7118 - val_loss: 3.8119 - val_acc: 0.2037\n",
      "\n",
      "Epoch 180/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 0.9630 - acc: 0.7136 - val_loss: 3.8099 - val_acc: 0.2037\n",
      "\n",
      "Epoch 181/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 877us/step - loss: 0.9571 - acc: 0.7170 - val_loss: 3.8076 - val_acc: 0.2099\n",
      "\n",
      "Epoch 182/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 861us/step - loss: 0.9510 - acc: 0.7187 - val_loss: 3.8059 - val_acc: 0.2099\n",
      "\n",
      "Epoch 183/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 916us/step - loss: 0.9451 - acc: 0.7204 - val_loss: 3.8037 - val_acc: 0.2099\n",
      "\n",
      "Epoch 184/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 828us/step - loss: 0.9390 - acc: 0.7221 - val_loss: 3.8018 - val_acc: 0.2160TA: 0s - loss: 0.9426 - acc: 0.72\n",
      "\n",
      "Epoch 185/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 933us/step - loss: 0.9333 - acc: 0.7256 - val_loss: 3.8001 - val_acc: 0.2160TA: 0s - loss: 0.9529 - acc: 0.7\n",
      "\n",
      "Epoch 186/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 0.9276 - acc: 0.7256 - val_loss: 3.7985 - val_acc: 0.2160\n",
      "\n",
      "Epoch 187/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 948us/step - loss: 0.9217 - acc: 0.7307 - val_loss: 3.7966 - val_acc: 0.2160\n",
      "\n",
      "Epoch 188/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 882us/step - loss: 0.9161 - acc: 0.7307 - val_loss: 3.7947 - val_acc: 0.2160\n",
      "\n",
      "Epoch 189/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 862us/step - loss: 0.9105 - acc: 0.7307 - val_loss: 3.7928 - val_acc: 0.2160\n",
      "\n",
      "Epoch 190/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 0.9051 - acc: 0.7358 - val_loss: 3.7912 - val_acc: 0.2160\n",
      "\n",
      "Epoch 191/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 833us/step - loss: 0.8996 - acc: 0.7358 - val_loss: 3.7893 - val_acc: 0.2160\n",
      "\n",
      "Epoch 192/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 826us/step - loss: 0.8942 - acc: 0.7376 - val_loss: 3.7874 - val_acc: 0.2160\n",
      "\n",
      "Epoch 193/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 915us/step - loss: 0.8890 - acc: 0.7410 - val_loss: 3.7846 - val_acc: 0.2160\n",
      "\n",
      "Epoch 194/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 979us/step - loss: 0.8836 - acc: 0.7427 - val_loss: 3.7821 - val_acc: 0.2160\n",
      "\n",
      "Epoch 195/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 849us/step - loss: 0.8783 - acc: 0.7444 - val_loss: 3.7803 - val_acc: 0.2160\n",
      "\n",
      "Epoch 196/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 817us/step - loss: 0.8730 - acc: 0.7479 - val_loss: 3.7785 - val_acc: 0.2160\n",
      "\n",
      "Epoch 197/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 872us/step - loss: 0.8679 - acc: 0.7479 - val_loss: 3.7764 - val_acc: 0.2160\n",
      "\n",
      "Epoch 198/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 0.8629 - acc: 0.7496 - val_loss: 3.7745 - val_acc: 0.2160TA: 0s - loss: 0.9119 - acc: 0\n",
      "\n",
      "Epoch 199/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 853us/step - loss: 0.8578 - acc: 0.7496 - val_loss: 3.7725 - val_acc: 0.2099\n",
      "\n",
      "Epoch 200/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 969us/step - loss: 0.8527 - acc: 0.7530 - val_loss: 3.7701 - val_acc: 0.2099\n",
      "\n",
      "65/65 [==============================]65/65 [==============================] - 0s 436us/step\n",
      "\n",
      "Train on 583 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "583/583 [==============================]583/583 [==============================] - 4s 6ms/step - loss: 5.2273 - acc: 0.1561 - val_loss: 5.4796 - val_acc: 0.1543\n",
      "\n",
      "Epoch 2/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 5.1365 - acc: 0.1578 - val_loss: 5.4211 - val_acc: 0.1605\n",
      "\n",
      "Epoch 3/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 5.0496 - acc: 0.1544 - val_loss: 5.3663 - val_acc: 0.1667\n",
      "\n",
      "Epoch 4/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 947us/step - loss: 4.9659 - acc: 0.1578 - val_loss: 5.3136 - val_acc: 0.1667\n",
      "\n",
      "Epoch 5/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 895us/step - loss: 4.8844 - acc: 0.1612 - val_loss: 5.2614 - val_acc: 0.1728\n",
      "\n",
      "Epoch 6/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 976us/step - loss: 4.8051 - acc: 0.1630 - val_loss: 5.2137 - val_acc: 0.1728\n",
      "\n",
      "Epoch 7/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 959us/step - loss: 4.7307 - acc: 0.1630 - val_loss: 5.1680 - val_acc: 0.1728\n",
      "\n",
      "Epoch 8/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 994us/step - loss: 4.6591 - acc: 0.1664 - val_loss: 5.1229 - val_acc: 0.1667\n",
      "\n",
      "Epoch 9/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 920us/step - loss: 4.5887 - acc: 0.1715 - val_loss: 5.0785 - val_acc: 0.1667\n",
      "\n",
      "Epoch 10/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 878us/step - loss: 4.5206 - acc: 0.1715 - val_loss: 5.0361 - val_acc: 0.1605\n",
      "\n",
      "Epoch 11/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 941us/step - loss: 4.4567 - acc: 0.1767 - val_loss: 4.9960 - val_acc: 0.1605\n",
      "\n",
      "Epoch 12/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 874us/step - loss: 4.3942 - acc: 0.1818 - val_loss: 4.9559 - val_acc: 0.1667\n",
      "\n",
      "Epoch 13/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 953us/step - loss: 4.3320 - acc: 0.1852 - val_loss: 4.9183 - val_acc: 0.1667\n",
      "\n",
      "Epoch 14/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 950us/step - loss: 4.2726 - acc: 0.1904 - val_loss: 4.8825 - val_acc: 0.1667TA: 0s - loss: 4.3179 - acc: 0.19\n",
      "\n",
      "Epoch 15/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 885us/step - loss: 4.2158 - acc: 0.1938 - val_loss: 4.8453 - val_acc: 0.1667\n",
      "\n",
      "Epoch 16/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 783us/step - loss: 4.1589 - acc: 0.1973 - val_loss: 4.8120 - val_acc: 0.1667TA: 0s - loss: 4.1389 - acc: 0.20\n",
      "\n",
      "Epoch 17/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 4.1052 - acc: 0.2007 - val_loss: 4.7790 - val_acc: 0.1852\n",
      "\n",
      "Epoch 18/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 956us/step - loss: 4.0513 - acc: 0.2024 - val_loss: 4.7474 - val_acc: 0.1790\n",
      "\n",
      "Epoch 19/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 896us/step - loss: 3.9998 - acc: 0.2058 - val_loss: 4.7153 - val_acc: 0.1790TA: 0s - loss: 3.9896 - acc: 0.206\n",
      "\n",
      "Epoch 20/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 936us/step - loss: 3.9486 - acc: 0.2041 - val_loss: 4.6854 - val_acc: 0.1790\n",
      "\n",
      "Epoch 21/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 827us/step - loss: 3.9008 - acc: 0.2075 - val_loss: 4.6560 - val_acc: 0.1852\n",
      "\n",
      "Epoch 22/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 800us/step - loss: 3.8531 - acc: 0.2127 - val_loss: 4.6274 - val_acc: 0.1852\n",
      "\n",
      "Epoch 23/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 884us/step - loss: 3.8068 - acc: 0.2161 - val_loss: 4.6001 - val_acc: 0.1790\n",
      "\n",
      "Epoch 24/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 857us/step - loss: 3.7616 - acc: 0.2247 - val_loss: 4.5740 - val_acc: 0.1790\n",
      "\n",
      "Epoch 25/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 861us/step - loss: 3.7178 - acc: 0.2264 - val_loss: 4.5474 - val_acc: 0.1790TA: 0s - loss: 3.6825 - acc: 0.2\n",
      "\n",
      "Epoch 26/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 3.6739 - acc: 0.2298 - val_loss: 4.5212 - val_acc: 0.1790\n",
      "\n",
      "Epoch 27/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 912us/step - loss: 3.6320 - acc: 0.2350 - val_loss: 4.4963 - val_acc: 0.1790\n",
      "\n",
      "Epoch 28/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 999us/step - loss: 3.5912 - acc: 0.2333 - val_loss: 4.4724 - val_acc: 0.1790\n",
      "\n",
      "Epoch 29/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 3.5507 - acc: 0.2367 - val_loss: 4.4500 - val_acc: 0.1728\n",
      "\n",
      "Epoch 30/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 917us/step - loss: 3.5115 - acc: 0.2401 - val_loss: 4.4293 - val_acc: 0.1728\n",
      "\n",
      "Epoch 31/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 3.4737 - acc: 0.2419 - val_loss: 4.4077 - val_acc: 0.1790\n",
      "\n",
      "Epoch 32/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 930us/step - loss: 3.4359 - acc: 0.2487 - val_loss: 4.3852 - val_acc: 0.1790\n",
      "\n",
      "Epoch 33/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 839us/step - loss: 3.3987 - acc: 0.2556 - val_loss: 4.3655 - val_acc: 0.1790TA: 0s - loss: 3.5034 - acc: 0.25\n",
      "\n",
      "Epoch 34/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 889us/step - loss: 3.3628 - acc: 0.2607 - val_loss: 4.3465 - val_acc: 0.1790\n",
      "\n",
      "Epoch 35/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 912us/step - loss: 3.3275 - acc: 0.2642 - val_loss: 4.3277 - val_acc: 0.1790TA: 0s - loss: 3.3113 - acc: 0.\n",
      "\n",
      "Epoch 36/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 975us/step - loss: 3.2921 - acc: 0.2659 - val_loss: 4.3092 - val_acc: 0.1790\n",
      "\n",
      "Epoch 37/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 972us/step - loss: 3.2583 - acc: 0.2710 - val_loss: 4.2913 - val_acc: 0.1790\n",
      "\n",
      "Epoch 38/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 939us/step - loss: 3.2250 - acc: 0.2727 - val_loss: 4.2713 - val_acc: 0.1790\n",
      "\n",
      "Epoch 39/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 968us/step - loss: 3.1910 - acc: 0.2779 - val_loss: 4.2548 - val_acc: 0.1790\n",
      "\n",
      "Epoch 40/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 864us/step - loss: 3.1583 - acc: 0.2796 - val_loss: 4.2373 - val_acc: 0.1790\n",
      "\n",
      "Epoch 41/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 913us/step - loss: 3.1260 - acc: 0.2864 - val_loss: 4.2215 - val_acc: 0.1790\n",
      "\n",
      "Epoch 42/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 917us/step - loss: 3.0948 - acc: 0.2899 - val_loss: 4.2055 - val_acc: 0.1790\n",
      "\n",
      "Epoch 43/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 882us/step - loss: 3.0643 - acc: 0.2899 - val_loss: 4.1875 - val_acc: 0.1790TA: 0s - loss: 3.0056 - acc: 0.30\n",
      "\n",
      "Epoch 44/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 834us/step - loss: 3.0332 - acc: 0.3002 - val_loss: 4.1723 - val_acc: 0.1852TA: 0s - loss: 3.1010 - acc: 0.29288/583 [=============>................] - ETA: 0s - loss: 2.9738 - acc: 0.29448/583 [======================>.......] - ETA: 0s - loss: 2.9696 - acc: 0.3\n",
      "\n",
      "Epoch 45/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 930us/step - loss: 3.0035 - acc: 0.3002 - val_loss: 4.1571 - val_acc: 0.1914\n",
      "\n",
      "Epoch 46/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 868us/step - loss: 2.9741 - acc: 0.3105 - val_loss: 4.1416 - val_acc: 0.1914TA: 0s - loss: 2.9368 - acc: 0.314\n",
      "\n",
      "Epoch 47/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 938us/step - loss: 2.9448 - acc: 0.3139 - val_loss: 4.1270 - val_acc: 0.1914TA: 0s - loss: 2.9455 - acc: 0.\n",
      "\n",
      "Epoch 48/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 899us/step - loss: 2.9157 - acc: 0.3173 - val_loss: 4.1122 - val_acc: 0.1914\n",
      "\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================]583/583 [==============================] - 1s 932us/step - loss: 2.8871 - acc: 0.3259 - val_loss: 4.0959 - val_acc: 0.1914TA: 0s - loss: 3.0304 - acc: 0\n",
      "\n",
      "Epoch 50/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 987us/step - loss: 2.8593 - acc: 0.3345 - val_loss: 4.0821 - val_acc: 0.1914\n",
      "\n",
      "Epoch 51/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 2.8322 - acc: 0.3362 - val_loss: 4.0690 - val_acc: 0.1914\n",
      "\n",
      "Epoch 52/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 955us/step - loss: 2.8063 - acc: 0.3345 - val_loss: 4.0559 - val_acc: 0.1975\n",
      "\n",
      "Epoch 53/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 2.7805 - acc: 0.3413 - val_loss: 4.0427 - val_acc: 0.2037\n",
      "\n",
      "Epoch 54/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 907us/step - loss: 2.7553 - acc: 0.3482 - val_loss: 4.0308 - val_acc: 0.1975TA: 0s - loss: 2.8053 - acc: 0.34\n",
      "\n",
      "Epoch 55/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 863us/step - loss: 2.7299 - acc: 0.3585 - val_loss: 4.0170 - val_acc: 0.1975\n",
      "\n",
      "Epoch 56/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 2.7050 - acc: 0.3636 - val_loss: 4.0050 - val_acc: 0.1975\n",
      "\n",
      "Epoch 57/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 893us/step - loss: 2.6810 - acc: 0.3654 - val_loss: 3.9925 - val_acc: 0.1975\n",
      "\n",
      "Epoch 58/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 2.6570 - acc: 0.3688 - val_loss: 3.9809 - val_acc: 0.2037\n",
      "\n",
      "Epoch 59/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 2.6343 - acc: 0.3722 - val_loss: 3.9687 - val_acc: 0.2037\n",
      "\n",
      "Epoch 60/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 958us/step - loss: 2.6113 - acc: 0.3791 - val_loss: 3.9569 - val_acc: 0.2037\n",
      "\n",
      "Epoch 61/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 976us/step - loss: 2.5887 - acc: 0.3791 - val_loss: 3.9457 - val_acc: 0.2037\n",
      "\n",
      "Epoch 62/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 2.5659 - acc: 0.3808 - val_loss: 3.9350 - val_acc: 0.2037\n",
      "\n",
      "Epoch 63/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 879us/step - loss: 2.5437 - acc: 0.3825 - val_loss: 3.9244 - val_acc: 0.2037\n",
      "\n",
      "Epoch 64/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 890us/step - loss: 2.5218 - acc: 0.3825 - val_loss: 3.9138 - val_acc: 0.2037\n",
      "\n",
      "Epoch 65/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 2.5002 - acc: 0.3842 - val_loss: 3.9042 - val_acc: 0.2037\n",
      "\n",
      "Epoch 66/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 2.4791 - acc: 0.3842 - val_loss: 3.8940 - val_acc: 0.2099\n",
      "\n",
      "Epoch 67/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 915us/step - loss: 2.4578 - acc: 0.3859 - val_loss: 3.8843 - val_acc: 0.2099\n",
      "\n",
      "Epoch 68/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 2.4374 - acc: 0.3962 - val_loss: 3.8739 - val_acc: 0.2099\n",
      "\n",
      "Epoch 69/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 943us/step - loss: 2.4172 - acc: 0.3962 - val_loss: 3.8638 - val_acc: 0.2099\n",
      "\n",
      "Epoch 70/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 798us/step - loss: 2.3975 - acc: 0.3979 - val_loss: 3.8550 - val_acc: 0.2099\n",
      "\n",
      "Epoch 71/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 2.3777 - acc: 0.4014 - val_loss: 3.8444 - val_acc: 0.2099\n",
      "\n",
      "Epoch 72/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 990us/step - loss: 2.3578 - acc: 0.4048 - val_loss: 3.8351 - val_acc: 0.2099\n",
      "\n",
      "Epoch 73/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 807us/step - loss: 2.3385 - acc: 0.4065 - val_loss: 3.8251 - val_acc: 0.2099\n",
      "\n",
      "Epoch 74/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 2.3198 - acc: 0.4117 - val_loss: 3.8161 - val_acc: 0.2160 [===============>..............] - ETA: 0s - loss: 2.3118 - acc: 0.\n",
      "\n",
      "Epoch 75/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 2.3012 - acc: 0.4134 - val_loss: 3.8076 - val_acc: 0.2160\n",
      "\n",
      "Epoch 76/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 2.2827 - acc: 0.4185 - val_loss: 3.7987 - val_acc: 0.2160\n",
      "\n",
      "Epoch 77/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 2.2643 - acc: 0.4220 - val_loss: 3.7903 - val_acc: 0.2099TA: 0s - loss: 2.1835 - acc: 0.\n",
      "\n",
      "Epoch 78/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 915us/step - loss: 2.2462 - acc: 0.4288 - val_loss: 3.7815 - val_acc: 0.2160\n",
      "\n",
      "Epoch 79/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 2.2284 - acc: 0.4305 - val_loss: 3.7730 - val_acc: 0.2160\n",
      "\n",
      "Epoch 80/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 883us/step - loss: 2.2107 - acc: 0.4340 - val_loss: 3.7652 - val_acc: 0.2160\n",
      "\n",
      "Epoch 81/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1000us/step - loss: 2.1936 - acc: 0.4357 - val_loss: 3.7571 - val_acc: 0.2222\n",
      "\n",
      "Epoch 82/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 989us/step - loss: 2.1766 - acc: 0.4357 - val_loss: 3.7494 - val_acc: 0.2222\n",
      "\n",
      "Epoch 83/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 924us/step - loss: 2.1596 - acc: 0.4374 - val_loss: 3.7417 - val_acc: 0.2222\n",
      "\n",
      "Epoch 84/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 795us/step - loss: 2.1429 - acc: 0.4408 - val_loss: 3.7334 - val_acc: 0.2222\n",
      "\n",
      "Epoch 85/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 980us/step - loss: 2.1262 - acc: 0.4408 - val_loss: 3.7256 - val_acc: 0.2222\n",
      "\n",
      "Epoch 86/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 798us/step - loss: 2.1098 - acc: 0.4443 - val_loss: 3.7178 - val_acc: 0.2222\n",
      "\n",
      "Epoch 87/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 861us/step - loss: 2.0940 - acc: 0.4443 - val_loss: 3.7107 - val_acc: 0.2222TA: 0s - loss: 2.0916 - acc: 0.446\n",
      "\n",
      "Epoch 88/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 867us/step - loss: 2.0782 - acc: 0.4511 - val_loss: 3.7029 - val_acc: 0.2222\n",
      "\n",
      "Epoch 89/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 845us/step - loss: 2.0623 - acc: 0.4511 - val_loss: 3.6953 - val_acc: 0.2222\n",
      "\n",
      "Epoch 90/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 918us/step - loss: 2.0471 - acc: 0.4511 - val_loss: 3.6878 - val_acc: 0.2222\n",
      "\n",
      "Epoch 91/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 854us/step - loss: 2.0320 - acc: 0.4528 - val_loss: 3.6798 - val_acc: 0.2222\n",
      "\n",
      "Epoch 92/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 892us/step - loss: 2.0169 - acc: 0.4528 - val_loss: 3.6726 - val_acc: 0.2222\n",
      "\n",
      "Epoch 93/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 897us/step - loss: 2.0019 - acc: 0.4563 - val_loss: 3.6660 - val_acc: 0.2222\n",
      "\n",
      "Epoch 94/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 788us/step - loss: 1.9870 - acc: 0.4563 - val_loss: 3.6596 - val_acc: 0.2222\n",
      "\n",
      "Epoch 95/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 851us/step - loss: 1.9726 - acc: 0.4597 - val_loss: 3.6526 - val_acc: 0.2222TA: 0s - loss: 1.9675 - acc: 0.4\n",
      "\n",
      "Epoch 96/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 1.9586 - acc: 0.4614 - val_loss: 3.6463 - val_acc: 0.2222\n",
      "\n",
      "Epoch 97/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 890us/step - loss: 1.9448 - acc: 0.4631 - val_loss: 3.6401 - val_acc: 0.2222\n",
      "\n",
      "Epoch 98/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 882us/step - loss: 1.9305 - acc: 0.4631 - val_loss: 3.6331 - val_acc: 0.2222\n",
      "\n",
      "Epoch 99/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 979us/step - loss: 1.9165 - acc: 0.4648 - val_loss: 3.6266 - val_acc: 0.2222\n",
      "\n",
      "Epoch 100/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 940us/step - loss: 1.9028 - acc: 0.4717 - val_loss: 3.6208 - val_acc: 0.2222\n",
      "\n",
      "Epoch 101/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 968us/step - loss: 1.8893 - acc: 0.4717 - val_loss: 3.6144 - val_acc: 0.2222\n",
      "\n",
      "Epoch 102/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.8755 - acc: 0.4734 - val_loss: 3.6082 - val_acc: 0.2222\n",
      "\n",
      "Epoch 103/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 830us/step - loss: 1.8623 - acc: 0.4786 - val_loss: 3.6021 - val_acc: 0.2222\n",
      "\n",
      "Epoch 104/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 889us/step - loss: 1.8494 - acc: 0.4803 - val_loss: 3.5960 - val_acc: 0.2222\n",
      "\n",
      "Epoch 105/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 953us/step - loss: 1.8363 - acc: 0.4854 - val_loss: 3.5899 - val_acc: 0.2160\n",
      "\n",
      "Epoch 106/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 819us/step - loss: 1.8231 - acc: 0.4889 - val_loss: 3.5835 - val_acc: 0.2222\n",
      "\n",
      "Epoch 107/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 847us/step - loss: 1.8102 - acc: 0.4957 - val_loss: 3.5767 - val_acc: 0.2160\n",
      "\n",
      "Epoch 108/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 872us/step - loss: 1.7974 - acc: 0.4957 - val_loss: 3.5714 - val_acc: 0.2160\n",
      "\n",
      "Epoch 109/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 879us/step - loss: 1.7851 - acc: 0.4974 - val_loss: 3.5664 - val_acc: 0.2222\n",
      "\n",
      "Epoch 110/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 856us/step - loss: 1.7728 - acc: 0.5009 - val_loss: 3.5614 - val_acc: 0.2222\n",
      "\n",
      "Epoch 111/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 940us/step - loss: 1.7605 - acc: 0.5009 - val_loss: 3.5567 - val_acc: 0.2222\n",
      "\n",
      "Epoch 112/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 837us/step - loss: 1.7484 - acc: 0.5026 - val_loss: 3.5524 - val_acc: 0.2222\n",
      "\n",
      "Epoch 113/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 853us/step - loss: 1.7363 - acc: 0.5077 - val_loss: 3.5464 - val_acc: 0.2222\n",
      "\n",
      "Epoch 114/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 883us/step - loss: 1.7241 - acc: 0.5146 - val_loss: 3.5414 - val_acc: 0.2222\n",
      "\n",
      "Epoch 115/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 1.7120 - acc: 0.5163 - val_loss: 3.5368 - val_acc: 0.2160\n",
      "\n",
      "Epoch 116/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 885us/step - loss: 1.7005 - acc: 0.5197 - val_loss: 3.5313 - val_acc: 0.2160\n",
      "\n",
      "Epoch 117/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.6890 - acc: 0.5197 - val_loss: 3.5256 - val_acc: 0.2160\n",
      "\n",
      "Epoch 118/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.6776 - acc: 0.5283 - val_loss: 3.5209 - val_acc: 0.2160\n",
      "\n",
      "Epoch 119/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 916us/step - loss: 1.6664 - acc: 0.5283 - val_loss: 3.5156 - val_acc: 0.2099\n",
      "\n",
      "Epoch 120/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 1.6551 - acc: 0.5334 - val_loss: 3.5106 - val_acc: 0.2160\n",
      "\n",
      "Epoch 121/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 889us/step - loss: 1.6439 - acc: 0.5403 - val_loss: 3.5052 - val_acc: 0.2160\n",
      "\n",
      "Epoch 122/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 949us/step - loss: 1.6328 - acc: 0.5403 - val_loss: 3.5001 - val_acc: 0.2160\n",
      "\n",
      "Epoch 123/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 882us/step - loss: 1.6217 - acc: 0.5420 - val_loss: 3.4954 - val_acc: 0.2160\n",
      "\n",
      "Epoch 124/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 914us/step - loss: 1.6111 - acc: 0.5420 - val_loss: 3.4900 - val_acc: 0.2160\n",
      "\n",
      "Epoch 125/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 911us/step - loss: 1.6002 - acc: 0.5455 - val_loss: 3.4851 - val_acc: 0.2099\n",
      "\n",
      "Epoch 126/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.5895 - acc: 0.5489 - val_loss: 3.4806 - val_acc: 0.2099\n",
      "\n",
      "Epoch 127/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 883us/step - loss: 1.5790 - acc: 0.5489 - val_loss: 3.4760 - val_acc: 0.2099\n",
      "\n",
      "Epoch 128/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 920us/step - loss: 1.5685 - acc: 0.5489 - val_loss: 3.4710 - val_acc: 0.2099\n",
      "\n",
      "Epoch 129/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 857us/step - loss: 1.5581 - acc: 0.5523 - val_loss: 3.4662 - val_acc: 0.2160\n",
      "\n",
      "Epoch 130/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 963us/step - loss: 1.5475 - acc: 0.5557 - val_loss: 3.4612 - val_acc: 0.2160\n",
      "\n",
      "Epoch 131/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 863us/step - loss: 1.5373 - acc: 0.5609 - val_loss: 3.4569 - val_acc: 0.2160\n",
      "\n",
      "Epoch 132/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.5271 - acc: 0.5609 - val_loss: 3.4526 - val_acc: 0.2160\n",
      "\n",
      "Epoch 133/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 896us/step - loss: 1.5172 - acc: 0.5660 - val_loss: 3.4482 - val_acc: 0.2099\n",
      "\n",
      "Epoch 134/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 848us/step - loss: 1.5073 - acc: 0.5695 - val_loss: 3.4440 - val_acc: 0.2099s - loss: 1.5041 - acc: 0.571\n",
      "\n",
      "Epoch 135/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 871us/step - loss: 1.4972 - acc: 0.5780 - val_loss: 3.4393 - val_acc: 0.2099\n",
      "\n",
      "Epoch 136/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 1.4873 - acc: 0.5798 - val_loss: 3.4351 - val_acc: 0.2160\n",
      "\n",
      "Epoch 137/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 902us/step - loss: 1.4775 - acc: 0.5901 - val_loss: 3.4312 - val_acc: 0.2160\n",
      "\n",
      "Epoch 138/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 941us/step - loss: 1.4678 - acc: 0.5883 - val_loss: 3.4277 - val_acc: 0.2160\n",
      "\n",
      "Epoch 139/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================]583/583 [==============================] - 1s 917us/step - loss: 1.4583 - acc: 0.5901 - val_loss: 3.4236 - val_acc: 0.2160\n",
      "\n",
      "Epoch 140/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 826us/step - loss: 1.4490 - acc: 0.5918 - val_loss: 3.4200 - val_acc: 0.2160\n",
      "\n",
      "Epoch 141/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 1.4401 - acc: 0.5935 - val_loss: 3.4160 - val_acc: 0.2160\n",
      "\n",
      "Epoch 142/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.4308 - acc: 0.5935 - val_loss: 3.4120 - val_acc: 0.2160\n",
      "\n",
      "Epoch 143/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 1.4218 - acc: 0.5935 - val_loss: 3.4081 - val_acc: 0.2160\n",
      "\n",
      "Epoch 144/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 857us/step - loss: 1.4128 - acc: 0.5952 - val_loss: 3.4044 - val_acc: 0.2160 0s - loss: 1.4414 - acc: 0.588\n",
      "\n",
      "Epoch 145/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 862us/step - loss: 1.4041 - acc: 0.5952 - val_loss: 3.4011 - val_acc: 0.2160TA: 0s - loss: 1.4103 - acc: 0.590\n",
      "\n",
      "Epoch 146/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 834us/step - loss: 1.3953 - acc: 0.5969 - val_loss: 3.3973 - val_acc: 0.2222\n",
      "\n",
      "Epoch 147/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 914us/step - loss: 1.3868 - acc: 0.6021 - val_loss: 3.3937 - val_acc: 0.2222\n",
      "\n",
      "Epoch 148/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 899us/step - loss: 1.3781 - acc: 0.6038 - val_loss: 3.3900 - val_acc: 0.2222\n",
      "\n",
      "Epoch 149/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 865us/step - loss: 1.3698 - acc: 0.6038 - val_loss: 3.3868 - val_acc: 0.2222\n",
      "\n",
      "Epoch 150/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 828us/step - loss: 1.3615 - acc: 0.6055 - val_loss: 3.3834 - val_acc: 0.2284\n",
      "\n",
      "Epoch 151/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 1.3531 - acc: 0.6089 - val_loss: 3.3797 - val_acc: 0.2346\n",
      "\n",
      "Epoch 152/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 880us/step - loss: 1.3447 - acc: 0.6141 - val_loss: 3.3765 - val_acc: 0.2346\n",
      "\n",
      "Epoch 153/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 891us/step - loss: 1.3363 - acc: 0.6158 - val_loss: 3.3727 - val_acc: 0.2346TA: 0s - loss: 1.3073 - acc: 0.612 - ETA: 0s - loss: 1.2814 - acc: 0.62\n",
      "\n",
      "Epoch 154/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 1.3280 - acc: 0.6158 - val_loss: 3.3701 - val_acc: 0.2346\n",
      "\n",
      "Epoch 155/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 1.3199 - acc: 0.6226 - val_loss: 3.3665 - val_acc: 0.2346\n",
      "\n",
      "Epoch 156/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 910us/step - loss: 1.3118 - acc: 0.6226 - val_loss: 3.3624 - val_acc: 0.2346\n",
      "\n",
      "Epoch 157/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 1.3039 - acc: 0.6226 - val_loss: 3.3593 - val_acc: 0.2346TA: 0s - loss: 1.2654 - acc: 0.63\n",
      "\n",
      "Epoch 158/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 914us/step - loss: 1.2961 - acc: 0.6244 - val_loss: 3.3562 - val_acc: 0.2346TA: 0s - loss: 1.3157 - acc: 0.\n",
      "\n",
      "Epoch 159/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 932us/step - loss: 1.2884 - acc: 0.6295 - val_loss: 3.3533 - val_acc: 0.2346TA: 0s - loss: 1.1972 - acc: 0\n",
      "\n",
      "Epoch 160/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 869us/step - loss: 1.2808 - acc: 0.6381 - val_loss: 3.3502 - val_acc: 0.2346TA: 0s - loss: 1.3297 - acc: 0.\n",
      "\n",
      "Epoch 161/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 850us/step - loss: 1.2733 - acc: 0.6398 - val_loss: 3.3470 - val_acc: 0.2346\n",
      "\n",
      "Epoch 162/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 867us/step - loss: 1.2660 - acc: 0.6415 - val_loss: 3.3439 - val_acc: 0.2346\n",
      "\n",
      "Epoch 163/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 914us/step - loss: 1.2585 - acc: 0.6449 - val_loss: 3.3411 - val_acc: 0.2346\n",
      "\n",
      "Epoch 164/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 883us/step - loss: 1.2512 - acc: 0.6518 - val_loss: 3.3382 - val_acc: 0.2346\n",
      "\n",
      "Epoch 165/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 802us/step - loss: 1.2442 - acc: 0.6518 - val_loss: 3.3352 - val_acc: 0.2346TA: 0s - loss: 1.2663 - acc: 0.\n",
      "\n",
      "Epoch 166/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 833us/step - loss: 1.2371 - acc: 0.6535 - val_loss: 3.3323 - val_acc: 0.2346\n",
      "\n",
      "Epoch 167/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 883us/step - loss: 1.2300 - acc: 0.6587 - val_loss: 3.3295 - val_acc: 0.2346\n",
      "\n",
      "Epoch 168/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 883us/step - loss: 1.2230 - acc: 0.6587 - val_loss: 3.3263 - val_acc: 0.2346TA: 0s - loss: 1.2371 - acc: 0.6\n",
      "\n",
      "Epoch 169/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 813us/step - loss: 1.2160 - acc: 0.6587 - val_loss: 3.3236 - val_acc: 0.2284\n",
      "\n",
      "Epoch 170/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 881us/step - loss: 1.2091 - acc: 0.6587 - val_loss: 3.3206 - val_acc: 0.2284\n",
      "\n",
      "Epoch 171/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 852us/step - loss: 1.2022 - acc: 0.6587 - val_loss: 3.3182 - val_acc: 0.2284\n",
      "\n",
      "Epoch 172/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 892us/step - loss: 1.1954 - acc: 0.6638 - val_loss: 3.3152 - val_acc: 0.2284\n",
      "\n",
      "Epoch 173/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 884us/step - loss: 1.1886 - acc: 0.6672 - val_loss: 3.3118 - val_acc: 0.2284TA: 0s - loss: 1.1952 - acc: 0.66\n",
      "\n",
      "Epoch 174/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 857us/step - loss: 1.1818 - acc: 0.6690 - val_loss: 3.3090 - val_acc: 0.2284\n",
      "\n",
      "Epoch 175/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 854us/step - loss: 1.1752 - acc: 0.6724 - val_loss: 3.3060 - val_acc: 0.2284TA: 0s - loss: 1.3949 - acc: \n",
      "\n",
      "Epoch 176/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 861us/step - loss: 1.1684 - acc: 0.6741 - val_loss: 3.3032 - val_acc: 0.2284TA: 0s - loss: 1.1953 - acc: 0.663\n",
      "\n",
      "Epoch 177/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 944us/step - loss: 1.1620 - acc: 0.6741 - val_loss: 3.3005 - val_acc: 0.2284\n",
      "\n",
      "Epoch 178/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 884us/step - loss: 1.1556 - acc: 0.6792 - val_loss: 3.2979 - val_acc: 0.2284\n",
      "\n",
      "Epoch 179/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 861us/step - loss: 1.1490 - acc: 0.6810 - val_loss: 3.2947 - val_acc: 0.2346\n",
      "\n",
      "Epoch 180/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 804us/step - loss: 1.1424 - acc: 0.6827 - val_loss: 3.2920 - val_acc: 0.2346\n",
      "\n",
      "Epoch 181/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 937us/step - loss: 1.1359 - acc: 0.6844 - val_loss: 3.2893 - val_acc: 0.2346\n",
      "\n",
      "Epoch 182/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 1.1298 - acc: 0.6861 - val_loss: 3.2866 - val_acc: 0.2346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 183/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 889us/step - loss: 1.1237 - acc: 0.6861 - val_loss: 3.2837 - val_acc: 0.2346\n",
      "\n",
      "Epoch 184/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 879us/step - loss: 1.1176 - acc: 0.6878 - val_loss: 3.2809 - val_acc: 0.2346\n",
      "\n",
      "Epoch 185/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 940us/step - loss: 1.1115 - acc: 0.6895 - val_loss: 3.2780 - val_acc: 0.2346\n",
      "\n",
      "Epoch 186/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 919us/step - loss: 1.1055 - acc: 0.6913 - val_loss: 3.2754 - val_acc: 0.2407\n",
      "\n",
      "Epoch 187/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 920us/step - loss: 1.0996 - acc: 0.6930 - val_loss: 3.2727 - val_acc: 0.2407\n",
      "\n",
      "Epoch 188/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 827us/step - loss: 1.0936 - acc: 0.6947 - val_loss: 3.2700 - val_acc: 0.2407TA: 0s - loss: 1.0623 - acc: 0.7\n",
      "\n",
      "Epoch 189/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 997us/step - loss: 1.0875 - acc: 0.6947 - val_loss: 3.2675 - val_acc: 0.2407\n",
      "\n",
      "Epoch 190/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 915us/step - loss: 1.0816 - acc: 0.6947 - val_loss: 3.2649 - val_acc: 0.2407\n",
      "\n",
      "Epoch 191/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 987us/step - loss: 1.0758 - acc: 0.6998 - val_loss: 3.2625 - val_acc: 0.2407\n",
      "\n",
      "Epoch 192/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 848us/step - loss: 1.0698 - acc: 0.7015 - val_loss: 3.2600 - val_acc: 0.2407TA: 0s - loss: 0.9301 - acc: \n",
      "\n",
      "Epoch 193/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 853us/step - loss: 1.0642 - acc: 0.7050 - val_loss: 3.2570 - val_acc: 0.2407\n",
      "\n",
      "Epoch 194/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 864us/step - loss: 1.0585 - acc: 0.7084 - val_loss: 3.2541 - val_acc: 0.2407\n",
      "\n",
      "Epoch 195/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 853us/step - loss: 1.0526 - acc: 0.7101 - val_loss: 3.2517 - val_acc: 0.2469\n",
      "\n",
      "Epoch 196/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 867us/step - loss: 1.0471 - acc: 0.7136 - val_loss: 3.2490 - val_acc: 0.2469\n",
      "\n",
      "Epoch 197/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 915us/step - loss: 1.0415 - acc: 0.7187 - val_loss: 3.2459 - val_acc: 0.2469TA: 0s - loss: 1.0170 - acc: \n",
      "\n",
      "Epoch 198/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 898us/step - loss: 1.0361 - acc: 0.7187 - val_loss: 3.2435 - val_acc: 0.2469\n",
      "\n",
      "Epoch 199/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 894us/step - loss: 1.0305 - acc: 0.7204 - val_loss: 3.2407 - val_acc: 0.2469\n",
      "\n",
      "Epoch 200/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 1.0252 - acc: 0.7204 - val_loss: 3.2381 - val_acc: 0.2469TA: 0s - loss: 1.1042 - acc: 0.\n",
      "\n",
      "65/65 [==============================]65/65 [==============================] - 0s 337us/step\n",
      "\n",
      "Train on 583 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "583/583 [==============================]583/583 [==============================] - 4s 7ms/step - loss: 5.1535 - acc: 0.0909 - val_loss: 4.7204 - val_acc: 0.0864\n",
      "\n",
      "Epoch 2/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 961us/step - loss: 5.0709 - acc: 0.0943 - val_loss: 4.6852 - val_acc: 0.0926\n",
      "\n",
      "Epoch 3/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 959us/step - loss: 4.9913 - acc: 0.0926 - val_loss: 4.6497 - val_acc: 0.0988\n",
      "\n",
      "Epoch 4/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 926us/step - loss: 4.9141 - acc: 0.0943 - val_loss: 4.6165 - val_acc: 0.0988: 0s - loss: 4.9776 - acc: 0.09\n",
      "\n",
      "Epoch 5/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 969us/step - loss: 4.8380 - acc: 0.0978 - val_loss: 4.5844 - val_acc: 0.0988\n",
      "\n",
      "Epoch 6/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 4.7627 - acc: 0.0995 - val_loss: 4.5534 - val_acc: 0.0988\n",
      "\n",
      "Epoch 7/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 4.6906 - acc: 0.1012 - val_loss: 4.5247 - val_acc: 0.0988\n",
      "\n",
      "Epoch 8/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 862us/step - loss: 4.6199 - acc: 0.1098 - val_loss: 4.4950 - val_acc: 0.0988\n",
      "\n",
      "Epoch 9/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 915us/step - loss: 4.5493 - acc: 0.1149 - val_loss: 4.4683 - val_acc: 0.1049\n",
      "\n",
      "Epoch 10/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 878us/step - loss: 4.4819 - acc: 0.1149 - val_loss: 4.4420 - val_acc: 0.1049\n",
      "\n",
      "Epoch 11/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 959us/step - loss: 4.4159 - acc: 0.1184 - val_loss: 4.4167 - val_acc: 0.1049\n",
      "\n",
      "Epoch 12/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 931us/step - loss: 4.3523 - acc: 0.1269 - val_loss: 4.3914 - val_acc: 0.1111\n",
      "\n",
      "Epoch 13/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 960us/step - loss: 4.2902 - acc: 0.1355 - val_loss: 4.3671 - val_acc: 0.1111\n",
      "\n",
      "Epoch 14/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 4.2302 - acc: 0.1389 - val_loss: 4.3431 - val_acc: 0.1111\n",
      "\n",
      "Epoch 15/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 4.1710 - acc: 0.1407 - val_loss: 4.3202 - val_acc: 0.1111\n",
      "\n",
      "Epoch 16/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 4.1132 - acc: 0.1424 - val_loss: 4.2978 - val_acc: 0.1111\n",
      "\n",
      "Epoch 17/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 908us/step - loss: 4.0582 - acc: 0.1475 - val_loss: 4.2765 - val_acc: 0.1111\n",
      "\n",
      "Epoch 18/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 918us/step - loss: 4.0042 - acc: 0.1475 - val_loss: 4.2564 - val_acc: 0.1111\n",
      "\n",
      "Epoch 19/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 828us/step - loss: 3.9511 - acc: 0.1527 - val_loss: 4.2379 - val_acc: 0.1111\n",
      "\n",
      "Epoch 20/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 928us/step - loss: 3.8992 - acc: 0.1561 - val_loss: 4.2193 - val_acc: 0.1173\n",
      "\n",
      "Epoch 21/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 818us/step - loss: 3.8482 - acc: 0.1578 - val_loss: 4.1993 - val_acc: 0.1173\n",
      "\n",
      "Epoch 22/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 872us/step - loss: 3.7980 - acc: 0.1647 - val_loss: 4.1814 - val_acc: 0.1173TA: 0s - loss: 3.8068 - acc: 0.171\n",
      "\n",
      "Epoch 23/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 899us/step - loss: 3.7504 - acc: 0.1664 - val_loss: 4.1633 - val_acc: 0.1173\n",
      "\n",
      "Epoch 24/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 820us/step - loss: 3.7022 - acc: 0.1750 - val_loss: 4.1458 - val_acc: 0.1173\n",
      "\n",
      "Epoch 25/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 3.6548 - acc: 0.1767 - val_loss: 4.1295 - val_acc: 0.1173\n",
      "\n",
      "Epoch 26/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 866us/step - loss: 3.6084 - acc: 0.1750 - val_loss: 4.1126 - val_acc: 0.1235\n",
      "\n",
      "Epoch 27/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 941us/step - loss: 3.5636 - acc: 0.1784 - val_loss: 4.0972 - val_acc: 0.1235TA: 0s - loss: 3.4729 - acc: 0\n",
      "\n",
      "Epoch 28/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 972us/step - loss: 3.5186 - acc: 0.1835 - val_loss: 4.0808 - val_acc: 0.1235\n",
      "\n",
      "Epoch 29/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 891us/step - loss: 3.4755 - acc: 0.1870 - val_loss: 4.0660 - val_acc: 0.1296\n",
      "\n",
      "Epoch 30/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 976us/step - loss: 3.4327 - acc: 0.1870 - val_loss: 4.0518 - val_acc: 0.1296\n",
      "\n",
      "Epoch 31/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 908us/step - loss: 3.3907 - acc: 0.1904 - val_loss: 4.0385 - val_acc: 0.1358\n",
      "\n",
      "Epoch 32/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 946us/step - loss: 3.3498 - acc: 0.1921 - val_loss: 4.0246 - val_acc: 0.1358\n",
      "\n",
      "Epoch 33/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 914us/step - loss: 3.3084 - acc: 0.1955 - val_loss: 4.0116 - val_acc: 0.1358\n",
      "\n",
      "Epoch 34/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 870us/step - loss: 3.2694 - acc: 0.1973 - val_loss: 3.9969 - val_acc: 0.1358\n",
      "\n",
      "Epoch 35/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 902us/step - loss: 3.2310 - acc: 0.2007 - val_loss: 3.9846 - val_acc: 0.1358[=========================>....] - ETA: 0s - loss: 3.2501 - acc: 0.191576/583 [============================>.] - ETA: 0s - loss: 3.2262 - acc: 0.201\n",
      "\n",
      "Epoch 36/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 798us/step - loss: 3.1948 - acc: 0.2075 - val_loss: 3.9717 - val_acc: 0.1358TA: 0s - loss: 3.2344 - acc: 0.20\n",
      "\n",
      "Epoch 37/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 971us/step - loss: 3.1586 - acc: 0.2075 - val_loss: 3.9595 - val_acc: 0.1358TA: 0s - loss: 3.1513 - acc: 0.21\n",
      "\n",
      "Epoch 38/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 875us/step - loss: 3.1226 - acc: 0.2144 - val_loss: 3.9475 - val_acc: 0.1420\n",
      "\n",
      "Epoch 39/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 841us/step - loss: 3.0872 - acc: 0.2178 - val_loss: 3.9353 - val_acc: 0.1420\n",
      "\n",
      "Epoch 40/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 941us/step - loss: 3.0532 - acc: 0.2213 - val_loss: 3.9248 - val_acc: 0.1481\n",
      "\n",
      "Epoch 41/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 3.0194 - acc: 0.2281 - val_loss: 3.9134 - val_acc: 0.1481\n",
      "\n",
      "Epoch 42/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 805us/step - loss: 2.9870 - acc: 0.2350 - val_loss: 3.9012 - val_acc: 0.1481\n",
      "\n",
      "Epoch 43/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 2.9545 - acc: 0.2401 - val_loss: 3.8894 - val_acc: 0.1481TA: 0s - loss: 2.8277 - acc: 0.\n",
      "\n",
      "Epoch 44/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 984us/step - loss: 2.9230 - acc: 0.2401 - val_loss: 3.8788 - val_acc: 0.1481\n",
      "\n",
      "Epoch 45/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 989us/step - loss: 2.8915 - acc: 0.2419 - val_loss: 3.8686 - val_acc: 0.1481\n",
      "\n",
      "Epoch 46/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 876us/step - loss: 2.8620 - acc: 0.2470 - val_loss: 3.8585 - val_acc: 0.1481TA: 0s - loss: 2.8788 - acc: 0.\n",
      "\n",
      "Epoch 47/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.8320 - acc: 0.2539 - val_loss: 3.8481 - val_acc: 0.1481\n",
      "\n",
      "Epoch 48/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 914us/step - loss: 2.8027 - acc: 0.2573 - val_loss: 3.8385 - val_acc: 0.1481\n",
      "\n",
      "Epoch 49/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 885us/step - loss: 2.7743 - acc: 0.2590 - val_loss: 3.8285 - val_acc: 0.1481\n",
      "\n",
      "Epoch 50/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 2.7455 - acc: 0.2590 - val_loss: 3.8174 - val_acc: 0.1481\n",
      "\n",
      "Epoch 51/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 892us/step - loss: 2.7173 - acc: 0.2624 - val_loss: 3.8088 - val_acc: 0.1481\n",
      "\n",
      "Epoch 52/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 2.6901 - acc: 0.2693 - val_loss: 3.7995 - val_acc: 0.1481\n",
      "\n",
      "Epoch 53/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 2.6633 - acc: 0.2727 - val_loss: 3.7893 - val_acc: 0.1481\n",
      "\n",
      "Epoch 54/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 961us/step - loss: 2.6362 - acc: 0.2796 - val_loss: 3.7787 - val_acc: 0.1481TA: 0s - loss: 2.5385 - acc: 0.2\n",
      "\n",
      "Epoch 55/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 830us/step - loss: 2.6101 - acc: 0.2899 - val_loss: 3.7704 - val_acc: 0.1481TA: 0s - loss: 2.6174 - acc: 0.290\n",
      "\n",
      "Epoch 56/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 855us/step - loss: 2.5848 - acc: 0.2916 - val_loss: 3.7611 - val_acc: 0.1481\n",
      "\n",
      "Epoch 57/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 2.5597 - acc: 0.2916 - val_loss: 3.7526 - val_acc: 0.1481\n",
      "\n",
      "Epoch 58/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 963us/step - loss: 2.5352 - acc: 0.2985 - val_loss: 3.7435 - val_acc: 0.1481\n",
      "\n",
      "Epoch 59/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 921us/step - loss: 2.5110 - acc: 0.2985 - val_loss: 3.7349 - val_acc: 0.1481\n",
      "\n",
      "Epoch 60/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 948us/step - loss: 2.4876 - acc: 0.3019 - val_loss: 3.7274 - val_acc: 0.1481TA: 0s - loss: 2.4949 - acc: 0.300\n",
      "\n",
      "Epoch 61/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 972us/step - loss: 2.4647 - acc: 0.3087 - val_loss: 3.7200 - val_acc: 0.1481\n",
      "\n",
      "Epoch 62/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 826us/step - loss: 2.4417 - acc: 0.3122 - val_loss: 3.7122 - val_acc: 0.1481\n",
      "\n",
      "Epoch 63/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 956us/step - loss: 2.4192 - acc: 0.3208 - val_loss: 3.7054 - val_acc: 0.1481\n",
      "\n",
      "Epoch 64/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 790us/step - loss: 2.3973 - acc: 0.3259 - val_loss: 3.6983 - val_acc: 0.1481\n",
      "\n",
      "Epoch 65/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 956us/step - loss: 2.3756 - acc: 0.3310 - val_loss: 3.6911 - val_acc: 0.1481\n",
      "\n",
      "Epoch 66/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 873us/step - loss: 2.3543 - acc: 0.3362 - val_loss: 3.6850 - val_acc: 0.1481TA: 0s - loss: 2.3737 - acc: 0.33\n",
      "\n",
      "Epoch 67/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.3330 - acc: 0.3413 - val_loss: 3.6790 - val_acc: 0.1420\n",
      "\n",
      "Epoch 68/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 949us/step - loss: 2.3126 - acc: 0.3516 - val_loss: 3.6713 - val_acc: 0.1420\n",
      "\n",
      "Epoch 69/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 2.2923 - acc: 0.3551 - val_loss: 3.6650 - val_acc: 0.1420\n",
      "\n",
      "Epoch 70/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 802us/step - loss: 2.2725 - acc: 0.3585 - val_loss: 3.6579 - val_acc: 0.1481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 71/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 919us/step - loss: 2.2527 - acc: 0.3602 - val_loss: 3.6514 - val_acc: 0.1481\n",
      "\n",
      "Epoch 72/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 938us/step - loss: 2.2331 - acc: 0.3619 - val_loss: 3.6447 - val_acc: 0.1481\n",
      "\n",
      "Epoch 73/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 952us/step - loss: 2.2141 - acc: 0.3688 - val_loss: 3.6384 - val_acc: 0.1481\n",
      "\n",
      "Epoch 74/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 2.1949 - acc: 0.3739 - val_loss: 3.6320 - val_acc: 0.1481\n",
      "\n",
      "Epoch 75/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 854us/step - loss: 2.1764 - acc: 0.3791 - val_loss: 3.6255 - val_acc: 0.1481\n",
      "\n",
      "Epoch 76/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 839us/step - loss: 2.1580 - acc: 0.3859 - val_loss: 3.6187 - val_acc: 0.1481\n",
      "\n",
      "Epoch 77/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 932us/step - loss: 2.1398 - acc: 0.3877 - val_loss: 3.6122 - val_acc: 0.1543\n",
      "\n",
      "Epoch 78/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 989us/step - loss: 2.1217 - acc: 0.3945 - val_loss: 3.6059 - val_acc: 0.1543\n",
      "\n",
      "Epoch 79/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 895us/step - loss: 2.1041 - acc: 0.3945 - val_loss: 3.5998 - val_acc: 0.1543\n",
      "\n",
      "Epoch 80/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 804us/step - loss: 2.0863 - acc: 0.3997 - val_loss: 3.5936 - val_acc: 0.1543\n",
      "\n",
      "Epoch 81/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 2.0692 - acc: 0.3997 - val_loss: 3.5873 - val_acc: 0.1543\n",
      "\n",
      "Epoch 82/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 943us/step - loss: 2.0526 - acc: 0.4082 - val_loss: 3.5811 - val_acc: 0.1543\n",
      "\n",
      "Epoch 83/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 916us/step - loss: 2.0360 - acc: 0.4168 - val_loss: 3.5751 - val_acc: 0.1605\n",
      "\n",
      "Epoch 84/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 2.0196 - acc: 0.4168 - val_loss: 3.5693 - val_acc: 0.1605TA: 0s - loss: 2.0138 - acc: 0.421\n",
      "\n",
      "Epoch 85/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 2.0035 - acc: 0.4202 - val_loss: 3.5624 - val_acc: 0.1605\n",
      "\n",
      "Epoch 86/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 1.9879 - acc: 0.4271 - val_loss: 3.5574 - val_acc: 0.1605\n",
      "\n",
      "Epoch 87/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 932us/step - loss: 1.9724 - acc: 0.4305 - val_loss: 3.5507 - val_acc: 0.1667TA: 0s - loss: 1.9068 - acc: 0.437 - ETA: 0s - loss: 1.9138 - acc: 0.43\n",
      "\n",
      "Epoch 88/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 816us/step - loss: 1.9566 - acc: 0.4322 - val_loss: 3.5453 - val_acc: 0.1667\n",
      "\n",
      "Epoch 89/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 813us/step - loss: 1.9413 - acc: 0.4340 - val_loss: 3.5399 - val_acc: 0.1667\n",
      "\n",
      "Epoch 90/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 945us/step - loss: 1.9264 - acc: 0.4391 - val_loss: 3.5342 - val_acc: 0.1728\n",
      "\n",
      "Epoch 91/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 1.9118 - acc: 0.4408 - val_loss: 3.5287 - val_acc: 0.1728\n",
      "\n",
      "Epoch 92/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 915us/step - loss: 1.8966 - acc: 0.4443 - val_loss: 3.5237 - val_acc: 0.1728TA: 0s - loss: 1.9021 - acc: 0.442\n",
      "\n",
      "Epoch 93/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 829us/step - loss: 1.8823 - acc: 0.4477 - val_loss: 3.5188 - val_acc: 0.1728\n",
      "\n",
      "Epoch 94/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 854us/step - loss: 1.8680 - acc: 0.4477 - val_loss: 3.5123 - val_acc: 0.1728\n",
      "\n",
      "Epoch 95/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.8537 - acc: 0.4511 - val_loss: 3.5071 - val_acc: 0.1790 ETA: 0s - loss: 1.8295 - acc: 0.46\n",
      "\n",
      "Epoch 96/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 1.8400 - acc: 0.4545 - val_loss: 3.5020 - val_acc: 0.1790\n",
      "\n",
      "Epoch 97/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 911us/step - loss: 1.8265 - acc: 0.4545 - val_loss: 3.4964 - val_acc: 0.1790TA: 0s - loss: 1.6724 - acc: 0 - ETA: 0s - loss: 1.7837 - acc: 0.460\n",
      "\n",
      "Epoch 98/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 833us/step - loss: 1.8128 - acc: 0.4563 - val_loss: 3.4908 - val_acc: 0.1790\n",
      "\n",
      "Epoch 99/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 885us/step - loss: 1.7993 - acc: 0.4597 - val_loss: 3.4857 - val_acc: 0.1790\n",
      "\n",
      "Epoch 100/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 961us/step - loss: 1.7865 - acc: 0.4631 - val_loss: 3.4802 - val_acc: 0.1790\n",
      "\n",
      "Epoch 101/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 979us/step - loss: 1.7733 - acc: 0.4666 - val_loss: 3.4743 - val_acc: 0.1852\n",
      "\n",
      "Epoch 102/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 923us/step - loss: 1.7605 - acc: 0.4700 - val_loss: 3.4692 - val_acc: 0.1852\n",
      "\n",
      "Epoch 103/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 857us/step - loss: 1.7469 - acc: 0.4717 - val_loss: 3.4643 - val_acc: 0.1852\n",
      "\n",
      "Epoch 104/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 862us/step - loss: 1.7343 - acc: 0.4751 - val_loss: 3.4590 - val_acc: 0.1852\n",
      "\n",
      "Epoch 105/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 917us/step - loss: 1.7218 - acc: 0.4803 - val_loss: 3.4545 - val_acc: 0.1852TA: 0s - loss: 1.7305 - acc: 0.476\n",
      "\n",
      "Epoch 106/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 796us/step - loss: 1.7096 - acc: 0.4871 - val_loss: 3.4502 - val_acc: 0.1852TA: 0s - loss: 1.6690 - acc: 0.\n",
      "\n",
      "Epoch 107/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 896us/step - loss: 1.6973 - acc: 0.4906 - val_loss: 3.4459 - val_acc: 0.1852\n",
      "\n",
      "Epoch 108/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 879us/step - loss: 1.6851 - acc: 0.4940 - val_loss: 3.4417 - val_acc: 0.1852\n",
      "\n",
      "Epoch 109/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 798us/step - loss: 1.6733 - acc: 0.4974 - val_loss: 3.4376 - val_acc: 0.1914TA: 0s - loss: 1.6557 - acc: 0.501\n",
      "\n",
      "Epoch 110/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.6617 - acc: 0.5026 - val_loss: 3.4331 - val_acc: 0.1914\n",
      "\n",
      "Epoch 111/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 940us/step - loss: 1.6501 - acc: 0.5043 - val_loss: 3.4285 - val_acc: 0.1914\n",
      "\n",
      "Epoch 112/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.6386 - acc: 0.5077 - val_loss: 3.4239 - val_acc: 0.1914\n",
      "\n",
      "Epoch 113/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 826us/step - loss: 1.6271 - acc: 0.5094 - val_loss: 3.4195 - val_acc: 0.1914TA: 0s - loss: 1.6507 - acc: 0.\n",
      "\n",
      "Epoch 114/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 889us/step - loss: 1.6159 - acc: 0.5129 - val_loss: 3.4144 - val_acc: 0.1975\n",
      "\n",
      "Epoch 115/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 942us/step - loss: 1.6048 - acc: 0.5129 - val_loss: 3.4097 - val_acc: 0.2037\n",
      "\n",
      "Epoch 116/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 895us/step - loss: 1.5931 - acc: 0.5146 - val_loss: 3.4054 - val_acc: 0.2037\n",
      "\n",
      "Epoch 117/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 910us/step - loss: 1.5825 - acc: 0.5180 - val_loss: 3.4008 - val_acc: 0.2037\n",
      "\n",
      "Epoch 118/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 953us/step - loss: 1.5716 - acc: 0.5180 - val_loss: 3.3971 - val_acc: 0.2099\n",
      "\n",
      "Epoch 119/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 1.5609 - acc: 0.5249 - val_loss: 3.3932 - val_acc: 0.2099\n",
      "\n",
      "Epoch 120/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 1.5507 - acc: 0.5266 - val_loss: 3.3894 - val_acc: 0.2099TA: 0s - loss: 1.6355 - acc: 0.\n",
      "\n",
      "Epoch 121/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 933us/step - loss: 1.5402 - acc: 0.5300 - val_loss: 3.3851 - val_acc: 0.2099TA: 0s - loss: 1.4936 - acc: 0.5\n",
      "\n",
      "Epoch 122/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 958us/step - loss: 1.5297 - acc: 0.5317 - val_loss: 3.3808 - val_acc: 0.2099\n",
      "\n",
      "Epoch 123/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 899us/step - loss: 1.5194 - acc: 0.5317 - val_loss: 3.3766 - val_acc: 0.2037\n",
      "\n",
      "Epoch 124/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.5094 - acc: 0.5334 - val_loss: 3.3727 - val_acc: 0.2037\n",
      "\n",
      "Epoch 125/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 951us/step - loss: 1.4994 - acc: 0.5403 - val_loss: 3.3683 - val_acc: 0.2099\n",
      "\n",
      "Epoch 126/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 1.4896 - acc: 0.5437 - val_loss: 3.3642 - val_acc: 0.2099\n",
      "\n",
      "Epoch 127/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 971us/step - loss: 1.4798 - acc: 0.5455 - val_loss: 3.3604 - val_acc: 0.2099\n",
      "\n",
      "Epoch 128/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 1.4703 - acc: 0.5472 - val_loss: 3.3560 - val_acc: 0.2099\n",
      "\n",
      "Epoch 129/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 879us/step - loss: 1.4609 - acc: 0.5506 - val_loss: 3.3522 - val_acc: 0.2099\n",
      "\n",
      "Epoch 130/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 804us/step - loss: 1.4513 - acc: 0.5557 - val_loss: 3.3481 - val_acc: 0.2099\n",
      "\n",
      "Epoch 131/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 917us/step - loss: 1.4421 - acc: 0.5609 - val_loss: 3.3439 - val_acc: 0.2099\n",
      "\n",
      "Epoch 132/200\n",
      "583/583 [==============================]583/583 [==============================] - ETA: 0s - loss: 1.4617 - acc: 0.550544/583 [==========================>...] - ETA: 0s - loss: 1.4316 - acc: 0.560 - 1s 926us/step - loss: 1.4330 - acc: 0.5643 - val_loss: 3.3403 - val_acc: 0.2099\n",
      "\n",
      "Epoch 133/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 877us/step - loss: 1.4240 - acc: 0.5660 - val_loss: 3.3366 - val_acc: 0.2099\n",
      "\n",
      "Epoch 134/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 930us/step - loss: 1.4151 - acc: 0.5712 - val_loss: 3.3327 - val_acc: 0.2099\n",
      "\n",
      "Epoch 135/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 811us/step - loss: 1.4063 - acc: 0.5746 - val_loss: 3.3292 - val_acc: 0.2099\n",
      "\n",
      "Epoch 136/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 918us/step - loss: 1.3974 - acc: 0.5780 - val_loss: 3.3255 - val_acc: 0.2160\n",
      "\n",
      "Epoch 137/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 823us/step - loss: 1.3886 - acc: 0.5780 - val_loss: 3.3216 - val_acc: 0.2160\n",
      "\n",
      "Epoch 138/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 806us/step - loss: 1.3801 - acc: 0.5780 - val_loss: 3.3172 - val_acc: 0.2160\n",
      "\n",
      "Epoch 139/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 857us/step - loss: 1.3713 - acc: 0.5832 - val_loss: 3.3139 - val_acc: 0.2160\n",
      "\n",
      "Epoch 140/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 943us/step - loss: 1.3629 - acc: 0.5866 - val_loss: 3.3104 - val_acc: 0.2160\n",
      "\n",
      "Epoch 141/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.3542 - acc: 0.5935 - val_loss: 3.3066 - val_acc: 0.2160\n",
      "\n",
      "Epoch 142/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 857us/step - loss: 1.3460 - acc: 0.5952 - val_loss: 3.3030 - val_acc: 0.2160: 0s - loss: 1.3405 - acc: 0.597\n",
      "\n",
      "Epoch 143/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 926us/step - loss: 1.3380 - acc: 0.5969 - val_loss: 3.2997 - val_acc: 0.2160\n",
      "\n",
      "Epoch 144/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 875us/step - loss: 1.3298 - acc: 0.5986 - val_loss: 3.2961 - val_acc: 0.2160\n",
      "\n",
      "Epoch 145/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 801us/step - loss: 1.3218 - acc: 0.6038 - val_loss: 3.2925 - val_acc: 0.2160TA: 0s - loss: 1.2455 - acc: 0.\n",
      "\n",
      "Epoch 146/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 1.3138 - acc: 0.6038 - val_loss: 3.2887 - val_acc: 0.2160\n",
      "\n",
      "Epoch 147/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 912us/step - loss: 1.3058 - acc: 0.6055 - val_loss: 3.2856 - val_acc: 0.2160TA: 0s - loss: 1.3595 - acc: 0.58\n",
      "\n",
      "Epoch 148/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 1.2979 - acc: 0.6055 - val_loss: 3.2824 - val_acc: 0.2160\n",
      "\n",
      "Epoch 149/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 944us/step - loss: 1.2901 - acc: 0.6123 - val_loss: 3.2790 - val_acc: 0.2160\n",
      "\n",
      "Epoch 150/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.2823 - acc: 0.6141 - val_loss: 3.2760 - val_acc: 0.2160\n",
      "\n",
      "Epoch 151/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 946us/step - loss: 1.2749 - acc: 0.6175 - val_loss: 3.2728 - val_acc: 0.2160\n",
      "\n",
      "Epoch 152/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 939us/step - loss: 1.2674 - acc: 0.6244 - val_loss: 3.2702 - val_acc: 0.2099\n",
      "\n",
      "Epoch 153/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 885us/step - loss: 1.2600 - acc: 0.6261 - val_loss: 3.2674 - val_acc: 0.2160\n",
      "\n",
      "Epoch 154/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.2526 - acc: 0.6278 - val_loss: 3.2641 - val_acc: 0.2160\n",
      "\n",
      "Epoch 155/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 973us/step - loss: 1.2453 - acc: 0.6295 - val_loss: 3.2609 - val_acc: 0.2160\n",
      "\n",
      "Epoch 156/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 884us/step - loss: 1.2381 - acc: 0.6329 - val_loss: 3.2573 - val_acc: 0.2222\n",
      "\n",
      "Epoch 157/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 942us/step - loss: 1.2310 - acc: 0.6364 - val_loss: 3.2540 - val_acc: 0.2222\n",
      "\n",
      "Epoch 158/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 920us/step - loss: 1.2240 - acc: 0.6381 - val_loss: 3.2510 - val_acc: 0.2222\n",
      "\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================]583/583 [==============================] - 0s 855us/step - loss: 1.2170 - acc: 0.6398 - val_loss: 3.2480 - val_acc: 0.2222\n",
      "\n",
      "Epoch 160/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.2102 - acc: 0.6432 - val_loss: 3.2454 - val_acc: 0.2222\n",
      "\n",
      "Epoch 161/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.2034 - acc: 0.6449 - val_loss: 3.2429 - val_acc: 0.2222\n",
      "\n",
      "Epoch 162/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 987us/step - loss: 1.1966 - acc: 0.6467 - val_loss: 3.2400 - val_acc: 0.2222\n",
      "\n",
      "Epoch 163/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 902us/step - loss: 1.1900 - acc: 0.6467 - val_loss: 3.2375 - val_acc: 0.2222\n",
      "\n",
      "Epoch 164/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 898us/step - loss: 1.1834 - acc: 0.6484 - val_loss: 3.2344 - val_acc: 0.2222\n",
      "\n",
      "Epoch 165/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 978us/step - loss: 1.1767 - acc: 0.6518 - val_loss: 3.2309 - val_acc: 0.2222\n",
      "\n",
      "Epoch 166/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 869us/step - loss: 1.1702 - acc: 0.6535 - val_loss: 3.2281 - val_acc: 0.2222\n",
      "\n",
      "Epoch 167/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 798us/step - loss: 1.1637 - acc: 0.6552 - val_loss: 3.2254 - val_acc: 0.2284\n",
      "\n",
      "Epoch 168/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 889us/step - loss: 1.1574 - acc: 0.6569 - val_loss: 3.2229 - val_acc: 0.2284\n",
      "\n",
      "Epoch 169/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.1512 - acc: 0.6569 - val_loss: 3.2200 - val_acc: 0.2284\n",
      "\n",
      "Epoch 170/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 915us/step - loss: 1.1450 - acc: 0.6587 - val_loss: 3.2173 - val_acc: 0.2284\n",
      "\n",
      "Epoch 171/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 880us/step - loss: 1.1388 - acc: 0.6690 - val_loss: 3.2145 - val_acc: 0.2284\n",
      "\n",
      "Epoch 172/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 912us/step - loss: 1.1326 - acc: 0.6724 - val_loss: 3.2118 - val_acc: 0.2284\n",
      "\n",
      "Epoch 173/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 1.1267 - acc: 0.6741 - val_loss: 3.2096 - val_acc: 0.2284\n",
      "\n",
      "Epoch 174/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 830us/step - loss: 1.1207 - acc: 0.6758 - val_loss: 3.2072 - val_acc: 0.2284\n",
      "\n",
      "Epoch 175/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 855us/step - loss: 1.1148 - acc: 0.6792 - val_loss: 3.2045 - val_acc: 0.2284\n",
      "\n",
      "Epoch 176/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 829us/step - loss: 1.1090 - acc: 0.6792 - val_loss: 3.2014 - val_acc: 0.2346\n",
      "\n",
      "Epoch 177/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 970us/step - loss: 1.1031 - acc: 0.6827 - val_loss: 3.1991 - val_acc: 0.2346\n",
      "\n",
      "Epoch 178/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 946us/step - loss: 1.0973 - acc: 0.6827 - val_loss: 3.1966 - val_acc: 0.2346\n",
      "\n",
      "Epoch 179/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 1.0915 - acc: 0.6844 - val_loss: 3.1946 - val_acc: 0.2346\n",
      "\n",
      "Epoch 180/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 830us/step - loss: 1.0859 - acc: 0.6861 - val_loss: 3.1927 - val_acc: 0.2346\n",
      "\n",
      "Epoch 181/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 938us/step - loss: 1.0802 - acc: 0.6861 - val_loss: 3.1902 - val_acc: 0.2346TA: 0s - loss: 0.9924 - acc:\n",
      "\n",
      "Epoch 182/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 926us/step - loss: 1.0748 - acc: 0.6878 - val_loss: 3.1879 - val_acc: 0.2346\n",
      "\n",
      "Epoch 183/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 1.0693 - acc: 0.6895 - val_loss: 3.1853 - val_acc: 0.2346\n",
      "\n",
      "Epoch 184/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 1.0638 - acc: 0.6913 - val_loss: 3.1832 - val_acc: 0.2346\n",
      "\n",
      "Epoch 185/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 843us/step - loss: 1.0585 - acc: 0.6930 - val_loss: 3.1812 - val_acc: 0.2346\n",
      "\n",
      "Epoch 186/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 931us/step - loss: 1.0532 - acc: 0.6930 - val_loss: 3.1793 - val_acc: 0.2346\n",
      "\n",
      "Epoch 187/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 861us/step - loss: 1.0478 - acc: 0.6998 - val_loss: 3.1773 - val_acc: 0.2346\n",
      "\n",
      "Epoch 188/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 927us/step - loss: 1.0426 - acc: 0.6998 - val_loss: 3.1757 - val_acc: 0.2346\n",
      "\n",
      "Epoch 189/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 940us/step - loss: 1.0374 - acc: 0.7015 - val_loss: 3.1736 - val_acc: 0.2346TA: 0s - loss: 1.0287 - acc: 0.702\n",
      "\n",
      "Epoch 190/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 945us/step - loss: 1.0323 - acc: 0.7015 - val_loss: 3.1710 - val_acc: 0.2346\n",
      "\n",
      "Epoch 191/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 829us/step - loss: 1.0272 - acc: 0.7050 - val_loss: 3.1689 - val_acc: 0.2346\n",
      "\n",
      "Epoch 192/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 803us/step - loss: 1.0221 - acc: 0.7050 - val_loss: 3.1667 - val_acc: 0.2346\n",
      "\n",
      "Epoch 193/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 834us/step - loss: 1.0172 - acc: 0.7050 - val_loss: 3.1646 - val_acc: 0.2346TA: 0s - loss: 1.0110 - acc: 0.6384/583 [==================>...........] - ETA: 0s - loss: 0.9792 - acc: 0.70544/583 [==========================>...] - ETA: 0s - loss: 1.0265 - acc: 0.700\n",
      "\n",
      "Epoch 194/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 992us/step - loss: 1.0122 - acc: 0.7050 - val_loss: 3.1622 - val_acc: 0.2346\n",
      "\n",
      "Epoch 195/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 974us/step - loss: 1.0072 - acc: 0.7050 - val_loss: 3.1599 - val_acc: 0.2346\n",
      "\n",
      "Epoch 196/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 1.0021 - acc: 0.7084 - val_loss: 3.1574 - val_acc: 0.2346\n",
      "\n",
      "Epoch 197/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 885us/step - loss: 0.9971 - acc: 0.7084 - val_loss: 3.1550 - val_acc: 0.2346\n",
      "\n",
      "Epoch 198/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 0.9921 - acc: 0.7118 - val_loss: 3.1528 - val_acc: 0.2346\n",
      "\n",
      "Epoch 199/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 0.9870 - acc: 0.7118 - val_loss: 3.1506 - val_acc: 0.2346TA: 0s - loss: 0.9751 - acc: 0.717\n",
      "\n",
      "Epoch 200/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 829us/step - loss: 0.9820 - acc: 0.7118 - val_loss: 3.1485 - val_acc: 0.2346\n",
      "\n",
      "65/65 [==============================]65/65 [==============================] - 0s 592us/step\n",
      "\n",
      "Train on 583 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "583/583 [==============================]583/583 [==============================] - 4s 7ms/step - loss: 4.9792 - acc: 0.1184 - val_loss: 4.5889 - val_acc: 0.1235\n",
      "\n",
      "Epoch 2/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 891us/step - loss: 4.9080 - acc: 0.1184 - val_loss: 4.5633 - val_acc: 0.1235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 934us/step - loss: 4.8401 - acc: 0.1218 - val_loss: 4.5361 - val_acc: 0.1235\n",
      "\n",
      "Epoch 4/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 918us/step - loss: 4.7724 - acc: 0.1252 - val_loss: 4.5128 - val_acc: 0.1235\n",
      "\n",
      "Epoch 5/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 941us/step - loss: 4.7089 - acc: 0.1304 - val_loss: 4.4893 - val_acc: 0.1235\n",
      "\n",
      "Epoch 6/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 878us/step - loss: 4.6482 - acc: 0.1338 - val_loss: 4.4659 - val_acc: 0.1235\n",
      "\n",
      "Epoch 7/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 873us/step - loss: 4.5893 - acc: 0.1407 - val_loss: 4.4425 - val_acc: 0.1235\n",
      "\n",
      "Epoch 8/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 847us/step - loss: 4.5315 - acc: 0.1441 - val_loss: 4.4203 - val_acc: 0.1235\n",
      "\n",
      "Epoch 9/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 920us/step - loss: 4.4754 - acc: 0.1441 - val_loss: 4.3990 - val_acc: 0.1296\n",
      "\n",
      "Epoch 10/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 853us/step - loss: 4.4202 - acc: 0.1492 - val_loss: 4.3775 - val_acc: 0.1296\n",
      "\n",
      "Epoch 11/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 918us/step - loss: 4.3684 - acc: 0.1527 - val_loss: 4.3575 - val_acc: 0.1296\n",
      "\n",
      "Epoch 12/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 4.3171 - acc: 0.1595 - val_loss: 4.3373 - val_acc: 0.1296 ETA: 0s - loss: 4.3363 - acc: 0\n",
      "\n",
      "Epoch 13/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 951us/step - loss: 4.2671 - acc: 0.1595 - val_loss: 4.3179 - val_acc: 0.1296\n",
      "\n",
      "Epoch 14/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 996us/step - loss: 4.2187 - acc: 0.1647 - val_loss: 4.2979 - val_acc: 0.1296\n",
      "\n",
      "Epoch 15/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 920us/step - loss: 4.1704 - acc: 0.1681 - val_loss: 4.2809 - val_acc: 0.1296\n",
      "\n",
      "Epoch 16/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 4.1255 - acc: 0.1715 - val_loss: 4.2639 - val_acc: 0.1358\n",
      "\n",
      "Epoch 17/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 882us/step - loss: 4.0820 - acc: 0.1732 - val_loss: 4.2490 - val_acc: 0.1420TA: 0s - loss: 4.1378 - acc:\n",
      "\n",
      "Epoch 18/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 932us/step - loss: 4.0391 - acc: 0.1750 - val_loss: 4.2334 - val_acc: 0.1481TA: 0s - loss: 4.0748 - acc: 0.17\n",
      "\n",
      "Epoch 19/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 3.9967 - acc: 0.1750 - val_loss: 4.2198 - val_acc: 0.1481\n",
      "\n",
      "Epoch 20/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 866us/step - loss: 3.9564 - acc: 0.1767 - val_loss: 4.2045 - val_acc: 0.1481\n",
      "\n",
      "Epoch 21/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 943us/step - loss: 3.9162 - acc: 0.1801 - val_loss: 4.1901 - val_acc: 0.1420\n",
      "\n",
      "Epoch 22/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 3.8774 - acc: 0.1818 - val_loss: 4.1759 - val_acc: 0.1358\n",
      "\n",
      "Epoch 23/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 855us/step - loss: 3.8393 - acc: 0.1852 - val_loss: 4.1629 - val_acc: 0.1358\n",
      "\n",
      "Epoch 24/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 805us/step - loss: 3.8019 - acc: 0.1887 - val_loss: 4.1497 - val_acc: 0.1358TA: 0s - loss: 3.8442 - acc: 0.189\n",
      "\n",
      "Epoch 25/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 882us/step - loss: 3.7650 - acc: 0.1904 - val_loss: 4.1369 - val_acc: 0.1358\n",
      "\n",
      "Epoch 26/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 932us/step - loss: 3.7285 - acc: 0.1904 - val_loss: 4.1228 - val_acc: 0.1358\n",
      "\n",
      "Epoch 27/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 842us/step - loss: 3.6924 - acc: 0.1904 - val_loss: 4.1103 - val_acc: 0.1420\n",
      "\n",
      "Epoch 28/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 3.6575 - acc: 0.1973 - val_loss: 4.0972 - val_acc: 0.1420\n",
      "\n",
      "Epoch 29/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 857us/step - loss: 3.6228 - acc: 0.2007 - val_loss: 4.0854 - val_acc: 0.1420TA: 0s - loss: 3.6492 - acc: 0.199\n",
      "\n",
      "Epoch 30/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 798us/step - loss: 3.5890 - acc: 0.2058 - val_loss: 4.0726 - val_acc: 0.1420\n",
      "\n",
      "Epoch 31/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 3.5543 - acc: 0.2144 - val_loss: 4.0604 - val_acc: 0.1358\n",
      "\n",
      "Epoch 32/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 856us/step - loss: 3.5212 - acc: 0.2144 - val_loss: 4.0486 - val_acc: 0.1358\n",
      "\n",
      "Epoch 33/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 857us/step - loss: 3.4881 - acc: 0.2230 - val_loss: 4.0368 - val_acc: 0.1420\n",
      "\n",
      "Epoch 34/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 3.4561 - acc: 0.2230 - val_loss: 4.0259 - val_acc: 0.1420\n",
      "\n",
      "Epoch 35/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 920us/step - loss: 3.4243 - acc: 0.2264 - val_loss: 4.0153 - val_acc: 0.1420\n",
      "\n",
      "Epoch 36/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 917us/step - loss: 3.3933 - acc: 0.2298 - val_loss: 4.0055 - val_acc: 0.1420\n",
      "\n",
      "Epoch 37/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 823us/step - loss: 3.3631 - acc: 0.2333 - val_loss: 3.9951 - val_acc: 0.1420\n",
      "\n",
      "Epoch 38/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 924us/step - loss: 3.3332 - acc: 0.2401 - val_loss: 3.9849 - val_acc: 0.1420\n",
      "\n",
      "Epoch 39/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 851us/step - loss: 3.3041 - acc: 0.2419 - val_loss: 3.9750 - val_acc: 0.1420\n",
      "\n",
      "Epoch 40/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 815us/step - loss: 3.2753 - acc: 0.2453 - val_loss: 3.9652 - val_acc: 0.1420\n",
      "\n",
      "Epoch 41/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 912us/step - loss: 3.2469 - acc: 0.2470 - val_loss: 3.9553 - val_acc: 0.1420\n",
      "\n",
      "Epoch 42/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 806us/step - loss: 3.2186 - acc: 0.2470 - val_loss: 3.9449 - val_acc: 0.1420\n",
      "\n",
      "Epoch 43/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 892us/step - loss: 3.1911 - acc: 0.2521 - val_loss: 3.9347 - val_acc: 0.1420\n",
      "\n",
      "Epoch 44/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 827us/step - loss: 3.1642 - acc: 0.2521 - val_loss: 3.9248 - val_acc: 0.1481TA: 0s - loss: 3.0560 - acc: 0.234 - ETA: 0s - loss: 3.0688 - acc: 0.\n",
      "\n",
      "Epoch 45/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 889us/step - loss: 3.1375 - acc: 0.2573 - val_loss: 3.9153 - val_acc: 0.1481\n",
      "\n",
      "Epoch 46/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 915us/step - loss: 3.1113 - acc: 0.2659 - val_loss: 3.9050 - val_acc: 0.1481\n",
      "\n",
      "Epoch 47/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 949us/step - loss: 3.0855 - acc: 0.2693 - val_loss: 3.8961 - val_acc: 0.1481\n",
      "\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================]583/583 [==============================] - 1s 938us/step - loss: 3.0603 - acc: 0.2762 - val_loss: 3.8871 - val_acc: 0.1481\n",
      "\n",
      "Epoch 49/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 3.0350 - acc: 0.2796 - val_loss: 3.8776 - val_acc: 0.1481\n",
      "\n",
      "Epoch 50/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 3.0099 - acc: 0.2830 - val_loss: 3.8673 - val_acc: 0.1481\n",
      "\n",
      "Epoch 51/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 977us/step - loss: 2.9849 - acc: 0.2899 - val_loss: 3.8590 - val_acc: 0.1481\n",
      "\n",
      "Epoch 52/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 914us/step - loss: 2.9606 - acc: 0.2916 - val_loss: 3.8504 - val_acc: 0.1481\n",
      "\n",
      "Epoch 53/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 933us/step - loss: 2.9362 - acc: 0.2933 - val_loss: 3.8423 - val_acc: 0.1481\n",
      "\n",
      "Epoch 54/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 932us/step - loss: 2.9129 - acc: 0.2950 - val_loss: 3.8346 - val_acc: 0.1481\n",
      "\n",
      "Epoch 55/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 954us/step - loss: 2.8896 - acc: 0.2985 - val_loss: 3.8266 - val_acc: 0.1481 [==========>...................] - ETA: 0s - loss: 2.7931 - acc: 0\n",
      "\n",
      "Epoch 56/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 938us/step - loss: 2.8666 - acc: 0.3019 - val_loss: 3.8190 - val_acc: 0.1481\n",
      "\n",
      "Epoch 57/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.8438 - acc: 0.3070 - val_loss: 3.8117 - val_acc: 0.1481 ETA: 0s - loss: 2.8617 - acc: 0.30\n",
      "\n",
      "Epoch 58/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 2.8213 - acc: 0.3087 - val_loss: 3.8042 - val_acc: 0.1481\n",
      "\n",
      "Epoch 59/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 897us/step - loss: 2.7994 - acc: 0.3122 - val_loss: 3.7960 - val_acc: 0.1481\n",
      "\n",
      "Epoch 60/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 841us/step - loss: 2.7772 - acc: 0.3139 - val_loss: 3.7889 - val_acc: 0.1481\n",
      "\n",
      "Epoch 61/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 913us/step - loss: 2.7557 - acc: 0.3190 - val_loss: 3.7820 - val_acc: 0.1481\n",
      "\n",
      "Epoch 62/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 884us/step - loss: 2.7347 - acc: 0.3242 - val_loss: 3.7746 - val_acc: 0.1481\n",
      "\n",
      "Epoch 63/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 901us/step - loss: 2.7133 - acc: 0.3259 - val_loss: 3.7676 - val_acc: 0.1481\n",
      "\n",
      "Epoch 64/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 2.6926 - acc: 0.3276 - val_loss: 3.7610 - val_acc: 0.1481\n",
      "\n",
      "Epoch 65/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 960us/step - loss: 2.6722 - acc: 0.3276 - val_loss: 3.7535 - val_acc: 0.1481\n",
      "\n",
      "Epoch 66/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 2.6518 - acc: 0.3310 - val_loss: 3.7467 - val_acc: 0.1543\n",
      "\n",
      "Epoch 67/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 941us/step - loss: 2.6313 - acc: 0.3345 - val_loss: 3.7397 - val_acc: 0.1543\n",
      "\n",
      "Epoch 68/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 924us/step - loss: 2.6108 - acc: 0.3379 - val_loss: 3.7339 - val_acc: 0.1543\n",
      "\n",
      "Epoch 69/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 825us/step - loss: 2.5906 - acc: 0.3431 - val_loss: 3.7277 - val_acc: 0.1605\n",
      "\n",
      "Epoch 70/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 2.5710 - acc: 0.3448 - val_loss: 3.7211 - val_acc: 0.1605\n",
      "\n",
      "Epoch 71/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 955us/step - loss: 2.5517 - acc: 0.3465 - val_loss: 3.7157 - val_acc: 0.1605\n",
      "\n",
      "Epoch 72/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 851us/step - loss: 2.5325 - acc: 0.3482 - val_loss: 3.7092 - val_acc: 0.1605\n",
      "\n",
      "Epoch 73/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 870us/step - loss: 2.5134 - acc: 0.3499 - val_loss: 3.7040 - val_acc: 0.1605\n",
      "\n",
      "Epoch 74/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 2.4948 - acc: 0.3516 - val_loss: 3.6983 - val_acc: 0.1605\n",
      "\n",
      "Epoch 75/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 953us/step - loss: 2.4762 - acc: 0.3619 - val_loss: 3.6927 - val_acc: 0.1605TA: 0s - loss: 2.5952 - acc: \n",
      "\n",
      "Epoch 76/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 891us/step - loss: 2.4578 - acc: 0.3654 - val_loss: 3.6868 - val_acc: 0.1605\n",
      "\n",
      "Epoch 77/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 942us/step - loss: 2.4400 - acc: 0.3671 - val_loss: 3.6816 - val_acc: 0.1605\n",
      "\n",
      "Epoch 78/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 944us/step - loss: 2.4222 - acc: 0.3688 - val_loss: 3.6759 - val_acc: 0.1605\n",
      "\n",
      "Epoch 79/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 885us/step - loss: 2.4051 - acc: 0.3705 - val_loss: 3.6693 - val_acc: 0.1605\n",
      "\n",
      "Epoch 80/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 857us/step - loss: 2.3880 - acc: 0.3739 - val_loss: 3.6640 - val_acc: 0.1605\n",
      "\n",
      "Epoch 81/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 2.3714 - acc: 0.3739 - val_loss: 3.6580 - val_acc: 0.1667TA: 0s - loss: 2.3919 - acc: 0.\n",
      "\n",
      "Epoch 82/200\n",
      "583/583 [==============================]583/583 [==============================] - ETA: 0s - loss: 2.3824 - acc: 0.367652/583 [=================>............] - ETA: 0s - loss: 2.3167 - acc: 0. - 1s 886us/step - loss: 2.3543 - acc: 0.3756 - val_loss: 3.6524 - val_acc: 0.1667\n",
      "\n",
      "Epoch 83/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 834us/step - loss: 2.3377 - acc: 0.3774 - val_loss: 3.6468 - val_acc: 0.1667\n",
      "\n",
      "Epoch 84/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 2.3211 - acc: 0.3808 - val_loss: 3.6419 - val_acc: 0.1667\n",
      "\n",
      "Epoch 85/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 2.3053 - acc: 0.3825 - val_loss: 3.6366 - val_acc: 0.1667\n",
      "\n",
      "Epoch 86/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 848us/step - loss: 2.2890 - acc: 0.3842 - val_loss: 3.6321 - val_acc: 0.1667\n",
      "\n",
      "Epoch 87/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 872us/step - loss: 2.2730 - acc: 0.3894 - val_loss: 3.6269 - val_acc: 0.1667\n",
      "\n",
      "Epoch 88/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 2.2575 - acc: 0.3894 - val_loss: 3.6218 - val_acc: 0.1667\n",
      "\n",
      "Epoch 89/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 833us/step - loss: 2.2420 - acc: 0.3894 - val_loss: 3.6176 - val_acc: 0.1667\n",
      "\n",
      "Epoch 90/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 827us/step - loss: 2.2259 - acc: 0.3911 - val_loss: 3.6124 - val_acc: 0.1667\n",
      "\n",
      "Epoch 91/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 833us/step - loss: 2.2111 - acc: 0.3945 - val_loss: 3.6068 - val_acc: 0.1667\n",
      "\n",
      "Epoch 92/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 2.1960 - acc: 0.3979 - val_loss: 3.6012 - val_acc: 0.1667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 93/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 829us/step - loss: 2.1812 - acc: 0.4014 - val_loss: 3.5956 - val_acc: 0.1667\n",
      "\n",
      "Epoch 94/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 914us/step - loss: 2.1661 - acc: 0.4031 - val_loss: 3.5907 - val_acc: 0.1667\n",
      "\n",
      "Epoch 95/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 953us/step - loss: 2.1515 - acc: 0.4048 - val_loss: 3.5851 - val_acc: 0.1667\n",
      "\n",
      "Epoch 96/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 862us/step - loss: 2.1367 - acc: 0.4065 - val_loss: 3.5806 - val_acc: 0.1667\n",
      "\n",
      "Epoch 97/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 2.1224 - acc: 0.4134 - val_loss: 3.5757 - val_acc: 0.1667\n",
      "\n",
      "Epoch 98/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 900us/step - loss: 2.1082 - acc: 0.4151 - val_loss: 3.5705 - val_acc: 0.1667TA: 0s - loss: 2.1140 - acc: 0.\n",
      "\n",
      "Epoch 99/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 874us/step - loss: 2.0941 - acc: 0.4185 - val_loss: 3.5653 - val_acc: 0.1667\n",
      "\n",
      "Epoch 100/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 803us/step - loss: 2.0800 - acc: 0.4271 - val_loss: 3.5593 - val_acc: 0.1667\n",
      "\n",
      "Epoch 101/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 839us/step - loss: 2.0659 - acc: 0.4288 - val_loss: 3.5551 - val_acc: 0.1667\n",
      "\n",
      "Epoch 102/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 881us/step - loss: 2.0522 - acc: 0.4305 - val_loss: 3.5506 - val_acc: 0.1667\n",
      "\n",
      "Epoch 103/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 804us/step - loss: 2.0386 - acc: 0.4357 - val_loss: 3.5455 - val_acc: 0.1667TA: 0s - loss: 1.9692 - acc: 0.447 - ETA: 0s - loss: 2.0068 - acc: 0.\n",
      "\n",
      "Epoch 104/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 799us/step - loss: 2.0251 - acc: 0.4374 - val_loss: 3.5409 - val_acc: 0.1790TA: 0s - loss: 1.9369 - acc: 0.46448/583 [======================>.......] - ETA: 0s - loss: 2.0574 - acc: 0.43\n",
      "\n",
      "Epoch 105/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 2.0119 - acc: 0.4391 - val_loss: 3.5364 - val_acc: 0.1790TA: 0s - loss: 1.9675 - acc: 0.447512/583 [=========================>....] - ETA: 0s - loss: 1.9703 - acc: 0.449\n",
      "\n",
      "Epoch 106/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 976us/step - loss: 1.9988 - acc: 0.4391 - val_loss: 3.5316 - val_acc: 0.1790\n",
      "\n",
      "Epoch 107/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 1.9857 - acc: 0.4425 - val_loss: 3.5270 - val_acc: 0.1790\n",
      "\n",
      "Epoch 108/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 1.9727 - acc: 0.4460 - val_loss: 3.5223 - val_acc: 0.1790\n",
      "\n",
      "Epoch 109/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 912us/step - loss: 1.9602 - acc: 0.4460 - val_loss: 3.5178 - val_acc: 0.1790TA: 0s - loss: 1.8316 - acc: 0\n",
      "\n",
      "Epoch 110/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 907us/step - loss: 1.9476 - acc: 0.4477 - val_loss: 3.5130 - val_acc: 0.1790\n",
      "\n",
      "Epoch 111/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 961us/step - loss: 1.9349 - acc: 0.4494 - val_loss: 3.5084 - val_acc: 0.1852\n",
      "\n",
      "Epoch 112/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 856us/step - loss: 1.9225 - acc: 0.4511 - val_loss: 3.5043 - val_acc: 0.1852\n",
      "\n",
      "Epoch 113/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 929us/step - loss: 1.9104 - acc: 0.4528 - val_loss: 3.4996 - val_acc: 0.1852\n",
      "\n",
      "Epoch 114/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 857us/step - loss: 1.8983 - acc: 0.4563 - val_loss: 3.4953 - val_acc: 0.1852\n",
      "\n",
      "Epoch 115/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 1.8859 - acc: 0.4545 - val_loss: 3.4910 - val_acc: 0.1852TA: 0s - loss: 1.6502 - acc: 0.\n",
      "\n",
      "Epoch 116/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 828us/step - loss: 1.8739 - acc: 0.4614 - val_loss: 3.4864 - val_acc: 0.1914\n",
      "\n",
      "Epoch 117/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 941us/step - loss: 1.8619 - acc: 0.4614 - val_loss: 3.4819 - val_acc: 0.1914\n",
      "\n",
      "Epoch 118/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 829us/step - loss: 1.8503 - acc: 0.4666 - val_loss: 3.4778 - val_acc: 0.1975\n",
      "\n",
      "Epoch 119/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.8385 - acc: 0.4683 - val_loss: 3.4727 - val_acc: 0.1975\n",
      "\n",
      "Epoch 120/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 1.8269 - acc: 0.4700 - val_loss: 3.4685 - val_acc: 0.1975\n",
      "\n",
      "Epoch 121/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 914us/step - loss: 1.8153 - acc: 0.4768 - val_loss: 3.4643 - val_acc: 0.1975\n",
      "\n",
      "Epoch 122/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 869us/step - loss: 1.8041 - acc: 0.4786 - val_loss: 3.4600 - val_acc: 0.1975\n",
      "\n",
      "Epoch 123/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 942us/step - loss: 1.7929 - acc: 0.4820 - val_loss: 3.4554 - val_acc: 0.1975\n",
      "\n",
      "Epoch 124/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.7817 - acc: 0.4854 - val_loss: 3.4517 - val_acc: 0.1975\n",
      "\n",
      "Epoch 125/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.7705 - acc: 0.4871 - val_loss: 3.4475 - val_acc: 0.1975TA: 0s - loss: 1.7940 - acc: 0.48\n",
      "\n",
      "Epoch 126/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 867us/step - loss: 1.7595 - acc: 0.4906 - val_loss: 3.4432 - val_acc: 0.1975\n",
      "\n",
      "Epoch 127/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 833us/step - loss: 1.7484 - acc: 0.4974 - val_loss: 3.4391 - val_acc: 0.1975\n",
      "\n",
      "Epoch 128/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 884us/step - loss: 1.7375 - acc: 0.5026 - val_loss: 3.4350 - val_acc: 0.1975\n",
      "\n",
      "Epoch 129/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 885us/step - loss: 1.7269 - acc: 0.5043 - val_loss: 3.4314 - val_acc: 0.1975\n",
      "\n",
      "Epoch 130/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 833us/step - loss: 1.7161 - acc: 0.5060 - val_loss: 3.4275 - val_acc: 0.1975TA: 0s - loss: 1.6646 - acc: 0.50\n",
      "\n",
      "Epoch 131/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 883us/step - loss: 1.7055 - acc: 0.5060 - val_loss: 3.4236 - val_acc: 0.1975\n",
      "\n",
      "Epoch 132/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 1.6950 - acc: 0.5060 - val_loss: 3.4204 - val_acc: 0.1975TA: 0s - loss: 1.6650 - acc: 0.50\n",
      "\n",
      "Epoch 133/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 899us/step - loss: 1.6845 - acc: 0.5060 - val_loss: 3.4165 - val_acc: 0.1975\n",
      "\n",
      "Epoch 134/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 932us/step - loss: 1.6744 - acc: 0.5060 - val_loss: 3.4126 - val_acc: 0.1975\n",
      "\n",
      "Epoch 135/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 987us/step - loss: 1.6645 - acc: 0.5060 - val_loss: 3.4085 - val_acc: 0.1975\n",
      "\n",
      "Epoch 136/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 922us/step - loss: 1.6544 - acc: 0.5060 - val_loss: 3.4047 - val_acc: 0.1975\n",
      "\n",
      "Epoch 137/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 804us/step - loss: 1.6443 - acc: 0.5060 - val_loss: 3.4011 - val_acc: 0.1975\n",
      "\n",
      "Epoch 138/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 974us/step - loss: 1.6344 - acc: 0.5129 - val_loss: 3.3975 - val_acc: 0.2037\n",
      "\n",
      "Epoch 139/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 1.6246 - acc: 0.5180 - val_loss: 3.3936 - val_acc: 0.2037TA: 0s - loss: 1.5621 - acc: \n",
      "\n",
      "Epoch 140/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 968us/step - loss: 1.6148 - acc: 0.5197 - val_loss: 3.3900 - val_acc: 0.2037\n",
      "\n",
      "Epoch 141/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 1.6052 - acc: 0.5232 - val_loss: 3.3862 - val_acc: 0.2037\n",
      "\n",
      "Epoch 142/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 1.5954 - acc: 0.5249 - val_loss: 3.3831 - val_acc: 0.2037TA: 0s - loss: 1.6249 - acc: 0.522544/583 [==========================>...] - ETA: 0s - loss: 1.6135 - acc: 0.523\n",
      "\n",
      "Epoch 143/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 913us/step - loss: 1.5860 - acc: 0.5283 - val_loss: 3.3795 - val_acc: 0.2037\n",
      "\n",
      "Epoch 144/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 868us/step - loss: 1.5767 - acc: 0.5283 - val_loss: 3.3758 - val_acc: 0.2037\n",
      "\n",
      "Epoch 145/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 968us/step - loss: 1.5676 - acc: 0.5352 - val_loss: 3.3723 - val_acc: 0.2037\n",
      "\n",
      "Epoch 146/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 851us/step - loss: 1.5584 - acc: 0.5403 - val_loss: 3.3690 - val_acc: 0.2037\n",
      "\n",
      "Epoch 147/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.5493 - acc: 0.5472 - val_loss: 3.3653 - val_acc: 0.2037\n",
      "\n",
      "Epoch 148/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 992us/step - loss: 1.5405 - acc: 0.5472 - val_loss: 3.3624 - val_acc: 0.2037\n",
      "\n",
      "Epoch 149/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 890us/step - loss: 1.5317 - acc: 0.5506 - val_loss: 3.3590 - val_acc: 0.2037\n",
      "\n",
      "Epoch 150/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 1.5229 - acc: 0.5506 - val_loss: 3.3557 - val_acc: 0.2037\n",
      "\n",
      "Epoch 151/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 912us/step - loss: 1.5141 - acc: 0.5506 - val_loss: 3.3522 - val_acc: 0.2037TA: 0s - loss: 1.5202 - acc: 0.550\n",
      "\n",
      "Epoch 152/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 914us/step - loss: 1.5056 - acc: 0.5506 - val_loss: 3.3486 - val_acc: 0.2037\n",
      "\n",
      "Epoch 153/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 980us/step - loss: 1.4972 - acc: 0.5523 - val_loss: 3.3454 - val_acc: 0.2037\n",
      "\n",
      "Epoch 154/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 941us/step - loss: 1.4889 - acc: 0.5523 - val_loss: 3.3421 - val_acc: 0.2037\n",
      "\n",
      "Epoch 155/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 854us/step - loss: 1.4804 - acc: 0.5523 - val_loss: 3.3389 - val_acc: 0.2037\n",
      "\n",
      "Epoch 156/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 885us/step - loss: 1.4723 - acc: 0.5523 - val_loss: 3.3356 - val_acc: 0.2037TA: 0s - loss: 1.2664 - acc:\n",
      "\n",
      "Epoch 157/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 935us/step - loss: 1.4640 - acc: 0.5592 - val_loss: 3.3322 - val_acc: 0.2037TA: 0s - loss: 1.5198 - acc: 0.\n",
      "\n",
      "Epoch 158/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 858us/step - loss: 1.4559 - acc: 0.5609 - val_loss: 3.3294 - val_acc: 0.2037\n",
      "\n",
      "Epoch 159/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 1.4479 - acc: 0.5678 - val_loss: 3.3263 - val_acc: 0.2037\n",
      "\n",
      "Epoch 160/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 888us/step - loss: 1.4399 - acc: 0.5678 - val_loss: 3.3234 - val_acc: 0.2037\n",
      "\n",
      "Epoch 161/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 1.4319 - acc: 0.5712 - val_loss: 3.3204 - val_acc: 0.2037\n",
      "\n",
      "Epoch 162/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 947us/step - loss: 1.4241 - acc: 0.5849 - val_loss: 3.3173 - val_acc: 0.1975\n",
      "\n",
      "Epoch 163/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 894us/step - loss: 1.4161 - acc: 0.5866 - val_loss: 3.3140 - val_acc: 0.1975\n",
      "\n",
      "Epoch 164/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 860us/step - loss: 1.4084 - acc: 0.5883 - val_loss: 3.3113 - val_acc: 0.1975\n",
      "\n",
      "Epoch 165/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 1.4008 - acc: 0.5918 - val_loss: 3.3087 - val_acc: 0.1975\n",
      "\n",
      "Epoch 166/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 1.3932 - acc: 0.5935 - val_loss: 3.3062 - val_acc: 0.1975\n",
      "\n",
      "Epoch 167/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 816us/step - loss: 1.3855 - acc: 0.6003 - val_loss: 3.3033 - val_acc: 0.1975\n",
      "\n",
      "Epoch 168/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 933us/step - loss: 1.3780 - acc: 0.6003 - val_loss: 3.2998 - val_acc: 0.1975\n",
      "\n",
      "Epoch 169/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 812us/step - loss: 1.3705 - acc: 0.6021 - val_loss: 3.2970 - val_acc: 0.1975TA: 0s - loss: 1.3918 - acc: 0.\n",
      "\n",
      "Epoch 170/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 823us/step - loss: 1.3629 - acc: 0.6038 - val_loss: 3.2941 - val_acc: 0.2037TA: 0s - loss: 1.2193 - acc: 0.\n",
      "\n",
      "Epoch 171/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 865us/step - loss: 1.3553 - acc: 0.6055 - val_loss: 3.2909 - val_acc: 0.2037TA: 0s - loss: 1.4047 - acc: 0.597 - ETA: 0s - loss: 1.3559 - acc: 0.604\n",
      "\n",
      "Epoch 172/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 910us/step - loss: 1.3482 - acc: 0.6055 - val_loss: 3.2880 - val_acc: 0.2037TA: 0s - loss: 1.4040 - acc: 0\n",
      "\n",
      "Epoch 173/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 830us/step - loss: 1.3409 - acc: 0.6072 - val_loss: 3.2849 - val_acc: 0.2037TA: 0s - loss: 1.4078 - acc: 0.5\n",
      "\n",
      "Epoch 174/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 944us/step - loss: 1.3339 - acc: 0.6106 - val_loss: 3.2819 - val_acc: 0.2037\n",
      "\n",
      "Epoch 175/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 1.3270 - acc: 0.6123 - val_loss: 3.2783 - val_acc: 0.2037\n",
      "\n",
      "Epoch 176/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 1.3199 - acc: 0.6141 - val_loss: 3.2755 - val_acc: 0.2037\n",
      "\n",
      "Epoch 177/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 841us/step - loss: 1.3126 - acc: 0.6175 - val_loss: 3.2724 - val_acc: 0.1975TA: 0s - loss: 1.3104 - acc: 0.616\n",
      "\n",
      "Epoch 178/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 880us/step - loss: 1.3059 - acc: 0.6175 - val_loss: 3.2695 - val_acc: 0.1975\n",
      "\n",
      "Epoch 179/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583/583 [==============================]583/583 [==============================] - 1s 929us/step - loss: 1.2990 - acc: 0.6209 - val_loss: 3.2670 - val_acc: 0.1975\n",
      "\n",
      "Epoch 180/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 832us/step - loss: 1.2922 - acc: 0.6209 - val_loss: 3.2645 - val_acc: 0.1975TA: 0s - loss: 1.2990 - acc: 0.6\n",
      "\n",
      "Epoch 181/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 912us/step - loss: 1.2854 - acc: 0.6209 - val_loss: 3.2619 - val_acc: 0.1975TA: 0s - loss: 1.3025 - acc:\n",
      "\n",
      "Epoch 182/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 861us/step - loss: 1.2788 - acc: 0.6226 - val_loss: 3.2594 - val_acc: 0.1975\n",
      "\n",
      "Epoch 183/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 851us/step - loss: 1.2723 - acc: 0.6244 - val_loss: 3.2565 - val_acc: 0.1975\n",
      "\n",
      "Epoch 184/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.2658 - acc: 0.6261 - val_loss: 3.2538 - val_acc: 0.1914\n",
      "\n",
      "Epoch 185/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 917us/step - loss: 1.2592 - acc: 0.6312 - val_loss: 3.2512 - val_acc: 0.1975\n",
      "\n",
      "Epoch 186/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 925us/step - loss: 1.2526 - acc: 0.6364 - val_loss: 3.2490 - val_acc: 0.1914\n",
      "\n",
      "Epoch 187/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 910us/step - loss: 1.2464 - acc: 0.6364 - val_loss: 3.2461 - val_acc: 0.1914\n",
      "\n",
      "Epoch 188/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 837us/step - loss: 1.2399 - acc: 0.6398 - val_loss: 3.2435 - val_acc: 0.1914\n",
      "\n",
      "Epoch 189/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 1.2337 - acc: 0.6398 - val_loss: 3.2410 - val_acc: 0.1914\n",
      "\n",
      "Epoch 190/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 875us/step - loss: 1.2274 - acc: 0.6449 - val_loss: 3.2386 - val_acc: 0.1975\n",
      "\n",
      "Epoch 191/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 886us/step - loss: 1.2212 - acc: 0.6449 - val_loss: 3.2360 - val_acc: 0.1975\n",
      "\n",
      "Epoch 192/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 831us/step - loss: 1.2151 - acc: 0.6467 - val_loss: 3.2335 - val_acc: 0.1975\n",
      "\n",
      "Epoch 193/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 880us/step - loss: 1.2091 - acc: 0.6484 - val_loss: 3.2310 - val_acc: 0.1975TA: 0s - loss: 1.1923 - acc: 0.6\n",
      "\n",
      "Epoch 194/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 1ms/step - loss: 1.2031 - acc: 0.6501 - val_loss: 3.2284 - val_acc: 0.1975\n",
      "\n",
      "Epoch 195/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 859us/step - loss: 1.1973 - acc: 0.6535 - val_loss: 3.2262 - val_acc: 0.1975\n",
      "\n",
      "Epoch 196/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 883us/step - loss: 1.1914 - acc: 0.6552 - val_loss: 3.2237 - val_acc: 0.1975\n",
      "\n",
      "Epoch 197/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 930us/step - loss: 1.1856 - acc: 0.6552 - val_loss: 3.2212 - val_acc: 0.1975\n",
      "\n",
      "Epoch 198/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 887us/step - loss: 1.1799 - acc: 0.6569 - val_loss: 3.2187 - val_acc: 0.1975\n",
      "\n",
      "Epoch 199/200\n",
      "583/583 [==============================]583/583 [==============================] - 1s 906us/step - loss: 1.1741 - acc: 0.6621 - val_loss: 3.2162 - val_acc: 0.1975\n",
      "\n",
      "Epoch 200/200\n",
      "583/583 [==============================]583/583 [==============================] - 0s 814us/step - loss: 1.1682 - acc: 0.6621 - val_loss: 3.2135 - val_acc: 0.1975TA: 0s - loss: 1.0891 - acc: 0.6\n",
      "\n",
      "65/65 [==============================]65/65 [==============================] - 0s 577us/step\n",
      "\n",
      "Train on 584 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "584/584 [==============================]584/584 [==============================] - 4s 7ms/step - loss: 4.9866 - acc: 0.1370 - val_loss: 5.0126 - val_acc: 0.0926\n",
      "\n",
      "Epoch 2/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 864us/step - loss: 4.9123 - acc: 0.1353 - val_loss: 4.9727 - val_acc: 0.0988\n",
      "\n",
      "Epoch 3/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 939us/step - loss: 4.8405 - acc: 0.1404 - val_loss: 4.9346 - val_acc: 0.0988\n",
      "\n",
      "Epoch 4/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 943us/step - loss: 4.7722 - acc: 0.1438 - val_loss: 4.8984 - val_acc: 0.0988\n",
      "\n",
      "Epoch 5/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 858us/step - loss: 4.7064 - acc: 0.1438 - val_loss: 4.8636 - val_acc: 0.0988\n",
      "\n",
      "Epoch 6/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 887us/step - loss: 4.6430 - acc: 0.1473 - val_loss: 4.8296 - val_acc: 0.0988\n",
      "\n",
      "Epoch 7/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 977us/step - loss: 4.5817 - acc: 0.1490 - val_loss: 4.7974 - val_acc: 0.0988\n",
      "\n",
      "Epoch 8/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 962us/step - loss: 4.5210 - acc: 0.1558 - val_loss: 4.7659 - val_acc: 0.0988\n",
      "\n",
      "Epoch 9/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 882us/step - loss: 4.4628 - acc: 0.1627 - val_loss: 4.7356 - val_acc: 0.0988\n",
      "\n",
      "Epoch 10/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 903us/step - loss: 4.4053 - acc: 0.1644 - val_loss: 4.7053 - val_acc: 0.0988\n",
      "\n",
      "Epoch 11/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 977us/step - loss: 4.3486 - acc: 0.1644 - val_loss: 4.6772 - val_acc: 0.0988\n",
      "\n",
      "Epoch 12/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 803us/step - loss: 4.2952 - acc: 0.1712 - val_loss: 4.6500 - val_acc: 0.0988\n",
      "\n",
      "Epoch 13/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 973us/step - loss: 4.2418 - acc: 0.1729 - val_loss: 4.6240 - val_acc: 0.0988\n",
      "\n",
      "Epoch 14/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 825us/step - loss: 4.1912 - acc: 0.1764 - val_loss: 4.5994 - val_acc: 0.0926\n",
      "\n",
      "Epoch 15/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 997us/step - loss: 4.1418 - acc: 0.1832 - val_loss: 4.5743 - val_acc: 0.0926\n",
      "\n",
      "Epoch 16/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 829us/step - loss: 4.0931 - acc: 0.1866 - val_loss: 4.5498 - val_acc: 0.0926\n",
      "\n",
      "Epoch 17/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 1ms/step - loss: 4.0446 - acc: 0.1901 - val_loss: 4.5266 - val_acc: 0.0988\n",
      "\n",
      "Epoch 18/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 913us/step - loss: 3.9986 - acc: 0.1935 - val_loss: 4.5033 - val_acc: 0.0926\n",
      "\n",
      "Epoch 19/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 908us/step - loss: 3.9530 - acc: 0.1918 - val_loss: 4.4814 - val_acc: 0.0926\n",
      "\n",
      "Epoch 20/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 947us/step - loss: 3.9090 - acc: 0.2038 - val_loss: 4.4605 - val_acc: 0.0988\n",
      "\n",
      "Epoch 21/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 855us/step - loss: 3.8663 - acc: 0.2089 - val_loss: 4.4410 - val_acc: 0.1049\n",
      "\n",
      "Epoch 22/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 885us/step - loss: 3.8245 - acc: 0.2123 - val_loss: 4.4216 - val_acc: 0.1049\n",
      "\n",
      "Epoch 23/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 855us/step - loss: 3.7845 - acc: 0.2140 - val_loss: 4.4035 - val_acc: 0.1049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 853us/step - loss: 3.7446 - acc: 0.2158 - val_loss: 4.3869 - val_acc: 0.1111\n",
      "\n",
      "Epoch 25/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 884us/step - loss: 3.7062 - acc: 0.2192 - val_loss: 4.3696 - val_acc: 0.1111\n",
      "\n",
      "Epoch 26/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 888us/step - loss: 3.6679 - acc: 0.2226 - val_loss: 4.3524 - val_acc: 0.1111\n",
      "\n",
      "Epoch 27/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 851us/step - loss: 3.6302 - acc: 0.2243 - val_loss: 4.3343 - val_acc: 0.1111\n",
      "\n",
      "Epoch 28/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 999us/step - loss: 3.5938 - acc: 0.2260 - val_loss: 4.3182 - val_acc: 0.1111\n",
      "\n",
      "Epoch 29/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 885us/step - loss: 3.5582 - acc: 0.2312 - val_loss: 4.3026 - val_acc: 0.1049\n",
      "\n",
      "Epoch 30/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 856us/step - loss: 3.5234 - acc: 0.2329 - val_loss: 4.2874 - val_acc: 0.1049\n",
      "\n",
      "Epoch 31/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 832us/step - loss: 3.4899 - acc: 0.2329 - val_loss: 4.2718 - val_acc: 0.0988\n",
      "\n",
      "Epoch 32/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 823us/step - loss: 3.4566 - acc: 0.2329 - val_loss: 4.2561 - val_acc: 0.0988\n",
      "\n",
      "Epoch 33/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 857us/step - loss: 3.4239 - acc: 0.2363 - val_loss: 4.2416 - val_acc: 0.0988TA: 0s - loss: 3.4289 - acc: 0.23\n",
      "\n",
      "Epoch 34/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 889us/step - loss: 3.3924 - acc: 0.2449 - val_loss: 4.2270 - val_acc: 0.0988\n",
      "\n",
      "Epoch 35/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 905us/step - loss: 3.3611 - acc: 0.2449 - val_loss: 4.2138 - val_acc: 0.0988\n",
      "\n",
      "Epoch 36/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 921us/step - loss: 3.3305 - acc: 0.2466 - val_loss: 4.2001 - val_acc: 0.0988TA: 0s - loss: 3.1316 - acc: 0.\n",
      "\n",
      "Epoch 37/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 907us/step - loss: 3.2999 - acc: 0.2466 - val_loss: 4.1869 - val_acc: 0.1049\n",
      "\n",
      "Epoch 38/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 889us/step - loss: 3.2704 - acc: 0.2500 - val_loss: 4.1745 - val_acc: 0.1111\n",
      "\n",
      "Epoch 39/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 885us/step - loss: 3.2421 - acc: 0.2534 - val_loss: 4.1628 - val_acc: 0.1111\n",
      "\n",
      "Epoch 40/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 888us/step - loss: 3.2136 - acc: 0.2534 - val_loss: 4.1503 - val_acc: 0.1049\n",
      "\n",
      "Epoch 41/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 860us/step - loss: 3.1849 - acc: 0.2551 - val_loss: 4.1369 - val_acc: 0.1049\n",
      "\n",
      "Epoch 42/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 805us/step - loss: 3.1569 - acc: 0.2568 - val_loss: 4.1244 - val_acc: 0.1049\n",
      "\n",
      "Epoch 43/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 932us/step - loss: 3.1295 - acc: 0.2568 - val_loss: 4.1125 - val_acc: 0.1049\n",
      "\n",
      "Epoch 44/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 809us/step - loss: 3.1025 - acc: 0.2603 - val_loss: 4.1006 - val_acc: 0.1111TA: 0s - loss: 3.1251 - acc: 0.2\n",
      "\n",
      "Epoch 45/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 831us/step - loss: 3.0754 - acc: 0.2654 - val_loss: 4.0896 - val_acc: 0.1111\n",
      "\n",
      "Epoch 46/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 870us/step - loss: 3.0493 - acc: 0.2671 - val_loss: 4.0778 - val_acc: 0.1111TA: 0s - loss: 3.0394 - acc: 0.269\n",
      "\n",
      "Epoch 47/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 908us/step - loss: 3.0227 - acc: 0.2705 - val_loss: 4.0667 - val_acc: 0.1111\n",
      "\n",
      "Epoch 48/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 771us/step - loss: 2.9972 - acc: 0.2774 - val_loss: 4.0548 - val_acc: 0.1111\n",
      "\n",
      "Epoch 49/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 831us/step - loss: 2.9717 - acc: 0.2791 - val_loss: 4.0446 - val_acc: 0.1173\n",
      "\n",
      "Epoch 50/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 829us/step - loss: 2.9467 - acc: 0.2808 - val_loss: 4.0341 - val_acc: 0.1173\n",
      "\n",
      "Epoch 51/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 888us/step - loss: 2.9222 - acc: 0.2825 - val_loss: 4.0231 - val_acc: 0.1235\n",
      "\n",
      "Epoch 52/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 826us/step - loss: 2.8981 - acc: 0.2860 - val_loss: 4.0122 - val_acc: 0.1235\n",
      "\n",
      "Epoch 53/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 880us/step - loss: 2.8734 - acc: 0.2877 - val_loss: 4.0018 - val_acc: 0.1235\n",
      "\n",
      "Epoch 54/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 861us/step - loss: 2.8496 - acc: 0.2945 - val_loss: 3.9924 - val_acc: 0.1235\n",
      "\n",
      "Epoch 55/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 972us/step - loss: 2.8261 - acc: 0.2979 - val_loss: 3.9821 - val_acc: 0.1235\n",
      "\n",
      "Epoch 56/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 950us/step - loss: 2.8029 - acc: 0.2997 - val_loss: 3.9718 - val_acc: 0.1235\n",
      "\n",
      "Epoch 57/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 931us/step - loss: 2.7797 - acc: 0.3014 - val_loss: 3.9619 - val_acc: 0.1235\n",
      "\n",
      "Epoch 58/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 915us/step - loss: 2.7570 - acc: 0.3031 - val_loss: 3.9529 - val_acc: 0.1235\n",
      "\n",
      "Epoch 59/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 930us/step - loss: 2.7347 - acc: 0.3031 - val_loss: 3.9426 - val_acc: 0.1235\n",
      "\n",
      "Epoch 60/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 883us/step - loss: 2.7123 - acc: 0.3065 - val_loss: 3.9330 - val_acc: 0.1235\n",
      "\n",
      "Epoch 61/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 892us/step - loss: 2.6908 - acc: 0.3099 - val_loss: 3.9234 - val_acc: 0.1296\n",
      "\n",
      "Epoch 62/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 857us/step - loss: 2.6695 - acc: 0.3116 - val_loss: 3.9153 - val_acc: 0.1296\n",
      "\n",
      "Epoch 63/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 855us/step - loss: 2.6484 - acc: 0.3151 - val_loss: 3.9057 - val_acc: 0.1296\n",
      "\n",
      "Epoch 64/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 890us/step - loss: 2.6269 - acc: 0.3168 - val_loss: 3.8971 - val_acc: 0.1296\n",
      "\n",
      "Epoch 65/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 851us/step - loss: 2.6062 - acc: 0.3185 - val_loss: 3.8884 - val_acc: 0.1296\n",
      "\n",
      "Epoch 66/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 888us/step - loss: 2.5855 - acc: 0.3202 - val_loss: 3.8798 - val_acc: 0.1296\n",
      "\n",
      "Epoch 67/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 883us/step - loss: 2.5655 - acc: 0.3202 - val_loss: 3.8713 - val_acc: 0.1296\n",
      "\n",
      "Epoch 68/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 870us/step - loss: 2.5455 - acc: 0.3185 - val_loss: 3.8627 - val_acc: 0.1296\n",
      "\n",
      "Epoch 69/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 887us/step - loss: 2.5256 - acc: 0.3271 - val_loss: 3.8546 - val_acc: 0.1296\n",
      "\n",
      "Epoch 70/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 829us/step - loss: 2.5058 - acc: 0.3322 - val_loss: 3.8467 - val_acc: 0.1296\n",
      "\n",
      "Epoch 71/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 895us/step - loss: 2.4867 - acc: 0.3408 - val_loss: 3.8373 - val_acc: 0.1296\n",
      "\n",
      "Epoch 72/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 858us/step - loss: 2.4670 - acc: 0.3425 - val_loss: 3.8289 - val_acc: 0.1296\n",
      "\n",
      "Epoch 73/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 998us/step - loss: 2.4480 - acc: 0.3476 - val_loss: 3.8217 - val_acc: 0.1296\n",
      "\n",
      "Epoch 74/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 860us/step - loss: 2.4291 - acc: 0.3476 - val_loss: 3.8146 - val_acc: 0.1358\n",
      "\n",
      "Epoch 75/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 913us/step - loss: 2.4106 - acc: 0.3476 - val_loss: 3.8068 - val_acc: 0.1358TA: 0s - loss: 2.2507 - acc: 0. - ETA: 0s - loss: 2.3857 - acc: 0.367480/584 [=======================>......] - ETA: 0s - loss: 2.4049 - acc: 0.36\n",
      "\n",
      "Epoch 76/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 912us/step - loss: 2.3924 - acc: 0.3476 - val_loss: 3.7998 - val_acc: 0.1358\n",
      "\n",
      "Epoch 77/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 826us/step - loss: 2.3742 - acc: 0.3510 - val_loss: 3.7919 - val_acc: 0.1358\n",
      "\n",
      "Epoch 78/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 881us/step - loss: 2.3564 - acc: 0.3527 - val_loss: 3.7846 - val_acc: 0.1358TA: 0s - loss: 2.5022 - acc: \n",
      "\n",
      "Epoch 79/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 957us/step - loss: 2.3387 - acc: 0.3545 - val_loss: 3.7772 - val_acc: 0.1358\n",
      "\n",
      "Epoch 80/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 803us/step - loss: 2.3207 - acc: 0.3596 - val_loss: 3.7701 - val_acc: 0.1358\n",
      "\n",
      "Epoch 81/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 1ms/step - loss: 2.3031 - acc: 0.3630 - val_loss: 3.7624 - val_acc: 0.1358 ETA: 0s - loss: 1.5729 - acc:\n",
      "\n",
      "Epoch 82/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 908us/step - loss: 2.2853 - acc: 0.3699 - val_loss: 3.7556 - val_acc: 0.1420TA: 0s - loss: 2.2939 - acc: 0.366\n",
      "\n",
      "Epoch 83/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 830us/step - loss: 2.2683 - acc: 0.3733 - val_loss: 3.7494 - val_acc: 0.1420\n",
      "\n",
      "Epoch 84/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 917us/step - loss: 2.2515 - acc: 0.3733 - val_loss: 3.7428 - val_acc: 0.1420TA: 0s - loss: 2.2554 - acc: 0.378576/584 [============================>.] - ETA: 0s - loss: 2.2618 - acc: 0.373\n",
      "\n",
      "Epoch 85/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 973us/step - loss: 2.2347 - acc: 0.3784 - val_loss: 3.7364 - val_acc: 0.1420\n",
      "\n",
      "Epoch 86/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 880us/step - loss: 2.2184 - acc: 0.3853 - val_loss: 3.7304 - val_acc: 0.1420\n",
      "\n",
      "Epoch 87/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 1ms/step - loss: 2.2018 - acc: 0.3887 - val_loss: 3.7244 - val_acc: 0.1481 ETA: 0s - loss: 2.3239 - acc: \n",
      "\n",
      "Epoch 88/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 859us/step - loss: 2.1854 - acc: 0.3904 - val_loss: 3.7178 - val_acc: 0.1481\n",
      "\n",
      "Epoch 89/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 941us/step - loss: 2.1693 - acc: 0.3904 - val_loss: 3.7116 - val_acc: 0.1481\n",
      "\n",
      "Epoch 90/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 920us/step - loss: 2.1534 - acc: 0.3955 - val_loss: 3.7053 - val_acc: 0.1481\n",
      "\n",
      "Epoch 91/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 858us/step - loss: 2.1374 - acc: 0.3955 - val_loss: 3.7001 - val_acc: 0.1481\n",
      "\n",
      "Epoch 92/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 888us/step - loss: 2.1217 - acc: 0.4024 - val_loss: 3.6940 - val_acc: 0.1481 [=============>................] - ETA: 0s - loss: 1.9506 - acc: 0.\n",
      "\n",
      "Epoch 93/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 931us/step - loss: 2.1063 - acc: 0.4041 - val_loss: 3.6879 - val_acc: 0.1481TA: 0s - loss: 2.1923 - acc: 0.4\n",
      "\n",
      "Epoch 94/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 930us/step - loss: 2.0915 - acc: 0.4092 - val_loss: 3.6818 - val_acc: 0.1481\n",
      "\n",
      "Epoch 95/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 866us/step - loss: 2.0762 - acc: 0.4161 - val_loss: 3.6759 - val_acc: 0.1481\n",
      "\n",
      "Epoch 96/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 968us/step - loss: 2.0614 - acc: 0.4161 - val_loss: 3.6698 - val_acc: 0.1481\n",
      "\n",
      "Epoch 97/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 861us/step - loss: 2.0471 - acc: 0.4229 - val_loss: 3.6636 - val_acc: 0.1481\n",
      "\n",
      "Epoch 98/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 883us/step - loss: 2.0326 - acc: 0.4264 - val_loss: 3.6576 - val_acc: 0.1481\n",
      "\n",
      "Epoch 99/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 916us/step - loss: 2.0181 - acc: 0.4281 - val_loss: 3.6521 - val_acc: 0.1481\n",
      "\n",
      "Epoch 100/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 945us/step - loss: 2.0037 - acc: 0.4349 - val_loss: 3.6465 - val_acc: 0.1481\n",
      "\n",
      "Epoch 101/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 818us/step - loss: 1.9895 - acc: 0.4384 - val_loss: 3.6407 - val_acc: 0.1481TA: 0s - loss: 2.0608 - acc: 0.41\n",
      "\n",
      "Epoch 102/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 901us/step - loss: 1.9755 - acc: 0.4384 - val_loss: 3.6351 - val_acc: 0.1481\n",
      "\n",
      "Epoch 103/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 1ms/step - loss: 1.9613 - acc: 0.4366 - val_loss: 3.6294 - val_acc: 0.1481\n",
      "\n",
      "Epoch 104/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 1ms/step - loss: 1.9473 - acc: 0.4384 - val_loss: 3.6240 - val_acc: 0.1481\n",
      "\n",
      "Epoch 105/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 1ms/step - loss: 1.9339 - acc: 0.4384 - val_loss: 3.6188 - val_acc: 0.1481\n",
      "\n",
      "Epoch 106/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 960us/step - loss: 1.9201 - acc: 0.4401 - val_loss: 3.6130 - val_acc: 0.1481\n",
      "\n",
      "Epoch 107/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 942us/step - loss: 1.9068 - acc: 0.4401 - val_loss: 3.6082 - val_acc: 0.1481\n",
      "\n",
      "Epoch 108/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 908us/step - loss: 1.8934 - acc: 0.4469 - val_loss: 3.6028 - val_acc: 0.1481\n",
      "\n",
      "Epoch 109/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 873us/step - loss: 1.8804 - acc: 0.4486 - val_loss: 3.5973 - val_acc: 0.1481 0s - loss: 1.9935 - acc: 0\n",
      "\n",
      "Epoch 110/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 875us/step - loss: 1.8675 - acc: 0.4538 - val_loss: 3.5920 - val_acc: 0.1481\n",
      "\n",
      "Epoch 111/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 951us/step - loss: 1.8547 - acc: 0.4555 - val_loss: 3.5870 - val_acc: 0.1481\n",
      "\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584/584 [==============================]584/584 [==============================] - 1s 895us/step - loss: 1.8422 - acc: 0.4555 - val_loss: 3.5820 - val_acc: 0.1481TA: 0s - loss: 1.8572 - acc: 0.45\n",
      "\n",
      "Epoch 113/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 916us/step - loss: 1.8299 - acc: 0.4589 - val_loss: 3.5773 - val_acc: 0.1481\n",
      "\n",
      "Epoch 114/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 912us/step - loss: 1.8180 - acc: 0.4623 - val_loss: 3.5723 - val_acc: 0.1481TA: 0s - loss: 1.6257 - acc:\n",
      "\n",
      "Epoch 115/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 968us/step - loss: 1.8057 - acc: 0.4623 - val_loss: 3.5674 - val_acc: 0.1481\n",
      "\n",
      "Epoch 116/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 947us/step - loss: 1.7938 - acc: 0.4623 - val_loss: 3.5614 - val_acc: 0.1481\n",
      "\n",
      "Epoch 117/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 936us/step - loss: 1.7817 - acc: 0.4658 - val_loss: 3.5566 - val_acc: 0.1481\n",
      "\n",
      "Epoch 118/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 913us/step - loss: 1.7700 - acc: 0.4658 - val_loss: 3.5527 - val_acc: 0.1481\n",
      "\n",
      "Epoch 119/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 917us/step - loss: 1.7584 - acc: 0.4658 - val_loss: 3.5484 - val_acc: 0.1481\n",
      "\n",
      "Epoch 120/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 887us/step - loss: 1.7468 - acc: 0.4692 - val_loss: 3.5440 - val_acc: 0.1481TA: 0s - loss: 1.7587 - acc: 0.4\n",
      "\n",
      "Epoch 121/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 951us/step - loss: 1.7355 - acc: 0.4760 - val_loss: 3.5392 - val_acc: 0.1481\n",
      "\n",
      "Epoch 122/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 884us/step - loss: 1.7242 - acc: 0.4777 - val_loss: 3.5345 - val_acc: 0.1481TA: 0s - loss: 2.0169 - acc: \n",
      "\n",
      "Epoch 123/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 960us/step - loss: 1.7133 - acc: 0.4795 - val_loss: 3.5302 - val_acc: 0.1543\n",
      "\n",
      "Epoch 124/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 891us/step - loss: 1.7020 - acc: 0.4846 - val_loss: 3.5253 - val_acc: 0.1543\n",
      "\n",
      "Epoch 125/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 1ms/step - loss: 1.6910 - acc: 0.4846 - val_loss: 3.5209 - val_acc: 0.1543\n",
      "\n",
      "Epoch 126/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 1ms/step - loss: 1.6800 - acc: 0.4846 - val_loss: 3.5164 - val_acc: 0.1543\n",
      "\n",
      "Epoch 127/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 887us/step - loss: 1.6690 - acc: 0.4897 - val_loss: 3.5123 - val_acc: 0.1543\n",
      "\n",
      "Epoch 128/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 910us/step - loss: 1.6583 - acc: 0.4949 - val_loss: 3.5075 - val_acc: 0.1543\n",
      "\n",
      "Epoch 129/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 891us/step - loss: 1.6475 - acc: 0.4966 - val_loss: 3.5027 - val_acc: 0.1605TA: 0s - loss: 1.6056 - acc: 0.511416/584 [====================>.........] - ETA: 0s - loss: 1.5894 - acc: 0.5\n",
      "\n",
      "Epoch 130/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 879us/step - loss: 1.6369 - acc: 0.5000 - val_loss: 3.4987 - val_acc: 0.1605\n",
      "\n",
      "Epoch 131/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 938us/step - loss: 1.6265 - acc: 0.5034 - val_loss: 3.4945 - val_acc: 0.1605\n",
      "\n",
      "Epoch 132/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 974us/step - loss: 1.6164 - acc: 0.5034 - val_loss: 3.4905 - val_acc: 0.1605\n",
      "\n",
      "Epoch 133/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 947us/step - loss: 1.6059 - acc: 0.5034 - val_loss: 3.4869 - val_acc: 0.1605\n",
      "\n",
      "Epoch 134/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 857us/step - loss: 1.5960 - acc: 0.5068 - val_loss: 3.4827 - val_acc: 0.1667\n",
      "\n",
      "Epoch 135/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 831us/step - loss: 1.5858 - acc: 0.5103 - val_loss: 3.4788 - val_acc: 0.1667TA: 0s - loss: 1.5983 - acc: 0.512\n",
      "\n",
      "Epoch 136/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 858us/step - loss: 1.5759 - acc: 0.5137 - val_loss: 3.4748 - val_acc: 0.1667\n",
      "\n",
      "Epoch 137/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 859us/step - loss: 1.5660 - acc: 0.5171 - val_loss: 3.4709 - val_acc: 0.1667TA: 0s - loss: 1.6295 - acc:\n",
      "\n",
      "Epoch 138/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 859us/step - loss: 1.5561 - acc: 0.5205 - val_loss: 3.4670 - val_acc: 0.1667\n",
      "\n",
      "Epoch 139/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 900us/step - loss: 1.5464 - acc: 0.5308 - val_loss: 3.4637 - val_acc: 0.1667[=================>............] - ETA: 0s - loss: 1.4202 - acc: 0.55512/584 [=========================>....] - ETA: 0s - loss: 1.5014 - acc: 0.53\n",
      "\n",
      "Epoch 140/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 938us/step - loss: 1.5367 - acc: 0.5360 - val_loss: 3.4598 - val_acc: 0.1667\n",
      "\n",
      "Epoch 141/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 964us/step - loss: 1.5272 - acc: 0.5394 - val_loss: 3.4558 - val_acc: 0.1728\n",
      "\n",
      "Epoch 142/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 838us/step - loss: 1.5180 - acc: 0.5445 - val_loss: 3.4518 - val_acc: 0.1728\n",
      "\n",
      "Epoch 143/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 856us/step - loss: 1.5084 - acc: 0.5445 - val_loss: 3.4479 - val_acc: 0.1728\n",
      "\n",
      "Epoch 144/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 856us/step - loss: 1.4991 - acc: 0.5479 - val_loss: 3.4443 - val_acc: 0.1728\n",
      "\n",
      "Epoch 145/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 910us/step - loss: 1.4900 - acc: 0.5514 - val_loss: 3.4405 - val_acc: 0.1728\n",
      "\n",
      "Epoch 146/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 952us/step - loss: 1.4809 - acc: 0.5531 - val_loss: 3.4369 - val_acc: 0.1728\n",
      "\n",
      "Epoch 147/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 884us/step - loss: 1.4720 - acc: 0.5565 - val_loss: 3.4332 - val_acc: 0.1728TA: 0s - loss: 1.4879 - acc: 0.5\n",
      "\n",
      "Epoch 148/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 878us/step - loss: 1.4631 - acc: 0.5616 - val_loss: 3.4302 - val_acc: 0.1728TA: 0s - loss: 1.4507 - acc: 0.562\n",
      "\n",
      "Epoch 149/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 866us/step - loss: 1.4542 - acc: 0.5702 - val_loss: 3.4265 - val_acc: 0.1728\n",
      "\n",
      "Epoch 150/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 902us/step - loss: 1.4453 - acc: 0.5719 - val_loss: 3.4228 - val_acc: 0.1728TA: 0s - loss: 1.4441 - acc: 0.571\n",
      "\n",
      "Epoch 151/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 937us/step - loss: 1.4366 - acc: 0.5753 - val_loss: 3.4196 - val_acc: 0.1728\n",
      "\n",
      "Epoch 152/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 863us/step - loss: 1.4277 - acc: 0.5753 - val_loss: 3.4163 - val_acc: 0.1728\n",
      "\n",
      "Epoch 153/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 854us/step - loss: 1.4189 - acc: 0.5771 - val_loss: 3.4125 - val_acc: 0.1728\n",
      "\n",
      "Epoch 154/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 886us/step - loss: 1.4103 - acc: 0.5788 - val_loss: 3.4093 - val_acc: 0.1728\n",
      "\n",
      "Epoch 155/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 1ms/step - loss: 1.4017 - acc: 0.5822 - val_loss: 3.4063 - val_acc: 0.1728\n",
      "\n",
      "Epoch 156/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 884us/step - loss: 1.3933 - acc: 0.5873 - val_loss: 3.4032 - val_acc: 0.1728\n",
      "\n",
      "Epoch 157/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 909us/step - loss: 1.3850 - acc: 0.5890 - val_loss: 3.3998 - val_acc: 0.1728TA: 0s - loss: 1.3857 - acc: 0.586\n",
      "\n",
      "Epoch 158/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 882us/step - loss: 1.3767 - acc: 0.5908 - val_loss: 3.3966 - val_acc: 0.1728TA: 0s - loss: 1.4298 - acc: 0.5\n",
      "\n",
      "Epoch 159/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 883us/step - loss: 1.3687 - acc: 0.5908 - val_loss: 3.3936 - val_acc: 0.1728TA: 0s - loss: 1.5603 - acc:\n",
      "\n",
      "Epoch 160/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 944us/step - loss: 1.3605 - acc: 0.5908 - val_loss: 3.3906 - val_acc: 0.1728\n",
      "\n",
      "Epoch 161/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 855us/step - loss: 1.3527 - acc: 0.5942 - val_loss: 3.3877 - val_acc: 0.1728\n",
      "\n",
      "Epoch 162/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 970us/step - loss: 1.3444 - acc: 0.5942 - val_loss: 3.3847 - val_acc: 0.1728\n",
      "\n",
      "Epoch 163/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 914us/step - loss: 1.3364 - acc: 0.5942 - val_loss: 3.3817 - val_acc: 0.1728\n",
      "\n",
      "Epoch 164/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 829us/step - loss: 1.3286 - acc: 0.5976 - val_loss: 3.3792 - val_acc: 0.1728\n",
      "\n",
      "Epoch 165/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 939us/step - loss: 1.3207 - acc: 0.6010 - val_loss: 3.3766 - val_acc: 0.1728\n",
      "\n",
      "Epoch 166/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 923us/step - loss: 1.3131 - acc: 0.6010 - val_loss: 3.3739 - val_acc: 0.1728\n",
      "\n",
      "Epoch 167/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 907us/step - loss: 1.3054 - acc: 0.6027 - val_loss: 3.3711 - val_acc: 0.1728\n",
      "\n",
      "Epoch 168/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 956us/step - loss: 1.2979 - acc: 0.6062 - val_loss: 3.3688 - val_acc: 0.1728TA: 0s - loss: 1.4346 - acc: 544/584 [==========================>...] - ETA: 0s - loss: 1.2889 - acc: 0.614\n",
      "\n",
      "Epoch 169/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 955us/step - loss: 1.2904 - acc: 0.6079 - val_loss: 3.3661 - val_acc: 0.1728\n",
      "\n",
      "Epoch 170/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 961us/step - loss: 1.2829 - acc: 0.6079 - val_loss: 3.3637 - val_acc: 0.1728========================>....] - ETA: 0s - loss: 1.2623 - acc: 0.61\n",
      "\n",
      "Epoch 171/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 858us/step - loss: 1.2754 - acc: 0.6079 - val_loss: 3.3614 - val_acc: 0.1728TA: 0s - loss: 1.2774 - acc: 0.60\n",
      "\n",
      "Epoch 172/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 977us/step - loss: 1.2681 - acc: 0.6079 - val_loss: 3.3589 - val_acc: 0.1728\n",
      "\n",
      "Epoch 173/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 855us/step - loss: 1.2609 - acc: 0.6096 - val_loss: 3.3560 - val_acc: 0.1728\n",
      "\n",
      "Epoch 174/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 855us/step - loss: 1.2536 - acc: 0.6113 - val_loss: 3.3540 - val_acc: 0.1728\n",
      "\n",
      "Epoch 175/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 828us/step - loss: 1.2466 - acc: 0.6130 - val_loss: 3.3515 - val_acc: 0.1728TA: 0s - loss: 1.1747 - acc: 0.\n",
      "\n",
      "Epoch 176/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 888us/step - loss: 1.2395 - acc: 0.6147 - val_loss: 3.3485 - val_acc: 0.1728\n",
      "\n",
      "Epoch 177/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 825us/step - loss: 1.2325 - acc: 0.6199 - val_loss: 3.3461 - val_acc: 0.1728\n",
      "\n",
      "Epoch 178/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 946us/step - loss: 1.2255 - acc: 0.6216 - val_loss: 3.3434 - val_acc: 0.1728\n",
      "\n",
      "Epoch 179/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 892us/step - loss: 1.2186 - acc: 0.6233 - val_loss: 3.3413 - val_acc: 0.1728\n",
      "\n",
      "Epoch 180/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 936us/step - loss: 1.2117 - acc: 0.6250 - val_loss: 3.3387 - val_acc: 0.1728TA: 0s - loss: 1.1753 - acc: 0.6\n",
      "\n",
      "Epoch 181/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 812us/step - loss: 1.2050 - acc: 0.6301 - val_loss: 3.3357 - val_acc: 0.1728\n",
      "\n",
      "Epoch 182/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 853us/step - loss: 1.1983 - acc: 0.6353 - val_loss: 3.3330 - val_acc: 0.1728\n",
      "\n",
      "Epoch 183/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 936us/step - loss: 1.1916 - acc: 0.6404 - val_loss: 3.3303 - val_acc: 0.1728TA: 0s - loss: 1.1754 - acc: 0.64\n",
      "\n",
      "Epoch 184/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 893us/step - loss: 1.1852 - acc: 0.6438 - val_loss: 3.3281 - val_acc: 0.1728\n",
      "\n",
      "Epoch 185/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 853us/step - loss: 1.1786 - acc: 0.6507 - val_loss: 3.3254 - val_acc: 0.1728\n",
      "\n",
      "Epoch 186/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 1ms/step - loss: 1.1720 - acc: 0.6524 - val_loss: 3.3235 - val_acc: 0.1728\n",
      "\n",
      "Epoch 187/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 928us/step - loss: 1.1657 - acc: 0.6558 - val_loss: 3.3208 - val_acc: 0.1728\n",
      "\n",
      "Epoch 188/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 843us/step - loss: 1.1593 - acc: 0.6575 - val_loss: 3.3186 - val_acc: 0.1728\n",
      "\n",
      "Epoch 189/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 854us/step - loss: 1.1530 - acc: 0.6610 - val_loss: 3.3164 - val_acc: 0.1790 [=======================>......] - ETA: 0s - loss: 1.1637 - acc: 0.66\n",
      "\n",
      "Epoch 190/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 913us/step - loss: 1.1465 - acc: 0.6610 - val_loss: 3.3143 - val_acc: 0.1728\n",
      "\n",
      "Epoch 191/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 950us/step - loss: 1.1404 - acc: 0.6610 - val_loss: 3.3120 - val_acc: 0.1728TA: 0s - loss: 1.1945 - acc: 0.\n",
      "\n",
      "Epoch 192/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 929us/step - loss: 1.1343 - acc: 0.6627 - val_loss: 3.3096 - val_acc: 0.1728\n",
      "\n",
      "Epoch 193/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 1ms/step - loss: 1.1281 - acc: 0.6627 - val_loss: 3.3071 - val_acc: 0.1728\n",
      "\n",
      "Epoch 194/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 1ms/step - loss: 1.1221 - acc: 0.6644 - val_loss: 3.3050 - val_acc: 0.1728\n",
      "\n",
      "Epoch 195/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 972us/step - loss: 1.1163 - acc: 0.6661 - val_loss: 3.3031 - val_acc: 0.1790\n",
      "\n",
      "Epoch 196/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 938us/step - loss: 1.1103 - acc: 0.6678 - val_loss: 3.3007 - val_acc: 0.1790\n",
      "\n",
      "Epoch 197/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 886us/step - loss: 1.1045 - acc: 0.6729 - val_loss: 3.2983 - val_acc: 0.1790TA: 0s - loss: 1.0001 - acc: \n",
      "\n",
      "Epoch 198/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584/584 [==============================]584/584 [==============================] - 1s 857us/step - loss: 1.0987 - acc: 0.6747 - val_loss: 3.2962 - val_acc: 0.1790\n",
      "\n",
      "Epoch 199/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 861us/step - loss: 1.0930 - acc: 0.6781 - val_loss: 3.2944 - val_acc: 0.1790TA: 0s - loss: 1.0732 - acc: 0.\n",
      "\n",
      "Epoch 200/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 853us/step - loss: 1.0873 - acc: 0.6781 - val_loss: 3.2924 - val_acc: 0.1790\n",
      "\n",
      "64/64 [==============================]64/64 [==============================] - 0s 305us/step\n",
      "\n",
      "Train on 584 samples, validate on 162 samples\n",
      "Epoch 1/200\n",
      "584/584 [==============================]584/584 [==============================] - 4s 7ms/step - loss: 5.0085 - acc: 0.0908 - val_loss: 5.2474 - val_acc: 0.0802\n",
      "\n",
      "Epoch 2/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 1ms/step - loss: 4.9274 - acc: 0.0925 - val_loss: 5.2111 - val_acc: 0.0802\n",
      "\n",
      "Epoch 3/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 980us/step - loss: 4.8486 - acc: 0.0942 - val_loss: 5.1723 - val_acc: 0.0802\n",
      "\n",
      "Epoch 4/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 895us/step - loss: 4.7689 - acc: 0.0976 - val_loss: 5.1375 - val_acc: 0.0802\n",
      "\n",
      "Epoch 5/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 874us/step - loss: 4.6930 - acc: 0.1045 - val_loss: 5.1033 - val_acc: 0.0802\n",
      "\n",
      "Epoch 6/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 856us/step - loss: 4.6196 - acc: 0.1113 - val_loss: 5.0702 - val_acc: 0.0802\n",
      "\n",
      "Epoch 7/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 924us/step - loss: 4.5487 - acc: 0.1147 - val_loss: 5.0394 - val_acc: 0.0802\n",
      "\n",
      "Epoch 8/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 998us/step - loss: 4.4804 - acc: 0.1164 - val_loss: 5.0100 - val_acc: 0.0802\n",
      "\n",
      "Epoch 9/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 918us/step - loss: 4.4134 - acc: 0.1250 - val_loss: 4.9813 - val_acc: 0.0802\n",
      "\n",
      "Epoch 10/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 992us/step - loss: 4.3500 - acc: 0.1267 - val_loss: 4.9547 - val_acc: 0.0741\n",
      "\n",
      "Epoch 11/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 917us/step - loss: 4.2871 - acc: 0.1284 - val_loss: 4.9278 - val_acc: 0.0741\n",
      "\n",
      "Epoch 12/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 912us/step - loss: 4.2250 - acc: 0.1318 - val_loss: 4.9024 - val_acc: 0.0741\n",
      "\n",
      "Epoch 13/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 889us/step - loss: 4.1658 - acc: 0.1370 - val_loss: 4.8765 - val_acc: 0.0802\n",
      "\n",
      "Epoch 14/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 922us/step - loss: 4.1062 - acc: 0.1387 - val_loss: 4.8510 - val_acc: 0.0802\n",
      "\n",
      "Epoch 15/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 955us/step - loss: 4.0485 - acc: 0.1404 - val_loss: 4.8264 - val_acc: 0.0802\n",
      "\n",
      "Epoch 16/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 971us/step - loss: 3.9926 - acc: 0.1438 - val_loss: 4.8019 - val_acc: 0.0802\n",
      "\n",
      "Epoch 17/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 944us/step - loss: 3.9378 - acc: 0.1455 - val_loss: 4.7787 - val_acc: 0.0864\n",
      "\n",
      "Epoch 18/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 914us/step - loss: 3.8845 - acc: 0.1473 - val_loss: 4.7553 - val_acc: 0.0926: 0s - loss: 3.8891 - acc: 0.145\n",
      "\n",
      "Epoch 19/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 939us/step - loss: 3.8311 - acc: 0.1473 - val_loss: 4.7341 - val_acc: 0.0988\n",
      "\n",
      "Epoch 20/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 970us/step - loss: 3.7806 - acc: 0.1507 - val_loss: 4.7133 - val_acc: 0.0988\n",
      "\n",
      "Epoch 21/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 913us/step - loss: 3.7307 - acc: 0.1592 - val_loss: 4.6935 - val_acc: 0.1049\n",
      "\n",
      "Epoch 22/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 888us/step - loss: 3.6826 - acc: 0.1627 - val_loss: 4.6743 - val_acc: 0.1049\n",
      "\n",
      "Epoch 23/200\n",
      "584/584 [==============================]584/584 [==============================] - ETA: 0s - loss: 3.6453 - acc: 0.163 - 1s 919us/step - loss: 3.6352 - acc: 0.1695 - val_loss: 4.6562 - val_acc: 0.1049\n",
      "\n",
      "Epoch 24/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 933us/step - loss: 3.5889 - acc: 0.1712 - val_loss: 4.6377 - val_acc: 0.1049\n",
      "\n",
      "Epoch 25/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 854us/step - loss: 3.5432 - acc: 0.1712 - val_loss: 4.6183 - val_acc: 0.1049\n",
      "\n",
      "Epoch 26/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 962us/step - loss: 3.4986 - acc: 0.1729 - val_loss: 4.6004 - val_acc: 0.1111\n",
      "\n",
      "Epoch 27/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 832us/step - loss: 3.4558 - acc: 0.1764 - val_loss: 4.5824 - val_acc: 0.1111\n",
      "\n",
      "Epoch 28/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 893us/step - loss: 3.4141 - acc: 0.1764 - val_loss: 4.5640 - val_acc: 0.1111\n",
      "\n",
      "Epoch 29/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 848us/step - loss: 3.3730 - acc: 0.1781 - val_loss: 4.5481 - val_acc: 0.1111\n",
      "\n",
      "Epoch 30/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 832us/step - loss: 3.3332 - acc: 0.1815 - val_loss: 4.5317 - val_acc: 0.1111TA: 0s - loss: 3.3715 - acc: 0.17\n",
      "\n",
      "Epoch 31/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 885us/step - loss: 3.2932 - acc: 0.1866 - val_loss: 4.5165 - val_acc: 0.1111\n",
      "\n",
      "Epoch 32/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 967us/step - loss: 3.2550 - acc: 0.1935 - val_loss: 4.5005 - val_acc: 0.1111\n",
      "\n",
      "Epoch 33/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 805us/step - loss: 3.2162 - acc: 0.1952 - val_loss: 4.4857 - val_acc: 0.1173\n",
      "\n",
      "Epoch 34/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 910us/step - loss: 3.1795 - acc: 0.2003 - val_loss: 4.4700 - val_acc: 0.1235\n",
      "\n",
      "Epoch 35/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 1ms/step - loss: 3.1429 - acc: 0.2089 - val_loss: 4.4547 - val_acc: 0.1235\n",
      "\n",
      "Epoch 36/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 992us/step - loss: 3.1072 - acc: 0.2158 - val_loss: 4.4385 - val_acc: 0.1235\n",
      "\n",
      "Epoch 37/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 918us/step - loss: 3.0723 - acc: 0.2192 - val_loss: 4.4233 - val_acc: 0.1235\n",
      "\n",
      "Epoch 38/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 882us/step - loss: 3.0382 - acc: 0.2209 - val_loss: 4.4081 - val_acc: 0.1235\n",
      "\n",
      "Epoch 39/200\n",
      "584/584 [==============================]576/584 [============================>.] - ETA: 0s - loss: 3.0259 - acc: 0.225584/584 [==============================] - 1s 937us/step - loss: 3.0044 - acc: 0.2277 - val_loss: 4.3939 - val_acc: 0.1173\n",
      "\n",
      "Epoch 40/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 917us/step - loss: 2.9720 - acc: 0.2329 - val_loss: 4.3795 - val_acc: 0.1235TA: 0s - loss: 3.0535 - acc: 0.2\n",
      "\n",
      "Epoch 41/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 851us/step - loss: 2.9395 - acc: 0.2329 - val_loss: 4.3658 - val_acc: 0.1235\n",
      "\n",
      "Epoch 42/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 830us/step - loss: 2.9074 - acc: 0.2397 - val_loss: 4.3522 - val_acc: 0.1235\n",
      "\n",
      "Epoch 43/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 861us/step - loss: 2.8761 - acc: 0.2414 - val_loss: 4.3382 - val_acc: 0.1235TA: 0s - loss: 2.6433 - acc: 0.27256/584 [============>.................] - ETA: 0s - loss: 2.8871 - acc: 0\n",
      "\n",
      "Epoch 44/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 855us/step - loss: 2.8448 - acc: 0.2466 - val_loss: 4.3246 - val_acc: 0.1235\n",
      "\n",
      "Epoch 45/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 854us/step - loss: 2.8146 - acc: 0.2483 - val_loss: 4.3120 - val_acc: 0.1235\n",
      "\n",
      "Epoch 46/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 887us/step - loss: 2.7843 - acc: 0.2500 - val_loss: 4.3001 - val_acc: 0.1235\n",
      "\n",
      "Epoch 47/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 827us/step - loss: 2.7553 - acc: 0.2500 - val_loss: 4.2871 - val_acc: 0.1235\n",
      "\n",
      "Epoch 48/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 911us/step - loss: 2.7258 - acc: 0.2551 - val_loss: 4.2740 - val_acc: 0.1235TA: 0s - loss: 2.7196 - acc: 0.252\n",
      "\n",
      "Epoch 49/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 860us/step - loss: 2.6969 - acc: 0.2637 - val_loss: 4.2599 - val_acc: 0.1235\n",
      "\n",
      "Epoch 50/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 798us/step - loss: 2.6683 - acc: 0.2757 - val_loss: 4.2481 - val_acc: 0.1235\n",
      "\n",
      "Epoch 51/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 792us/step - loss: 2.6401 - acc: 0.2791 - val_loss: 4.2346 - val_acc: 0.1235\n",
      "\n",
      "Epoch 52/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 1ms/step - loss: 2.6130 - acc: 0.2825 - val_loss: 4.2216 - val_acc: 0.1235 ETA: 0s - loss: 2.6293 - acc: 0. - ETA: 0s - loss: 2.6080 - acc: 0.\n",
      "\n",
      "Epoch 53/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 891us/step - loss: 2.5860 - acc: 0.2894 - val_loss: 4.2098 - val_acc: 0.1235\n",
      "\n",
      "Epoch 54/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 825us/step - loss: 2.5596 - acc: 0.2979 - val_loss: 4.1972 - val_acc: 0.1235\n",
      "\n",
      "Epoch 55/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 918us/step - loss: 2.5335 - acc: 0.3014 - val_loss: 4.1862 - val_acc: 0.1235\n",
      "\n",
      "Epoch 56/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 883us/step - loss: 2.5081 - acc: 0.3116 - val_loss: 4.1755 - val_acc: 0.1235\n",
      "\n",
      "Epoch 57/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 885us/step - loss: 2.4832 - acc: 0.3168 - val_loss: 4.1633 - val_acc: 0.1235TA: 0s - loss: 2.4557 - acc: 0.324480/584 [=======================>......] - ETA: 0s - loss: 2.4745 - acc: 0.31\n",
      "\n",
      "Epoch 58/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 914us/step - loss: 2.4582 - acc: 0.3185 - val_loss: 4.1520 - val_acc: 0.1296\n",
      "\n",
      "Epoch 59/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 896us/step - loss: 2.4336 - acc: 0.3236 - val_loss: 4.1418 - val_acc: 0.1296\n",
      "\n",
      "Epoch 60/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 957us/step - loss: 2.4094 - acc: 0.3253 - val_loss: 4.1324 - val_acc: 0.1296\n",
      "\n",
      "Epoch 61/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 969us/step - loss: 2.3860 - acc: 0.3322 - val_loss: 4.1226 - val_acc: 0.1296\n",
      "\n",
      "Epoch 62/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 882us/step - loss: 2.3633 - acc: 0.3408 - val_loss: 4.1123 - val_acc: 0.1358\n",
      "\n",
      "Epoch 63/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 829us/step - loss: 2.3408 - acc: 0.3442 - val_loss: 4.1030 - val_acc: 0.1420\n",
      "\n",
      "Epoch 64/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 935us/step - loss: 2.3182 - acc: 0.3493 - val_loss: 4.0933 - val_acc: 0.1420TA: 0s - loss: 2.2099 - acc: 0.3\n",
      "\n",
      "Epoch 65/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 978us/step - loss: 2.2961 - acc: 0.3527 - val_loss: 4.0842 - val_acc: 0.1420\n",
      "\n",
      "Epoch 66/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 925us/step - loss: 2.2743 - acc: 0.3562 - val_loss: 4.0757 - val_acc: 0.1420\n",
      "\n",
      "Epoch 67/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 902us/step - loss: 2.2533 - acc: 0.3647 - val_loss: 4.0668 - val_acc: 0.1420\n",
      "\n",
      "Epoch 68/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 840us/step - loss: 2.2329 - acc: 0.3664 - val_loss: 4.0581 - val_acc: 0.1420\n",
      "\n",
      "Epoch 69/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 785us/step - loss: 2.2125 - acc: 0.3682 - val_loss: 4.0490 - val_acc: 0.1420\n",
      "\n",
      "Epoch 70/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 852us/step - loss: 2.1922 - acc: 0.3716 - val_loss: 4.0417 - val_acc: 0.1420\n",
      "\n",
      "Epoch 71/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 861us/step - loss: 2.1730 - acc: 0.3750 - val_loss: 4.0336 - val_acc: 0.1420TA: 0s - loss: 2.1968 - acc: 0.3\n",
      "\n",
      "Epoch 72/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 850us/step - loss: 2.1536 - acc: 0.3784 - val_loss: 4.0264 - val_acc: 0.1420\n",
      "\n",
      "Epoch 73/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 916us/step - loss: 2.1348 - acc: 0.3853 - val_loss: 4.0172 - val_acc: 0.1420\n",
      "\n",
      "Epoch 74/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 913us/step - loss: 2.1158 - acc: 0.3887 - val_loss: 4.0101 - val_acc: 0.1420TA: 0s - loss: 2.0067 - acc:\n",
      "\n",
      "Epoch 75/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 943us/step - loss: 2.0974 - acc: 0.3904 - val_loss: 4.0021 - val_acc: 0.1420\n",
      "\n",
      "Epoch 76/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 973us/step - loss: 2.0796 - acc: 0.3938 - val_loss: 3.9946 - val_acc: 0.1420TA: 0s - loss: 2.1807 - acc:\n",
      "\n",
      "Epoch 77/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 941us/step - loss: 2.0616 - acc: 0.3990 - val_loss: 3.9874 - val_acc: 0.1420\n",
      "\n",
      "Epoch 78/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 798us/step - loss: 2.0439 - acc: 0.4058 - val_loss: 3.9807 - val_acc: 0.1420TA: 0s - loss: 2.0484 - acc: 0.408\n",
      "\n",
      "Epoch 79/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 853us/step - loss: 2.0265 - acc: 0.4110 - val_loss: 3.9738 - val_acc: 0.1420\n",
      "\n",
      "Epoch 80/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 852us/step - loss: 2.0097 - acc: 0.4195 - val_loss: 3.9673 - val_acc: 0.1420TA: 0s - loss: 1.9863 - acc: 0.42\n",
      "\n",
      "Epoch 81/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 833us/step - loss: 1.9933 - acc: 0.4212 - val_loss: 3.9609 - val_acc: 0.1420TA: 0s - loss: 1.8437 - acc:\n",
      "\n",
      "Epoch 82/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 845us/step - loss: 1.9770 - acc: 0.4247 - val_loss: 3.9553 - val_acc: 0.1420TA: 0s - loss: 1.9842 - acc: 0.42\n",
      "\n",
      "Epoch 83/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 951us/step - loss: 1.9613 - acc: 0.4298 - val_loss: 3.9491 - val_acc: 0.1420\n",
      "\n",
      "Epoch 84/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 1ms/step - loss: 1.9458 - acc: 0.4298 - val_loss: 3.9435 - val_acc: 0.1420\n",
      "\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584/584 [==============================]584/584 [==============================] - 0s 824us/step - loss: 1.9304 - acc: 0.4349 - val_loss: 3.9380 - val_acc: 0.1420\n",
      "\n",
      "Epoch 86/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 911us/step - loss: 1.9152 - acc: 0.4366 - val_loss: 3.9323 - val_acc: 0.1420TA: 0s - loss: 1.9144 - acc: 0.43\n",
      "\n",
      "Epoch 87/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 869us/step - loss: 1.8999 - acc: 0.4384 - val_loss: 3.9267 - val_acc: 0.1420\n",
      "\n",
      "Epoch 88/200\n",
      "584/584 [==============================]584/584 [==============================] - ETA: 0s - loss: 1.8676 - acc: 0.442 - 1s 859us/step - loss: 1.8850 - acc: 0.4401 - val_loss: 3.9205 - val_acc: 0.1420\n",
      "\n",
      "Epoch 89/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 905us/step - loss: 1.8700 - acc: 0.4469 - val_loss: 3.9137 - val_acc: 0.1420\n",
      "\n",
      "Epoch 90/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 810us/step - loss: 1.8552 - acc: 0.4486 - val_loss: 3.9075 - val_acc: 0.1420TA: 0s - loss: 1.8252 - acc: 0.44\n",
      "\n",
      "Epoch 91/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 911us/step - loss: 1.8409 - acc: 0.4486 - val_loss: 3.9027 - val_acc: 0.1420\n",
      "\n",
      "Epoch 92/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 874us/step - loss: 1.8268 - acc: 0.4538 - val_loss: 3.8966 - val_acc: 0.1420\n",
      "\n",
      "Epoch 93/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 817us/step - loss: 1.8130 - acc: 0.4555 - val_loss: 3.8909 - val_acc: 0.1420\n",
      "\n",
      "Epoch 94/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 834us/step - loss: 1.7991 - acc: 0.4572 - val_loss: 3.8848 - val_acc: 0.1420\n",
      "\n",
      "Epoch 95/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 857us/step - loss: 1.7854 - acc: 0.4623 - val_loss: 3.8793 - val_acc: 0.1420\n",
      "\n",
      "Epoch 96/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 1ms/step - loss: 1.7719 - acc: 0.4623 - val_loss: 3.8742 - val_acc: 0.1420 ETA: 0s - loss: 1.7709 - acc: 0.\n",
      "\n",
      "Epoch 97/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 885us/step - loss: 1.7590 - acc: 0.4640 - val_loss: 3.8690 - val_acc: 0.1420\n",
      "\n",
      "Epoch 98/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 938us/step - loss: 1.7460 - acc: 0.4658 - val_loss: 3.8636 - val_acc: 0.1420\n",
      "\n",
      "Epoch 99/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 856us/step - loss: 1.7333 - acc: 0.4692 - val_loss: 3.8586 - val_acc: 0.1420TA: 0s - loss: 1.7214 - acc: 0.48\n",
      "\n",
      "Epoch 100/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 953us/step - loss: 1.7204 - acc: 0.4743 - val_loss: 3.8538 - val_acc: 0.1420\n",
      "\n",
      "Epoch 101/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 907us/step - loss: 1.7081 - acc: 0.4812 - val_loss: 3.8485 - val_acc: 0.1420\n",
      "\n",
      "Epoch 102/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 827us/step - loss: 1.6957 - acc: 0.4846 - val_loss: 3.8429 - val_acc: 0.1420TA: 0s - loss: 1.7276 - acc: 0.4\n",
      "\n",
      "Epoch 103/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 939us/step - loss: 1.6831 - acc: 0.4880 - val_loss: 3.8378 - val_acc: 0.1420\n",
      "\n",
      "Epoch 104/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 857us/step - loss: 1.6709 - acc: 0.4897 - val_loss: 3.8326 - val_acc: 0.1420\n",
      "\n",
      "Epoch 105/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 859us/step - loss: 1.6587 - acc: 0.4914 - val_loss: 3.8278 - val_acc: 0.1420TA: 0s - loss: 1.5984 - acc: 0\n",
      "\n",
      "Epoch 106/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 880us/step - loss: 1.6467 - acc: 0.4949 - val_loss: 3.8234 - val_acc: 0.1481\n",
      "\n",
      "Epoch 107/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 889us/step - loss: 1.6350 - acc: 0.4966 - val_loss: 3.8180 - val_acc: 0.1481\n",
      "\n",
      "Epoch 108/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 912us/step - loss: 1.6235 - acc: 0.5000 - val_loss: 3.8131 - val_acc: 0.1481TA: 0s - loss: 1.6177 - acc: 0\n",
      "\n",
      "Epoch 109/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 855us/step - loss: 1.6118 - acc: 0.5051 - val_loss: 3.8088 - val_acc: 0.1481\n",
      "\n",
      "Epoch 110/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 807us/step - loss: 1.6006 - acc: 0.5103 - val_loss: 3.8052 - val_acc: 0.1481\n",
      "\n",
      "Epoch 111/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 885us/step - loss: 1.5896 - acc: 0.5154 - val_loss: 3.8010 - val_acc: 0.1481\n",
      "\n",
      "Epoch 112/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 804us/step - loss: 1.5789 - acc: 0.5171 - val_loss: 3.7966 - val_acc: 0.1481\n",
      "\n",
      "Epoch 113/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 902us/step - loss: 1.5681 - acc: 0.5188 - val_loss: 3.7924 - val_acc: 0.1481\n",
      "\n",
      "Epoch 114/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 897us/step - loss: 1.5573 - acc: 0.5205 - val_loss: 3.7878 - val_acc: 0.1481\n",
      "\n",
      "Epoch 115/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 869us/step - loss: 1.5468 - acc: 0.5274 - val_loss: 3.7830 - val_acc: 0.1481\n",
      "\n",
      "Epoch 116/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 1ms/step - loss: 1.5362 - acc: 0.5274 - val_loss: 3.7788 - val_acc: 0.1481\n",
      "\n",
      "Epoch 117/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 824us/step - loss: 1.5260 - acc: 0.5308 - val_loss: 3.7747 - val_acc: 0.1481\n",
      "\n",
      "Epoch 118/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 888us/step - loss: 1.5160 - acc: 0.5360 - val_loss: 3.7700 - val_acc: 0.1481\n",
      "\n",
      "Epoch 119/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 1000us/step - loss: 1.5060 - acc: 0.5428 - val_loss: 3.7657 - val_acc: 0.1481\n",
      "\n",
      "Epoch 120/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 919us/step - loss: 1.4961 - acc: 0.5445 - val_loss: 3.7612 - val_acc: 0.1481: 0s - loss: 1.4676 - acc: 0.54576/584 [============================>.] - ETA: 0s - loss: 1.5068 - acc: 0.541\n",
      "\n",
      "Epoch 121/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 851us/step - loss: 1.4864 - acc: 0.5479 - val_loss: 3.7567 - val_acc: 0.1481\n",
      "\n",
      "Epoch 122/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 917us/step - loss: 1.4764 - acc: 0.5479 - val_loss: 3.7527 - val_acc: 0.1481\n",
      "\n",
      "Epoch 123/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 967us/step - loss: 1.4670 - acc: 0.5497 - val_loss: 3.7487 - val_acc: 0.1481\n",
      "\n",
      "Epoch 124/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 856us/step - loss: 1.4574 - acc: 0.5514 - val_loss: 3.7451 - val_acc: 0.1543\n",
      "\n",
      "Epoch 125/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 826us/step - loss: 1.4481 - acc: 0.5531 - val_loss: 3.7410 - val_acc: 0.1543TA: 0s - loss: 1.3232 - acc: 0\n",
      "\n",
      "Epoch 126/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 882us/step - loss: 1.4387 - acc: 0.5548 - val_loss: 3.7374 - val_acc: 0.1543\n",
      "\n",
      "Epoch 127/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 988us/step - loss: 1.4296 - acc: 0.5599 - val_loss: 3.7332 - val_acc: 0.1543\n",
      "\n",
      "Epoch 128/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 896us/step - loss: 1.4207 - acc: 0.5616 - val_loss: 3.7296 - val_acc: 0.1543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 129/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 859us/step - loss: 1.4118 - acc: 0.5616 - val_loss: 3.7263 - val_acc: 0.1543\n",
      "\n",
      "Epoch 130/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 940us/step - loss: 1.4029 - acc: 0.5668 - val_loss: 3.7227 - val_acc: 0.1543\n",
      "\n",
      "Epoch 131/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 889us/step - loss: 1.3942 - acc: 0.5719 - val_loss: 3.7192 - val_acc: 0.1543\n",
      "\n",
      "Epoch 132/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 912us/step - loss: 1.3857 - acc: 0.5753 - val_loss: 3.7159 - val_acc: 0.1543\n",
      "\n",
      "Epoch 133/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 889us/step - loss: 1.3771 - acc: 0.5771 - val_loss: 3.7122 - val_acc: 0.1543\n",
      "\n",
      "Epoch 134/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 797us/step - loss: 1.3688 - acc: 0.5788 - val_loss: 3.7085 - val_acc: 0.1543\n",
      "\n",
      "Epoch 135/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 909us/step - loss: 1.3603 - acc: 0.5788 - val_loss: 3.7045 - val_acc: 0.1605\n",
      "\n",
      "Epoch 136/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 870us/step - loss: 1.3520 - acc: 0.5805 - val_loss: 3.7013 - val_acc: 0.1605\n",
      "\n",
      "Epoch 137/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 932us/step - loss: 1.3438 - acc: 0.5873 - val_loss: 3.6972 - val_acc: 0.1605TA: 0s - loss: 1.3482 - acc: 0.58\n",
      "\n",
      "Epoch 138/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 885us/step - loss: 1.3357 - acc: 0.5908 - val_loss: 3.6932 - val_acc: 0.1605TA: 0s - loss: 1.3614 - acc: 0\n",
      "\n",
      "Epoch 139/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 959us/step - loss: 1.3275 - acc: 0.5942 - val_loss: 3.6892 - val_acc: 0.1605\n",
      "\n",
      "Epoch 140/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 896us/step - loss: 1.3195 - acc: 0.6027 - val_loss: 3.6861 - val_acc: 0.1605\n",
      "\n",
      "Epoch 141/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 878us/step - loss: 1.3116 - acc: 0.6045 - val_loss: 3.6826 - val_acc: 0.1667\n",
      "\n",
      "Epoch 142/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 973us/step - loss: 1.3037 - acc: 0.6113 - val_loss: 3.6795 - val_acc: 0.1667\n",
      "\n",
      "Epoch 143/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 1ms/step - loss: 1.2960 - acc: 0.6164 - val_loss: 3.6751 - val_acc: 0.1667\n",
      "\n",
      "Epoch 144/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 909us/step - loss: 1.2882 - acc: 0.6164 - val_loss: 3.6715 - val_acc: 0.1667\n",
      "\n",
      "Epoch 145/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 916us/step - loss: 1.2805 - acc: 0.6164 - val_loss: 3.6682 - val_acc: 0.1667\n",
      "\n",
      "Epoch 146/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 909us/step - loss: 1.2731 - acc: 0.6182 - val_loss: 3.6645 - val_acc: 0.1667TA: 0s - loss: 1.3276 - acc: 0.6\n",
      "\n",
      "Epoch 147/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 872us/step - loss: 1.2656 - acc: 0.6164 - val_loss: 3.6614 - val_acc: 0.1605\n",
      "\n",
      "Epoch 148/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 898us/step - loss: 1.2583 - acc: 0.6182 - val_loss: 3.6579 - val_acc: 0.1605\n",
      "\n",
      "Epoch 149/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 881us/step - loss: 1.2507 - acc: 0.6216 - val_loss: 3.6543 - val_acc: 0.1605\n",
      "\n",
      "Epoch 150/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 881us/step - loss: 1.2433 - acc: 0.6233 - val_loss: 3.6509 - val_acc: 0.1605TA: 0s - loss: 1.1890 - acc: \n",
      "\n",
      "Epoch 151/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 947us/step - loss: 1.2361 - acc: 0.6318 - val_loss: 3.6473 - val_acc: 0.1605\n",
      "\n",
      "Epoch 152/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 914us/step - loss: 1.2290 - acc: 0.6370 - val_loss: 3.6440 - val_acc: 0.1605\n",
      "\n",
      "Epoch 153/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 852us/step - loss: 1.2220 - acc: 0.6387 - val_loss: 3.6407 - val_acc: 0.1605\n",
      "\n",
      "Epoch 154/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 915us/step - loss: 1.2151 - acc: 0.6404 - val_loss: 3.6373 - val_acc: 0.1605\n",
      "\n",
      "Epoch 155/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 853us/step - loss: 1.2083 - acc: 0.6404 - val_loss: 3.6341 - val_acc: 0.1605\n",
      "\n",
      "Epoch 156/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 896us/step - loss: 1.2013 - acc: 0.6421 - val_loss: 3.6312 - val_acc: 0.1605\n",
      "\n",
      "Epoch 157/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 885us/step - loss: 1.1945 - acc: 0.6455 - val_loss: 3.6282 - val_acc: 0.1605\n",
      "\n",
      "Epoch 158/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 885us/step - loss: 1.1877 - acc: 0.6507 - val_loss: 3.6246 - val_acc: 0.1605TA: 0s - loss: 1.2658 - acc: 0.62\n",
      "\n",
      "Epoch 159/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 823us/step - loss: 1.1809 - acc: 0.6524 - val_loss: 3.6215 - val_acc: 0.1605TA: 0s - loss: 1.1993 - acc: 0.64\n",
      "\n",
      "Epoch 160/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 828us/step - loss: 1.1741 - acc: 0.6558 - val_loss: 3.6187 - val_acc: 0.1605\n",
      "\n",
      "Epoch 161/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 870us/step - loss: 1.1674 - acc: 0.6592 - val_loss: 3.6154 - val_acc: 0.1605\n",
      "\n",
      "Epoch 162/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 858us/step - loss: 1.1609 - acc: 0.6592 - val_loss: 3.6126 - val_acc: 0.1605\n",
      "\n",
      "Epoch 163/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 919us/step - loss: 1.1543 - acc: 0.6592 - val_loss: 3.6099 - val_acc: 0.1605TA: 0s - loss: 1.1878 - acc: 0.65\n",
      "\n",
      "Epoch 164/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 881us/step - loss: 1.1478 - acc: 0.6661 - val_loss: 3.6069 - val_acc: 0.1605\n",
      "\n",
      "Epoch 165/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 922us/step - loss: 1.1414 - acc: 0.6695 - val_loss: 3.6040 - val_acc: 0.1605\n",
      "\n",
      "Epoch 166/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 858us/step - loss: 1.1348 - acc: 0.6729 - val_loss: 3.6007 - val_acc: 0.1605\n",
      "\n",
      "Epoch 167/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 884us/step - loss: 1.1285 - acc: 0.6729 - val_loss: 3.5977 - val_acc: 0.1605\n",
      "\n",
      "Epoch 168/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 885us/step - loss: 1.1221 - acc: 0.6729 - val_loss: 3.5946 - val_acc: 0.1605\n",
      "\n",
      "Epoch 169/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 907us/step - loss: 1.1158 - acc: 0.6764 - val_loss: 3.5914 - val_acc: 0.1605\n",
      "\n",
      "Epoch 170/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 830us/step - loss: 1.1096 - acc: 0.6764 - val_loss: 3.5884 - val_acc: 0.1605\n",
      "\n",
      "Epoch 171/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 883us/step - loss: 1.1030 - acc: 0.6764 - val_loss: 3.5860 - val_acc: 0.1605\n",
      "\n",
      "Epoch 172/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 888us/step - loss: 1.0969 - acc: 0.6781 - val_loss: 3.5833 - val_acc: 0.1605\n",
      "\n",
      "Epoch 173/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 928us/step - loss: 1.0909 - acc: 0.6781 - val_loss: 3.5804 - val_acc: 0.1543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 174/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 956us/step - loss: 1.0849 - acc: 0.6798 - val_loss: 3.5774 - val_acc: 0.1543\n",
      "\n",
      "Epoch 175/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 906us/step - loss: 1.0788 - acc: 0.6798 - val_loss: 3.5751 - val_acc: 0.1543\n",
      "\n",
      "Epoch 176/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 833us/step - loss: 1.0729 - acc: 0.6798 - val_loss: 3.5727 - val_acc: 0.1543TA: 0s - loss: 1.1074 - acc: 0.67\n",
      "\n",
      "Epoch 177/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 826us/step - loss: 1.0670 - acc: 0.6815 - val_loss: 3.5705 - val_acc: 0.1543\n",
      "\n",
      "Epoch 178/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 880us/step - loss: 1.0610 - acc: 0.6832 - val_loss: 3.5678 - val_acc: 0.1543TA: 0s - loss: 1.0448 - acc: 0.\n",
      "\n",
      "Epoch 179/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 947us/step - loss: 1.0552 - acc: 0.6849 - val_loss: 3.5658 - val_acc: 0.1543\n",
      "\n",
      "Epoch 180/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 830us/step - loss: 1.0495 - acc: 0.6849 - val_loss: 3.5630 - val_acc: 0.1605\n",
      "\n",
      "Epoch 181/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 835us/step - loss: 1.0439 - acc: 0.6849 - val_loss: 3.5603 - val_acc: 0.1543\n",
      "\n",
      "Epoch 182/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 1ms/step - loss: 1.0381 - acc: 0.6849 - val_loss: 3.5578 - val_acc: 0.1543\n",
      "\n",
      "Epoch 183/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 885us/step - loss: 1.0327 - acc: 0.6866 - val_loss: 3.5554 - val_acc: 0.1543\n",
      "\n",
      "Epoch 184/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 813us/step - loss: 1.0271 - acc: 0.6884 - val_loss: 3.5532 - val_acc: 0.1543\n",
      "\n",
      "Epoch 185/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 827us/step - loss: 1.0217 - acc: 0.6918 - val_loss: 3.5508 - val_acc: 0.1543\n",
      "\n",
      "Epoch 186/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 888us/step - loss: 1.0162 - acc: 0.6952 - val_loss: 3.5486 - val_acc: 0.1543TA: 0s - loss: 1.0676 - acc: 0.\n",
      "\n",
      "Epoch 187/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 989us/step - loss: 1.0110 - acc: 0.6969 - val_loss: 3.5467 - val_acc: 0.1543\n",
      "\n",
      "Epoch 188/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 895us/step - loss: 1.0058 - acc: 0.7003 - val_loss: 3.5444 - val_acc: 0.1543\n",
      "\n",
      "Epoch 189/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 825us/step - loss: 1.0006 - acc: 0.7055 - val_loss: 3.5420 - val_acc: 0.1543\n",
      "\n",
      "Epoch 190/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 860us/step - loss: 0.9955 - acc: 0.7106 - val_loss: 3.5400 - val_acc: 0.1543TA: 0s - loss: 1.0191 - acc:\n",
      "\n",
      "Epoch 191/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 857us/step - loss: 0.9903 - acc: 0.7123 - val_loss: 3.5380 - val_acc: 0.1543TA: 0s - loss: 1.0489 - acc: 0.6\n",
      "\n",
      "Epoch 192/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 995us/step - loss: 0.9851 - acc: 0.7140 - val_loss: 3.5356 - val_acc: 0.1543\n",
      "\n",
      "Epoch 193/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 911us/step - loss: 0.9800 - acc: 0.7140 - val_loss: 3.5339 - val_acc: 0.1543\n",
      "\n",
      "Epoch 194/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 905us/step - loss: 0.9748 - acc: 0.7140 - val_loss: 3.5322 - val_acc: 0.1543\n",
      "\n",
      "Epoch 195/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 923us/step - loss: 0.9697 - acc: 0.7158 - val_loss: 3.5304 - val_acc: 0.1543\n",
      "\n",
      "Epoch 196/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 995us/step - loss: 0.9648 - acc: 0.7209 - val_loss: 3.5282 - val_acc: 0.1543 - loss: 0.9566 - acc: 0.72\n",
      "\n",
      "Epoch 197/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 888us/step - loss: 0.9597 - acc: 0.7209 - val_loss: 3.5266 - val_acc: 0.1543\n",
      "\n",
      "Epoch 198/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 943us/step - loss: 0.9549 - acc: 0.7209 - val_loss: 3.5246 - val_acc: 0.1543\n",
      "\n",
      "Epoch 199/200\n",
      "584/584 [==============================]584/584 [==============================] - 0s 798us/step - loss: 0.9501 - acc: 0.7209 - val_loss: 3.5227 - val_acc: 0.1543TA: 0s - loss: 0.9621 - acc: 0.71\n",
      "\n",
      "Epoch 200/200\n",
      "584/584 [==============================]584/584 [==============================] - 1s 951us/step - loss: 0.9453 - acc: 0.7243 - val_loss: 3.5208 - val_acc: 0.1543TA: 0s - loss: 0.9997 - acc: 0.6\n",
      "\n",
      "64/64 [==============================]64/64 [==============================] - 0s 546us/step\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras._impl.keras.wrappers.scikit_learn.KerasRegressor object at 0x0000025D4FE9E4A8>, as the constructor either does not set or modifies parameter inputs_size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-151-99579d88c203>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mearly_stop_cb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrnd_search_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstd_inputs_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstd_inputs_te\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets_te\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mearly_stop_cb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;31m# of the params are estimators as well.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[1;32m--> 762\u001b[1;33m                 **self.best_params_))\n\u001b[0m\u001b[0;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     96\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0;32m     97\u001b[0m                                \u001b[1;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m                                (estimator, name))\n\u001b[0m\u001b[0;32m     99\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras._impl.keras.wrappers.scikit_learn.KerasRegressor object at 0x0000025D4FE9E4A8>, as the constructor either does not set or modifies parameter inputs_size"
     ]
    }
   ],
   "source": [
    "early_stop_cb = tf.keras.callbacks.EarlyStopping(patience = 10)\n",
    "rnd_search_cv.fit(std_inputs_tr, targets_tr, validation_data = (std_inputs_te, targets_te), epochs = 200, callbacks = [early_stop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outputs_size': 9,\n",
       " 'n_neurons': 100,\n",
       " 'n_layers': 20,\n",
       " 'lr': 0.0001,\n",
       " 'kernel_init': 'he_normal',\n",
       " 'inputs_size': [178],\n",
       " 'active_function': 'relu'}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
